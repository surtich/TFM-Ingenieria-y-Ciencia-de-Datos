## Comparación de test1 y test2 entre grupos

```{r, echo=FALSE, include=FALSE}
# Leemos el tibble preprocesado
test_df <- read_csv("./data/preprocess/test_clean.csv", show_col_types = FALSE)

# Lo transformamos en formato largo
test_lg_df <- test_df %>% pivot_longer(cols = all_of(starts_with("Q")), names_to = "Question", values_to = "Response")
```

Representamos la función de frecuencias relativas (ver gráfico \@ref(fig:04freqs)) de las respuestas para cada grupo y test. Observamos que para el grupo que hemos denominado como A, las puntuaciones son mejores en el primer test y que para el grupo B ocurre lo contrario, siendo mejores en el segundo test. Esto nos permite conjeturar que con gran probabilidad al grupo A se le presentó primero el vídeo bien subtitulado mientras que al grupo B se le presentó el de los subtítulos malos.
Las valoraciones negativas  (0 y 1) son muy similares en los dos grupos respecto del mismo vídeo. Lo mismo pasa con la valoración central (2). Encontramos que en el grupo B hay relativamente más preguntas valoradas con 3 y menos con 4 que en el grupo A en ambos vídeos. Pero mientras que esta diferencia es pequeña en el vídeo con subtítulos malos, se hace acusada en el otro. De esto podemos llegar a la conclusión temporal de que los estudiantes del grupo A son menos críticos con el subtitulado que los del grupo B. Queda explicar si esta diferencia puede ser debida al orden de presentación de los vídeos. Pudiera ser que los estudiantes del grupo B, que vieron primero el vídeo con subtítulos incorrectos, aprendieran de los errores de ese vídeo y eso les llevó a ser más exigentes con el subtitulado del otro vídeo.


```{r 04freqs, out.width="90%", echo=FALSE, fig.cap = "Frecuencias relativas de las respuestas al test."}

level_labeller <- function(variable, value) {
    if (variable == "Group") {
        return(paste0("Grupo ", value))
    } else {
        return(paste0("Test ", value))
    }
}


test_lg_df %>%
    group_by(Group, Test) %>%
    count(Response) %>%
    mutate(n = n / sum(n)) %>%
    ggplot(aes(
        x = Response, y = n,
        fill = factor(Response)
    )) +
    geom_bar(stat = "identity") +
    facet_wrap(~ Group + Test, nrow = 2, labeller = level_labeller) +
    geom_text(aes(label = Response, y = 0.65), size = 3) +
    geom_text(aes(label = round(n, 2)), nudge_y = 0.02, size = 2) +
    ylim(0, 0.65) +
    theme(
        legend.position = "none",
        axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        strip.text = element_text(size = 16), strip.background = element_blank()
    ) +
    labs(y = "Frecuencia relativa de respuesta", x = "Valor de la respuesta")
```


El gráfico (\@ref(fig:04diff)) presenta una forma alternativa de comparar los dos test que realizó cada grupo. En este caso para cada usuario se comparó pregunta a pregunta y se contabilizó la diferencia entre el número de preguntas en que la puntuación en el segundo vídeo fue superior y en las que lo fue inferior.
^[En la comparación se han omitido aquellas preguntas en las que el usuario contestó "No sé/No contesto" en la pregunta correspondiente de uno de los test.]. Esto es una forma de evaluar si el usuario valoró mejor o no el segundo vídeo que el primero.


```{r 04diff, out.width="90%", fig.pos="h", echo=FALSE, fig.cap = "Frecuencias absolutas de las diferencias en las respuestas por usuario y grupo."}

compare_test_user_df <- test_lg_df %>%
    group_by(Group, User, Question) %>%
    arrange(User, Question, Test) %>%
    mutate(n = if_else(Response != 5 & lag(Response) != 5, sign(Response - lag(Response)), 0)) %>%
    arrange(User, Question, Test) %>%
    filter(row_number() %% 2 == 0) %>%
    summarise(Total = sum(n)) %>%
    summarise(Total = sum(Total))

compare_test_df <- compare_test_user_df %>%
    count(Total) %>%
    mutate(n = if_else(Total >= 0, n, -n))

compare_test_modes_df <- compare_test_df %>% summarise(min = -min(n), max = max(n))

compare_test_df %>% ggplot(aes(x = Total, y = n, fill = Total >= 0)) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("darkred", "darkblue")) +
    facet_wrap(~Group, nrow = 2, labeller = function(variable, value) {
        paste0("Grupo ", value)
    }) +
    theme(
        legend.position = "none",
        strip.text = element_text(size = 16), strip.background = element_blank()
    ) +
    labs(y = "Frecuencia de las diferencias de respuesta por usuario", x = "Valor de las diferencias entre respuestas")

```

Vemos que en el grupo A las diferencias tienden a ser negativas y en el B positivas. Esto es consistente con lo anteriormente explicado referente a que al grupo A se le presentó en primer lugar el vídeo con subtítulos correctos y al B al revés. Por ello es esperable que las valoraciones de los estudiantes del grupo A hayan empeorado y por eso sean negativas y que lo contrario haya sucedido con las del grupo B. La diferencia más frecuente en el grupo A es `r 
(compare_test_modes_df %>% filter(Group == "A"))$min` y en el grupo B este valor es `r 
(compare_test_modes_df %>% filter(Group == "B"))$max`.

Resulta desconcertante que haya estudiantes del grupo A que hayan considerado mejor subtitulado el segundo vídeo que el primero y que suceda lo contrario con algunos estudiantes del grupo B. En la tabla (\@ref(tab:04diff2)) se presentan los test en cuestión para valorar su eliminación del estudio.


```{r 04diff2, echo=FALSE, fig.cap = "Estudiantes que valoran mejor o igual el vídeo mal subtitulado"}
left_join(compare_test_user_df %>% filter(Group == "A" & Total >= 0 | Group == "B" & Total <= 0), test_df %>% dplyr::select(Row, User, Test) %>%
    pivot_wider(names_from = Test, values_from = Row, names_prefix = "Test")) %>% rename(Diff = Total) %>% arrange(desc(Diff), Group, User) %>%
     knitr::kable(caption="Estudiantes que valoran mejor el vídeo mal subtitulado.", booktabs = TRUE, escape = FALSE) %>%
    kableExtra::kable_styling(latex_options = c("hold_position"))
```