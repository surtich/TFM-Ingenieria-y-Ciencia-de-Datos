{
  "hash": "04ff72592096375a2b347e9dbc18f87d",
  "result": {
    "markdown": "\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n# Análisis de la varianza de un factor.\n\nSiguiendo a @lawson2018 [pp. 353-354] vamos a realizar un análisis de la varianza de un factor usando sólo la pregunta 18 que es una valoración general de subtitulado.\n\n## Preparación de datos\n\nTODO: Comentar y poner en bonito la tabla\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 174 × 24\n     Row Group Test   User LastTry               Q01   Q02   Q03   Q04   Q05\n   <dbl> <chr> <chr> <dbl> <dttm>              <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     5 A     01        4 2022-04-13 14:21:55     2     2     2     2     2\n 2     4 A     02        4 2022-04-13 14:23:38     2     2     2     2     2\n 3    47 B     01       33 2022-04-28 07:52:08     3     3     3     3     1\n 4    27 B     02       33 2022-04-28 08:00:20     3     3     3     3     3\n 5    85 A     01       35 2022-04-14 02:53:36     4     4     4     4     4\n 6    49 A     02       35 2022-04-14 02:58:19     4     3     4     4     3\n 7    23 A     01       38 2022-04-15 14:19:38     4     4     4     4     4\n 8    15 A     02       38 2022-04-15 14:28:36     0     4     4     4     0\n 9    68 A     01       59 2022-04-18 19:12:43     4     4     4     4     4\n10    37 A     02       59 2022-04-18 19:22:01     3     2     3     3     1\n# … with 164 more rows, and 14 more variables: Q06 <dbl>, Q07 <dbl>, Q08 <dbl>,\n#   Q09 <dbl>, Q10 <dbl>, Q11 <dbl>, Q12 <dbl>, Q13 <dbl>, Q14 <dbl>,\n#   Q15 <dbl>, Q16 <dbl>, Q17 <dbl>, Q18 <dbl>, Rows <int>\n```\n:::\n:::\n\n\nDisponemos de estos datos:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n     Test\nGroup 01 02\n    A 43 43\n    B 44 44\n```\n:::\n:::\n\n\nVamos a cambiar la nomenclatura para adaptarla a @lawson2018:\n\n* El grupo A pasará a llamarse AB.\n* El grupo B pasará a llamarse BA.\n\n* Los estudiantes se denominarán sujetos.\n* Los test 01 y 02 tratamientos.\n* Se introduce una variable periodo.\n\nLos valores del test de Likert se desplazarán para que tengan valores más lógicos:\n\n* 0 = No sé / No constesto\n* 1 = Muy en desacuerdo\n* 2 = En desacuerdo\n* 3 = Neutral\n* 4 = De acuerdo\n* 5 = Muy de acuerdo\n\nFinalmente la tabla se pasará a formato largo.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3,132 × 6\n   Group Period Treat Subject Question Response\n   <fct> <fct>  <fct> <fct>   <chr>       <dbl>\n 1 AB    1      A     4       Q01             3\n 2 AB    1      A     4       Q02             3\n 3 AB    1      A     4       Q03             3\n 4 AB    1      A     4       Q04             3\n 5 AB    1      A     4       Q05             3\n 6 AB    1      A     4       Q06             3\n 7 AB    1      A     4       Q07             3\n 8 AB    1      A     4       Q08             3\n 9 AB    1      A     4       Q09             3\n10 AB    1      A     4       Q10             3\n# … with 3,122 more rows\n```\n:::\n:::\n\n\nEl análisis de la varianza, ANOVA, se debe realizar una variable de respuesta cuantitativo (TODO: incluir supuestos de ANOVA).\nEl test de Likert tiene una escala ordinal y, por lo tanto, ANOVA no es una técnica adecuada. De todas formas\nvamos a realizar un análisis de la varianza para la pregunta 18 que es una valoración general del subtitulado.\n\n\n\n\n\nVamos a seguir el proceso descrito en @meier2022 para realizar el ANOVA.\n\n## Análisis de la varianza de un factor.\n\n### Ajuste del modelo.\n\nEl factor va a ser el tratamiento con dos niveles A y B\n^[Para este ejemplo en el que sólo hay dos niveles de factor, podríamos haber utilizado un $t$-test de comparación de medias.].\n\nEl modelo que vamos a ajustar es:\n\n$$\n   Y_{ij} \\sim N(\\mu_i, \\sigma^2), \\textrm{ independientes}\n$$ {#eq-one-anova-1}\n\nLos valores observados $y_{ij}$ corresponden a las respuestas a la pregunta 18 del sujeto j-ésimo que recibió el i-ésimo tratamiento (A o B) y siguen una distribución normal con media $\\mu_i$ y varianza $\\sigma^2$. Es decir, que estamos suponiendo que los dos tratamientos tienen la misma varianza pero pueden tener distinta media.\n\nEl modelo (@eq-one-anova-1) también se puede expresar:\n\n$$\n  Y_{ij} = \\mu_i + \\epsilon_{ij}\n$$ {#eq-one-anova-2}\n\nCon $\\epsilon_{ij} \\textrm{ i.i.d.} \\sim N(0,\\sigma^2)$. En esta ecuación simplemente hemos separado el término determinista $\\mu_i$ del estocástico $\\epsilon_{ij}$.\n\nUna reparametrización alternativa es:\n\n$$\n  Y_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n$$ {#eq-one-anova-3}\n\nEn este caso, estamos considerando que existe un efecto fijo, $\\mu$, y que cada factor tiene una desviación, $\\alpha_i$, sobre el ese nivel fijo. Así $\\displaystyle \\sum_{i=1}^g \\alpha_i = 0$. Lo que en nuestro, en el que sólo hay dos niveles ($g=2$),\nimplica que $\\alpha_A + \\alpha_B = 0$. En R se puede elegir uno (@eq-one-anova-2) u otro (@eq-one-anova-2) tipo de parametrización.\n\nPodemos visualizar que los valores de respuesta cada nivel de tratamiento está claramente separado: \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Resumen de las respuestas a la pregunta 18 en cada nivel de tratamiento.](anoveOne_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nFinalmente ajustamos el modelo y mostramos los coeficientes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit.q18 <- aov(Response ~ Treat, data = df18)\ncoef.q18 <- coef(fit.q18)\ncoef.q18\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)      TreatB \n   4.459770   -1.574713 \n```\n:::\n:::\n\n\nPor defecto R elige como nivel de referencia del factor el A por ser menor alfabéticamente y el término de intercepción se corresponde con este valor, así $\\mu_A=4.46$ y el nivel del tratamiento B está como diferencias sobre el de referencia. Por lo tanto, $\\mu_B=2.89$.\n\nAlternativamente podemos obtener las medias de cada nivel de esta forma:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit.q18, newdata = data.frame(Treat = c(\"A\", \"B\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1        2 \n4.459770 2.885057 \n```\n:::\n:::\n\n\nO con la librería `emmeans`, que también nos proporciona el intervalo de confianza con el 95%:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nemmeans(fit.q18, specs = ~Treat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Treat emmean   SE  df lower.CL upper.CL\n A       4.46 0.11 172     4.24     4.68\n B       2.89 0.11 172     2.67     3.10\n\nConfidence level used: 0.95 \n```\n:::\n:::\n\n\nCon R, podemos obtener los valores correspondientes a la segunda parametrización (@eq-one-anova-3) del modelo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\nfit.q18.2 <- aov(Response ~ Treat, data = df18)\ncoef.q18.2 <- coef(fit.q18.2)\ncoef.q18.2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)      Treat1 \n  3.6724138   0.7873563 \n```\n:::\n\n```{.r .cell-code}\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n```\n:::\n\n\nVemos que cambian tanto los valores como el esquema de nombrado. Ahora el término de intercepción se corresponde con la media global ($\\mu=3.67$) y `Treat1` es la diferencia del nivel de factor 1 con esa media ($\\alpha_A=0.79$), como la suma de todos los niveles tiene que ser 0, $\\alpha_B=-0.79$.\n\n### Tests estadísticos.\n\nEn ANOVA el contraste de hipótesis habitual es contrastar si las medias de los niveles de un factor son iguales o hay alguna diferente:\n\n$$\n\\begin{array}{lll}\nH_0 & : & \\mu_1 = \\mu_2 = \\ldots = \\mu_g \\\\\nH_A & : & \\mu_k \\neq \\mu_l \\textrm{ para al menos un par } k \\neq l \\\\\n\\end{array}\n$$\n\nLos resultados de $F$-test son significativos y permiten rechazar la hipótesis nula de que los dos tratamientos son iguales, es decir que podemos concluir que el subtitulado de los vídeos es percibido por los estudiantes con diferente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit.q18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value Pr(>F)    \nTreat         1  107.9  107.87   101.7 <2e-16 ***\nResiduals   172  182.5    1.06                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nPodemos calcular el estadístico F usando un test $drop1$ que consiste en ajustar el modelo con y sin variables predictoras y comparar los resultados.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(fit.q18, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nResponse ~ Treat\n       Df Sum of Sq    RSS    AIC F value    Pr(>F)    \n<none>              182.46 12.261                      \nTreat   1    107.87 290.33 91.080  101.68 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nUna tercera forma obtener los mismos resultados es comparar mediante un $F$-test el modelo con un factor con el modelo nulo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit.q18.single <- aov(Response ~ 1, data = df18)\nanova(fit.q18.single, fit.q18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: Response ~ 1\nModel 2: Response ~ Treat\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    173 290.33                                  \n2    172 182.46  1    107.87 101.68 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nPodemos obtener las significación estadística y los intervalos de confianza de los $\\alpha_i's$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary.lm(fit.q18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\naov(formula = Response ~ Treat, data = df18)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4598 -0.8851  0.1149  0.5402  2.1149 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   4.4598     0.1104   40.39   <2e-16 ***\nTreatB       -1.5747     0.1562  -10.08   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.03 on 172 degrees of freedom\nMultiple R-squared:  0.3715,\tAdjusted R-squared:  0.3679 \nF-statistic: 101.7 on 1 and 172 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(fit.q18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                2.5 %    97.5 %\n(Intercept)  4.241811  4.677729\nTreatB      -1.882953 -1.266472\n```\n:::\n:::\n\n\n### Comprobación de los supuestos del modelo.\n\nLa inferencia estadística solo es válida si se cumplen las siguientes premisas:\n\n* Los errores son independientes.\n* Los errores están distribuidos normalmente.\n* La varianza del error es constante.\n* Los errores tienen una media de cero.\n\nLa independencia de los errores se consigue aleatorizando el experimento. Habría que hacer comprobaciones estadísticas de la representatividad de la muestra que no se abordan en este trabajo por no ser objeto del mismo. En cualquier caso, en un estudio cruzado los errores no son independientes y trataremos este problema más adelante.\n\n#### Análisis de residuos\n\nNo observamos directamente los errores, $\\epsilon_{ij}$, sino una estimación suya que denominamos residuos:\n\n$$\nr_{ij} = y_{ij} - \\widehat{\\mu}_{i}.\n$$\n\nPara comprobar la normalidad de los residuos es habitual utilizar un gráfico **QQ-plot** que compara los percentiles de los residuos obtenidos de tras ajustar el modelo con los que resultarían de un distribución normal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqPlot(fit.q18, distribution = \"norm\")\n```\n\n::: {.cell-output-display}\n![QQ-plot para comprobar la normalidad de los residuos.](anoveOne_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 54 96\n```\n:::\n:::\n\n\nComo era de esperar, una variable de respuesta ordinal no va a producir residuos con distribución normal.\n\nSi los residuos no tienen una distribución normal, el resto de test que hagamos carecen de sentido ya parten de la premisa de que los residuos son normales. De todas formas realizaremos algunos de estos test. Por ejemplo, para comprobar si los residuos tienen una varianza constante, podemos utilizar el **Tukey-Anscombe plot (TA-plot)**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit.q18, which = 1)\n```\n\n::: {.cell-output-display}\n![TA-plot para comprobar la varianza constante de los residuos.](anoveOne_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nConstatamos que los residuos tienden a crecer ligeramente. \n\n### Aproximaciones no paramétricas.\n\nDado que la variable de respuesta es ordinal y no sigue una distribución normal, podemos hacer un test no paramétrico como es el **test de Kruskal-Wallis**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit.q18.kw <- kruskal.test(Response ~ Treat, data = df18)\nfit.q18.kw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  Response by Treat\nKruskal-Wallis chi-squared = 65.658, df = 1, p-value = 5.364e-16\n```\n:::\n:::\n\n\nEste test produce significación estadística de la diferencia de medias.\n",
    "supporting": [
      "anoveOne_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}