### Regresión Ordinal Multinivel {#sec-multinivel-2}

En la @sec-multinivel se expuso el fundamento teórico de los modelos multinivel. Aquí se justifica su interés aplicado al caso del subtitulado de vídeos. Hay dos variables susceptibles de ser incorporadas al modelo como efectos aleatorios. El primer candidato es el factor `Subject`. Es evidente que los estudiantes son una muestra de una población más amplia que estaría constituida por todos los estudiantes del curso de \gls{accesibilidad}. Pero es que además cada estudiante responde a cada ítem dos veces y, por lo tanto, sus observaciones no son independientes. En la @fig-subjects se muestran las respuestas de diez estudiantes a cada subtitulado. Se observa que las respuestas no son independientes ya que cada estudiante tiene un preferencia por uno o varios niveles de respuesta en cada test. Por otro lado, los ítems no son independientes unos de otros ya que pretenden medir la misma variable subyacente. Además, el interés no es conocer el valor concreto de sus coeficientes sino su valor en relación a los coeficientes de los otros ítems. En @burkner2021 [pp. 14-16] @burkner2019 [pp. 19-20] se puede encontrar un ejemplo con esta parametrización aplicada a una \gls{escala de likert}.

#### Modelo Response ~ Treat * Period + (1 | Subject)

El primer modelo que se propone es un modelo que mantiene los predictores `Treat` y `Period` y su interacción (equivalente al \gls{efecto secuencia}) como efectos fijos que fueron seleccionadas en la sección anterior (ver @sec-mejor-modelo-efectos-fijos) e incorpora los estudiantes como efectos aleatorios sobre los interceptos:

\small


$$
\begin{aligned}
Nivel\ 1: & \text{logit}(P(Response_{ij} \leq k)) = \tau_{kj} - \beta_1 \text{Treat}_{ij} - \beta_2 \text{Period}_{ij} - \beta_3 \text{Treat}_{ij} * \text{Period}_{ij} \\
Nivel\ 2: & \tau_{kj}  =  \tau_{k} + Subject_{0j}
\end{aligned}
$$

\normalsize

donde $ij$ es la observación $i$ del estudiante $j$. Obsérvese que ahora los interceptos $\tau_{kj}$ se descomponen en una parte fija y común para cada nivel de respuesta $k$, $\tau_{k}$ y una parte variable específica para cada estudiante $Subject_{0j}$. Para ajustar el modelo se va a utilizar la función `clmm` del paquete `ordinal` [ver @ordinalR] ya que permite la inclusión de efectos aleatorios. 

\scriptsize
```{r}
#| label: fig-subjects
#| fig-cap: Respuestas de los estudiantes por nivel de subtitulado.

set.seed(10)
random_subjects <- sample(unique(df_response$Subject), size = 10)
df_response %>%
    filter(Subject %in% random_subjects) %>%
    ggplot(aes(x = Treat, y = Response, color = Treat)) +
    geom_point(position = position_jitter(height = 0.3, width = 0), size = 1) +
    facet_grid(cols = vars(Subject), space = "free", switch = "both") +
    theme(panel.grid.major.x = element_blank(), legend.position = "none")
```
\normalsize


\scriptsize
```{r}
#| echo: true
#| cache: true
options(contrasts = rep("contr.sum", 2))
clmm_treat.period_subject <- clmm(
    Response ~ Treat * Period + (1 | Subject),
    data = df_response
)
summary(clmm_treat.period_subject)
```
\normalsize

En la parte de efectos fijos: los interceptos tienen valores similares al modelo de efectos fijos (ver @sec-response-treat.period) aunque los coeficientes incrementan ligeramente su valor. Esto indica una mayor distancia entre las respuestas de los subtitulados $A$ y $B$. En este modelo el efecto secuencia no es significativo. En cuanto a los efectos aleatorios: la varianza del intercepto aleatorio de los estudiantes es `r round(VarCorr(clmm_treat.period_subject)$Subject[1], 2)`. En la @fig-random-subject-var se muestran los valores de los interceptos estimados de los estudiantes. La media de estos interceptos como se espera es cercana a cero (`r round(ranef(clmm_treat.period_subject)$Subject %>% unlist() %>% mean(),3)`).


```{r}
#| label: fig-random-subject-var
#| fig-cap: Distribución de interceptos aleatorios por estudiante en el modelo Response ~ Treat * Period + (1 | Subject)
#| fig-scap: Distribución de interceptos aleatorios por estudiante.
#| fig-width: 4
ranef(clmm_treat.period_subject) %>%
    data.frame() %>%
    ggplot(aes(y = X.Intercept.)) +
    geom_boxplot() +
    ylab("Subject intercept") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank()
    )
```

#### Modelo Response ~ Treat * Period + (1 + Treat | Subject)

Es posible que cada estudiante valore con diferente criterio cada subtitulado. Para estimarlo, se propone el siguiente modelo:


\small


$$
\begin{aligned}
Nivel\ 1: & \text{logit}(P(Response_{ij} \leq k)) = \tau_{kj} - \beta_{1j} \text{Treat}_{ij} - \beta_{2} \text{Period}_{ij} - \beta_{3} \text{Treat}_{ij} * \text{Period}_{ij} \\
Nivel\ 2: & \tau_{kj}  =  \tau_{k} + Subject_{0j} \\
          & \beta_{1j}  =  \beta_{1} + Subject_{1j}
\end{aligned}
$$

\normalsize


Ahora el parámetro $\beta_{1j}$ del subtitulado tiene dos componentes: Uno común a todos los niveles de respuesta $\beta_{1}$ y otro particular de cada estudiante $Subject_{1j}$. El modelo ajustado ocasiona que solo `Treat1` sea significativo, ya que ni el periodo ni la secuencia lo son. En los efectos aleatorios la correlación entre intercepto y pendiente es prácticamente nula.

\scriptsize
```{r}
#| echo: true
#| cache: true
options(contrasts = rep("contr.sum", 2))
clmm_treat.period_treat.subject <- clmm(
    Response ~ Treat * Period + (1 + Treat | Subject),
    data = df_response
)
summary(clmm_treat.period_treat.subject)
```
\normalsize

#### Comparación de modelos

Se pueden comparar los modelos con el test de razón de verosimilitud que se realiza con la función `anova` del paquete `ordinal` [ver @ordinalR]. Se comprueba que en este test resulta significativamente mejor el último modelo:

\scriptsize
```{r}
#| echo: true
anova(clmm_treat.period_subject, clmm_treat.period_treat.subject)
```
\normalsize

#### Elección del mejor modelo

Se han comparado distintos modelos:

* Response ~ (1 | Subject)
* Response ~ (1 + Treat | Subject)
* Response ~ (1 + Treat | Item)
* Response ~ Treat + (1 + Treat | Subject)
* Response ~ Treat + (1 + Treat | Item)
* Response ~ Treat*Period + (1 + Treat  | Subject)
* Response ~ Treat*Period + (1 + Treat  | Item)
* Response ~ Treat*Period + (1 + Period | Subject) + (1 + Treat | Item)
* Response ~ Treat + (1 + Treat | Subject) + (1 + Treat | Item)
* Response ~ Treat*Period + (1 + Treat  | Subject) + (1 + Treat | Item)

El último de ellos produce un resultado significativo en el test de razón de verosimilitud con todos los demás. Sin embargo los parámetros de todos los modelos tienen valores similares por lo que no cambia la interpretación que se haga de ellos en cada modelo. Este modelo tiene un $AIC$ menor que los modelos ordinales ajustados en el apartado anterior (ver @sec-ordinal-2) incluso si a esos modelos se les añade como factor predictor `Item`. Será este, por lo tanto, el modelo seleccionado.



La @eq-mejor-modelo del modelo seleccionado es la siguiente:

\small


$$
\begin{aligned}
Nivel\ 1: & \text{logit}(P(Response_{ijl} \leq k)) = \tau_{kjl} - \beta_{1jl} \text{Treat}_{ijl} - \beta_{2} \text{Period}_{ijl} - \beta_{3} \text{Treat}_{ijl} * \text{Period}_{ijl} \\
Nivel\ 2: & \tau_{kjl}  =  \tau_{k} + Subject_{0j} + Item_{0l} \\
          & \beta_{1jl}  =  \beta_{1} + Subject_{1j} + Item_{1l}
\end{aligned}
$$ {#eq-mejor-modelo}

\normalsize

donde $ijl$ se corresponde con la observación $i$-ésima del estudiante $j$ e ítem $l$. Ahora los interceptos y el coeficiente del subtitulado se componen de tres sumandos: una parte fija, una parte que depende del estudiante y una parte que depende del ítem de Likert. 


El resumen de parámetros del modelo es el siguiente:

\scriptsize
```{r}
#| echo: true
#| cache: true
options(contrasts = rep("contr.sum", 2))
clmm_treat.period.subject.item <- clmm(
    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item),
    data = df_response
)
summary(clmm_treat.period.subject.item)
```
\normalsize

Con este modelo los efectos secuencia y periodo no son significativos. En cualquier caso se mantienen ya que el test de razón de verosimilitud resulta significativo en este modelo respecto al modelo sin estos predictores.

 
{{< include 4.3.qmd >}}



