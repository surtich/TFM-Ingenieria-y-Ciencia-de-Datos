### Modelado bayesiano {#sec-bayesiano-2}

Existen muchos paquetes en R para hacer inferencia bayesiana. Algunos de ellos son:

* OpenBUGS y WinBUGS: basado en el muestreo de Gibbs.
* JAGS: también utiliza el muestreo de Gibbs.
* Stan: Más moderna y con una comunidad de desarrollo más activa que los anteriores. Utiliza muestreo HMC (Hamiltonian Monte Carlo) y NUTS (no U-turn sampler). Se pueden definir modelos directamente con el lenguaje de modelado de Stan. Hay muchos paquetes basados en Stan que facilitan la especificación de modelos con una sintaxis más sencilla. En este trabajo se utilizará uno de ellos, $brms$.
* INLA: Evita la simulación MCMC haciendo más rápida la convergencia. Es menos flexible ya que solo se pueden especificar modelos de la familia exponencial.

Se han comparado múltiples modelos usando la función `LOO` que realiza una validación cruzada bayesiana `leave-one-out` similar a la que se explicó en la @sec-bayesiano. El mejor modelo ha resultado ser el mismo que se seleccionó en modelos mixtos (ver @eq-mejor-modelo). Es decir:

\small
> Response ~ Treat*Period + (1 + Treat  | Subject) + (1 + Treat | Question)
\normalsize

\scriptsize
```{r}
#| echo: true
#| cache: true
options(contrasts = rep("contr.sum", 2))
brm_treat.period.subject.question <- brm(
    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),
    data = df_clean,
    family = cumulative("logit"),
    iter = 4000,
    sample_prior = TRUE,
    file = "models/brm_treat.period.subject.question",
    file_refit = "on_change"
)
```
\normalsize

El modelo utiliza como factores con efectos fijos (`complete pooling` en terminología bayesiana) el nivel de subtitulado y el periodo y la interacción entre ambos; y como efectos aleatorios (`partial pooling`) los sujetos y las preguntas del test, cada uno de ellos con un intercepto y un nivel de subtitulado variable. El resumen del modelo es el siguiente:

\tiny
```{r}
#| echo: true
summary(brm_treat.period.subject.question)
```
\normalsize


Se han mantenido las distribuciones de probabilidad a priori que por defecto utiliza `brm` confiando en que sus parámetros son adecuados. Sin embargo, conviene comprobar que realmente sea así. En la @tbl-priors se muestran las distribuciones a priori de los parámetros aleatorios del modelo. En la @fig-priors se constata que toman valores razonables y no informativos.

\tiny
```{r}
#| label: tbl-priors
#| tbl-cap: Distribuciones a priori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).
prior_summary(brm_treat.period.subject.question) %>%
    gt() %>%
    tab_options(table.font.size = 6)
```
\normalsize

```{r}
#| label: fig-priors
#| fig-cap: Distribuciones a priori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).
prior_draws(brm_treat.period.subject.question) %>%
    pivot_longer(cols = everything(), names_to = "term", values_to = "value") %>%
    ggplot(aes(x = value, y = term, fill = term)) +
    geom_violin() +
    labs(y = NULL) +
    coord_cartesian(xlim = c(-7.5, 7.5)) +
    theme(legend.position = "none")
```

Es importante asegurar que el entrenamiento ha convergido a su distribución a posteriori. En la tabla de resumen constatamos que el valor de `Rhat` es inferior a 1.1 y el de `ESS` superior a 400 en todos los parámetros, que son umbrales que no se deberían violar [ver @burkner2019]. En la
 @fig-trace se comprueba que las cadenas MCMC de muestreo de la distribución a posteriori se mezclan correctamente y no se aprecia autocorrelación en ninguno de las parámetros. Por último, en la @fig-predictive se muestra una comparación entre los histogramas construidos con los datos con los intervalos de confianza marginales de la función predictiva a posteriori del modelo. En la mayoría de las preguntas, el muestreo reproduce bastante bien el histograma de respuestas, aunque en algunas preguntas, como la `Q16` o la `Q17`, se aprecian diferencias relevantes.
 
```{r}
#| label: fig-trace
#| fig-cap: Cadenas MCMC del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).
#| cache: true
#| fig-height: 10
mcmc_plot(brm_treat.period.subject.question, type = "trace")
```

```{r}
#| label: fig-predictive
#| fig-cap: Comparación de los valores reales con los obtenidos a partir de la función predictiva a posteriori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).
#| fig-height: 10
pp_check(brm_treat.period.subject.question, type = "bars_grouped", group = "Question", ndraws = 1000)
```
