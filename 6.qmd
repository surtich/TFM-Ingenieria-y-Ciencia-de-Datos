```{r}
source("_setup.R")
```

# Discusión y conclusiones {#sec-conclusiones}

## Comparación con *Odds Ratio* {#sec-or-4}

En la @sec-or-3 se constató la existencia de un efecto periodo en las respuestas 4 y 5. El test es significativo porque el ratio entre subtítulos de respuestas con valor 4 es diferente en cada periodo habiendo mayor respuestas 4 en el segundo periodo que en el primero. Con las respuestas 5 ocurre lo contrario: la proporción es mayor en el primer periodo. La @fig-or2 permite una comprobación visual. Esto estaría indicando que los estudiantes de ambos grupos prestaron más atención o fueron más exigentes en el segundo visionado y decidieron no otorgar la puntuación máxima. Que el efecto periodo sea de signo contrario en dos respuestas no debe sorprender en este diseño de experimento, ya que un test es un juego de suma cero: la valoraciones que se ganan o se pierden en un nivel de respuesta necesariamente provocan que el resto de niveles pierdan o ganen respectivamente la misma cantidad. En cualquier caso, vemos que el efecto periodo es cuantitativa y cualitativamente pequeño. Al afectar solo al intercambio de valoraciones entre los niveles 4 y 5, es simplemente una pequeña corrección en la valoración del subtitulado y que cualitativamente es poco importante ya que las respuestas 4 y 5 son ambas valoraciones positivas.


```{r}
#| label: fig-or2
#| fig-cap: OR ~ Treat + Period + Response
#| fig-height: 4
fourfold(xtabs(~ Treat + Period + Response, data = df_all))
```

## Modelado

La probabilidad de que los alumnos puntúen mejor el subtitulado $A$ que el $B$ frente a que lo puntúen igual o peor se estima que es del `r paste(round(100/(1+exp(-fixef(glmer_improve_subject_question)[[1]])),2),"%", sep="")`. Sin embargo, la distribución por ítems no es uniforme (ver @tbl-improve-question). Así, hay ítems en que esta probabilidad sobrepasa el 80% (`r paste((improve_question %>% filter(Prob > .8) %>% arrange(desc(Prob)))$Question, collapse=", ")`). Sin embargo hay otros en que no supera el 25% (`r paste((improve_question %>% filter(Prob < .25) %>% arrange(Prob))$Question, collapse=", ")`). La respuesta al ítem Q18 está por encima de la media (`r paste(round((improve_question %>% filter(Question=="Q18"))$Pro * 100, 2), "%", sep="")`). Parece claro que los ítems en los que la respuesta de los estudiantes es diferente en los dos subtitulados es porque aprecian diferencias reales entre ellos. Quedaría por dilucidar si en los ítems en los que no hay diferencia en las respuestas, se debe a que realmente no las hay o si es que los estudiantes no son capaces de detectarlas.

La magnitud del efecto del subtitulado sobre las valoraciones es muy superior a la de los efectos periodo y secuencia (ver @tbl-model-comp), por lo que podemos realizar interpretaciones del modelo sin que nos deba preocupar su existencia. En la @fig-pred-3 se representan 50 muestras de la esperanza de la distribución predictiva a posteriori para cada pregunta y nivel de subtitulado marginalizadas por periodo y estudiante. La primera conclusión que podemos extraer es que el modelo tiene bastante incertidumbre sobre los valores de respuesta a cada pregunta no superando casi nunca el 50% de probabilidad para todas las preguntas y niveles de subtitulado. En general se observa en la mayoría de las preguntas del nivel de subtitulado $A$ que los alumnos están bastante seguros de que la respuesta a las preguntas debe ser 4 ó 5, asignando una muy baja probabilidad a los valores 1, 2, ó 3, pero habiendo bastante incertidumbre respecto cuál de los dos valores (4 ó 5) asignar. En el nivel de subtitulado $B$ la situación es bastante más confusa. Aunque la opción de respuesta preferida es 4 y las menos preferidas son la 5 y la 1, hay bastante mezcla entre las opciones de respuesta 2, 3 y 4. En cuanto al análisis individualizado por pregunta podemos extraer las siguientes conclusiones:

* En las preguntas $Q04$ y $Q13$ los estudiantes no aprecian defectos en el subtitulado ni diferencias entre un nivel y otro. Son valoradas en ambos subtitulados con puntuaciones de 4 y de 5.

* En las preguntas $Q15$, $Q16$ y $Q17$, la opción de respuesta más probable es 4 en ambos subtitulados. El modelo asigna una baja probabilidad de respuesta a la opción 1 y similares al resto. La probabilidad de la opción 5 decrece ligeramente entre subtitulado $A$ y $B$ y lo contrario ocurre con las opciones 2 y 3.

* Las preguntas $Q01$, $Q02$, $Q03$, $Q10$, $Q11$ y $Q12$ son similares a las anteriores. Particularmente en lo referente a que la respuesta más probable en el subtitulado $B$ es 4. En el subtitulado $A$ hay preferencia por 4 y 5. El nivel 5 cae acusadamente en el subtitulado $B$ y en este nivel aumenta ligeramente la probabilidad de respuesta 2 y 3.

* Las preguntas $Q06$, $Q07$, $Q14$ y $Q18$ no son muy diferentes de las anteriores. En general el modelo predice mayor probabilidad de respuesta para 5 en el subtitulado $A$ pero este valor es con alta probabilidad cercano a cero en el subtitulado $B$. En el subtitulado $B$ la probabilidad de respuesta 2, 3 ó 4 es similar.

* Las preguntas $Q05$, $Q08$ y $Q09$ son las que más diferencias entre subtitulados presentan. La respuesta más probable en el subtitulado $A$ es 5 (en $Q08$ y en $Q09$ muy parecida a 4). Por contra, en el subtitulado $B$ las respuestas 4 y 5 tienden a cero, siendo la más probable la respuesta 2. En $Q05$ y en $Q09$ la segunda respuesta más probable al subtitulado $B$ es 1 y 4 en la $Q08$.

En definitiva, nuestro modelo predice que los estudiantes están bastante de acuerdo en que en las preguntas $Q05$ y $Q09$ hay una diferencia de calidad importante entre subtitulados. También están de acuerdo en que en las preguntas $Q04$ y $Q13$ no hay apenas cambio entre los subtitulados. En las preguntas $Q15$, $Q16$ y $Q17$ hay una gran confusión en ambos niveles de subtitulado predominando la respuesta 4 y siendo muy parecidas las respuestas en ambos niveles. En el resto la confusión se circunscribe al nivel de subtitulado $B$, ya que en el nivel $A$ las opciones 4 y 5 predominan.

![Muestreo de la función predictiva a posteriori por tratamiento y pregunta del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).](images/bayes-preg.png){#fig-pred-3 width=100%}


```{r}
#| fig-height: 10
#| fig-width: 8
#| cache: true
#| eval: false
pred2_brm <- brm_treat.period.subject.question %>%
    epred_draws(ndraws = 50, newdata = newdata, re_formula = ~ (1 + Treat | Question), by = c("Treat", "Question"), category = "Response") %>%
    select(Period, Treat, Question, Response, Probability = .epred, .draw) %>%
    mutate(Median = ave(Probability, FUN = function(x) quantile(x, .5, type = 3, na.rm = TRUE))) %>%
    ungroup() %>%
    group_by(.draw, Response) %>%
    mutate(indices = cur_group_id()) %>%
    ungroup()

colors <- viridis(
    option = "plasma",
    begin = 0,
    end = 0.9,
    direction = -1,
    n = 5
)

questions_vector <- setNames(levels(df_clean$Question_lr), levels(df_clean$Question))

question_labeller <- function(string) paste0(string, ": ", questions_vector[string])

# Plotting the fitted draws
p <- pred2_brm %>%
    ggplot(aes(
        x = Treat,
        y = Probability,
        color = Response,
        # Don't forget the indices!
        group = indices
    )) +
    facet_wrap(~Question, nrow = 6, labeller = as_labeller(question_labeller)) +
    geom_line(alpha = 0.4) +
    scale_color_manual(values = colors) +
    # We won't need these
    guides(
        color = FALSE,
        label = FALSE,
        scale = "none"
    ) +
    theme_ipsum_ps(base_family = NULL)
p +
    labs(
        x = "Treat",
        y = "Probability"
    ) +
    theme(
        plot.margin = margin(0, 100, 0, 0),
    ) +
    # This allows any labels or data to go past the grid
    coord_cartesian(clip = "off") +
    # Finally, our labels. We filter the data to avoid having a million of them
    geom_text_repel(
        data = pred2_brm %>% filter(Probability == Median & Question %in% c("Q02", "Q05", "Q08", "Q11", "Q14", "Q17") & Period == 2, Treat == "B") %>% distinct(Treat,
            Period, Question, Response,
            .keep_all = TRUE
        ) %>% mutate(Response_l = ordered(Response, labels = levels(df_clean$Response_l))),
        aes(label = Response_l),
        direction = "y",
        hjust = 0,
        segment.size = 0.2,
        # Move the labels to the right
        nudge_x = 0.1,
        na.rm = TRUE,
        # Expand limits so that the label doesn't get stuck
        xlim = c(0, 5),
        # Adjust size as needed!
        size = 3.5
    ) + scale_x_discrete(expand = c(0, 0), limits = c("A", "B"))

```
