```{r}
source("_setup.R")
```

# Resultados {#sec-resultados}

En este capítulo se comentan los resultados de los modelos seleccionados (ver @sec-modelado).

### Comparación con *Odds Ratio* {#sec-or-3}

El contraste de hipótesis del $log\ OR$ del subtitulado para cada grupo (ver @sec-or-2) no produce significación estadística en ningún nivel de respuesta, por lo que según esta prueba estadística la secuencia de subtitulado no influiría en la respuesta de los estudiantes (ver @tbl-logor1). Es decir, de acuerdo a este test la secuencia no influye en la valoración de los subtítulos.

```{r}
#| label: tbl-logor1
#| tbl-cap: Log OR ~ Treat + Seq + Response_l
data.frame(summary(loddsratio(~ Treat + Seq + Response_l, data = df_all)) %>% unclass(), check.names = F) %>%
    rownames_to_column("Response") %>%
    mutate_if(is.numeric, round, 3) %>%
    gt()
```

Sin embargo, si se realiza este contraste entre subtítulos y periodos, se constata la existencia de un efecto periodo de signo contrario para las preguntas 4 y 5 (ver @tbl-logor2). 

```{r}
#| label: tbl-logor2
#| tbl-cap: Log OR ~ Treat + Period + Response_l
data.frame(summary(loddsratio(~ Treat + Period + Response_l, data = df_all)) %>% unclass(), check.names = F) %>%
    rownames_to_column("Response") %>%
    mutate_if(is.numeric, round, 3) %>%
    gt()
```

### Modelado

```{r}
options(contrasts = rep("contr.sum", 2))
glmer_improve_subject_question <- glmer(Improve ~ 1 + (1 | Subject) + (1 | Question), family = "binomial", data = df_improve)

improve_question <- 1 / (1 + exp(-coef(glmer_improve_subject_question)$Question + fixef(glmer_improve_subject_question)))

improve_question <- cbind(rownames(improve_question), improve_question)
colnames(improve_question) <- c("Question", "Prob")

# summary(glmer_improve_subject_question)
```

El modelo de efectos mixtos ajustado con Regresión Logística:

> Improve ~ 1 + (1 | Subject) + (1 | Question)

estima la probabilidad de que la respuesta a un ítem en el subtitulado $A$ sea mejor que en el subtitulado $B$ frente a que sea igual o peor.
El intercepto del modelo ajustado es `r round(fixef(glmer_improve_subject_question)[[1]],3)`. Por ello, la probabilidad de que se otorgue una mayor puntuación en $A$ que en $B$ es del `r paste(round(100/(1+exp(-fixef(glmer_improve_subject_question)[[1]])),2),"%", sep="")`. En la @tbl-improve-question se muestra la probabilidad de que la respuesta sea mejor en $A$ que en $B$ por ítem.

\scriptsize
```{r}
#| label: tbl-improve-question
#| tbl-cap: Probabilidad de que la respuesta a un ítem sea A > B frente a A <= B
improve_question %>%
    gt() %>%
    fmt_number(Prob, decimals = 2)
```

\normalsize

En la @sec-ordinal-2 se evaluaron distintas parametrizaciones de la Regresión Ordinal Acumulativa tanto desde el punto de vista frecuentista como bayesiano y considerando únicamente efectos fijos y también efectos aleatorios. Finalmente, tanto en el análisis frecuentista como en el bayesiano, el modelo que resultó ser más parsimonioso es el de la @eq-mejor-modelo, que se reproduce aquí en sintaxis R:

\small
> Response ~ Treat*Period + (1 + Treat  | Subject) + (1 + Treat | Question)
\normalsize


Este modelo produce en los dos paradigmas unas estimaciones similares, como se puede comprobar en la @tbl-model-comp.


```{r}
#| cache: true
options(contrasts = rep("contr.sum", 2))

clmm_treat.period.subject.question <- clmm(
    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),
    data = df_clean
)

brm_treat.period.subject.question <- brm(
    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),
    data = df_clean,
    family = cumulative("logit"),
    iter = 4000,
    sample_prior = TRUE,
    file = "models/brm_treat.period.subject.question",
    file_refit = "on_change"
)
```


\tiny
```{r}
#| label: tbl-model-comp
#| tbl-cap: Comparación frecuentista/bayesiano de coeficientes estimados en el modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).
#| tbl-scap: Comparación frecuentista/bayesiano de coeficientes estimados.
#| cache: true
df_clmm <- coef(clmm_treat.period.subject.question) %>% data.frame()
colnames(df_clmm) <- c("Estimation.clmm")

df_clmm <- bind_cols(df_clmm, confint(clmm_treat.period.subject.question))

df_clmm_ranef_coefs <- c(
    attr(VarCorr(clmm_treat.period.subject.question)$Question, "stddev")[1],
    attr(VarCorr(clmm_treat.period.subject.question)$Question, "stddev")[2],
    attr(VarCorr(clmm_treat.period.subject.question)$Subject, "stddev")[1],
    attr(VarCorr(clmm_treat.period.subject.question)$Subject, "stddev")[2],
    attr(VarCorr(clmm_treat.period.subject.question)$Question, "correlation")[2, 1],
    attr(VarCorr(clmm_treat.period.subject.question)$Subject, "correlation")[2, 1]
) %>% data.frame()

rownames(df_clmm_ranef_coefs) <- c("Question.sd(Intercept)", "Question.sd(Treat1)", "Subject.sd(Intercept)", "Subject.sd(Treat1)", "Question.cor(Intercept,Treat1)", "Subject.cor(Intercept,Treat1)")
colnames(df_clmm_ranef_coefs) <- c("Estimation.clmm")

df_clmm <- bind_rows(df_clmm, df_clmm_ranef_coefs)
df_brm <- (broom.mixed::tidyMCMC(brm_treat.period.subject.question, conf.int = T))[1:13, ]

colnames(df_clmm) <- c("Estimation.clmm", "conf.2.5%", "conf.97.5%")
colnames(df_brm) <- c("Name", "Estimation.brm", "std.error", "cred.2.5%", "cred.97.5%")
df_brm$Name <- rownames(df_clmm)
df_clmm$Name <- df_brm$Name
df_clmm <- df_clmm %>% tibble()

left_join(df_clmm, df_brm) %>%
    relocate(Name) %>%
    mutate(across(where(is.numeric), ~ round(., 2))) %>%
    select(-c("std.error")) %>%
    gt() %>%
    tab_spanner(
        label = "ordinal::clmm",
        columns = c(Estimation.clmm, `conf.2.5%`, `conf.97.5%`)
    ) %>%
    tab_spanner(
        label = "brms::brm",
        columns = c(Estimation.brm, `cred.2.5%`, `cred.97.5%`)
    ) %>%
    sub_missing(columns = everything(), missing_text = "") %>%
    tab_options(table.font.size = 6)
```
\normalsize



{{< include 6.qmd >}}

