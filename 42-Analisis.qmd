```{r}
source("_setup.R")
```


# Análisis estadístico.

## Agrupamientos de preguntas. {#sec-cluster}

### Correlación entre preguntas con el alfa de Cronbach. {#sec-cronbach}

Normalmente las preguntas de un cuestionario pretenden medir una variable que está oculta o latente. En nuestro caso es la calidad del subtitulado. Las respuestas a estas preguntas relacionadas deben ser consistentes internamente, es decir, las respuestas deben correlacionarse fuerte y positivamente.

Un índice que se utiliza habitualmente para medir la consistencia interna de un cuestionario es el coeficiente `alfa de Cronbach`, ver @schweinberger2020survey. Se define de esta forma:

\begin{equation}
\alpha = \frac{N}{N-1} \left(1 - \frac{\sum_{i=1}^{N} s_{i}^{2}}{s^{2}} \right)
\end{equation}

Donde:

* $\alpha$ es el coeficiente `alfa de Cronbach`.
* $N$ es el número de items de la escala de Likert.
* $s_{i}^{2}$ es la varianza de la puntuación del item $i$.
* $s^{2}$ es la varianza total de las puntuaciones de todos los items.

Valores cercanos 1 indican una fuerte correlación en las respuestas y se admite que las preguntas del cuestionario están midiendo la misma variable latente.

Para calcular en R este coeficiente podemos usar la función `alpha` del paquete `psych`:

\scriptsize
```{r}
#| echo: true
alpha <- df_all %>%
    pivot_wider(
        names_from = Question,
        values_from = Response_v,
        id_cols = c(Treat, Subject)
    ) %>%
    dplyr::select(-c(Treat, Subject)) %>%
    psych::alpha()
```
\normalsize

Se obtiene un coeficiente alfa de `alfa de Cronbach` de `r round(alpha$total[1], 2)` que indica una muy buena correlación entre las respuestas a todas las preguntas. Este valor apenas se ve alterado si se elimina una de las preguntas (ver @tbl-drop-alpha).

\scriptsize
```{r}
#| label: tbl-drop-alpha
#| tbl-cap: Valor del coeficiente alpha de Cronbach si se elimina una pregunta.
alpha.drop <- alpha$alpha.drop %>%
    t() %>%
    data.frame() %>%
    head(1) %>%
    round(2)
alpha.drop[1:9] %>% gt()
alpha.drop[10:18] %>% gt()
```
\normalsize

En la @tbl-item-alpha mostramos las preguntas que más contribuyen al índice `alpha de Cronbach`. Es interesante que la pregunta $Q18$, que es la valoración general del cuestionario, sea la que mejor contribución tiene al índice.

\scriptsize
```{r}
#| label: tbl-item-alpha
#| tbl-cap: Relación de cada pregunta con el índice alpha de Cronbach.
alpha.item <- alpha$item.stats[2] %>%
    arrange(desc(raw.r)) %>%
    t() %>%
    data.frame() %>%
    round(2)
alpha.item[1:9] %>% gt()
alpha.item[10:18] %>% gt()
```
\normalsize

\clearpage
### Agrupamiento jerárquico aglomerativo. {#sec-cluster2}

En en la @sec-cronbach y en la @sec-eda-3 hemos visto que algunas de las preguntas tienen respuestas similares a otras pero diferentes del resto. Puede ser interesante aplicar una técnica de agrupamiento que nos permita crear grupos de preguntas que podremos analizar por separado.

Vamos a realizar una agrupación jerárquica aglomerativa de las preguntas en función de la tabla de contingencia de las respuestas utilizando la distancia euclidea como medida de distancia y el método de aglomeración de enlace completo para unir conglomerados
^[El método de enlace completo usa la distancia máxima entre dos conglomerados para seleccionar los más cercanos a unir.]. Para ello primero calculamos la tabla de contingencia (ver @tbl-contingencia) de preguntas y respuestas.

```{r}
#| echo: true
table <- df_all %>%
    xtabs(~ Question + Response, data = .)
```

\scriptsize
```{r}
#| label: tbl-contingencia
#| tbl-cap: Tabla de contingencia de preguntas y respuestas.
table %>%
    data.frame() %>%
    pivot_wider(names_from = Response, values_from = Freq, names_prefix = "Response_") %>%
    gt()
```
\normalsize


Con la tabla de contingencia calculamos las distancias entre preguntas y realizamos el agrupamiento. 
En el dendograma se aprecian claramente tres agrupamientos. Es muy interesante constatar que los tres grupos están formados por preguntas que en su mayor parte son correlativas. Esto es consistente con que al elaborar un test normalmente se colocan las preguntas por unidades temáticas y con que el encuestado también suele hacerlo teniendo en cuenta esta estructura y tiende a responder de forma similar a las preguntas correlativas.


```{r}
#| echo: true
#| label: fig-dendo
#| eval: false
#| fig-cap: Dendograma de aglomeramiento jerárquico de preguntas en función de la tabla de contingencia de respuestas.
dist <- dist(table, method = "euclidean")
cluster <- hclust(dist, method = "complete")
plot(cluster)
```

![Dendograma de aglomeramiento jerárquico de preguntas en función de la tabla de contingencia de respuestas.](images/cluster.png){width=400}


Podemos distinguir los siguientes grupos y subgrupos:

* Grupo 1: Trata sobre la corrección del subtítulo.
    * Subgrupo 05, 06, 07, 08, 09: Preguntas sobre si la información que presenta el subtítulo es correcta y está bien escrita.
    * Pregunta 18: Valoración general del subtitulado. El que esta pregunta esté incluida en el grupo sobre corrección estaría indicando que este es el apartado al que más importancia dan los estudiantes a la hora de valorar la calidad del subtitulado.

* Grupo 2: Es el más numeroso. En general está formado por preguntas sobre el grado de dificultad que presenta la lectura del subtítulo.
    * Subgrupo preguntas Q01, Q02, Q03: Colocación de los subtítulos.
    * Subgrupo preguntas Q10, Q11, Q12: Sincronización, velocidad y número de líneas.
    * Subgrupo preguntas Q04, Q13: Contraste y legibilidad.

* Grupo 3: Son preguntas que tratan también sobre la corrección del subtítulo, pero con la diferencia sobre el grupo uno de  que se trata de cuestiones más sutiles y presumiblemente más difíciles de valorar por un novato. Está formado por las preguntas Q14, Q15, Q16 y Q17.


## Análisis de tablas de contingencia.

En esta sección se aplicarán técnicas estadísticas que se basan en tablas de contingencia. Una descripción teórica de este tipo de técnicas se pueden encontrar en @agresti_2018. Un tratamiento aplicado y basado en gráficos, que será el enfoque que seguiremos en este trabajo, es realizado en @frienly2015.

### Comparación mediante mosaicos.

En el @fig-mosaic se representan en forma de mosaico las tablas de contingencia de las respuestas por tratamiento y secuencia.
La información mostrada es similar a la que presentamos en la @fig-freqs, aunque el gráfico es más intuitivo ya que la anchura y altura de los rectángulos son proporcionales a la frecuencia marginal de la secuencia y el tratamiento respectivamente y el área es proporcional a la frecuencia conjunta. En esta ocasión hemos decidido emparejar los tratamientos en lugar de hacerlo con la secuencia, como hicimos anteriormente. Esto permite una mejor comparación de las diferencias entre grupos. Con ello podemos ver fácilmente que el tratamiento $A$ es mejor valorado por los estudiantes y que el grupo que realizó la secuencia $AB$ tiene más respuestas 5 pero menor número de respuestas positivas totales que el grupo de secuencia $BA$ en ambos niveles de tratamiento.


```{r}
#| label: fig-mosaic
#| fig-cap: Mosaico de tratamientos y secuencias.
#| fig-height: 7
df_all %>%
    dplyr::select(Seq, Response, Treat, Cluster) %>%
    mosaic(Response ~ Treat + Seq,
        data = .,
        labeling = labeling_values
    )
```

### Comparación con $Odds\ Ratio$.

Hasta este momento ha quedado claro que el nivel de subtitulado $A$ es preferido por los estudiantes y que las respuestas de ambos grupos son similares. Pero, ¿cuánto de similares son? Una forma de contestar esta pregunta es utilizar el `odds ratio` de tratamientos y grupos para cada nivel de respuesta.

Es decir, calcular:

\begin{equation}
OR_{(Treat, Seq \mid Response=r)}=\frac{
    \frac{
            P(Treat=A \mid Seq=AB, Response=r)
        }{
            P(Treat=B \mid Seq=AB, Response=r)
        }
    }
    {\frac{
        P(Treat=A \mid Seq=BA, Response=r)
        }{
        P(Treat=B \mid Seq=BA, Response=r)
    }
}
\end{equation}

Si los $OR$ son similares en todos los niveles de respuesta, podemos afirmar que los grupos son homogéneos. Los resultados en R no producen significación estadística en ningún nivel de respuesta:


\scriptsize

```{r}
#| echo: true
summary(loddsratio(~ Treat + Seq + Response_l, data = df_all))
```
\normalsize

La @fig-or-1 presenta visualmente la misma información.

```{r}
#| label: fig-or-1
#| fig-cap: OR entre tratamiento y grupo por nivel de respuesta.
#| fig-height: 4
fourfold(xtabs(~ Treat + Seq + Response, data = df_all))
```

Sería interesante calcular el $OR$ para cada nivel de respuesta y pregunta pero por desgracia la muestra es demasiado pequeña para hacerlo. Se ha calculado el $OR$ sobre los agrupamientos de preguntas y se ha obtenido significación estadística tan solo en el agrupamiento 2 y nivel de respuesta 2:

\scriptsize

```{r}
#| echo: true
summary(loddsratio(~ Treat + Seq + Cluster + Response_l, data = df_all))
```
\normalsize

Sin embargo no podemos asumir que esta significación no se deba al azar ya que estamos realizando 18 contrastes de hipótesis diferentes y cada uno tiene un error tipo I asociado, con lo que la probabilidad de encontrar una significación estadística por puro azar aumenta. Se han propuesto correcciones del $p$-value como la de Bonferroni que no se aplican en este trabajo.

Otro $OR$ que tiene interés calcular es el de tratamiento y periodo para evaluar si las respuestas son homogéneas. Mostramos tanto la tabla de resultados en R y también su representación visual (ver @fig-or-2).

\scriptsize
```{r}
#| echo: true
summary(loddsratio(~ Treat + Period + Response_l, data = df_all))
```
\normalsize

```{r}
#| label: fig-or-2
#| fig-cap: OR entre tratamiento y periodo por nivel de respuesta.
#| fig-height: 4
fourfold(xtabs(~ Treat + Period + Response, data = df_all))
```

Podemos constatar la existencia de un efecto periodo de signo contrario para las preguntas 4 y 5. La razón de que se produzca este efecto periodo es que algunas de las respuestas de valoración 5 en ambos niveles de subtitulado y grupos en el primer periodo se convierten en valoración 4 en el segundo periodo. Es decir, que esto nos está indicando que los estudiantes de ambos grupos prestaron más atención o fueron más exigentes en el segundo visionado y decidieron no otorgar la puntuación máxima incluso en algunos items al subtitulado correcto. Que el efecto periodo sea contrario en dos preguntas no debe sorprendernos en este diseño de experimento, ya que un test es un juego de suma cero: la valoraciones que se ganan o se pierden en un nivel de respuesta necesariamente provoca que el resto de niveles pierdan o ganen respectivamente la misma cantidad. En cualquier caso, vemos que el efecto periodo es cuantitativa y cualitativamente pequeño. Al afectar solo al intercambio de valoraciones entre los niveles 4 y 5, y ser las dos positivas, es simplemente una pequeña corrección en la valoración del subtitulado.



