```{r}
source("_setup.R")
```



# Resultados {#sec-resultados}

En el @sec-modelado se realizó una exploración de los datos y se adecuaron los modelos presentados en el @sec-arte al diseño del experimento del subtitulado. En este capítulo se comentan los resultados de los modelos seleccionados siguiendo el mismo orden expositivo, comenzando por el análisis del \gls{OR}, continuando por la \gls{Regresión Logística} y finalizando con la \gls{Regresión Ordinal}.

### Comparación con *Odds Ratio* {#sec-or-3}

El contraste de hipótesis del $log\ OR$ del nivel subtitulado y secuencia (ver @sec-or-2) no produce significación estadística en ningún nivel de respuesta, por lo que según esta prueba estadística el orden en el que se ven los vídeos no influiría en la respuesta de los estudiantes (ver @tbl-logor1).



```{r}
#| label: tbl-logor1
#| tbl-cap: Log OR ~ Treat + Seq + Response
data.frame(summary(loddsratio(~ Treat + Seq + Response_l, data = df_all)) %>% unclass(), check.names = F) %>%
    rownames_to_column("Response") %>%
    mutate_if(is.numeric, round, 3) %>%
    gt()
```



Sin embargo, si se realiza este contraste entre subtítulos y periodos, se constata la existencia de un \gls{efecto periodo} de signo contrario para los ítems 4 y 5 (ver @tbl-logor2).  El test es significativo porque el ratio entre subtítulos de respuestas con valor 4 es diferente en cada periodo habiendo mayor cantidad de respuestas 4 en el segundo periodo que en el primero. Con las respuestas 5 ocurre lo contrario: la proporción es mayor en el primer periodo. La @fig-or2 permite una comprobación visual. Esto indica que los estudiantes de ambos grupos prestaron más atención o fueron más exigentes en el segundo visionado y valoraron relativamente peor el segundo vídeo. Que el efecto periodo sea de signo contrario en dos respuestas no debe sorprender en este diseño de experimento, ya que un test es un juego de suma cero: la valoraciones que se ganan o se pierden en un nivel de respuesta necesariamente se reparten entre el resto de niveles. En cualquier caso, el efecto periodo es cuantitativa y cualitativamente pequeño. Al afectar solo al intercambio de valoraciones entre los niveles 4 y 5 es simplemente una pequeña corrección en la valoración del subtitulado y cualitativamente es poco importante ya que las respuestas 4 y 5 son ambas valoraciones positivas. 



```{r}
#| label: tbl-logor2
#| tbl-cap: Log OR ~ Treat + Period + Response
data.frame(summary(loddsratio(~ Treat + Period + Response_l, data = df_all)) %>% unclass(), check.names = F) %>%
    rownames_to_column("Response") %>%
    mutate_if(is.numeric, round, 3) %>%
    gt()
```

```{r}
#| label: fig-or2
#| fig-cap: OR ~ Treat + Period + Response
#| fig-scap: Test Odds Ratio ~ Treat + Period + Response
#| fig-height: 4
fourfold(xtabs(~ Treat + Period + Response, data = df_all))
```




### Modelado

#### Regresión Logística {#sec-logistica-3}



```{r}
options(contrasts = rep("contr.sum", 2))
glmer_improve_subject_question <- glmer(Improve ~ 1 + (1 | Subject) + (1 | Item), family = "binomial", data = df_improve)

glmer_positive_treat_subject_question <- glmer(I(Level == "Positivo") ~ Treat + (1 + Treat | Subject) + (1 + Treat | Item), family = "binomial", df_response)

```



En la @sec-logistica-2 se explicó una forma de crear una variable dicotómica que permite ajustar los datos a una Regresión Logística. Concretamente, se creó la variable respuesta $Improve$ que compara si las respuestas de cada estudiante a cada Ítem entre los niveles de subtitulado ($A$ frente $B$) han mejorado (valor 1) o se han mantenido o empeorado (valor 0). El modelo que se propone en esta sección no tiene en cuenta el \gls{efecto secuencia} ya que resultó no significativo en el análisis y, en cambio, se incluye como efectos aleatorios los estudiantes y los ítems sobre el intercepto ya que, como se ha explicado, son variables que no se pueden considerar independientes:

> Improve ~ 1 + (1 | Subject) + (1 | Item)


\scriptsize


```{r}
#| echo: true
#| eval: false
glmer_improve_subject_question <- glmer(
    Improve ~ 1 + (1 | Subject) + (1 | Item),
    family = "binomial", data = df_improve
)
```


\normalsize


El resumen del modelo ajustado con la función `glmer` del paquete `lme4` [ver @lme4] produce los resultados de la columna izquierda de la @tbl-selected-logistic. El intercepto del modelo ajustado es `r round(fixef(glmer_improve_subject_question)[[1]],3)` (std.error `r round((vcov(glmer_improve_subject_question)^.5)[1], 3)`). Por ello, la probabilidad de que se otorgue una mayor puntuación en $A$ que en $B$ es del `r paste(round(100/(1+exp(-fixef(glmer_improve_subject_question)[[1]])),2),"%", sep="")`. La proporción de varianza explicada por los efectos aleatorios (*\gls{ICC}*) es `r round((performance::icc(glmer_improve_subject_question))$ICC_adjusted,3)`.



```{r}
#| eval: true
#| label: tbl-selected-logistic
#| tbl-cap: Resumen de los modelos de Regresión Logística.
modelsummary(list("Improve (A>B)" = glmer_improve_subject_question, "Level == 'Positivo'" = glmer_positive_treat_subject_question), gof_omit = "RMSE|R2|ICC", output = "kableExtra")
``` 




Una forma alternativa de Regresión Logística es simplemente saber si cada respuesta es positiva (4 ó 5) frente a si es negativa o neutra (1, 2, ó 3). Como efecto fijo se incorpora el nivel de subtitulado y como efectos aleatorios el estudiante y el ítem ambos con intercepto y pendiente sobre el subtitulado variables por tener mejor valor de $AIC$. La fórmula del modelo es la siguiente:

\small

> I(Level == "Positivo") ~ Treat + (1 + Treat | Subject) + (1 + Treat | Item)

\normalsize

En la columna derecha de la @tbl-selected-logistic se muestra el resumen del modelo. En este caso, el intercepto tiene una valor de `r round(fixef(glmer_positive_treat_subject_question)[1], 3)`. Por lo que la probabilidad de respuesta positiva en cualquier ítem y nivel de subtitulado es `r paste(round(100*plogis(fixef(glmer_positive_treat_subject_question)[1]), 1), "%", sep="")`. El coeficiente `Treat1` tiene valor `r round(fixef(glmer_positive_treat_subject_question)[2], 3)` y es el valor en `logits` que se añade o se quita en función de si el subtitulado es el $A$ o el $B$. Esto se traduce en que la posibilidad de una respuesta positiva en el subtitulado $A$ es `r paste(round(100*plogis(fixef(glmer_positive_treat_subject_question)[1]+fixef(glmer_positive_treat_subject_question)[2]),1),"%",sep="")`. En el subtitulado $B$ esta probabilidad se reduce a `r paste(round(100*plogis(fixef(glmer_positive_treat_subject_question)[1]-fixef(glmer_positive_treat_subject_question)[2]),1),"%",sep="")`. Por último, el valor de $ICC$ del modelo es `r round((performance::icc(glmer_positive_treat_subject_question))$ICC_adjusted,3)`


#### Regresión Ordinal {#sec-ordinal-3}




```{r}
#| cache: true
options(contrasts = rep("contr.sum", 2))

clmm_treat.period.subject.item <- clmm(
    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item),
    data = df_response
)

brm_treat.period.subject.item <- brm(
    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item),
    data = df_response,
    family = cumulative("logit"),
    iter = 4000,
    sample_prior = TRUE,
    file = "models/brm_treat.period.subject.item",
    file_refit = "on_change"
)
```




En la @sec-ordinal-2 se evaluaron distintas parametrizaciones de la Regresión Ordinal Acumulativa tanto desde el punto de vista frecuentista como bayesiano, considerando únicamente efectos fijos y también efectos aleatorios. Finalmente, tanto en el análisis frecuentista como en el bayesiano, el modelo que resultó ser más parsimonioso (evaluado con *\gls{LRT}* y con $AIC$) es el de la @eq-mejor-modelo, que se reproduce aquí en sintaxis R:

\small

> Response ~ Treat*Period + (1 + Treat  | Subject) + (1 + Treat | Item)


\normalsize


Este modelo incluye como efectos fijos el nivel de subtitulado (`Treat`), el periodo (`Period`) y su interacción; y como efectos aleatorios el estudiante (`Subject`) y el ítem (`Item`). Ambos con interceptos y pendientes variables por nivel de subtítulo. Los coeficientes estimados son muy similares tanto en el paradigma frecuentista como en el bayesiano. En la @tbl-model-comp se comparan las estimaciones producidas por ambos modelos. Como ya se dijo, el efecto más importante es el debido al subtitulado (coeficiente frecuentista `r round(coef(clmm_treat.period.subject.item)[5], 3)`). En comparación con él, los efectos debido al periodo y la secuencia son muy pequeños (coeficientes `r round(coef(clmm_treat.period.subject.item)[6], 3)` y `r round(coef(clmm_treat.period.subject.item)[7], 3)` respectivamente). La proporción de la varianza explicada debida a efectos aleatorios ($ICC$) es `r round((performance::icc(clmm_treat.period.subject.item))$ICC_adjusted,3)`.



En la @fig-probs-clmm_treat.period.subject.question se muestran las predicciones del modelo por nivel de subtítulo y periodo. El modelo predice para el subtitulado $B$ el nivel 4 de respuesta como el más probable seguido del 3, mientras para el subtitulado $A$ el nivel de respuesta más probable es el 5 seguido del 4. En el subtitulado $B$ apenas hay diferencias entre periodos, sin embargo, en el subtitulado $A$ hay mayor probabilidad del nivel de respuesta 5 en el periodo 1 y nivel de respuesta 4 en el periodo 2.



```{r}
#| label: fig-probs-clmm_treat.period.subject.question
#| fig-cap: Probabilidades de respuesta para el modelo ordinal Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item)
#| fig-scap: Probabilidades de respuesta para el modelo ordinal seleccionado.
#| fig-height: 2
emmeans(clmm_treat.period.subject.item, ~ Response + Treat + Period, mode = "prob") %>%
    data.frame() %>%
    ggplot(aes(x = glue::glue("{Treat}-{Period}"), y = prob, fill = Response)) +
    geom_col() +
    scale_fill_td(palette = "div5") +
    scale_y_continuous(expand = c(0, 0), labels = scales::percent) +
    labs(x = "Treat-Period", y = "Predicted probability")
```




\scriptsize


```{r}
#| label: tbl-model-comp
#| tbl-scap: Comparación frecuentista/bayesiano de coeficientes estimados en el modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item).
#| tbl-cap: Comparación frecuentista/bayesiano de coeficientes estimados en el modelo ordinal.
#| cache: false
df_clmm <- coef(clmm_treat.period.subject.item) %>% data.frame()
colnames(df_clmm) <- c("Estimation.clmm")

df_clmm <- bind_cols(df_clmm, confint(clmm_treat.period.subject.item))

df_clmm_ranef_coefs <- c(
    attr(VarCorr(clmm_treat.period.subject.item)$Item, "stddev")[1],
    attr(VarCorr(clmm_treat.period.subject.item)$Item, "stddev")[2],
    attr(VarCorr(clmm_treat.period.subject.item)$Subject, "stddev")[1],
    attr(VarCorr(clmm_treat.period.subject.item)$Subject, "stddev")[2],
    attr(VarCorr(clmm_treat.period.subject.item)$Item, "correlation")[2, 1],
    attr(VarCorr(clmm_treat.period.subject.item)$Subject, "correlation")[2, 1]
) %>% data.frame()

rownames(df_clmm_ranef_coefs) <- c("Item.sd(Intercept)", "Item.sd(Treat1)", "Subject.sd(Intercept)", "Subject.sd(Treat1)", "Item.cor(Intercept,Treat1)", "Subject.cor(Intercept,Treat1)")
colnames(df_clmm_ranef_coefs) <- c("Estimation.clmm")

df_clmm <- bind_rows(df_clmm, df_clmm_ranef_coefs)
df_brm <- (broom.mixed::tidyMCMC(brm_treat.period.subject.item, conf.int = T))[1:13, ]

colnames(df_clmm) <- c("Estimation.clmm", "conf.2.5%", "conf.97.5%")
colnames(df_brm) <- c("Name", "Estimation.brm", "std.error", "cred.2.5%", "cred.97.5%")
df_brm$Name <- rownames(df_clmm)
df_clmm$Name <- df_brm$Name
df_clmm <- df_clmm %>% tibble()

left_join(df_clmm, df_brm) %>%
    relocate(Name) %>%
    mutate(across(where(is.numeric), ~ round(., 2))) %>%
    select(-c("std.error")) %>%
    gt() %>%
    tab_spanner(
        label = "ordinal::clmm",
        columns = c(Estimation.clmm, `conf.2.5%`, `conf.97.5%`)
    ) %>%
    tab_spanner(
        label = "brms::brm",
        columns = c(Estimation.brm, `cred.2.5%`, `cred.97.5%`)
    ) %>%
    sub_missing(columns = everything(), missing_text = "") %>%
    tab_options(table.font.size = 6) %>%
    cols_label(Estimation.clmm = "Est.", Estimation.brm = "Est.")
```


\normalsize



En la @fig-pred-3 se representan 50 muestras de la esperanza de la distribución predictiva a posteriori para cada ítem y nivel de subtitulado marginalizados por periodo y estudiante. La primera conclusión que se puede extraer es que el modelo tiene bastante incertidumbre sobre los valores de respuesta a cada ítem no superando casi nunca el 50% de probabilidad para todos los ítems y niveles de subtitulado. En general se observa en la mayoría de los ítems del nivel de subtitulado $A$ que los alumnos están bastante seguros de que la respuesta a los ítems debe ser 4 ó 5, asignando una muy baja probabilidad a los valores 1, 2, ó 3, pero habiendo bastante incertidumbre respecto cuál de los dos valores (4 ó 5) asignar. En el nivel de subtitulado $B$ la situación es bastante más confusa. Aunque la opción de respuesta preferida es 4 y las menos preferidas son la 5 y la 1, hay bastante mezcla entre las opciones de respuesta 2, 3 y 4. En cuanto al análisis individualizado por ítem se llega a las siguientes conclusiones:

- En los ítems $Q04$ y $Q13$ los estudiantes no aprecian defectos en el subtitulado ni diferencias entre un nivel y otro. Son valoradas en ambos subtitulados con puntuaciones de 4 y de 5.

- En los ítems $Q15$, $Q16$ y $Q17$, la opción de respuesta más probable es 4. El modelo asigna una baja probabilidad de respuesta a la opción 1 y similares al resto. La probabilidad de la opción 5 decrece ligeramente entre subtitulado $A$ y $B$ y lo contrario ocurre con las opciones 2 y 3.

- Los ítems $Q01$, $Q02$, $Q03$, $Q10$, $Q11$ y $Q12$ son similares a las anteriores. Particularmente en lo referente a que la respuesta más probable en el subtitulado $B$ es 4. En el subtitulado $A$ hay preferencia por 4 y 5. El nivel 5 cae acusadamente en el subtitulado $B$ y en este nivel aumenta ligeramente la probabilidad de respuesta 2 y 3.

- Los ítems $Q06$, $Q07$, $Q14$ y $Q18$ no son muy diferentes de los anteriores. En general el modelo predice mayor probabilidad de respuesta para 5 en el subtitulado $A$ pero este valor es con alta probabilidad cercano a cero en el subtitulado $B$. En el subtitulado $B$ la probabilidad de respuesta 2, 3 ó 4 es similar.

- Los ítems $Q05$, $Q08$ y $Q09$ son los que más diferencias entre subtitulados presentan. La respuesta más probable en el subtitulado $A$ es 5 (en $Q08$ y en $Q09$ muy parecida a 4). Por contra, en el subtitulado $B$ las respuestas 4 y 5 tienden a cero, siendo la más probable la respuesta 2. En los ítems $Q05$ y $Q09$ la segunda respuesta más probable al subtitulado $B$ es 1 y 4 en el ítem $Q08$.

En definitiva, nuestro modelo predice que los estudiantes están bastante de acuerdo en que en los ítems $Q05$ y $Q09$ hay una diferencia de calidad importante entre subtitulados. También están de acuerdo en que en los ítems $Q04$ y $Q13$ no hay apenas cambio entre los subtitulados. En los ítems $Q15$, $Q16$ y $Q17$ hay una gran confusión en ambos niveles de subtitulado predominando la respuesta 4 y siendo muy parecidas las respuestas en ambos niveles. En el resto la confusión se circunscribe al nivel de subtitulado $B$, ya que en el nivel $A$ las opciones 4 y 5 predominan.

![Muestreo de la función predictiva a posteriori por tratamiento e ítem.](images/bayes-preg.png){#fig-pred-3 width="120%"}



```{r}
#| fig-height: 10
#| fig-width: 8
#| cache: true
#| eval: false
pred2_brm <- brm_treat.period.subject.item %>%
    epred_draws(ndraws = 50, newdata = expand.grid(list(Period = c(1, 2), Treat = levels(df_response$Treat), Item = levels(df_response$Item))), re_formula = ~ (1 + Treat | Item), by = c("Treat", "Item"), category = "Response") %>%
    select(Period, Treat, Item, Response, Probability = .epred, .draw) %>%
    mutate(q50 = ave(Probability, FUN = function(x) quantile(x, .5, type = 3, na.rm = TRUE))) %>%
    ungroup() %>%
    group_by(.draw, Response) %>%
    mutate(indices = cur_group_id()) %>%
    ungroup()

colors <- viridis(
    option = "plasma",
    begin = 0,
    end = 0.9,
    direction = -1,
    n = 5
)

questions_vector <- setNames(levels(df_response$Item_lr), levels(df_response$Item))

question_labeller <- function(string) paste0(string, ": ", questions_vector[string])

# Plotting the fitted draws
p <- pred2_brm %>%
    ggplot(aes(
        x = Treat,
        y = Probability,
        color = Response,
        # Don't forget the indices!
        group = indices
    )) +
    facet_wrap(~Item, nrow = 6, labeller = as_labeller(question_labeller)) +
    geom_line(alpha = 0.4) +
    scale_color_manual(values = colors) +
    # We won't need these
    guides(
        color = FALSE,
        label = FALSE,
        scale = "none"
    ) +
    theme_ipsum_ps(base_family = NULL)
p +
    labs(
        x = "Treat",
        y = "Probability"
    ) +
    theme(
        plot.margin = margin(0, 100, 0, 0)
    ) +
    # This allows any labels or data to go past the grid
    coord_cartesian(clip = "off") +
    # Finally, our labels. We filter the data to avoid having a million of them
    geom_text_repel(
        data = pred2_brm %>% filter(Probability == q50 & Item %in% c("Q02", "Q05", "Q08", "Q11", "Q14", "Q17") & Period == 2, Treat == "B") %>% distinct(Treat,
            Period, Item, Response,
            .keep_all = TRUE
        ) %>% mutate(Response_l = ordered(Response, labels = levels(df_response$Response_l))),
        aes(label = Response_l),
        direction = "y",
        hjust = 0,
        segment.size = 0.2,
        # Move the labels to the right
        nudge_x = 0.1,
        na.rm = TRUE,
        # Expand limits so that the label doesn't get stuck
        xlim = c(0, 5),
        # Adjust size as needed!
        size = 5.5
    ) + scale_x_discrete(expand = expansion(mult = c(0, .5)), limits = c("A", "B")) + theme(panel.spacing.x = unit(-5, "lines"), axis.title.x = element_text(size = 15), axis.title.y = element_text(size = 15), strip.text = element_text(size = 12))

```

```{r}
source("_setup.R")
```


# Discusión {#sec-discusion}



```{r}
#| eval: true
#| cache: false

q.errors <- c("Q02", "Q05", "Q06", "Q07", "Q08", "Q09", "Q10", "Q11", "Q12", "Q14", "Q18")
q.no.errors <- setdiff(levels(df_response$Item), q.errors)
``` 

```{r}
#| eval: true
#| cache: false

improve_question <- 1 / (1 + exp(-ranef(glmer_improve_subject_question)$Item - fixef(glmer_improve_subject_question)))

improve_question <- cbind(rownames(improve_question), improve_question)
colnames(improve_question) <- c("Item", "Prob")

df_improve <- inner_join(
    df_improve %>% group_by(Item) %>% summarize(n = n(), improve = sum(Improve), Freq = improve / n) %>% select(Item, Freq),
    improve_question
)

newdata <- df_response %>%
    select(Treat, Item) %>%
    distinct()

Prob <- predict(glmer_positive_treat_subject_question,
    type = "response", newdata = newdata,
    re.form = ~ (1 + Treat | Item)
)

df_positive <- cbind(newdata, Prob)
df_positive <- inner_join(
    df_response %>%
        group_by(Treat, Item) %>%
        summarize(Freq = sum(Level == "Positivo") / n()) %>%
        ungroup(),
    df_positive
)
df_positive <- df_positive %>%
    pivot_wider(id_cols = Item, names_from = Treat, values_from = c(Freq, Prob)) %>%
    select(1, 2, 4, 3, 5)

g <- inner_join(df_improve, df_positive) %>%
    gt() %>%
    tab_spanner(label = "Improve Model", columns = c(Freq, Prob), level = 2) %>%
    tab_spanner(label = "Positive Model", columns = c(Freq_A, Prob_A, Freq_B, Prob_B), level = 2) %>%
    tab_spanner(label = "Treat A", ends_with("_A"), level = 1) %>%
    tab_spanner(label = "Treat B", ends_with("_B"), level = 1) %>%
    tab_row_group(label = "Control Items", row = Item %in% q.no.errors) %>%
    tab_row_group(label = "Evaluated Items", rows = Item %in% q.errors) %>%
    fmt_percent(decimals = 1) %>%
    data_color(
        rows = Item %in% q.errors, columns = Prob, palette = "ggsci::grey_material", target_columns = c(Freq, Prob), reverse = T, domain = c(0.4, 1)
    ) %>%
    data_color(
        rows = Item %in% q.no.errors, columns = Prob, palette = "ggsci::grey_material", target_columns = c(Freq, Prob), domain = c(0, 1)
    ) %>%
    data_color(
        rows = Item %in% q.errors, columns = Prob_B, palette = "ggsci::grey_material", target_columns = c(Freq_B, Prob_B)
    ) %>%
    data_color(
        rows = Item %in% q.no.errors, columns = Prob_B, palette = "ggsci::grey_material", target_columns = c(Freq_B, Prob_B), reverse = T, , domain = c(-0.5, 1)
    ) %>%
    cols_label(Freq_A = "Freq", Prob_A = "Prob", Freq_B = "Freq", Prob_B = "Prob")


gtsave(g, "images/improve.png", expand=c(10,20,10,0))
```



\scriptsize

```{r}
#| eval: true
#| cache: false
#|
set.seed(100)
df_prob_data <- df_response %>%
    dplyr::select(Subject, Period, Seq, Treat, Response, Item) %>%
    arrange(Treat, Item, Response) %>%
    group_by(Treat, Item, Response, .drop = F) %>%
    summarize(n = n()) %>%
    ungroup(Response) %>%
    mutate(acc = cumsum(n), `Prob_data` = n / last(acc)) %>%
    pivot_wider(
        id_cols = c(Treat, Item),
        names_from = c(Response),
        values_from = c(Prob_data),
        names_glue = "{Response}_{.value}"
    )

df_prob_model <- epred_draws(brm_treat.period.subject.item, expand.grid(list(Period = c(1, 2), Treat = levels(df_response$Treat), Item = levels(df_response$Item))), re_formula = ~ (1 + Treat | Item)) %>%
    group_by(Treat, Item, .category) %>%
    summarize(q10 = quantile(.epred, probs = 0.1), q50 = quantile(.epred, probs = 0.5), q90 = quantile(.epred, probs = 0.9)) %>%
    ungroup() %>%
    pivot_wider(
        names_from = c(.category),
        values_from = c(q10, q50, q90),
        names_glue = "{.category}_{.value}"
    )

g3 <- inner_join(df_prob_data, df_prob_model) %>%
    pivot_wider(id_cols = Item, names_from = Treat, values_from = starts_with(paste(1:5))) %>%
    dplyr::select(Item, ends_with("A"), ends_with("B")) %>%
    ungroup() %>%
    gt() %>%
    fmt_number(columns = contains("_q"), decimals = 1, scale = 100) %>%
    fmt_percent(columns = contains("_data"), decimals = 1) %>%
    cols_merge(columns = c("1_q10_A", "1_q50_A", "1_q90_A"), pattern = "{2}%") %>%
    cols_merge(columns = c("2_q10_A", "2_q50_A", "2_q90_A"), pattern = "{2}%") %>%
    cols_merge(columns = c("3_q10_A", "3_q50_A", "3_q90_A"), pattern = "{2}%") %>%
    cols_merge(columns = c("4_q10_A", "4_q50_A", "4_q90_A"), pattern = "{2}%") %>%
    cols_merge(columns = c("5_q10_A", "5_q50_A", "5_q90_A"), pattern = "{2}%") %>%
    cols_merge(columns = c("1_q10_B", "1_q50_B", "1_q90_B"), pattern = "{2}%") %>%
    cols_merge(columns = c("2_q10_B", "2_q50_B", "2_q90_B"), pattern = "{2}%") %>%
    cols_merge(columns = c("3_q10_B", "3_q50_B", "3_q90_B"), pattern = "{2}%") %>%
    cols_merge(columns = c("4_q10_B", "4_q50_B", "4_q90_B"), pattern = "{2}%") %>%
    cols_merge(columns = c("5_q10_B", "5_q50_B", "5_q90_B"), pattern = "{2}%") %>%
    cols_label_with(
        fn = function(x) substr(x, 1, 1), columns = matches("Prob|[1-5]")
    ) %>%
    tab_spanner(label = "Data Frequencies", ends_with("Prob_data_A"), level = 1, id = "data_A") %>%
    tab_spanner(label = "Model Prob.", ends_with("_q10_A"), level = 1, id = "model_A") %>%
    tab_spanner(label = "Data Frequencies", ends_with("Prob_data_B"), level = 1, id = "data_B") %>%
    tab_spanner(label = "Model Prob.", ends_with("_q10_B"), level = 1, id = "model_B") %>%
    tab_spanner(label = "Treat A", ends_with("_A"), level = 2) %>%
    tab_spanner(label = "Treat B", ends_with("_B"), level = 2) %>%
    data_color(method = "numeric", columns = ends_with("A"), palette = "ggsci::blue_material", direction = "row") %>%
    data_color(method = "numeric", columns = ends_with("B"), palette = "ggsci::orange_material", direction = "row") %>%
    cols_align(align = "center", columns = everything()) %>%
    tab_style(style = cell_borders(sides = c("top", "bottom"), color = "blue", weight = px(3.5), style = "dashed"), locations = cells_body(rows = Item %in% q.errors, columns = ends_with("_A"))) %>%
    tab_style(
        style = cell_borders(sides = c("right"), color = "blue", weight = px(3.5), style = "dashed"),
        locations = cells_body(rows = Item %in% q.errors, columns = Item)
    ) %>%
    tab_style(
        style = cell_borders(sides = c("top", "bottom"), color = "#ff4d00", weight = px(3.5), style = "dashed"),
        locations = cells_body(rows = Item %in% q.errors, columns = ends_with("_B"))
    ) %>%
    tab_style(
        style = cell_borders(sides = c("right"), color = "#ff4d00", weight = px(3.5), style = "dashed"),
        locations = cells_body(rows = Item %in% q.errors, columns = "5_q10_B")
    ) %>%
    gt_highlight_rows(rows = Item %in% q.errors, columns = Item) %>%
    tab_style(style = cell_text(weight = "bold"), cells_body(rows = Item %in% q.errors))

gtsave(g3, "images/bayes-probs.png", vwidth = 1500, expand = c(0, 15, 0, 0))

# g %>% as_raw_html()
```

\normalsize



```{r}
comments_df <- read_delim(
    "./data/preprocess/comments.csv",
    delim = ",", show_col_types = FALSE
)
```


En este capítulo se discuten los resultados una vez "descubierto el ciego" y se responde a la pregunta de investigación y a los objetivos específicos planteados en la @sec-objetivos. Las respuestas a estas preguntas llevan a concluir que se ha cumplido el objetivo principal del estudio: los estudiantes del curso MOOC son capaces de evaluar las diferencias en la calidad del subtitulado de dos vídeos. Se discuten también las limitaciones del estudio y posibles mejoras al mismo.

Una vez realizado el análisis estadístico y obtenidos los resultados (ver @sec-resultados) se reveló que el subtitulado que en este trabajo se ha denominado $A$ se corresponde con el vídeo correctamente subtitulado. Adicionalmente se ha suministrado un documento que contiene los errores introducidos en el subtitulado $B$. A partir del mismo, se ha elaborado la Tabla \ref{tbl-blind-errors} en la que se muestra la correspondencia de cada error con los ítems de la \gls{escala de likert} a la que respondieron los estudiantes (ver en la @tbl-likert-scale una descripción textual de cada ítem). Para `r length(q.no.errors)` de los `r length(q.no.errors) + length(q.errors)` ítems (`r paste(q.no.errors, collapse=", ")`) no se ha encontrado una adscripción clara en el documento de errores y, por lo tanto, esos ítems sirven de control del test y sería esperable que en ellos las respuestas de los estudiantes fueran similares en ambos subtitulados.


```{=tex}
\begin{table}[]
\caption{\label{tbl-blind-errors}Correspondencia entre los errores introducidos en el subtitulado del vídeo B y los ítems de la escala de Likert.}\tabularnewline
\tiny
\begin{adjustwidth}{-2.5cm}{}
\begin{tabular}{|c|l|l|l|}
\hline
\multicolumn{1}{|l|}{\textbf{Error nº}} &
  \textbf{Subtítulo incorrecto} &
  \textbf{Requisito que se incumple} &
  \textbf{Ítems} \\ \hline
1 &
  Hola este video nos ba a servir &
  \begin{tabular}[c]{@{}l@{}}Los subtítulos deben ser correctos\\ ortográfica y gramaticalmente.\end{tabular} &
  Q05 \\ \hline
2 &
  \begin{tabular}[c]{@{}l@{}}para hacer una prácti\\ ca de subtitulado\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}No se deben separar en dos líneas\\ las sílabas de la misma palabra.\end{tabular} &
  Q14 \\ \hline
3 &
  \begin{tabular}[c]{@{}l@{}}Podemos pensar en personas \\ que no entienden bien \\ un determinado idioma\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Los subtítulos deben ocupar\\ dos líneas y, excepcionalmente tres.\end{tabular} &
  Q02 \\ \hline
4 &
  \begin{tabular}[c]{@{}l@{}}Muchos ejemplos que \\ harán que estos subtítulos\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Las conjunciones y los nexos\\ deben ir en la línea inferior.\end{tabular} &
  Q14 \\ \hline
5 &
  \begin{tabular}[c]{@{}l@{}}El texto del subtítulo es válido,\\ pero su entrada debe producirse antes para que\\ coincida con la información sonora.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Las entradas y salidas de los subtítulos\\ deben coincidir con el movimiento labial,\\ con la locución y/o con la información sonora.\end{tabular} &
  Q10, Q09 \\ \hline
6 &
  Perdonad &
  \begin{tabular}[c]{@{}l@{}}Deben describirse los efectos sonoros\\ que sean relevantes para la comprensión del vídeo.\end{tabular} &
  Q09 \\ \hline
7 &
  ¿Dígame? (EMI) Hola, soy Emilio. &
  \begin{tabular}[c]{@{}l@{}}Para cada participante en el diálogo\\ debe comenzarse una nueva línea.\end{tabular} &
  Q08 \\ \hline
8 &
  (ALE) Emilio, muy buenas. Mira, precisamente estoy grabando el vídeo &
  \begin{tabular}[c]{@{}l@{}}El máximo número de caracteres\\ por línea es 37.\end{tabular} &
  Q12 \\ \hline
9 &
  \begin{tabular}[c]{@{}l@{}}El texto del subtítulo es válido,\\ pero su duración debe ser de al menos 3 segundos.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}La velocidad de exposición del subtítulo\\ debe permitir leerlo sin dificultad.\\ La velocidad recomendada para los subtítulos\\ es de unos 12 caracteres por segundo.\end{tabular} &
  Q11 \\ \hline
10 &
  Luego voy a verte al despacho ¿Ok? &
  Los subtítulos deben ser literales. &
  Q06 \\ \hline
11 &
  \begin{tabular}[c]{@{}l@{}}Muy bien, estupendo. Aquí estaré. \\ Hasta luego\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Los diferentes personajes que intervienen en la\\ obra audiovisual deben estar claramente identificados.\end{tabular} &
  Q07 \\ \hline
\end{tabular}
\end{adjustwidth}
\normalsize
\end{table}
```


Para responder a las preguntas de investigación se van a utilizar los hallazgos del Análisis Exploratorio (ver @sec-eda) y los resultados de los tres modelos comentados en el @sec-resultados:

* \gls{Regresión Logística} con variable respuesta `Improve`, que calcula la probabilidad de que la respuesta a un ítem mejore entre subtitulados $A$ > $B$ (ver @sec-logistica-3).
* \gls{Regresión Logística} con variable respuesta `Positive`, que calcula la probabilidad de que la respuesta a un ítem sea positiva (4 ó 5).
* \gls{Regresión Ordinal} con variable Respuesta `Response`, que calcula la probabilidad de cada nivel de respuesta (ver @sec-ordinal-3).

Para mayor comodidad del lector se vuelven a plantear aquí la pregunta de investigación y los objetivos específicos:

::: {.callout-note}
## Pregunta de investigación

¿Son los estudiantes de un curso de creación de materiales accesibles capaces de evaluar las diferencias en la calidad del subtitulado de un vídeo?
:::

El subtitulado $A$, que es el correcto, ha sido mejor evaluado por los estudiantes. Esto se ha constatado tanto en la exploración inicial como en cada uno de los tres modelos propuestos. Por ejemplo, en la exploración inicial se vio que la respuesta más frecuente en el subtitulado $A$ es 5 y en el $B$ es 4 y en ll modelo con variable respuesta `Improve` predice que la probabilidad de que se otorgue una mayor puntuación en $A$ que en $B$ es `r paste(round(100/(1+exp(-fixef(glmer_improve_subject_question)[[1]])),2),"%", sep="")`. Por lo tanto, se concluye respondiendo afirmativamente a la pregunta: los estudiantes del curso han sabido evaluar las diferencias en el subtitulado de los vídeos.


::: {.callout-tip}
## Objetivo específico

¿En qué pautas de subtitulado los estudiantes tienen mayor facilidad para reconocer diferencias entre un subtitulado correcto y otro incorrecto?
:::

La respuesta a esta pregunta requiere un análisis pormenorizado ítem a ítem. Se ha elaborado una tabla para los dos modelos logísticos y otra para el modelo de Regresión Ordinal. La @fig-or contiene la tabla de los dos modelos logísticos. Para su correcta interpretación se deben tener en cuenta las siguientes premisas:

* En la parte izquierda se presentan los resultados del modelo logístico con variable respuesta `Improve` y en la derecha el modelo logístico con variable respuesta `Positive`.
* En la parte superior se presentan los ítems en los que hay diferencias en el subtitulado y que son objeto de este objetivo específico. En la parte inferior se muestran los ítems que se usan como control ya que no hay diferencias en ellos entre subtitulados y se analizan en el objetivo correspondiente.
* La columna `Freq` es la frecuencia relativa de las tablas de contingencia que resultan del análisis exploratorio. La columna `Prob` son las probabilidades predichas por cada uno de los modelos.
* Los datos se muestran con un fondo coloreado con una tonalidad más oscura cuando más inesperado sea el resultado obtenido. 

En el modelo con variable respuesta `Improve` (ver parte izquierda de @fig-or), los alumnos han sabido de identificar correctamente errores de subtitulado en $Q05$ (`r tolower(question_labels[6])`), $Q06$ (`r tolower(question_labels[7])`), $Q07$ (`r tolower(question_labels[8])`), $Q08$ (`r tolower(question_labels[9])`), $Q09$ (`r tolower(question_labels[10])`) y $Q14$ (`r tolower(question_labels[15])`).

En la parte derecha de la @fig-or se muestran las predicciones del modelo con variable respuesta `Positive` de obtener una respuesta con nivel 4 ó 5. Las conclusiones que se pueden extraer son muy similares a las del modelo con variable respuesta `Improve`.

![Predicciones de los modelos de Regresión Logística](images/improve.png){#fig-or height=70%}

En la Figura \ref{fig-prob-compare} se muestran las probabilidades por nivel de respuesta, ítem y nivel de subtitulado correspondiente al modelo de Regresión Ordinal y se comparan con las frecuencias de la tabla de contingencia. Los ítems con errores se presentan en negrita y recuadrados. Se observa que en el subtitulado $A$ todas las respuestas a los ítems se concentran en valores positivos (4 ó 5). En el subtitulado $B$ se espera que los ítems en los que se han introducido errores tengan peores valoraciones. Esto sucede claramente en $Q05$ y en $Q09$ y también aunque en menor medida en $Q06$, $Q07$, $Q08$ y $Q14$. Estos ítems coinciden con los que se han destacado en los dos modelos logísticos y son, por lo tanto, en los que los estudiantes reconocen más fácilmente diferencias entre subtitulados.


```{=tex}

\begin{figure}[h]
\begin{adjustwidth}{-3.4cm}{}

\includegraphics[width=1.2\linewidth]{images/bayes-probs.png} \hfill{}

\caption{\label{fig-prob-compare}Predicciones del modelo de Regresión Logística.}

\end{adjustwidth}
\end{figure}

```




::: {.callout-tip}
## Objetivo específico

¿En qué pautas de subtitulado los estudiantes tienen más dificultades para reconocer diferencias entre un subtitulado correcto y otro incorrecto?
:::

Los dos modelos logísticos (ver @fig-or) coinciden en que los estudiantes tienen dificultad para reconocer diferencias en el subtitulado en los ítems:

* $Q02$ (`r tolower(question_labels[3])`) con probabilidad predicha de mejorar la valoración de `r paste(round(100*(improve_question$Prob)[3],2),"%",sep="")`.
* $Q10$ (`r tolower(question_labels[11])`) con probabilidad de mejora `r paste(round(100*(improve_question$Prob)[11],2),"%",sep="")`.
* $Q11$ (`r tolower(question_labels[12])`) con probabilidad `r paste(round(100*(improve_question$Prob)[12],2),"%",sep="")`.
* $Q12$ (`r tolower(question_labels[13])`) con probabilidad `r paste(round(100*(improve_question$Prob)[13],2),"%",sep="")`.

En estos mismos ítems, el modelo ordinal (ver Figura \ref{fig-prob-compare}) predice más respuestas negativas en el subtitulado $B$ que en el $A$ pero aún así el subtitulado $B$ tiene un alto número de respuestas positivas.

Para entender las motivaciones de las valoraciones de los alumnos se han analizado los comentarios que dejaron
^[Estos comentarios se separaron en la fase de preprocesado y no se han utilizado ni consultado hasta la realización de este capítulo.]. La siguiente es una selección de los comentarios más relevantes en cada ítem:

* $Q02$, **`r tolower(question_labels[3])`**: En los comentarios al subtitulado $A$ hay bastantes que se quejan del número excesivo de líneas.  

\small
> Subtitulado $A$: `r paste("'",(comments_df %>% filter(Item == "02" & Row %in% c(50,41,100,108)) %>%  arrange(Group, Response))$Comment, "'", collapse=", ", sep="")`.

\normalsize

* $Q10$, **`r tolower(question_labels[11])`**: En los comentarios al subtitulado $A$ hay algunos que dicen que hay falta de sincronización y, por el contrario, en el $B$ que estaban bien sincronizados. Hay por tanto una falta de atención de algunos estudiantes para evaluar este aspecto del subtitulado.

\small
> Subtitulado $A$: `r paste("'",(comments_df %>% filter(Item == "10" & Row %in% c(111,123,99,88)) %>%  arrange(Group, Response))$Comment, "'", collapse=", ", sep="")`.

\normalsize

\small
> Subtitulado $B$: `r paste("'",(comments_df %>% filter(Item == "10" & Row %in% c(45,72,96,219,24,52)) %>%  arrange(Group, Response))$Comment, "'", collapse=", ", sep="")`.

\normalsize

* $Q11$, **`r tolower(question_labels[12])`**: Los comentarios al subtitulado $B$ denotan que muchos estudiantes no han tenido en cuenta que el subtítulo debe permanecer al menos tres segundos en la pantalla.

\small
> Subtitulado $B$: `r paste("'",(comments_df %>% filter(Item == "11" & Row %in% c(102,120,52,219,48,124)) %>%  arrange(Group, Response))$Comment, "'", collapse=", ", sep="")`.

\normalsize


* $Q12$, **`r tolower(question_labels[13])`**: Los comentarios denotan que en general los alumnos conocen el número máximo de caracteres por línea, pero que no se han detenido a medir cuántos hay realmente. 

\small
> Subtitulado $A$: `r paste("'",(comments_df %>% filter(Item == "12" & Row %in% c(142)) %>%  arrange(Group, Response))$Comment, "'", collapse=", ", sep="")`.

\normalsize

\small
> Subtitulado $B$: `r paste("'",(comments_df %>% filter(Item == "12" & Row %in% c(164,109,264)) %>%  arrange(Group, Response))$Comment, "'", collapse=", ", sep="")`.

\normalsize

Se aprecia que los alumnos tienen dificultades para valorar las diferencias en la calidad del subtitulado en estos aspectos principalmente porque, aunque conozcan las normas de subtitulado, no han comprobado que se estén cumpliendo en los vídeos de la actividad.


::: {.callout-tip}
## Objetivo específico

¿Son los estudiantes capaces de valorar de forma similar los aspectos del subtitulado que no cambian en los vídeos?
:::

Los ítems en los que no se han introducido errores deberían ser valorados de forma similar por los estudiantes. En los modelos logísticos las probabilidades y frecuencias de estos ítems se muestran en la parte inferior de la tabla de la @fig-or y en el modelo ordinal son las filas no resaltadas de la tabla de la Figura \ref{fig-prob-compare}. Se comprueba que los ítems $Q04$ (`r tolower(question_labels[5])`) y $Q13$ (`r tolower(question_labels[14])`) se valoran, como se esperaba, de forma positiva y similar en ambos subtitulados. Los ítems $Q01$ (`r tolower(question_labels[2])`) y $Q03$ (`r tolower(question_labels[4])`) se valoran positivamente en el subtitulado $A$, pero en el subtitulado $B$ hay una polarización de las valoraciones habiendo muchas positivas y negativas y pocas neutras. Por último, los ítems $Q15$ (`r tolower(question_labels[16])`), $Q16$ (`r tolower(question_labels[17])`) y $Q17$ (`r tolower(question_labels[18])`) tienen una valoración comparativamente inferior al resto de ítems en el subtitulado $A$.Esta valoración todavía inferior en el subtitulado $B$. Los estudiantes que han realizado comentarios en estos ítems indican que ninguno de ellos es aplicable a los vídeos. Ante esta circunstancia, los alumnos han consignado distintas valoraciones: algunos han contestado "No sé / No contesto", otros han consignado valoraciones neutrales y, finalmente, otros han optado por valoraciones positivas y negativas.

::: {.callout-tip}
## Objetivo específico
Efecto secuencia: ¿El orden en el que vieron los vídeos los estudiantes influye en la calidad del subtitulado percibida?
:::

::: {.callout-tip}
## Objetivo específico
Efecto periodo: ¿La evaluación del subtitulado del segundo vídeo visto está influida por haber evaluado un vídeo previamente?
:::

Estos objetivos se responden de forma conjunta por estar ambos efectos relacionados ya que, como se ha explicado, el efecto secuencia en un estudio cruzado $AB/BA$ es la interacción entre el tratamiento y el periodo. 

En el modelo ordinal `Response ~ Treat * Period` (ver @sec-response-treat.period) se constató que tanto el periodo como la secuencia sin significativos. No obstante, estos efectos son mucho menos importantes que los debidos al subtitulado. Al introducir como variables explicativas el estudiante y el ítem (ver @sec-multinivel-2) tanto el efecto como la secuencia pasan a ser no significativos. En la @sec-or-3 se comprobó que estos efectos se producen porque la proporción de respuestas de nivel 5 en el subtitulado $A$ sobre el $B$ es superior en el primer periodo que en el segundo y lo contrario ocurre con las de nivel 4. En el  modelado logístico ni la secuencia ni el periodo resultaron significativos. Se concluye que ni el efecto secuencia ni el efecto periodo tienen significación estadística.


# Conclusión y trabajo futuro {#sec-conclusion}

Este trabajo ha pretendido responder a la pregunta de investigación de si los estudiantes de un curso de \gls{accesibilidad} son capaces de identificar los errores en el subtitulado de un vídeo, y como objetivos específicos averiguar qué aspectos del subtitulado han sido más fácilmente reconocidos por los estudiantes y en cuáles han tenido más dificultad. Para ello se ha partido de una Exploración Inicial (ver @sec-eda) y se han propuesto varios modelos estadísticos que tengan en cuenta la naturaleza ordinal y dependiente de la variable respuesta (ver @sec-modelos-utilizados). Como variables explicativas se ha considerado el nivel de subtitulado, el periodo en el que se ha realizado cada test, la secuencia u orden de realización de los test, el estudiante que ha realizado el test y el ítem al que se responde.

La conclusión más importante es que todos los análisis estadísticos realizados muestran que el nivel de subtitulado es la variable que mejor explica la respuesta a cada ítem. Los efectos secuencia y periodo son comparativamente de poca importancia y se traducen en que en general los estudiantes valoran peor el vídeo visto en el segundo periodo para un mismo nivel de subtitulado. Las variables estudiante e ítem se han tratado como efectos aleatorios por haber considerado que sus observaciones no son independientes. La varianza explicada por la variable estudiante ha sido más grande que la explicada por la variable ítem.

Los estudiantes han sabido reconocer los errores de subtitulado de los ítems $Q05$ (`r tolower(question_labels[6])`), $Q06$ (`r tolower(question_labels[7])`), $Q07$ (`r tolower(question_labels[8])`), $Q08$ (`r tolower(question_labels[9])`), $Q09$ (`r tolower(question_labels[10])`) y $Q14$ (`r tolower(question_labels[15])`).

Sin embargo, han tenido más dificultades en identificar los errores introducidos en los ítems $Q02$ (`r tolower(question_labels[3])`), $Q10$ (`r tolower(question_labels[11])`), $Q11$ (`r tolower(question_labels[12])`) y $Q12$ (`r tolower(question_labels[13])`). El análisis realizado sobre los comentarios a estos ítems, evidencia que los estudiantes han aprendido las normas que debe regir el subtitulado en estos aspectos pero que no han evaluado minuciosamente si se cumplen realmente. Hay que tener en consideración que esta fue una actividad voluntaria sin incidencia en la calificación del curso, y que en una situación real esto no habría sucedido y habrían realizado una corroboración minuciosa.

En definitiva, los estudiantes conocen las normas de subtitulado y son capaces identificar los errores que no requieren una comprobación exhaustiva. En los que sí lo requieren, algunos estudiantes han contestado sin realizar las comprobaciones necesarias.

En cuanto a los ítems que tratan aspectos en los que no hay errores en ninguno de los vídeos, los estudiantes han valorado positivamente ambos subtitulados en los ítems $Q04$ (`r tolower(question_labels[5])`) y $Q13$ (`r tolower(question_labels[14])`). Esto no implica necesariamente que, de haber habido deficiencias en estos aspectos, las hubieran reconocido. De hecho, hay evidencias de que los estudiantes noveles tienen dificultades en la identificación de deficiencias en el contraste [ver @jperez2].

En los ítems $Q01$ (`r tolower(question_labels[2])`) y $Q03$ (`r tolower(question_labels[4])`) los alumnos han manifestado en los comentarios la existencia de problemas en el ítem $Q01$ en el subtitulado $B$ y en el ítem $Q03$ y subtitulado $A$. Sería conveniente que fuera evaluado por un experto en subtitulado si realmente los subtítulos son correctos en estos aspectos o si es que no han sido evaluados adecuadamente por los estudiantes.

Los ítems $Q15$ (`r tolower(question_labels[16])`), $Q16$ (`r tolower(question_labels[17])`) y $Q17$ (`r tolower(question_labels[18])`) preguntan cuestiones que no se producen en los vídeos y que son relativamente fáciles de verificar. En las respuestas de los estudiantes han confluido varios problemas verificables a través de los comentarios a los ítems. Por un lado, algunos estudiantes manifiestan que no recuerdan con seguridad la existencia de lo preguntado (puntos suspensivos, números, ...). Este problema no es importante ya que es de suponer que en una situación de evaluación de subtitulado real realizarían un segundo visionado de los vídeos para asegurarse. Más preocupante resulta el segundo de los problemas detectados ya que podría estar también presente en otros ítems y haber pasado inadvertido en este trabajo. El problema en cuestión es que en estos ítems la respuesta esperable es "No sé / No contesto". En la @tbl-no-response se constató que estos son los ítems que más respuestas de este nivel reciben pero que esta respuesta no es masiva. Muchos estudiantes se decantan por valoraciones negativas, positivas o neutrales a pesar de haber indicado en los comentarios que la pregunta realizada no tiene aplicación en la actividad. Este problema es una preocupación general en análisis de escalas de Likert. Por ejemplo, ver @tutz2020 para una propuesta de modelado estadístico de la categoría neutral en una escala de Likert. Un tercer problema detectado en estos ítems que es probable que también haya tenido incidencia en otros ítems es que, a pesar de que los comentarios revelan que los estudiantes piensan que estos ítems no tienen aplicación en ninguno de los vídeos, obtienen peor valoración en el subtitulado $B$ que en el $A$. Esto estaría indicando que las contestaciones de los estudiantes sufren cierto "efecto de ventana rota". La hipótesis que aquí se plantea para explicar por qué el subtitulado $B$ ha obtenido peores respuestas que el $A$ incluso en ítems en los que el estudiante sabe que los subtitulados son idénticos es la siguiente: Hay ítems como $Q05$ (`r tolower(question_labels[6])`) que son fáciles de identificar y responder por los estudiantes. Si el estudiante encuentra una falta de ortografía en un subtitulado, estaría psicológicamente condicionado a ser más crítico con cualquier otro aspecto del subtitulado. Ante una pregunta que el estudiante no recuerda haber encontrado (por ejemplo, la presencia de puntos suspensivos) tiene a una valoración inferior en el subtitulado con faltas de ortografía porque considera que existe la posibilidad de haber pasado por alto la presencia de puntos suspensivos. Esto no sucede en todos los casos. Por ejemplo, en la pregunta sobre el contraste (ítem $Q04$), la diferencia entre subtitulados aunque existe es menor. La hipótesis expuesta es coherente con este hecho ya que, mientras que los puntos suspensivos son algo puntual cuya existencia el estudiante sabe que puede pasar inadvertida, el contraste es algo que afecta o puede afectar a todo el subtitulado del vídeo.

Estas conclusiones abren varias vías de investigación que se enumeran aquí a modo de propuesta y sin ánimo de exhaustividad:

* Incorporar al modelo variables como el sexo, la edad, el lugar de nacimiento, el nivel de estudios o el grado de conocimientos de accesibilidad previo. En el momento de realizar este trabajo se disponía de esta información aunque de forma muy incompleta ya que la mayoría de los estudiantes participantes no suministraron la información personal.
* Volver a realizar el análisis completo con los mismos datos pero incorporando desde el principio el conocimiento del subtitulado correcto y siendo más crítico con la calidad de los datos, lo que llevaría a eliminar alguno de los cuestiorarios.
* Analizar los datos de la edición del curso de 2023 para ver en qué medida los modelos y las conclusiones se mantienen o cambian.
* Plantear mejoras en la recogida de datos como, por ejemplo, indicaciones detalladas de como responder en caso de duda, desconocimiento, inaplicabilidad, ....
* Sería interesante ver cómo cambian las respuestas de los estudiantes si en ambos vídeos se introducen errores en el subtitulado en diferentes aspectos.
* Añadir errores de subtitulado para todos o casi todos los ítems.
* Además de las respuestas de los estudiantes, se podría plantear la actividad a profesionales del subtitulado para evaluar las semejanzas y diferencias entre grupos.


