% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
  a4paper,
  extrafontsizes,
  onecolumn,
  openright]{memoir}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[Extension=.otf,UprightFont=*-regular,BoldFont=*-bold,BoldItalicFont=*-bolditalic,ItalicFont=*-italic]{texgyretermes}
  \setmathfont[]{texgyretermes-math.otf}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
% pandoc tempate
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

% Add LaTeX code into the preamble of the document here
\hyphenation{bio-di-ver-si-ty sap-lings}

% Define colors for text boxes
\definecolor{grey}{HTML}{F5F5F5}

% Define text box environments
\usepackage[tikz]{bclogo}
\newmdenv[
  style=boxstyle,
  backgroundcolor=grey,
  frametitlebackgroundcolor=grey,
]{greybox}

\usepackage[automake]{glossaries-extra}
\makeglossaries


\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Tabla de contenidos}
\else
  \newcommand\contentsname{Tabla de contenidos}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Listado de Figuras}
\else
  \newcommand\listfigurename{Listado de Figuras}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Listado de Tablas}
\else
  \newcommand\listtablename{Listado de Tablas}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figura}
\else
  \newcommand\figurename{Figura}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabla}
\else
  \newcommand\tablename{Tabla}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listado}
\newcommand*\listoflistings{\listof{codelisting}{Listado de Listados}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother


% Additional content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\graphicspath{{images/}}


% Chapter Summary environment
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[tikz]{bclogo}
\newenvironment{Summary}
  {\begin{bclogo}[logo=\bctrombone, noborder=true, couleur=lightgray!50]{In
a Nutshell}\parindent0pt}
  {\end{bclogo}}
% Syntax:
%
%```{block, type='Summary'}
% Deliver message here.
% ```


% PDF title page to insert
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Fonts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Local toc
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{titletoc}
\newcommand{\toc}[1]{%
  \startcontents[chapters]%
  \printcontents[chapters]{}{1}[#1]{}%
  ~\newline%
}


% Text boxes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Define a style for mdframed boxes
\mdfdefinestyle{boxstyle}{
	skipabove=1.5\topskip,
	skipbelow=.5\topskip,
	rightmargin=0pt,
	leftmargin=0pt,
	innerrightmargin=7pt,
	innerleftmargin=7pt,
	topline=false,
	bottomline=false,
	rightline=false,
	leftline=false,
	frametitlerule=true,
	linecolor=black,
	fontcolor=black,
	frametitlealignment=\noindent
}


% Layout
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Based on memoir, style companion
\newcommand{\MemoirChapStyle}{daleif1}
\newcommand{\MemoirPageStyle}{Ruled}

% Space between paragraphs
\usepackage{parskip}
  \abnormalparskip{3pt}

% Adjust margin paragraphs vertical position
\usepackage{marginfix}


% Margins
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% allow use of '-',+','/' ans '*' to make simple length computation
\usepackage{calc}

% Full-width figures utilities
\newlength\widthw % full width
\newlength{\rf}
\newcommand*{\definesHSpace}{
  \strictpagecheck % slower but efficient detection of odd/even pages
  \checkoddpage
  \ifoddpage
  \setlength{\rf}{0mm}
  \else
  \setlength{\rf}{\marginparsep+\marginparwidth}
  \fi
}

\makeatletter
% 1" margins for the front matter.
\newcommand*{\SmallMargins}{
  \setlrmarginsandblock{1.5in}{1.5in}{*}
  \setmarginnotes{0.1in}{0.1in}{0.1in}
  \setulmarginsandblock{1.5in}{1in}{*}
  \checkandfixthelayout
  \ch@ngetext
  \clearpage
  \setlength{\widthw}{\textwidth+\marginparsep+\marginparwidth}
  \footnotesatfoot
  \chapterstyle{\MemoirChapStyle}  % Chapter and page styles must be recalled
  \pagestyle{\MemoirPageStyle}
}

% 3" outer margin for the main matter
\newcommand{\LargeMargins}{\SmallMargins}
\makeatother

% Figure captions and footnotes in outer margins


%% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Repeated citation as author-year-title instead of author-title (modification of footcite:note in verbose-inote.cbx)


% memoiR dalef3 chapter style
% https://ctan.crest.fr/tex-archive/info/latex-samples/MemoirChapStyles/MemoirChapStyles.pdf
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{soul}
\definecolor{nicered}{rgb}{.647,.129,.149}
\makeatletter
\newlength\dlf@normtxtw
\setlength\dlf@normtxtw{\textwidth}
\def\myhelvetfont{\def\sfdefault{mdput}}
\newsavebox{\feline@chapter}
% \so\protect\@chapapp replaces \so\@chapapp or \so will fail with babel
\newcommand\feline@chapter@marker[1][4cm]{%
  \sbox\feline@chapter{%
    \resizebox{!}{#1}{\fboxsep=1pt%
	  \colorbox{nicered}{\color{white}\bfseries\sffamily\thechapter}%
	}}%
  \rotatebox{90}{%
    \resizebox{%
	  \heightof{\usebox{\feline@chapter}}+\depthof{\usebox{\feline@chapter}}}%
	{!}{\scshape\so\protect\@chapapp}}\quad%
  \raisebox{\depthof{\usebox{\feline@chapter}}}{\usebox{\feline@chapter}}%
 }
\newcommand\feline@chm[1][4cm]{%
  \sbox\feline@chapter{\feline@chapter@marker[#1]}%
  \makebox[0pt][l]{% aka \rlap
    \makebox[1cm][r]{\usebox\feline@chapter}%
  }}
\makechapterstyle{daleif1}{
  \renewcommand\chapnamefont{\normalfont\Large\scshape\raggedleft\so}
  \renewcommand\chaptitlefont{\normalfont\huge\bfseries\scshape\color{nicered}}
  \renewcommand\chapternamenum{}
  \renewcommand\printchaptername{}
  \renewcommand\printchapternum{\null\hfill\feline@chm[2.5cm]\par}
  \renewcommand\afterchapternum{\par\vskip\midchapskip}
  \renewcommand\printchaptertitle[1]{\chaptitlefont\raggedleft ##1\par}
}
\makeatother


% scriptsize code
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\let\oldverbatim\verbatim
\def\verbatim{\oldverbatim\scriptsize}
% Applies to code blocks and R code results
% code chunk options size='scriptsize' applies only to R code and results
% if the code chunk sets a different size, \def\verbatim{...} is prioritary for code results


% Strict localized quotes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Comes before \usepackage{csquotes} in pandoc template
\usepackage[strict,autostyle]{csquotes}

% End of pandoc.tex. Two line feeds are necessary to avoid commenting the next command
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{spanish}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[backend=biber,style=authoryear-ibid,isbn=false,backref=true,giveninits=true,uniquename=init,maxcitenames=2,maxbibnames=150,sorting=nyt,sortcites=false]{biblatex}
\addbibresource{references.bib}
\usepackage{csquotes}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos},
  pdfauthor={Javier Pérez Arteaga},
  pdflang={es},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

% Title, author, date from YAML to LaTeX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Utilización de técnicas multivariantes para el estudio del
aprendizaje de la mejora de la accesibilidad en el subtitulado de
vídeos}

\author{Javier Pérez Arteaga}

\date{2023-10-03}


% Main title page with filigrane
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Text blocks
\usepackage[absolute,overlay]{textpos}
  \setlength{\TPHorizModule}{1mm}
  \setlength{\TPVertModule}{1mm}

\newcommand{\MainTitlePage}[2]{
  \pagestyle{empty}
    \begin{center}
		\includegraphics[width=10cm]{images/logo.png}
		\LARGE
		\mbox{Universidad Nacional de Educación a Distancia}
		\LARGE
		\mbox{Escuela Técnica Superior de Informática}

		\LARGE
		\mbox{Máster en Ingeniería y Ciencia de Datos}

		\vspace{2cm}
		
		\LARGE
		\textbf{Trabajo Fin de Máster}
		
		\LARGE
		\textbf{\thetitle}

		
		\vspace{2cm}		
		
	\end{center}  
	
	\begin{flushright}
		\LARGE
		\begin{tabular}{ r l }
			Autor: & \theauthor \\
			Directores: & Emilio Letón Molina \\
			& Jorge Pérez Martín \\
			Fecha de realización: & \thedate
		\end{tabular}
		
	\end{flushright}

  \SmallMargins % Margins
  \newpage
  \textblockorigin{\trimedge}{\trimtop} % verso
  \begin{textblock*}{\textwidth}(\paperwidth-\spinemargin-\textwidth, \uppermargin)
    #1
  \end{textblock*}
  \begin{textblock*}{\textwidth}[0,1](\paperwidth-\spinemargin-\textwidth, \uppermargin+\textheight+\footskip)
    \centering
          \includegraphics[width=\paperwidth/4]{logo}\\ \bigskip
        #2
  \end{textblock*}
 
}

% Clear page and open an even one (\clearpage opens an odd one)
\newcommand{\evenpage}{
  \clearpage
  \strictpagecheck % slower but efficient detection of odd/even pages
  \checkoddpage
  \ifoddpage
    \thispagestyle{empty}
    ~\\ % Print a character or the page will not exist
    \newpage
  \else
    % do nothing
  \fi

  
}
\begin{document}
\frontmatter

% Title page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\MainTitlePage{This document is reproducible thanks to:

\begin{itemize}
  \item \LaTeX and its class memoir (\url{http://www.ctan.org/pkg/memoir}).
  \item R (\url{http://www.r-project.org/}) and RStudio (\url{http://www.rstudio.com/})
  \item bookdown (\url{http://bookdown.org/}) and memoiR (\url{https://ericmarcon.github.io/memoiR/})
\end{itemize}}{Name of the owner of the logo

\url{http://www.company.com}

An explanatory sentence. Leave an empty line for line breaks.}


\phantomsection % Necesario con hyperref
\selectlanguage{spanish} % Selección de idioma del resumen.
\makeatletter
\begin{center} %
\chapter*{Resumen} % Opción con * para que no aparezca en TOC ni numerada
\addcontentsline{toc}{chapter}{Resumen} % Añade al TOC.
\end{center}   
\makeatother
TODO: Incluir un resumen del trabajo.

\phantomsection % Necesario con hyperref
\chapter*{Agradecimientos} % Opción con * para que no aparezca en TOC ni numerada
\addcontentsline{toc}{chapter}{Agradecimientos} % Añade al TOC.

\hyphenpenalty=1000

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed malesuada nulla augue, ac facilisis risus pretium a. Ut bibendum risus id ex fermentum, at accumsan erat vulputate. In hac habitasse platea dictumst. Sed lobortis est a enim bibendum, ac pulvinar nulla aliquam. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Pellentesque efficitur justo id suscipit pretium. Proin iaculis sit amet nibh vel euismod. Aenean tincidunt faucibus ex, non vehicula ipsum tristique in. Fusce vel tincidunt lectus, vel rutrum nisi. Suspendisse malesuada lectus ac enim vehicula rhoncus. Nullam convallis justo in bibendum eleifend.

Phasellus vitae magna nec mi sagittis luctus vitae eu augue. Donec scelerisque laoreet arcu, eget tempor mi ultricies vel. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum at blandit ex. Vestibulum eu sagittis mauris. In hac habitasse platea dictumst. Duis eget ante vel lacus sollicitudin convallis quis eu velit. Sed auctor sem non nisi hendrerit, vel tincidunt tortor bibendum.

\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[enhanced, boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}, frame hidden, interior hidden, breakable, sharp corners]}{\end{tcolorbox}}\fi

% Contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% fix the typesetting of the part number
\renewcommand\partnumberlinebox[2]{#2\ ---\ }


\LargeMargins
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}

% Tables (of tables, of figures)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\LargeMargins
\listoftables

\cleardoublepage
\LargeMargins
\listoffigures

\input{latex/glossary.tex}

\mainmatter
\bookmarksetup{startatroot}

\hypertarget{intro}{%
\chapter{Introducción}\label{intro}}

\bookmarksetup{startatroot}

\hypertarget{sec-arte}{%
\chapter{Marco teórico y estado del arte}\label{sec-arte}}

\hypertarget{caracteruxedsticas-del-diseuxf1o-del-experimento}{%
\section{Características del diseño del
experimento}\label{caracteruxedsticas-del-diseuxf1o-del-experimento}}

El objetivo del estudio es responder a la pregunta de investigación:

\begin{tcolorbox}[enhanced jigsaw, left=2mm, arc=.35mm, coltitle=black, opacityback=0, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Pregunta de investigación}, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, breakable, bottomtitle=1mm, opacitybacktitle=0.6, titlerule=0mm, toprule=.15mm, leftrule=.75mm, colback=white, toptitle=1mm]

¿Son los estudiantes de un curso de creación de materiales accesibles
capaces de encontrar diferencias en la calidad del subtitulado de un
vídeo?

\end{tcolorbox}

El diseño del experimento es completamente aleatorizado, de respuesta
ordinal, cruzado \(AB/BA\) y doble ciego. Es decir, que la asignación de
los estudiantes a cada grupo fue aleatoria; cada grupo vio los vídeos en
orden inverso; los estudiantes no conocían a priori qué vídeo estaban
viendo en cada momento y tampoco se disponía de esta información en el
momento de realizar el modelado estadístico.

Un diseño \textbf{completamente aleatorizado}
\autocite[pp.~18]{lawson2015} \enquote{garantiza la validez del
experimento contra sesgos causados por otras variables ocultas. Cuando
las unidades experimentales se asignan aleatoriamente a los niveles de
factor de tratamiento, se puede realizar una prueba exacta de la
hipótesis de que el efecto del tratamiento es cero utilizando una prueba
de aleatorización}.

En este trabajo se estudiarán las diferencias existentes entre los dos
niveles de subtitulado a través de las respuestas de los alumnos a las
escalas de Likert de cada uno de los vídeos. Para ello se propondrán
modelos estadísticos adecuados al diseño del experimento. La primera
cuestión que debemos abordar es que el diseño sea cruzado. Siguiendo a
\textcite{senn2022}, para que el ensayo sea de tipo cruzado no sería
suficiente intercambiar las secuencias sino que debe ser objeto del
ensayo el estudio de las diferencias entre los tratamientos individuales
que componen las secuencias. Los principales problemas de un diseño
cruzado son el abandono, \texttt{drop-out}, de alguno de los
participantes y la interacción entre el tratamiento y el periodo o
\texttt{carry-over}. Además, el análisis estadístico es más complicado y
particularmente cuando la respuesta es ordinal y hay más de dos
tratamientos. En la misma línea, \textcite{lui2016} afirma que
\enquote{el objetivo principal de un diseño cruzado es estudiar la
diferencia entre tratamientos individuales (en lugar de la diferencia
entre secuencias de tratamiento). Debido a que cada paciente sirve como
su propio control, el diseño cruzado es una alternativa útil al diseño
de grupos paralelos para aumentar la potencia}.

En un diseño cruzado debemos preocuparnos de la existencia de los
efectos periodo y secuencia (o \texttt{carry-over}). El \textbf{efecto
periodo} aplicado al experimento del subtitulado, se producirá si las
respuestas del segundo periodo están influidas por haber realizado la
primera actividad de subtitulado. El \textbf{efecto secuencia} se
producirá si las respuestas fueran diferentes cuando se realizan en un
orden que cuando se realizan en el otro.

La segunda cuestión de relevancia es que las respuestas a los ítems de
una escala de Likert son de \textbf{tipo ordinal}. Los test estadísticos
ANOVA o MANOVA presuponen que la variable de respuesta es cuantitativa y
con distribución normal. Tratar las respuestas a una escala de Likert
como si fueran cuantitativas no es correcto por las siguientes razones:

\begin{itemize}
\item
  Los niveles de respuesta no son necesariamente equidistantes: la
  distancia entre un par de opciones de respuesta puede no ser la misma
  para todos los pares de opciones de respuesta. Por ejemplo, la
  diferencia entre \enquote{Muy en desacuerdo} y \enquote{En desacuerdo}
  y la diferencia entre \enquote{De acuerdo} y \enquote{Muy de acuerdo}
  es de un nivel, pero psicológicamente puede ser percibida de forma
  diferente por cada sujeto.
\item
  La distribución de las respuestas ordinales puede ser no normal. En
  particular esto sucederá si hay muchas respuestas en los extremos del
  cuestionario.
\item
  Las varianzas de las variables no observadas que subyacen a las
  variables ordinales observadas pueden diferir entre grupos,
  tratamientos, periodos, etc.
\end{itemize}

En \textcite{kruschke2018} se han analizado los problemas potenciales de
tratar datos ordinales como si fueran cuantitativos constatando que se
pueden presentar las siguientes situaciones:

\begin{itemize}
\tightlist
\item
  Se pueden encontrar diferencias significativas entre grupos cuando no
  las hay: error tipo I.
\item
  Se pueden obviar diferencias cuando en realidad sí existen: error tipo
  II.
\item
  Incluso se pueden invertir los efectos de un tratamiento.
\item
  También puede malinterpretarse la interacción entre factores.
\end{itemize}

Otro factor que hay que tener en cuenta es que, al tratarse de un diseño
cruzado, es de \textbf{medidas repetidas} ya que cada sujeto realiza dos
veces el test, uno con cada vídeo y que, por lo tanto, las respuestas a
cada test de un mismo sujeto no son independientes. Además, tampoco
podemos considerar independientes los ítems que componen el test ya que
los ítems pretenden medir la misma variable latente: la calidad del
subtitulado.

\hypertarget{sec-tecnicas}{%
\section{Técnicas estadísticas utilizadas}\label{sec-tecnicas}}

En los siguientes apartados se proponen distintas técnicas que pretenden
responder al objetivo del trabajo teniendo en cuenta las peculiaridades
del diseño del experimento comentadas en el apartado anterior.

\hypertarget{sec-cronbach}{%
\subsection{Correlación entre preguntas con el alfa de
Cronbach}\label{sec-cronbach}}

Normalmente las preguntas de un cuestionario pretenden medir una
variable que está oculta o latente. En nuestro caso es la calidad del
subtitulado. Las respuestas a estas preguntas relacionadas deben ser
consistentes internamente, es decir, las respuestas deben
correlacionarse fuerte y positivamente.

Un índice que se utiliza habitualmente para medir la consistencia
interna de un cuestionario es el coeficiente \texttt{alfa\ de\ Cronbach}
\autocite[ver][]{schweinberger2020survey}. Se define de esta forma:

\begin{equation}
\alpha = \frac{N}{N-1} \left(1 - \frac{\sum_{i=1}^{N} s_{i}^{2}}{s^{2}} \right)
\end{equation}

Donde:

\begin{itemize}
\tightlist
\item
  \(\alpha\) es el coeficiente \texttt{alfa\ de\ Cronbach}.
\item
  \(N\) es el número de items de la escala de Likert.
\item
  \(s_{i}^{2}\) es la varianza de la puntuación del item \(i\).
\item
  \(s^{2}\) es la varianza total de las puntuaciones de todos los items.
\end{itemize}

Valores cercanos 1 indican una fuerte correlación en las respuestas y se
admite que las preguntas del cuestionario están midiendo la misma
variable latente.

\hypertarget{muxe9todos-exploratorios}{%
\section{Métodos exploratorios}\label{muxe9todos-exploratorios}}

En esta sección se aplicarán técnicas estadísticas que se basan en
tablas de contingencia. Una descripción teórica de este tipo de técnicas
se pueden encontrar en \textcite{agresti_2018}. Un tratamiento aplicado
y basado en gráficos, que será el enfoque que seguiremos en este
trabajo, es realizado en \textcite{frienly2015}.

\hypertarget{sec-chi2}{%
\subsection{\texorpdfstring{Asociación de variables con la prueba de
homogeneidad
\(\chi^2\)}{Asociación de variables con la prueba de homogeneidad \textbackslash chi\^{}2}}\label{sec-chi2}}

La prueba de homogeneidad \(\chi^2\) \autocite[ver][]{leton2021} está
enmarcarda en el esquema \(Nominal \leftarrow Nominal\) y contrasta la
hipótesis \(H_0\) de que no hay diferencias entre grupos frente a
\(H_1\) de que existen diferencias. Dada una tabla de contingencia (ver
Tabla~\ref{tbl-contingencia}). El valor del estadístico se calcula:

\[
\chi^2 = \sum_{i=1}^r\sum_{j=1}^c\frac{(n_{ij}-c{ij})^2}{c{ij}}
\]

que sigue una \(\chi^2_{(r-1)(c-1)}\), donde \(c_{ij}\) son las
frecuencias esperadas bajo \(H_0\) y que se calculan:

\[
c{ij}=\frac{r_ic_j}{n}
\]

\hypertarget{tbl-contingencia}{}
\begin{longtable}[]{@{}lrrrr@{}}
\caption{\label{tbl-contingencia}Tabla de contingencia}\tabularnewline
\toprule\noalign{}
& X = 1 & X = 2 & X =3 & \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& X = 1 & X = 2 & X =3 & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Y = 1 & \(n_{11}\) & \(n_{12}\) & \(n_{13}\) & \(r_1\) \\
Y = 2 & \(n_{21}\) & \(n_{22}\) & \(n_{23}\) & \(r_2\) \\
& \(c_1\) & \(c_2\) & \(c_3\) & \(n\) \\
\end{longtable}

\hypertarget{sec-or}{%
\subsection{\texorpdfstring{Comparación con
\(Odds\ Ratio\)}{Comparación con Odds\textbackslash{} Ratio}}\label{sec-or}}

Dada una tabla de contingencia \(2\ X\ 2\) (ver
Tabla~\ref{tbl-contingencia-3}), el \(odds ratio\) poblacional (\(OR\))
se define como el cociente de las probabilidades complementarias (ver
\textcite{leton2021}). Dado que los factores \(Treat\), \(Period\) y
\(Seq\) tienen todos 2 niveles, podemos contrastar si hay interacción
entre ellos para cada nivel de respuesta. Para ello contrastamos \(H_0\)
de que \(OR=1\) frente a \(H_1\) (\(OR\neq1\)) \footnote{Ver
  \textcite{leton2021} para el procedimiento del contraste de hipótesis
  mediante \(log\ OR\).}.

\hypertarget{tbl-contingencia-3}{}
\begin{longtable}[]{@{}lrr@{}}
\caption{\label{tbl-contingencia-3}Tabla de contingencia}\tabularnewline
\toprule\noalign{}
& X = 1 & X = 0 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& X = 1 & X = 0 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Y = 1 & \(n_{11}\) & \(n_{12}\) \\
Y = 0 & \(n_{21}\) & \(n_{22}\) \\
\end{longtable}

\hypertarget{sec-glm}{%
\section{Modelos lineales generalizados}\label{sec-glm}}

Los modelos lineales generalizados (\(GLM\)) son modelos en los que la
variable respuesta no es normal. Para especificar un \(GLM\) son
necesarios tres componentes \autocite[ver][pp.~66-67]{agresti_2018}:

\begin{itemize}
\tightlist
\item
  Un componente aleatorio: será una distribución de probabilidad de la
  familia exponencial que se asume que sigue la variable respuesta,
  \(Y\).
\item
  Un componente lineal de predictores.
\end{itemize}

\[
\alpha+\beta_1x_1+...+\beta_px_p
\]

\begin{itemize}
\tightlist
\item
  Una función de enlace \(g\) que relaciona \(\mu=E(Y)\) con los
  predictores, de tal forma que:
\end{itemize}

\[
g(\mu)=\alpha+\beta_1x_1+...+\beta_px_p
\]

En GLM se realiza maximizando la función de verosimilitud (\(MLE\)). Es
decir, que los coeficientes del modelo son aquellos que maximizan la
probabilidad de los datos.

\hypertarget{sec-logistica}{%
\subsection{Regresión Logística}\label{sec-logistica}}

La regresión logística \autocite[ver][pp.~68-69]{agresti_2018} es un
caso particular de \(GLM\) donde la variable respuesta, \(Y\), es
Benoulli o Binomial. Es decir, que \(Y\) toma valores 0 ó 1. En una
función de Bernoulli de parámetro \(\pi\), \(E[Y] = P(Y=1) = \pi\).
Necesitamos una función que \enquote{mapee} los valores que puede tomar
el componente lineal de rango \((-\infty, +\infty)\) a los valores que
puede tomar \(\pi\) en el rango \((0, 1)\). Una función que puede hacer
esto es la función \(logit\):

\[
logit(Y=1) = log \left[\frac{P(Y=1)}{1-P(Y=1)} \right] = \alpha+\beta_1x_1+...+\beta_px_p
\]

por lo que:

\[
P(Y=1) = \frac{exp^{\alpha + \beta x}}{1 + exp^{\alpha + \beta x}}
\]

Para interpretar los coeficientes, podemos reescribir la ecuación
\autocite[ver][p.~260]{frienly2015}:

\[
\frac{P(Y=1 \mid X = x)}{1-P(Y=1 \mid X = x)} = e^{\alpha}e^{\beta x}
\]

Para una unidad de incremento de \(x\):

\[
\frac{P(Y=1 \mid X = x + 1)}{1-P(Y=1 \mid X = x + 1)} = e^{\alpha}e^{\beta(x + 1)}
\]

Dividiendo la segunda ecuación entre la primera:

\[
\frac{\frac{P(Y=1 \mid X = x + 1)}{1-P(Y=1 \mid X = x + 1)}}{\frac{P(Y=1 \mid X = x)}{1-P(Y=1 \mid X = x)}} = \frac{e^{\alpha}e^{\beta(x + 1)}}{e^{\alpha}e^{\beta(x)}} = e^\beta
\]

Es decir:

\begin{itemize}
\tightlist
\item
  \(\beta\) es el \(log\ OR\) asociado a una unidad de incremento de
  \(x\).
\item
  \(\alpha\) es el \(log\ odds\) cuando \(x=0\).
\end{itemize}

El contraste de hipótesis para los coeficientes \(\beta\):

\[
\begin{aligned}
H_0: \beta_j =  0 \\
H_1: \beta_j \ne  0
\end{aligned}
\]

se puede realizar con el test de Wald:

\[
\begin{aligned}
W & = \frac{\hat\beta_j - 0}{se(\hat\beta_j)} \sim N(0,1)
\end{aligned}
\]

o con el test de razón de verosimilitudes (LRT):

\[
\begin{aligned}
\Lambda &= -2 \log \frac{L(\widehat{reduced})}{L(\widehat{full})}\\
&= -2 \log L(\widehat{reduced}) + 2 \log L(\widehat{full}) \sim \chi^2_r\ (\text{donde r es el número de betas } = 0)
\end{aligned}
\]

Para comparar modelos no anidados, se puede usar el Criterio de
Información de Akaike (AIC) o el Criterio de Información Bayesiano
(BIC), que se definen:

\[
\begin{aligned}
AIC &: -2 \log L + 2p \\
BIC &: -2 \log L + p \log(n)
\end{aligned}
\]

, donde \(L\) es el valor de maxima verosimilitud.

\hypertarget{sec-ordinal}{%
\subsection{Regresión Ordinal}\label{sec-ordinal}}

Las respuestas a los ítems de una escala de Likert son ordinales. La
Regresión Ordinal es clase de \(GLM\) que comparte muchas similitudes
con la regresión logística (ver Sección~\ref{sec-logistica}). Según
\textcite{burkner2019} hay tres clases de Regresión Ordinal:

\begin{itemize}
\tightlist
\item
  Regresión Ordinal Acumulativa.
\item
  Regresión Ordinal Secuencial.
\item
  Regresión Ordinal Adyacente.
\end{itemize}

Nos centraremos en la primera ya que es la más habitual y adecuada para
nuestro caso \autocite[ver][pp.~23-24]{burkner2019} \footnote{Las
  regresiones ordinales secuencial y adyacente presuponen que para
  alcanzar un nivel se ha tenido que pasar previamente por los
  anteriores, que no es nuestro caso.}. El modelo acumulativo, CM,
presupone que la variable ordinal observada, \(Y\), proviene de la
categorización de una variable latente (no observada) continua,
\(\tilde{Y}\). Hay \(K\) umbrales \(\tau_k\) que particionan
\(\tilde{Y}\) en \(K + 1\) categorías ordenadas observables (ver
Figura~\ref{fig-cumulative}). Si asumimos que \(\tilde{Y}\) tiene una
cierta distribución (por ejemplo, normal) con distribución acumulada
\(F\), se puede calcular la probabilidad de que \(Y\) sea la categoría
\(k\) de esta forma:

\[Pr(Y = k) = F(\tau_k) - F(\tau_{k-1})\]

\begin{figure}[h]

{\centering \includegraphics{2_files/figure-pdf/fig-cumulative-1.pdf}

}

\caption{\label{fig-cumulative}Función latente en una regresión ordinal
acumulativa.}

\end{figure}

Por ejemplo en la Figura~\ref{fig-cumulative},

\[Pr(Y = 2) = F(\tau_2) - F(\tau_{1})\]

Si suponemos que \(\tilde{Y}\) tiene una relación lineal los
predictores:

\[\tilde{Y} = \eta + \epsilon = \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon\],

y que los errores son \(N(0,\sigma^2)\). Entonces la función de
probabilidad acumulada de los errores tendrá la misma forma que la de
\(\tilde{Y}\):

\[\mathrm{Pr}(\epsilon \leq z) = F(z)\]

Y podremos calcular la distribución de probabilidad acumulada de \(Y\):

\[\mathrm{Pr}(Y \leq k \mid \eta) = \mathrm{Pr}(\tilde{Y} \leq \tau_k \mid \eta) = \mathrm{Pr}(\eta + \epsilon \leq \tau_k) = \mathrm{Pr}(\epsilon \leq \tau_k - \eta) = F(\tau_k - \eta)\]

Por lo que asumiendo la normalidad de los errores:

\[\mathrm{Pr}(Y = k) = \Phi(\tau_k - \eta) - \Phi(\tau_{k - 1} - \eta)\]

Donde hay que estimar los umbrales y los coeficientes de regresión. La
función anterior es la conocida como la función de enlace
\texttt{probit}. Otra función de enlace popular es la función
\texttt{logit}. Es la que usaremos en este trabajo por ser más fácil su
interpretación \footnote{En la práctica los coeficientes estimados con
  las funciones de enlace \texttt{probit} y \texttt{logit} suelen
  similares.}. Con esta función de enlace la interpretación de los
coeficientes es parecida a la de los coeficientes de la regresión
logística. Se parte del supuesto de que el \(logit\) de la función de
probabilidad es lineal:

\[logit [P(Y \le k)] = \tau_{k} - \eta = \tau_{k} - (\beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p)\]

En ese caso, se puede demostrar fácilmente que, por ejemplo:

\[\frac{\frac{\mathrm{Pr}(Y \leq k \mid \eta)}{\mathrm{Pr}(Y > k \mid \eta)}}{\frac{\mathrm{Pr}(Y \leq k+1 \mid \eta)}{\mathrm{Pr}(Y > k+1 \mid \eta)}} = \exp(\tau_{k} - \tau_{k+1})\]

Y que \footnote{En la Sección~\ref{sec-ordinal-2} se demuestra esta
  fórmula.}:

\[\frac{\frac{\mathrm{Pr}(Y \leq k \mid x_i = 1)}{\mathrm{Pr}(Y > k \mid x_i = 1)}}{\frac{\mathrm{Pr}(Y \leq k \mid x_i=0)}{\mathrm{Pr}(Y > k \mid x_i = 0)}} = \exp(-\beta_{i})\]

o, equivalentemente:

\[\frac{\frac{\mathrm{Pr}(Y > k \mid x_i = x + 1)}{\mathrm{Pr}(Y \leq k \mid x_i = x + 1)}}{\frac{\mathrm{Pr}(Y > k \mid x_i = x)}{\mathrm{Pr}(Y \leq k \mid x_i = x)}} = \exp(\beta_{i})\]

Es decir, que \(\exp(\beta_{i})\) es el \(OR\) (cambio en \(odds\)) de
que la variable respuesta esté por encima de una determinada categoría
versus estar por debajo de ella para una unidad de incremento del
predictor \(x_i\). Este modelo se denomina proporcional ya que cada
predictor se asume que tiene los mismos efectos sobre todas las
categorías de la variable de respuesta ordinal
\autocite[ver][]{Liu2202}. Un valor del coeficiente \(\beta_i\) positivo
indica que la relación entre el predictor \(x_i\) y la función de
\(logit\) es positiva y, por lo tanto, se incrementa la posibilidad de
un mayor valor de la variable respuesta. Como veremos, esta suposición
se puede relajar y permitir que los coeficientes de todos o de algunos
de los predictores sean diferentes para cada pareja consecutiva de
valores de respuesta. Tendríamos entonces más parámetros a estimar con
una interpretación más compleja.

\bookmarksetup{startatroot}

\hypertarget{sec-metodo}{%
\chapter{Métodología/Materiales y métodos}\label{sec-metodo}}

\hypertarget{descripciuxf3n-de-la-experiencia}{%
\section{Descripción de la
experiencia}\label{descripciuxf3n-de-la-experiencia}}

\hypertarget{marco-de-la-experiencia}{%
\subsection{Marco de la experiencia}\label{marco-de-la-experiencia}}

Los datos se recogieron de una actividad de subtitulado que se propuso a
los estudiantes de la edición 2022 del curso MOOC Materiales digitales
accesibles de la UNED Abierta. Este curso pertenece al Canal Fundación
ONCE y según se recoge en la propia página Web del curso sus objetivos
son:

\begin{itemize}
\item
  Reconocer y abordar los desafíos a los que se enfrentan las personas
  con discapacidad (por ejemplo los estudiantes) al usar los documentos
  electrónicos, adquirir conciencia y experiencia.
\item
  Obtener una mejor comprensión de la accesibilidad como un asunto de
  derechos civiles y desarrollar los conocimientos y habilidades
  necesarios para diseñar recursos de aprendizaje que promuevan
  ambientes de aprendizaje inclusivos.
\item
  Valorar cómo los documentos accesibles benefician a todas las
  personas, incluyendo a las que tienen y a las que no tienen
  discapacidad, a través de una mayor facilidad de uso y la
  interoperabilidad de los materiales basados en la web.
\item
  Tomar conciencia de que cómo los autores pueden no solo eliminar
  barreras, sino evitar crearlas en primer lugar.
\item
  Adquirir autosuficiencia en la producción de contenidos accesibles y
  en la identificación de problemas de accesibilidad.
\item
  Adquirir, como autores, estrategias para la producción sostenible de
  material digital, como la modularidad.
\end{itemize}

Está destinado \enquote{a todos aquellas personas que desean participar
en el desarrollo de soluciones de diseño éticas y creativas, que quieran
escribir o gestionar contenidos electrónicos accesibles, desde páginas
web o aplicaciones a libros electrónicos}ePub''.

El curso tiene cuatro módulos:

\begin{itemize}
\tightlist
\item
  Introducción.
\item
  Accesibilidad de material multimedia.
\item
  Accesibilidad de texto digitales.
\item
  Materiales digitales en la práctica.
\end{itemize}

\hypertarget{actividad-de-subtitulado}{%
\subsection{Actividad de subtitulado}\label{actividad-de-subtitulado}}

La actividad de subtitulado es voluntaria y sin influencia en la
calificación final del alumno ni el material al que el tiene acceso. Se
realiza en el módulo \enquote{Accesibilidad del material multimedia}. En
este mismo módulo, y antes de proponerles la actividad de subtitulado,
los alumnos previamente completaron las secciones \enquote{Accesibilidad
de la información sonora} y \enquote{Accesibilidad de la información
visual}, con lo cual ya tienen conocimiento sobre creación de vídeos y
subtítulos accesibles.

La actividad consistió en ver dos vídeos idénticos y que solo se
diferencian en la calidad del subtitulado de 43 segundos de duración.
Los subtítulos de uno de los vídeos se realizaron
\autocites[ver][]{jperez1,jperez2} siguiendo la guía Web Content
Accessibility Guidelines 2.1 (WCAG 2.1) del W3C (World Wide Web
Consortium). El otro vídeo tenía un subtitulado similar pero se
introdujeron pequeñas deficiencias, algunas de ellas inapreciables para
alguien que carezca de conocimientos sobre accesibilidad. El orden de
los vídeos es aleatorio, de tal forma que una cohorte de alumnos vio
primero el vídeo bien subtitulado y luego el mal subtitulado y la otra
lo hizo al revés. Después de ver cada uno de los vídeos, los alumnos
respondieron a una escala de Likert de 5 niveles y 18 ítems. Los 18
items de Likert responden a los criterios de la norma UNE 153010
\autocite[ver][]{aenor2012}. Es diseño de experimento es doble ciego: es
decir, a los alumnos no se les informó de si estaban viendo el vídeo con
mejor o con peor calidad de subtitulado. Esta información tampoco se
conoce en el momento de realizar este trabajo ya que los vídeos tienen
identificaciones genéricas que no contienen ninguna indicación del tipo
de subtitulado del vídeo\footnote{En la respuesta a cada ítem, el alumno
  puede añadir comentarios. Éstos han sido eliminados del estudio para
  que no filtren información referente al tipo de subtitulado que el
  alumno cree estar contestando.}.

En la Tabla~\ref{tbl-likert-levels} se muestran los 5 niveles de cada
uno de los items de la escala de Likert utilizados para valorar el
subtitulado \footnote{En la codificación original los valores asignados
  a cada respuesta eran diferentes: la opción \enquote{No sé / No
  contesto} se codificó con 5 y las demás opciones con una unidad menos
  que la mostrada. En este trabajo se ha hecho una rotación para asignar
  valores más usuales en la literatura científica sobre el tema.}. En la
Tabla~\ref{tbl-likert-scale} se muestran los 18 items de la escala de
Likert que se propuso a los alumnos para que evaluaran cada uno de los
vídeos.

\hypertarget{tbl-likert-levels}{}
\begin{longtable}[]{@{}rl@{}}
\caption{\label{tbl-likert-levels}Niveles de los items de la escala de
Likert.}\tabularnewline
\toprule\noalign{}
values & levels \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
values & levels \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & No sé / No contesto \\
1 & Muy en desacuerdo \\
2 & En desacuerdo \\
3 & Neutral \\
4 & De acuerdo \\
5 & Muy de acuerdo \\
\end{longtable}

\hypertarget{tbl-likert-scale}{}
\begin{longtable}{ll}
\caption{\label{tbl-likert-scale}Items de la escala de Likert. }\tabularnewline

\toprule
Item & Texto \\ 
\midrule
Q01 & La posición de los subtítulos. \\ 
Q02 & El número de líneas por subtítulo. \\ 
Q03 & La disposición del texto respecto a la caja donde se muestran los subtítulos. \\ 
Q04 & El contraste entre los caracteres y el fondo. \\ 
Q05 & La corrección ortográfica y gramatical. \\ 
Q06 & La literalidad. \\ 
Q07 & La identificación de los personajes. \\ 
Q08 & La asignación de líneas a los personajes en los diálogos. \\ 
Q09 & La descripción de efectos sonoros. \\ 
Q10 & La sincronización de las entradas y salidas de los subtítulos. \\ 
Q11 & La velocidad de exposición de los subtítulos. \\ 
Q12 & El máximo número de caracteres por línea. \\ 
Q13 & La legibilidad de la tipografía. \\ 
Q14 & La separación en líneas diferentes de sintagmas nominales, verbales y preposicionales. \\ 
Q15 & La utilización de puntos suspensivos. \\ 
Q16 & La escritura de los números. \\ 
Q17 & Las incorrecciones en el habla. \\ 
Q18 & Los subtítulos del vídeo cumplen en general con los requisitos de accesibilidad. \\ 
\bottomrule
\end{longtable}

\hypertarget{participantes}{%
\section{Participantes}\label{participantes}}

Los datos personales de los estudiantes se suministraron anonimizados
para evitar conocer su identidad. De acuerdo con nuestro compromiso
ético, del estudio se han eliminado a aquellos estudiantes que, a pesar
de haber realizado la actividad, no dieron su consentimiento para que
sus datos se utilizaran en estudios científicos. Tras este proceso, se
dispone de 198 cuestionarios correspondientes a 111 alumnos. Hay 24
estudiantes que sólo realizaron el primero de los test. Como la muestra
es suficientemente amplia, se ha decidido eliminar estos test quedando
87 estudiantes participantes. En la Tabla~\ref{tbl-contingencia-eco} se
muestran las tablas de contingencia de algunos de los datos que los
estudiantes voluntariamente facilitaron en el cuestionario inicial del
curso.

\begin{table}

\caption{\label{tbl-contingencia-eco}Tablas de contingencia de la
información socioeconómica de los
estudiantes.}\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-eco-1}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
gender & Freq \\ 
\midrule
f & 46 \\ 
m & 19 \\ 
NA & 22 \\ 
\bottomrule
\end{longtable}

Estudiantes por sexo.

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-eco-2}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
year\_of\_birth & Freq \\ 
\midrule
None & 22 \\ 
NA & 1 \\ 
\bottomrule
\end{longtable}

Estudiantes con valor nulo en el campo año de nacimiento.

}

\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-eco-3}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
level\_of\_education & Freq \\ 
\midrule
a & 25 \\ 
b & 8 \\ 
hs & 2 \\ 
m & 15 \\ 
other & 2 \\ 
p & 10 \\ 
NA & 25 \\ 
\bottomrule
\end{longtable}

Estudiantes por nivel educativo.

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-eco-4}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
level\_of\_knowledge & Freq \\ 
\midrule
4 & 1 \\ 
6 & 2 \\ 
7 & 15 \\ 
8 & 22 \\ 
9 & 20 \\ 
10 & 16 \\ 
NA & 11 \\ 
\bottomrule
\end{longtable}

Estudiantes en función del número de preguntas acertadas en el test de
conocimiento sobre accesibilidad.

}

\end{minipage}%

\end{table}

\hypertarget{ficheros-suministrados}{%
\section{Ficheros suministrados}\label{ficheros-suministrados}}

Se dispuso de los siguientes ficheros \texttt{csv}:

\begin{itemize}
\tightlist
\item
  El fichero \texttt{grade} contiene el identificador de estudiante y el
  grupo al que pertenece (campo \texttt{cohort}).
\item
  El fichero \texttt{abo} es la información socioeconómica que
  voluntariamente ha aportado el estudiante: sexo, año nacimiento, nivel
  de estudios, ocupación.
\item
  El fichero \texttt{conoc} contiene el test de evaluación inicial de
  conocimientos del estudiante.
\item
  El fichero \texttt{exp} es la evaluación del curso realizada por cada
  estudiante.
\item
  El fichero \texttt{acc} contiene la información sobre las
  necesidades/preferencias de accesibilidad que tiene el estudiante.
\item
  Los ficheros \texttt{test1} y \texttt{test2} son las repuestas al test
  de Likert sobre la calidad del subtitulado del primer y del segundo
  vídeo realizado por cada grupo respectivamente.
\end{itemize}

\hypertarget{sec-preprocesado}{%
\section{Preprocesado}\label{sec-preprocesado}}

En esta sección se describen las transformaciones realizadas con los
ficheros suministrados:

\begin{itemize}
\item
  Se lee el fichero de perfil del usuario. El número de fila con el que
  el usuario aparece en el fichero se utilizará como identificador del
  usuario para mantener la trazabilidad y comprobar que las
  transformaciones realizadas son correctas.
\item
  Se eliminan los datos de los estudiantes que aún habiendo realizado la
  actividad, no han dado su consentimiento para participar en el
  estudio.
\item
  El valor del campo \texttt{cohort} se sustituye por una letra, \(A\) o
  \(B\), en función del grupo asignado. En el momento de realizar este
  proceso se desconoce qué vídeo vio primero cada cohorte.
\item
  Se lee el fichero \texttt{profile} y se añade información sobre el
  sexo, el año de nacimiento y el nivel de estudios.
\item
  Se lee el fichero \texttt{conoc} y se calcula cuántas preguntas acertó
  cada usuario en el test de evaluación de conocimientos previos. Se
  añade esta información al perfil del usuario.
\item
  Se leen los ficheros de test y se procesan. Se utiliza el nombre del
  fichero (\texttt{test1} o \texttt{test2}) para saber de qué vídeo se
  está respondiendo el test \footnote{Se reitera que en el momento de
    realizar este proceso se desconoce si el vídeo es el correctamente
    subtitulado o el otro. La única información que se almacena es si se
    está respondiendo al vídeo que se vio primero.}.
\item
  Se seleccionan las preguntas que contienen las respuestas y se
  renombran para que sea más fácil saber de qué pregunta se trata
  \footnote{En los ficheros suministrados la respuesta a cada pregunta
    ocupa varios campos. e selecciona en cada pregunta el que contiene
    el valor de la respuesta y se convierte a numérico.}. Se convierte
  el campo \texttt{LastTry}, que contiene la fecha y hora de realización
  del test, a formato fecha y hora.
\item
  Se realizan algunas comprobaciones como la ausencia de valores nulos
  en la variables más relevantes o que no existan inconsistencias ni
  errores de procesado.
\item
  Se eliminan los comentarios y se graban en fichero aparte para que no
  revelen información que podría descubrir el tipo de subtitulado que
  piensa que está evaluando el estudiante.
\item
  Se almacenan los resultados de los test preprocesados en un fichero
  \texttt{csv}.
\end{itemize}

\hypertarget{variables}{%
\section{Variables del modelo.}\label{variables}}

En la Tabla~\ref{tbl-variables} se describen las características más
relevantes de las principales variables que se utilizarán en en modelado
y en el análisis estadístico.

\footnotesize

\hypertarget{tbl-variables}{}
\setlength{\LTpost}{0mm}
\begin{longtable}{llll}
\caption{\label{tbl-variables}Descripción de las variables más importantes. }\tabularnewline

\toprule
Nombre & Descripción & Tipo & Valores \\ 
\midrule
Response & Respuesta a las preguntas del test. & Factor ordenado & De 0 a 5\textsuperscript{1} \\ 
Level & Valoración de la respuesta. & Factor ordenado & Negative, Neutral, Positive\textsuperscript{2} \\ 
Treat & Subtítulos & Factor & A o B\textsuperscript{3} \\ 
Period & Periodo & Factor & 1 ó 2\textsuperscript{4} \\ 
Seq & Secuencia de aplicación de los tratamientos. & Factor & AB o BA \\ 
Subject & Identificación del estudiante & Factor & Numérico \\ 
Question & Número de la pregunta & Factor & Q01, Q02, ..., Q18\textsuperscript{5} \\ 
\bottomrule
\end{longtable}
\begin{minipage}{\linewidth}
\textsuperscript{1}Se ha hecho una rotación sobre los valores originales. 0 = No sé, 1 = Muy en desacuerdo, ..., 5 Muy de acuerdo.\\
\textsuperscript{2}Positive cuando Response sea 4 ó 5, Negative cuando sea 1 ó 2 y Neutral para 3.\\
\textsuperscript{3}No se conoce si el tratamiento A es el subtitulado bueno o lo es el B.\\
\textsuperscript{4}1 para el primer vídeo visto y 2 el segundo.\\
\textsuperscript{5}Se ha reorganizado de tal forma que Q18, que es la pregunta resumen, sea el valor primero y de referencia.\\
\end{minipage}

\normalsize

Partiendo del \texttt{dataframe} que se construyó en el preprocesado
(ver Sección~\ref{sec-preprocesado}) construimos el \texttt{dataframe}
que usaremos a partir de este momento. Las operaciones principales que
se han realizado han sido:

\begin{itemize}
\tightlist
\item
  Renombrar las variables (ver Tabla~\ref{tbl-variables}).
\item
  Eliminar del estudio los usuarios que solo han realizado uno de los
  test.
\item
  Transformar las variables que lo requieran en factores. La pregunta 18
  se usará como referencia en el factor \texttt{Question}.
\item
  Rotar los valores de respuesta para que \enquote{No sé / No contesto}
  tenga valor 0 y el resto de 1 a 5 desde \enquote{Muy en desacuerdo},
  1, hasta \enquote{Muy de acuerdo}, 5.
\item
  Crear el factor \texttt{Level} con los niveles \texttt{negative},
  \texttt{neutral} y \texttt{positive} dependiendo de si la respuesta es
  1 ó 2, 3, 4 ó 5 respectivamente.
\item
  Transformar el \texttt{dataframe} de formato ancho a largo: los
  ficheros de respuestas se suministran en formato ancho. Es decir, que
  cada fila es un test que contiene 18 columnas para las respuestas a
  cada pregunta. Los nombres de las columnas son \(Q01\), \(Q02\),
  \ldots, \(Q18\) y tendrán valores de 0 a 5 con las respuestas. La
  mayoría de los paquetes de R que vamos a usar requieren que los datos
  estén en formato largo. Esto que quiere decir que cada fila tendrá una
  única respuesta por lo que habrá únicamente dos columnas, \(Question\)
  y \(Response\). En la primera se almacenará el identificador de la
  pregunta (\(Q01\), \(Q02\), \ldots, \(Q18\)) y en la segunda el valor
  de la respuesta (de 0 a 5). De esta forma, un test pasará de ocupar
  una fila y 18 columnas en el formato ancho a 18 filas y dos columnas
  en el largo.
\end{itemize}

Se crean dos \texttt{dataframes}:

\begin{itemize}
\tightlist
\item
  \texttt{df\_all} contiene en formato largo todas las respuestas a los
  test.
\item
  \texttt{df\_clean} tiene la misma estructura que \texttt{df\_all} pero
  en él se han eliminado las respuestas \enquote{No sé / No contesto}.
\end{itemize}

\texttt{df\_all} se utilizará cuando se traten las respuestas como
categóricas y, por lo tanto, como no ordenadas. \texttt{df\_clean} se
utilizará cuando se traten las respuestas como ordenadas y por ello no
contiene las respuestas con valor \enquote{No sé / No contesto}.

La estructura de estos \texttt{dataframes} es la siguiente:

\begin{verbatim}
tibble [2,980 x 7] (S3: tbl_df/tbl/data.frame)
 $ Seq     : Factor w/ 2 levels "AB","BA": 1 1 1 1 1 1 1 1 1 1 ...
 $ Period  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ Treat   : Factor w/ 2 levels "A","B": 1 1 1 1 1 1 1 1 1 1 ...
 $ Subject : Factor w/ 87 levels "4","33","35",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Question: Factor w/ 18 levels "Q18","Q01","Q02",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Response: Ord.factor w/ 5 levels "1"<"2"<"3"<"4"<..: 3 3 3 3 3 3 3 3 3 3 ...
 $ Level   : Ord.factor w/ 3 levels "Negative"<"Neutral"<..: 2 2 2 2 2 2 2 2 2..
\end{verbatim}

En la Tabla~\ref{tbl-df_clean} se muestran algunos ejemplos datos.

\hypertarget{tbl-df_clean}{}
\begin{longtable}{ccccccc}
\caption{\label{tbl-df_clean}Muestra del dataframe preparado para el modelado estadístico en formato
largo. }\tabularnewline

\toprule
Seq & Period & Treat & Subject & Question & Response & Level \\ 
\midrule
BA & 1 & B & 871 & Q05 & 5 & Positive \\ 
BA & 1 & B & 371 & Q03 & 2 & Negative \\ 
BA & 1 & B & 749 & Q02 & 4 & Positive \\ 
BA & 1 & B & 749 & Q13 & 4 & Positive \\ 
AB & 1 & A & 380 & Q07 & 4 & Positive \\ 
BA & 2 & A & 901 & Q04 & 5 & Positive \\ 
BA & 1 & B & 110 & Q06 & 5 & Positive \\ 
AB & 1 & A & 339 & Q02 & 5 & Positive \\ 
AB & 1 & A & 893 & Q08 & 2 & Negative \\ 
BA & 1 & B & 220 & Q03 & 3 & Neutral \\ 
\bottomrule
\end{longtable}

\bookmarksetup{startatroot}

\hypertarget{sec-modelado}{%
\chapter{Modelado estadístico}\label{sec-modelado}}

\hypertarget{sec-eda}{%
\section{Análisis inicial}\label{sec-eda}}

Como se explica en la Tabla~\ref{tbl-variables}, al subtitulado le
denominamos tratamiento y a sus niveles (correcto e incorrecto) los
hemos llamado \(A\) y \(B\) sin hacer ninguna conjetura de cual de los
dos es el subtitulado correcto. El grupo con secuencia \(AB\) será el
que primero vio el vídeo con subtitulado \(A\) y luego el \(B\).
Análogamente, el grupo con secuencia \(BA\) vio los vídeos en orden
inverso. Recuérdese que el nivel 0 de respuesta se corresponde con
\enquote{No sé / No contesto} (ver Tabla~\ref{tbl-likert-levels}). Tras
eliminar los test de los usuarios que no dieron su consentimiento para
participar en el estudio y los de los que no realizaron el segundo test,
las dos cohortes están equilibradas (ver Figura~\ref{fig-groups}).

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-groups-1.pdf}

}

\caption{\label{fig-groups}Estudiantes asignados a cada grupo.}

\end{figure}

\hypertarget{anuxe1lisis-de-la-calidad-de-los-datos}{%
\subsection{Análisis de la calidad de los
datos}\label{anuxe1lisis-de-la-calidad-de-los-datos}}

En esta sección buscamos si hay test que tienen valores de respuesta que
puedan resultar anómalos. En los test no se ha observado ningún valor
nulo ni erróneo.

El campo \texttt{LastTry} contiene la fecha y hora de realización del
test. Con esta información podemos conocer el tiempo que empleó cada
estudiante entre actividades. La Tabla~\ref{tbl-washout} muestra que hay
algunos test que se hicieron demasiado rápido \footnote{Hay que tener en
  cuenta que la duración de vídeo es de algo más de 40 segundos y que
  los estudiantes tienen que contestar un test de 18 ítems.}.

\hypertarget{tbl-washout}{}
\begin{longtable}{c}
\caption{\label{tbl-washout}Tiempos de realización de la segunda actividad de duración inferior a 2
minutos. }\tabularnewline

\toprule
Minutes \\ 
\midrule
0.93 \\ 
1.3 \\ 
1.7 \\ 
1.72 \\ 
1.78 \\ 
1.97 \\ 
\bottomrule
\end{longtable}

La Figura~\ref{fig-distinct} muestra que hay 28 test en los que el
estudiante contestó a todas las preguntas usando únicamente 2 respuestas
diferentes. Además hay 13 test en los que se contestaron todas las
preguntas con 1 respuesta.

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-distinct-1.pdf}

}

\caption{\label{fig-distinct}Número de respuestas diferentes en un mismo
test.}

\end{figure}

La tabla Tabla~\ref{tbl-distinct2} muestra los test de respuesta única y
el valor de esa respuesta.

\hypertarget{tbl-distinct2}{}
\begin{longtable}{rlr}
\caption{\label{tbl-distinct2}Test en los que todas las preguntas se contestan el mismo valor de
respuesta. }\tabularnewline

\toprule
Response & Seq & Test \\ 
\midrule
2 & AB & 01 \\ 
2 & AB & 02 \\ 
3 & BA & 01 \\ 
3 & BA & 02 \\ 
3 & BA & 02 \\ 
3 & BA & 02 \\ 
4 & AB & 01 \\ 
4 & AB & 01 \\ 
4 & AB & 02 \\ 
4 & BA & 01 \\ 
4 & BA & 02 \\ 
4 & BA & 02 \\ 
4 & BA & 02 \\ 
\bottomrule
\end{longtable}

La Figura~\ref{fig-compare} presenta la distribución de la cantidad de
respuestas cuyo valor cambia entre los dos test que realiza cada
estudiante.

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-compare-1.pdf}

}

\caption{\label{fig-compare}Número de respuestas diferentes entre los
test para cada estudiante.}

\end{figure}

Tan solo 1 estudiante respondió a todas las preguntas con el mismo valor
en los dos test. Por otro lado, no hay test que tengan un número
excesivo de contestaciones \enquote{No sé/No contesto} (ver
Tabla~\ref{tbl-noanswer}).

\hypertarget{tbl-noanswer}{}
\begin{longtable}{rr}
\caption{\label{tbl-noanswer}Los 5 test con más respuestas `No sé/No contesto' }\tabularnewline

\toprule
Test & Total respuesta por test \\ 
\midrule
01 & 5 \\ 
01 & 5 \\ 
02 & 5 \\ 
02 & 5 \\ 
01 & 4 \\ 
\bottomrule
\end{longtable}

Vemos que algunos test tienen valores que no parecen muy razonables. Por
ejemplo, no parece razonable realizar la actividad en menos de 2
minutos. Se observa que en algunos test hay poca variabilidad. Sin
embargo, no son muchos los test con estas características así que se ha
decidido mantener estos datos a pesar de que se pueda dudar de si en
ellos los estudiantes contestaron con la debida atención y diligencia.

\hypertarget{sec-eda-3}{%
\subsection{\texorpdfstring{Comparación de los tratamientos \(A\) y
\(B\) entre
grupos.}{Comparación de los tratamientos A y B entre grupos.}}\label{sec-eda-3}}

La Figura~\ref{fig-diff} presenta una forma de comparar los dos test
realizados por los estudiantes. Para cada estudiante se comparó pregunta
a pregunta sus dos test y se contabilizó la diferencia entre el número
de preguntas en que la puntuación en el segundo vídeo fue superior y en
las que lo fue inferior (las que no variaron de puntuación no se
consideraron). En el eje \(x\) se muestra la diferencia entre preguntas.
Cantidades negativas indican que hay más respuestas en el segundo de los
test que han empeorado respecto al primero de las que han mejorado. En
el eje \(y\) se representa el número de estudiantes para cada
diferencia. Esta frecuencia se representa en negativo cuando la
diferencia es negativa \footnote{En la comparación se han omitido
  aquellas respuestas en las que el estudiante contestó \enquote{No
  sé/No contesto} en la pregunta correspondiente de uno de los test.}.
Esto es una forma de evaluar si el estudiante valoró mejor o no el
segundo vídeo que el primero.

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-diff-1.pdf}

}

\caption{\label{fig-diff}Frecuencias absolutas de las diferencias en las
respuestas entre test por estudiante y grupo.}

\end{figure}

Vemos que en el grupo \(AB\) las diferencias tienden a ser negativas y
en el \(BA\) positivas. Esto estaría indicando que los estudiantes
valoran mejor el subtitulado de nivel \(A\) en ambas secuencias. Por
ello es esperable que las respuestas de los estudiantes del grupo \(AB\)
hayan empeorado y que las diferencias sean negativas y que lo contrario
haya sucedido con las del grupo \(BA\). La diferencia más frecuente en
el grupo \(AB\) es 12 y en el grupo \(BA\) este valor es 11.

Resulta llamativo que haya estudiantes cuyas contestaciones estén tan
alejadas de la tendencia de su grupo. En la Tabla~\ref{tbl-diff} se
muestran los tiempos que han transcurrido entre la realización de los
test de aquellos estudiantes cuyas respuestas difieren de forma
importante de su grupo. Se observa que casi todos son tiempos entre
actividades muy cortos. En cualquier caso y, como no son muchos, se ha
decidido no eliminarlos y realizar el análisis con ellos.

\hypertarget{tbl-diff}{}
\begin{longtable}{lrc}
\caption{\label{tbl-diff}Estudiantes que tienen diferencias en sus respuestas muy alejadas de la
tendencia de su grupo. }\tabularnewline

\toprule
Seq & Diff & Minutes \\ 
\midrule
AB & 17 & 1.3 \\ 
AB & 7 & 3.33 \\ 
BA & -10 & 50345.95 \\ 
BA & -12 & 1.7 \\ 
\bottomrule
\end{longtable}

En la Figura~\ref{fig-freqs} representamos la frecuencia relativa del
valor de respuesta para cada grupo y test en todas la preguntas
\footnote{En el Tabla~\ref{tbl-resume} se presenta la misma información
  con los valores absolutos.}. Esta es otra forma de comparar los
niveles de subtitulado.

\hypertarget{tbl-resume}{}
\begin{longtable}{cccrrrrrr}
\caption{\label{tbl-resume}Resumen de frecuencias de respuesta. }\tabularnewline

\toprule
 &  &  &  & \multicolumn{5}{c}{Response} \\ 
\cmidrule(lr){5-9}
Seq & Period & Treat & 0 & 1 & 2 & 3 & 4 & 5 \\ 
\midrule
AB & 1 & A & 39 & 2 & 25 & 71 & 203 & 434 \\ 
AB & 2 & B & 43 & 87 & 185 & 121 & 172 & 166 \\ 
BA & 1 & B & 40 & 76 & 174 & 127 & 237 & 138 \\ 
BA & 2 & A & 30 & 2 & 30 & 64 & 345 & 321 \\ 
\bottomrule
\end{longtable}

La Figura~\ref{fig-freqs} muestra algunas cuestiones interesantes:

\begin{itemize}
\item
  El tratamiento (subtitulado) con nivel \(A\) presenta claramente
  mayores valores de respuesta que el \(B\) como ya habíamos visto (ver
  Figura~\ref{fig-diff}).
\item
  En general los dos grupos muestran bastante acuerdo en el subtitulado
  en ambos niveles: En el nivel de tratamiento \(A\) los dos grupos
  tienen una frecuencia relativa similar de respuestas positivas
  (valores 4 y 5). El grupo \(AB\) tiene un 82\% de respuestas positivas
  frente a un 84\% el grupo \(BA\). No obstante, el grupo \(AB\) tiene
  más respuestas con valor 5 que el grupo \(BA\) (56\% frente a 41\%).
  La valoración es también similar entre grupos en el nivel de
  tratamiento \(B\): el grupo \(AB\) tiene 44\% de respuestas positivas
  y 47\% el grupo \(BA\). Las valoraciones negativas (1, 2), la neutra
  (3) y la \enquote*{No sé / No contesto} (0) son también muy similares.
\item
  Las respuestas son similares entre periodos aunque ligeramente más
  negativas en el segundo. Así un 65\% de las respuestas son positivas
  en el primer periodo frente a un 64\% en el segundo.
\end{itemize}

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-freqs-1.pdf}

}

\caption{\label{fig-freqs}Frecuencias relativas de las respuestas al
test.}

\end{figure}

El análisis marginalizado de tratamiento, secuencia y periodo tiene
estos resultados referidos a las preguntas con contestación positiva (4,
5):

\begin{itemize}
\item
  El tratamiento \(A\) tiene un 83\% marginalizado de respuestas
  positivas frente al 46\% del tratamiento \(B\).
\item
  El periodo 1 tiene un 65\% marginalizado de respuestas positivas
  frente al 64\% del periodo 2.
\item
  Finalmente, la secuencia \(AB\) tiene un 63\% de respuestas positivas
  frente 66\% de la secuencia \(BA\).
\end{itemize}

\hypertarget{anuxe1lisis-de-las-preguntas.}{%
\subsection{Análisis de las
preguntas.}\label{anuxe1lisis-de-las-preguntas.}}

El gráfico Figura~\ref{fig-levels} muestra la frecuencia relativa por
grupo y por test de las preguntas clasificadas por niveles de respuesta,
considerando que:

\begin{itemize}
\tightlist
\item
  Los niveles 1 y 2 se consideran valoraciones negativas.
\item
  El nivel 3 se considera neutro.
\item
  Los niveles 4 y 5 se consideran positivos.
\item
  El nivel 0 (\enquote{No sé / No contesto}) se excluye en este
  análisis.
\end{itemize}

Se muestra en primer lugar la pregunta 18 por ser una valoración global
del subtitulado y que resume la opinión que sobre el mismo tiene el
estudiante. Volvemos a constatar que el subtitulado \(A\) es mejor
valorado por los estudiantes, pero ahora vemos que en las 18 preguntas
ambos grupos tienen más puntuaciones positivas y menos negativas en el
subtitulado \(A\) que el \(B\). También volvemos a encontrar que los dos
grupos valoran de forma muy similar los dos niveles de subtitulado en
todas la preguntas. En el nivel de subtitulado \(A\) las preguntas
\(Q15\), \(Q16\) y \(Q17\) obtienen relativamente peores valoraciones
(consultar la Tabla~\ref{tbl-likert-scale} para ver los valores) y estas
son similares en ambos subtitulados. Hay algunas preguntas que son
valoradas de forma positiva incluso en el nivel de subtitulado \(B\)
(por ejemplo \(Q04\) o \(Q13\)) y que, por lo tanto, su valoración es
similar en ambos subtitulados. Por último, las preguntas \(Q05\) y
\(Q09\) (también la \(Q14\) pero solo para el grupo \(BA\)) tienen una
valoración muy negativa en el nivel de subtitulado \(B\).

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-levels-1.pdf}

}

\caption{\label{fig-levels}Frecuencias relativas de las respuestas por
pregunta.}

\end{figure}

La figura Figura~\ref{fig-likert} clasifica la preguntas por valoración
y permite constatar lo que ya habíamos visto en el párrafo anterior con
mayor comodidad.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{4_files/figure-pdf/fig-likert-1.pdf}

}

}

\subcaption{\label{fig-likert-1}Seq AB , Treat A}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{4_files/figure-pdf/fig-likert-2.pdf}

}

}

\subcaption{\label{fig-likert-2}Seq AB , Treat B}
\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{4_files/figure-pdf/fig-likert-3.pdf}

}

}

\subcaption{\label{fig-likert-3}Seq BA , Treat A}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{4_files/figure-pdf/fig-likert-4.pdf}

}

}

\subcaption{\label{fig-likert-4}Seq BA , Treat B}
\end{minipage}%

\caption{\label{fig-likert}Preguntas ordenadas por valoración.}

\end{figure}

En la Figura~\ref{fig-improve} se muestra para cada pregunta la
proporción de estudiantes que han valorado mejor el subtitulado \(A\)
que el \(B\) \footnote{Se han eleminado las preguntas en las que una de
  las dos respuestas del usuario ha sido \enquote{No sé / No contesto}.
  La comparación realizada es respuesta en \(A > B\) frente a
  \(A >= B\).}. Se comprueba que la mayoría de las preguntas superan el
50\%, lo que indica que los estudiantes valoran mejor el subtitulado
\(A\).

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-improve-1.pdf}

}

\caption{\label{fig-improve}Frecuencia de preguntas que mejoran por
estudiante entre subtitulados (A \textgreater{} B)}

\end{figure}

\begin{figure}[h]

{\centering \includegraphics{4_files/figure-pdf/fig-improve-2-1.pdf}

}

\caption{\label{fig-improve-2}Frecuencia de preguntas que mejoran por
estudiante entre subtitulados (positive A vs negative B)}

\end{figure}

En la Figura~\ref{fig-improve-2} se hace una comparación más exigente ya
que ahora se muestra la frecuencia con la que los estudiantes cambian el
nivel del subtitulado: de haber valorado el subtitulado positivamente (4
ó 5) en \(A\) a hacerlo de forma negativa en \(B\) (1 ó 2). En esta
ocasión solo las preguntas Q05, Q09 superan el 50\%.

\hypertarget{sec-or-2}{%
\section{\texorpdfstring{Comparación con
\(Odds\ Ratio\)}{Comparación con Odds\textbackslash{} Ratio}}\label{sec-or-2}}

En la sección Sección~\ref{sec-or} se explicó el fundamento teórico de
esta técnica. Aquí se expone como se puede aplicar al diseño de
experimento que se está analizando. En la sección de resultados se
comentarán e interpretarán los valores producidos por este test. Podemos
contrastar la hipótesis de que el \(OR\) entre subtítulos y grupos para
cada nivel de respuesta presenta diferencias significativas entre los
dos grupos. Este \(OR\) se define:

\begin{equation}
OR_{(Treat, Seq \mid Response=r)}=\frac{
    \frac{
            P(Treat=A \mid Seq=AB, Response=r)
        }{
            P(Treat=B \mid Seq=AB, Response=r)
        }
    }
    {\frac{
        P(Treat=A \mid Seq=BA, Response=r)
        }{
        P(Treat=B \mid Seq=BA, Response=r)
    }
}
\end{equation}

Si los \(odds\) son similares en cada nivel de respuesta, podemos
aceptar que la hipótesis nula de que los grupos responden de forma
similar a cada nivel de subtitulado. Se hará un test similar pero entre
subtitulado y periodos.

\hypertarget{sec-logistica-2}{%
\section{Regresión Logística}\label{sec-logistica-2}}

En la Sección~\ref{sec-logistica} se presentó el fundamento teórico de
la Regresión Ordinal Acumulativa. En esta sección se justifica el uso de
esta técnica y se ajustan y comparan varios modelos. La variable
respuesta se compone de 5 valores ordenados. Esto impide usar
directamente la Regresión Logística. No obstante, podemos comparar la
respuesta que cada estudiante dio a cada uno de los subtitulados y
comprobar si ha mejorado o no. Esto producirá una variable de respuesta
binaria que permitirá el uso de la regresión logística. Por el contrario
reducirá la cantidad de datos disponibles a la mitad e impedirá analizar
el efecto periodo. Se ha transformado el \texttt{dataframe} de tal forma
que si un usuario valoró una pregunta mejor en el subtitulado \(A\) que
en el \(B\), se consigna 1 en la variable respuesta, si empeoró o puntuó
igual se consigna 0. Si en un0 de los test valora una pregunta con
\enquote{No sé / No contesto}, se elimina esa pregunta.

Se ajusta el modelo con la secuencia como predictor. Se constata que el
coeficiente del intercepto es positivo y significativo. El intercepto es
el \(log\ odds\) de mejorar la valoración en \(A\) sobre \(B\) respecto
a empeorar la valoración. Sin embargo, la secuencia no resulta
significativa y además añadirla apenas reduce la \enquote{deviance}, por
lo que el modelo nulo sin predictores resulta más parsimonioso. Se
podrían añadir como predictores las preguntas y los estudiantes. No se
hace aquí y se pospone la discusión de esto hasta el uso de modelos
mixtos.

\begin{verbatim}

Call:
glm(formula = Improve ~ 1 + Seq, data = df_improve)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.5935  -0.5811   0.4065   0.4189   0.4189  

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.59353    0.01848  32.125   <2e-16 ***
SeqBA       -0.01245    0.02587  -0.481     0.63    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for gaussian family taken to be 0.2426952)

    Null deviance: 351.72  on 1450  degrees of freedom
Residual deviance: 351.67  on 1449  degrees of freedom
AIC: 2067.2

Number of Fisher Scoring iterations: 2
\end{verbatim}

\hypertarget{sec-ordinal-2}{%
\section{Regresión Ordinal}\label{sec-ordinal-2}}

En la Sección~\ref{sec-ordinal} se presentó el fundamento teórico de la
Regresión Ordinal Acumulativa. En esta sección se ajustan algunos
modelos y se interpretan los resultados.

\hypertarget{ajuste-del-modelo-ordinal-response-treat}{%
\subsection{\texorpdfstring{Ajuste del modelo ordinal
\texttt{Response\ \textasciitilde{}\ Treat}}{Ajuste del modelo ordinal Response \textasciitilde{} Treat}}\label{ajuste-del-modelo-ordinal-response-treat}}

Existen varios paquetes en R que permiten ajustar una regresión ordinal
logística. El más popular es el paquete \texttt{Ordinal}
\autocite{ordinalR}. El paquete \texttt{VGAM} \autocite{VGAMR} es más
flexible y potente. Otra posibilidad es usar la función \texttt{polr}
del paquete \texttt{MASS} \autocite{MASSR}. Finalmente la función
\texttt{orm} del paquete \texttt{rms} también permite hacerlo
\autocite[ver][]{harrell2015}. En este trabajo usaremos el paquete
\texttt{Ordinal} por permitir también incluir efectos aleatorios que
utilizaremos en un apartado posterior. Comenzamos con un modelo simple
que tiene como único predictor el nivel de subtitulado por ser la
variable objetivo de nuestro modelo:

\[
\text{logit}(P(Response_i \leq k)) = \tau_k - \beta_1 \text{Treat}_i,
\]

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clm\_treat }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(clm\_treat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
formula: Response ~ Treat
data:    df_clean

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  2980 -3966.11 7942.21 5(0)  1.64e-10 3.1e+01

Coefficients:
       Estimate Std. Error z value Pr(>|z|)    
TreatB  -1.7206     0.0731  -23.54   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -3.97230    0.09678 -41.045
2|3 -2.45446    0.06812 -36.029
3|4 -1.66453    0.05936 -28.042
4|5 -0.10547    0.04946  -2.132
\end{verbatim}

\normalsize

El método \texttt{summary()} muestra la información resumen. Para su
interpretación vamos a seguir \textcite{christensen2018CumulativeLM}. El
número de condición Hessiano es inferior a \(10^4\) lo que es indicativo
de que no hay problemas de optimización \footnote{El número de condición
  de Hessiano es una medida de la curvatura de una función en un punto.
  Si el número de condición de Hessiano es grande, la función es muy
  sensible a pequeñas perturbaciones y puede ser difícil de optimizar.}.
La sección de coeficientes es la más importante. Se muestra la
estimación de parámetros, el error estándar y la significación
estadística de acuerdo al test de Wald \footnote{El test de Wald es un
  contraste de hipótesis estadístico en el que se evalúa si el valor
  estimado es cero suponiendo que
  \(W = \left(\frac{\hat{\theta} - \theta_0}{se(\hat{\theta})}\right)^2 \sim \chi^{2}\)
  .}. Comprobamos que el valor es claramente significativo. Es decir,
que los estudiantes han valorado de forma diferente la calidad del
subtitulado en ambos vídeos. El estimador de maxima verosimilitud del
coeficiente \texttt{TreatB} es -1.72. Siguiendo la deducción de
\textcite{bruin2011} podemos, por ejemplo, hacer la siguiente
interpretación del significado de este coeficiente referido a dos
niveles consecutivos de respuesta:

\[
\begin{aligned}
logit [P(Y \le 1)] & = & -3.97 - (-1.72 x_1) \\
logit [P(Y \le 2)] & = & -2.45 - (-1.72 x_1)
\end{aligned}
\]

Por lo tanto los \(odds\) serían:

\[
\begin{aligned}
\frac{P(Y \le 1 \mid x_1 = B)}{P(Y > 1 \mid x_1 = B)} & = & exp(-3.97)/exp(-1.72) \\
\frac{P(Y \le 1 \mid x_1 = A)}{P(Y > 1 \mid x_1 = A)} & = & exp(-3.97) \\
\frac{P(Y \le 2 \mid x_1 = B)}{P(Y > 2 \mid x_1 = B)} & = & exp(-2.45)/exp(-1.72) \\
\frac{P(Y \le 2 \mid x_1 = A)}{P(Y > 2 \mid x_1 = A)} & = & exp(-2.45)
\end{aligned}
\]

Y los \(OR\):

\[
\begin{aligned}
\frac{P(Y \le 1 | x_1=B)}{P(Y > 1 | x_1=B)} / \frac{P(Y \le 1 | x_1=A)}{P(Y > 1 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\
\frac{P(Y \le 2 | x_1=B)}{P(Y > 2 | x_1=B)} / \frac{P(Y \le 2 | x_1=A)}{P(Y > 2 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\
\end{aligned}
\]

Se comprueba que el \(OR\) es equivalente en todos los niveles de
respuesta al cuestionario. Esta es una de las suposiciones de la
regresión ordinal acumulativa. El \(odds\) de respuesta al cuestionario
entre los niveles inferiores y superiores a uno dado, \(k\), es 5.59
veces en el subtitulado \(B\) que en el \(A\). Esto indica que el
subtitulado \(B\) es percibido por los estudiantes como de peor calidad
que el subtitulado \(A\). Concretamente, el coeficiente \(\beta\) para
\texttt{Treat} es el \texttt{log\ odds} de observar una mejor respuesta
en una pregunta del test es 5.59 veces superior en el nivel de
subtitulado \(A\) que en el \(B\). Aunque no suele ser de interés la
interpretación de los coeficientes de los umbrales
(\texttt{Threshold\ coefficients}), se pueden utilizar para estimar las
probabilidades de respuesta. Por ejemplo, para el nivel de subtitulado
\(B\):

\[
\begin{aligned}
logit [P(Y \le 1)] & = & -3.97 - (-1.72) & = & -2.25 \\
odds (P(Y \le 1)) & = & exp(logit [P(Y \le 1)]) & = & 0.11 \\
P(Y \le 1) & = & \frac{exp(-2.25)}{1 + exp(-2.25)} & = & 0.10 \\
P(Y \le 2) & = & \frac{exp(-0.73)}{1 + exp(-0.73)} & = & 0.32 \\
P(Y = 2) & = & P(Y \le 2) - P(Y \le 1) & = &  0.23 
\end{aligned}
\]

Para el subtitulado \(A\) no se tiene en cuenta el coeficiente
\(TreatB\) ya que el valor \(x_1\) es cero:

\[
\begin{aligned}
logit [P(Y \le 1)] & = & & & -3.97\\
odds (P(Y \le 1)) & = & exp(logit [P(Y \le 1)]) & = & 0.02 \\
P(Y \le 1) & = & \frac{exp(-3.97)}{1 + exp(-3.97)} & = & 0.02
\end{aligned}
\]

En Tabla~\ref{tbl-probs-clm-treat} se muestran las probabilidades para
ambos niveles de subtitulado y todos los posibles valores de respuesta.

\hypertarget{tbl-probs-clm-treat}{}
\begin{longtable}[]{@{}lrrrrr@{}}
\caption{\label{tbl-probs-clm-treat}Probabilidades de respuesta para el
modelo ordinal Response \textasciitilde{} Treat}\tabularnewline
\toprule\noalign{}
& 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 0.018 & 0.061 & 0.08 & 0.315 & 0.526 \\
B & 0.095 & 0.229 & 0.19 & 0.320 & 0.166 \\
\end{longtable}

\hypertarget{ajuste-del-modelo-ordinal-response-treat-period}{%
\subsection{\texorpdfstring{Ajuste del modelo ordinal
\texttt{Response\ \textasciitilde{}\ Treat\ +\ Period}}{Ajuste del modelo ordinal Response \textasciitilde{} Treat + Period}}\label{ajuste-del-modelo-ordinal-response-treat-period}}

Para saber si existe un efecto periodo, añadimos como predictor la
variable \texttt{Period}.

\[
\text{logit}(P(Response_i \leq k)) = \tau_k - \beta_1 \text{Treat}_i - \beta_2 \text{Period}_i
\]

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clm\_treat\_period }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(clm\_treat\_period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
formula: Response ~ Treat + Period
data:    df_clean

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  2980 -3957.88 7927.76 5(0)  1.94e-10 4.1e+01

Coefficients:
        Estimate Std. Error z value Pr(>|z|)    
TreatB  -1.74090    0.07339  -23.72  < 2e-16 ***
Period2 -0.27560    0.06805   -4.05 5.12e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -4.13085    0.10507 -39.314
2|3 -2.60905    0.07872 -33.143
3|4 -1.81652    0.07073 -25.681
4|5 -0.25187    0.06153  -4.093
\end{verbatim}

\normalsize

Vemos que ambos coeficientes son significativos y con signo negativo. Un
signo negativo en el efecto periodo está asociado con que la valoración
del subtitulado empeora en el segundo periodo independientemente de si
se trata del subtitulado correcto o incorrecto. Aplicando el mismo
razonamiento del apartado anterior, el \(OR\) del efecto periodo es
\(1/exp(-0.28) = 1.32\). Lo que quiere decir que una vez controlado el
efecto principal del tratamiento, el subtitulado en el segundo periodo
es valorado como de inferior calidad que en el primero. Esto estaría
indicando que los estudiantes son más exigentes con el subtitulado en la
segunda actividad independientemente de su calidad real.

\hypertarget{ajuste-del-modelo-ordinal-response-treat-period-1}{%
\subsection{\texorpdfstring{Ajuste del modelo ordinal
\texttt{Response\ \textasciitilde{}\ Treat\ *\ Period}}{Ajuste del modelo ordinal Response \textasciitilde{} Treat * Period}}\label{ajuste-del-modelo-ordinal-response-treat-period-1}}

Añadimos al modelo la interacción entre subtitulado y periodo. Esta
interacción corresponde al efecto secuencia. Se puede demostrar que los
modelos \texttt{Response\ \textasciitilde{}\ Treat*Period} y
\texttt{Response\ \textasciitilde{}\ Treat\ +\ Period\ +\ Seq}
ver~\ref{sec-contrasts}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.treatment"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{clm\_treat.period }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
formula: Response ~ Treat * Period
data:    df_clean

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  2980 -3953.01 7920.03 5(0)  2.14e-10 8.1e+01

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB         -1.96046    0.10229 -19.166  < 2e-16 ***
Period2        -0.49179    0.09744  -5.047 4.49e-07 ***
TreatB:Period2  0.42510    0.13638   3.117  0.00183 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -4.24649    0.11182 -37.977
2|3 -2.72823    0.08821 -30.928
3|4 -1.93833    0.08167 -23.732
4|5 -0.36991    0.07308  -5.062
\end{verbatim}

\normalsize

Vemos que los tres coeficientes son significativos. El principal efecto
es el nivel de subtitulado obteniendo mejores puntuaciones el nivel
\(A\); el efecto periodo es negativo por lo que el primer periodo
obtiene mejores puntuaciones; por último, el efecto secuencia es
positivo pero de menor valor absoluto que el efecto periodo. Esto quiere
decir que el subtitulado de nivel \(B\) en el periodo 2 (secuencia
\(AB\)), tiene un efecto periodo inferior que el subtitulado \(A\) en el
mismo periodo. Matemáticamente:

\[
\begin{aligned}
logit [P(Y \le 1 \mid Treat = A, Period = 1)] & = & -4.25 \\
logit [P(Y \le 1 \mid Treat = B, Period = 1)] & = & -4.25 - (-1.96) \\
logit [P(Y \le 1 \mid Treat = A, Period = 2)] & = & -4.25 - (-0.49) \\
logit [P(Y \le 1 \mid Treat = B, Period = 2)] & = & -4.25 -(-1.96 -0.49 + 0.43)
\end{aligned}
\]

En definitiva, en el nivel de subtitulado \(B\) apenas encontramos
diferencias entre periodos, sin embargo, en el nivel de subtitulado
\(A\) existe un efecto periodo cuyo valor en \texttt{logits} es -0.49.
Es decir, que la valoración del subtitulado de nivel \(A\) es inferior
en el segundo periodo que en el primero.

\hypertarget{elecciuxf3n-del-modelo-ordinal-mediante-el-test-de-razuxf3n-de-verosimilitud}{%
\subsection{Elección del modelo ordinal mediante el test de razón de
verosimilitud}\label{elecciuxf3n-del-modelo-ordinal-mediante-el-test-de-razuxf3n-de-verosimilitud}}

Al ser los tres modelos anidados, podemos compararlos con la prueba de
razón de verosimilitud. Comprobamos que el tercer modelo (el que
incorpora la interacción entre los subtítulos y el periodo) reduce
significativamente el logaritmo de la función de verosimilitud y, por lo
tanto, debe ser aceptado:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(clm\_treat, clm\_treat\_period, clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Likelihood ratio tests of cumulative link models:
 
                 formula:                  link: threshold:
clm_treat        Response ~ Treat          logit flexible  
clm_treat_period Response ~ Treat + Period logit flexible  
clm_treat.period Response ~ Treat * Period logit flexible  

                 no.par    AIC  logLik LR.stat df Pr(>Chisq)    
clm_treat             5 7942.2 -3966.1                          
clm_treat_period      6 7927.8 -3957.9  16.448  1      5e-05 ***
clm_treat.period      7 7920.0 -3953.0   9.738  1   0.001805 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

\hypertarget{comprobaciuxf3n-de-las-hipuxf3tesis-del-modelo}{%
\subsection{Comprobación de las hipótesis del
modelo}\label{comprobaciuxf3n-de-las-hipuxf3tesis-del-modelo}}

La principal hipótesis de un modelo de regresión logística ordinal
proporcional acumulativa es que los coeficientes son iguales entre
cualesquiera dos niveles de respuestas correlativos. Se han propuesto
diversas fórmulas para comprobar esta hipótesis. El paquete
\texttt{Ordinal} dispone de la función \texttt{nominal\_test()} que lo
que hace es realizar un test de razón de verosimilitud para cada
predictor ajustando un modelo en el que se ha relajado la condición de
proporcionalidad. Se constata que el test resulta significativo para
\texttt{Treat} y para \texttt{Treat:Period}, por lo que para estas dos
variables no se puede asumir que los coeficientes estimados se mantengan
constantes en todos los niveles de respuesta.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nominal\_test}\NormalTok{(clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Tests of nominal effects

formula: Response ~ Treat * Period
             Df  logLik    AIC     LRT Pr(>Chi)    
<none>          -3953.0 7920.0                     
Treat         3 -3904.4 7828.9  97.172   <2e-16 ***
Period        3 -3951.4 7922.7   3.307   0.3467    
Treat:Period  9 -3884.8 7801.6 136.408   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

Lo que procede es ajustar el modelo relajando la constante de
proporcionalidad de esas variables. Se ha realizado esto utilizando la
función \texttt{vglm} del paquete \texttt{VGAM}. Vemos que ahora hay
cuatro coeficientes para cada una de las variables \texttt{Treat} y
\texttt{Treat:Period} \footnote{Los umbrales tienen los mismos valores
  pero de signo contrario debido a diferencias en la parametrización del
  modelo en cada función utilizada.}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vglm\_treat.period }\OtherTok{\textless{}{-}} \FunctionTok{vglm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period,}
\NormalTok{    VGAM}\SpecialCharTok{::}\FunctionTok{cumulative}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{, }\AttributeTok{parallel =}\NormalTok{ F }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Treat}\SpecialCharTok{:}\NormalTok{Period, }\AttributeTok{reverse =}\NormalTok{ T),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{coef}\NormalTok{(vglm\_treat.period) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{data.frame}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                          .
(Intercept):1     6.2295614
(Intercept):2     3.5001281
(Intercept):3     2.2121438
(Intercept):4     0.2998788
TreatB:1         -4.0441016
TreatB:2         -2.8029889
TreatB:3         -2.2174630
TreatB:4         -1.7926200
Period2          -0.5345919
TreatB:Period2:1  0.3509228
TreatB:Period2:2  0.3607009
TreatB:Period2:3  0.3891474
TreatB:Period2:4  0.8024952
\end{verbatim}

\normalsize

\bookmarksetup{startatroot}

\hypertarget{sec-resultados}{%
\chapter{Resultados}\label{sec-resultados}}

En esté capítulo se comentarán los resultados de las técnicas
estadísticas (ver Sección~\ref{sec-tecnicas}) y de los modelos
propuestos (ver \textbf{?@sec-modelos}).

\hypertarget{sec-cronbach-2}{%
\subsection{Correlación entre preguntas con el alfa de
Cronbach.}\label{sec-cronbach-2}}

\scriptsize

\normalsize

El coeficiente \texttt{alfa\ de\ Cronbach} (ver
Sección~\ref{sec-cronbach}) de la escala de Likert es 0.921 que indica
una muy buena correlación entre las respuestas a todas las preguntas.
Este valor apenas se ve alterado si se elimina una de las preguntas.
Esto nos permite concluir que todos los ítems pertenecen a la misma
escala de Likert.

En la Tabla~\ref{tbl-item-alpha} mostramos las preguntas que más
contribuyen al índice \texttt{alpha\ de\ Cronbach}. Es interesante que
la pregunta \(Q18\), que es la valoración general del cuestionario, sea
la que mejor contribución tiene al índice.

\tiny

\begin{table}

\caption{\label{tbl-item-alpha}Relación de cada pregunta con el índice
alpha de Cronbach.}\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-item-alpha-1}Variables con mayor asociación. }

{\centering 

\begin{longtable}{rrrrrrrrr}
\tabularnewline

\toprule
Q18 & Q05 & Q06 & Q09 & Q08 & Q07 & Q10 & Q12 & Q02 \\ 
\midrule
0.86 & 0.81 & 0.79 & 0.79 & 0.77 & 0.75 & 0.73 & 0.72 & 0.71 \\ 
\bottomrule
\end{longtable}

}

\end{minipage}%
\newline
\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-item-alpha-2}Variables con menor asociación. }

{\centering 

\begin{longtable}{rrrrrrrrr}
\tabularnewline

\toprule
Q03 & Q14 & Q01 & Q11 & Q15 & Q13 & Q04 & Q16 & Q17 \\ 
\midrule
0.68 & 0.66 & 0.65 & 0.64 & 0.56 & 0.51 & 0.46 & 0.44 & 0.42 \\ 
\bottomrule
\end{longtable}

}

\end{minipage}%

\end{table}

\normalsize

\hypertarget{sec-chi2-2}{%
\subsection{\texorpdfstring{Asociación de variables con la prueba de
homogeneidad
\(\chi^2\)}{Asociación de variables con la prueba de homogeneidad \textbackslash chi\^{}2}}\label{sec-chi2-2}}

En la Sección~\ref{sec-chi2} se describe el marco teórico de esta prueba
no paramétrica. Se ha contrastado la existencia de asociación entre la
variable respuesta \(Response\) y cada una de las tres variables más
importantes de nuestro modelo (\(Treat\), \(Period\) y \(Seq\)). En la
Tabla~\ref{tbl-contingencia-2} se muestran las tablas de contingencia.
En la Tabla~\ref{tbl-chi2} se muestra que todos los contrastes son
significativos, con lo que se rechaza la hipótesis nula de homogeneidad.
Todas las variables explicativas tienen influencia en la variable
respuesta.

\begin{table}

\caption{\label{tbl-contingencia-2}Tablas de
contingencia.}\begin{minipage}[t]{0.33\linewidth}
\subcaption{\label{tbl-contingencia-2-1}\textasciitilde{} Response +
Treat}

{\centering 

\begin{tabular}[t]{lrr}
\toprule
Response & A & B\\
\midrule
1 & 4 & 163\\
2 & 55 & 359\\
3 & 135 & 248\\
4 & 548 & 409\\
5 & 755 & 304\\
\bottomrule
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}
\subcaption{\label{tbl-contingencia-2-2}\textasciitilde{} Response +
Period}

{\centering 

\begin{tabular}[t]{rr}
\toprule
1 & 2\\
\midrule
78 & 89\\
199 & 215\\
198 & 185\\
440 & 517\\
572 & 487\\
\bottomrule
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}
\subcaption{\label{tbl-contingencia-2-3}\textasciitilde{} Response +
Seq}

{\centering 

\begin{tabular}[t]{rr}
\toprule
AB & BA\\
\midrule
89 & 78\\
210 & 204\\
192 & 191\\
375 & 582\\
600 & 459\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}

\hypertarget{tbl-chi2}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1100}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2900}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3000}}@{}}
\caption{\label{tbl-chi2}Valores del contraste de hipótesis
\(\chi^2\)}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\textasciitilde{} Response + Treat
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\textasciitilde{} Response + Period
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\textasciitilde{} Response + Seq
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\textasciitilde{} Response + Treat
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\textasciitilde{} Response + Period
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\textasciitilde{} Response + Seq
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\chi^2\) & 621.497 & 15.039 & 64.904 \\
\(p\)-value & \ensuremath{4.5778215\times 10^{-132}} & 0.0101975 &
\ensuremath{1.1733569\times 10^{-12}} \\
\(df\) & 5 & 5 & 5 \\
\end{longtable}

\hypertarget{sec-or-3}{%
\subsection{\texorpdfstring{Comparación con
\(Odds\ Ratio\)}{Comparación con Odds\textbackslash{} Ratio}}\label{sec-or-3}}

En Sección~\ref{sec-or} y en Sección~\ref{sec-or-2} se exponen el marco
teórico y la fundamentación de los contrastes de hipótesis realizados
respectivamente. El contraste de hipótesis del \(log\ OR\) del
subtitulado para cada grupo no produce significación estadística en
ningún nivel de respuesta, por lo que según esta prueba estadística la
secuencia de subtitulado no influiría en la respuesta de los estudiantes
(ver Tabla~\ref{tbl-logor1}). Es decir, de acuerdo a este la secuencia
no influye en la valoración de los subtítulos.

\hypertarget{tbl-logor1}{}
\begin{longtable}{lrrrr}
\caption{\label{tbl-logor1}\(Log OR\) \textasciitilde{} Treat + Seq + Response\_l }\tabularnewline

\toprule
Response & Estimate & Std. Error & z value & Pr(>|z|) \\ 
\midrule
No sé / No contesto & 0.190 & 0.327 & 0.580 & 0.562 \\ 
Muy en desacuerdo & -0.135 & 1.012 & -0.134 & 0.894 \\ 
En desacuerdo & -0.244 & 0.291 & -0.838 & 0.402 \\ 
Neutral & 0.152 & 0.214 & 0.711 & 0.477 \\ 
De acuerdo & -0.210 & 0.134 & -1.570 & 0.116 \\ 
Muy de acuerdo & 0.117 & 0.137 & 0.855 & 0.393 \\ 
\bottomrule
\end{longtable}

Sin embargo, si realizamos este contraste entre subtítulos y periodos
podemos constatar la existencia de un efecto periodo de signo contrario
para las preguntas 4 y 5 (ver Tabla~\ref{tbl-logor2}). La razón de que
se produzca este efecto periodo es que algunas de las respuestas de
valoración 5 en ambos niveles de subtitulado y grupos en el primer
periodo se convierten en valoración 4 en el segundo periodo. Esto se
puede ver más claramente en la Figura~\ref{fig-or2}.

\hypertarget{tbl-logor2}{}
\begin{longtable}{lrrrr}
\caption{\label{tbl-logor2}\(Log OR\) \textasciitilde{} Treat + Period + Response\_l }\tabularnewline

\toprule
Response & Estimate & Std. Error & z value & Pr(>|z|) \\ 
\midrule
No sé / No contesto & 0.335 & 0.327 & 1.022 & 0.307 \\ 
Muy en desacuerdo & 0.135 & 1.012 & 0.134 & 0.894 \\ 
En desacuerdo & -0.121 & 0.291 & -0.416 & 0.677 \\ 
Neutral & 0.055 & 0.214 & 0.259 & 0.796 \\ 
De acuerdo & -0.851 & 0.134 & -6.367 & 0.000 \\ 
Muy de acuerdo & 0.486 & 0.137 & 3.557 & 0.000 \\ 
\bottomrule
\end{longtable}

\begin{figure}[h]

{\centering \includegraphics{5_files/figure-pdf/fig-or2-1.pdf}

}

\caption{\label{fig-or2}OR \textasciitilde{} Treat + Period + Response}

\end{figure}

\bookmarksetup{startatroot}

\hypertarget{sec-conclusiones}{%
\chapter{Discusión y conclusiones}\label{sec-conclusiones}}

\hypertarget{sec-or-4}{%
\section{\texorpdfstring{Comparación con
\(Odds\ Ratio\)}{Comparación con Odds\textbackslash{} Ratio}}\label{sec-or-4}}

En la Sección~\ref{sec-or-3} se constató que hay más proporción de
respuestas 5 en el primer periodo que en el segundo en ambos niveles de
subtitulado. Esto estaría indicando que los estudiantes de ambos grupos
prestaron más atención o fueron más exigentes en el segundo visionado y
decidieron no otorgar la puntuación máxima incluso en algunos ítems al
subtitulado correcto. Que el efecto periodo sea contrario en dos
preguntas (ver @Figura~\ref{fig-or2}) no debe sorprendernos en este
diseño de experimento, ya que un test es un juego de suma cero: la
valoraciones que se ganan o se pierden en un nivel de respuesta
necesariamente provocan que el resto de niveles pierdan o ganen
respectivamente la misma cantidad. En cualquier caso, vemos que el
efecto periodo es cuantitativa y cualitativamente pequeño. Al afectar
solo al intercambio de valoraciones entre los niveles 4 y 5, y ser las
dos positivas, es simplemente una pequeña corrección en la valoración
del subtitulado.

\bookmarksetup{startatroot}

\hypertarget{referencias}{%
\chapter*{Referencias}\label{referencias}}
\addcontentsline{toc}{chapter}{Referencias}

\markboth{Referencias}{Referencias}

\printbibliography[heading=none]

\cleardoublepage
\phantomsection
\addcontentsline{toc}{part}{Apéndices}
\appendix

\hypertarget{sec-contrasts}{%
\chapter{Efecto secuencia e interacción tratamiento
vs.~periodo.}\label{sec-contrasts}}

Vamos a demostrar que el efecto secuencia es equivalente a la
interacción de los factores tratamiento y periodo.

\hypertarget{preparaciuxf3n.}{%
\section{Preparación.}\label{preparaciuxf3n.}}

Partimos del siguiente conjunto de datos generado aleatoriamente
\footnote{Obsérvese que se la variable \texttt{Response} en esta
  simulación es cuantitativa y no ordinal. Se ha realizado de esta forma
  para poder usar un ajuste de mínimos cuadrados en lugar de una
  regresión ordinal para facilitar el cálculo y su interpretación.}:
\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{Response =} \FunctionTok{rnorm}\NormalTok{(n),}
    \AttributeTok{Treat =} \FunctionTok{as.factor}\NormalTok{(}\FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)),}
    \AttributeTok{Period =} \FunctionTok{as.factor}\NormalTok{(}\FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{)}

\NormalTok{df}\SpecialCharTok{$}\NormalTok{Seq }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(}
    \FunctionTok{ifelse}\NormalTok{(}
\NormalTok{        df}\SpecialCharTok{$}\NormalTok{Period }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Treat }\SpecialCharTok{==} \StringTok{"A"} \SpecialCharTok{|}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Period }\SpecialCharTok{==} \DecValTok{2} \SpecialCharTok{\&}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Treat }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{,}
        \StringTok{"AB"}\NormalTok{,}
        \StringTok{"BA"}
\NormalTok{    )}
\NormalTok{)}

\FunctionTok{head}\NormalTok{(df, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      Response Treat Period Seq
1  -0.50219235     B      2  AB
2   0.13153117     A      1  AB
3  -0.07891709     A      2  BA
4   0.88678481     A      2  BA
5   0.11697127     A      1  AB
6   0.31863009     A      2  BA
7  -0.58179068     A      2  BA
8   0.71453271     A      1  AB
9  -0.82525943     B      2  AB
10 -0.35986213     B      1  BA
\end{verbatim}

\normalsize

Calculamos las medias por cada nivel de factor y combinaciones de
niveles que utilizaremos luego en la interpretación de los coeficientes
de los modelos

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Response) }\CommentTok{\# 1 media de respuesta global}

\CommentTok{\# 2 medias de respuesta para tratamientos A y B}
\NormalTok{mTreat }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, Treat, mean))}

\CommentTok{\# 2 medias de respuesta para periodos 1 y 2}
\NormalTok{mPeriod }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, Period, mean))}

\CommentTok{\# 2 medias de respuesta para secuencias AB y BA}
\NormalTok{mSeq }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, Seq, mean))}

\CommentTok{\# 4 medias de respuesta para las cuatro combinaciones de tratamiento y periodo}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, }\FunctionTok{list}\NormalTok{(Treat, Period), mean))}

\NormalTok{dTreat }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(mTreat) }\CommentTok{\# diferencia de medias entre tratamientos A y B}

\NormalTok{dPeriod }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(mPeriod) }\CommentTok{\# diferencia de medias entre periodos 1 y 2}

\NormalTok{d2 }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(m2) }\CommentTok{\# diferencias entre niveles de tratamiento en cada nivel de periodo}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{anuxe1lisis-con-un-solo-factor-tratamiento.}{%
\section{Análisis con un solo factor
(tratamiento).}\label{anuxe1lisis-con-un-solo-factor-tratamiento.}}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l1))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l1}{}
\begin{longtable}{rr}
\caption{\label{tbl-l1}Ajuste del modelo Response \textasciitilde{} Treat con contrasts
treatment. }\tabularnewline

\toprule
X.Intercept. & TreatB \\ 
\midrule
0.03624217 & -0.03966751 \\ 
\bottomrule
\end{longtable}

\normalsize

Vemos que el intercepto es la media de la respuesta en el nivel de
tratamiento \(A\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mTreat[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         A 
0.03624217 
\end{verbatim}

\normalsize

Que la pendiente (parámetro \(TreatB\)) es la diferencia entre las
medias tratamientos:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dTreat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          B 
-0.03966751 
\end{verbatim}

\normalsize

Por ello, para conocer el efecto del tratamiento en el nivel \(B\) hay
que sumar intercepto y pendiente:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(l1)[[}\DecValTok{1}\NormalTok{]] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(l1)[[}\DecValTok{2}\NormalTok{]] }\SpecialCharTok{{-}}\NormalTok{ mTreat[[}\DecValTok{2}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.214306e-16
\end{verbatim}

\normalsize

Esto es así ya que por defecto R utiliza el contraste conocido como
\texttt{codificación\ de\ tratamiento}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{contr.treatment}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  2
1 0
2 1
\end{verbatim}

\normalsize

Podemos ver la matriz ampliada añadiendo el intercepto, que siempre será
una columna de 1's:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{Treat, }\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{Treat =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) TreatB
1           1      0
2           1      1
attr(,"assign")
[1] 0 1
attr(,"contrasts")
attr(,"contrasts")$Treat
[1] "contr.treatment"
\end{verbatim}

\normalsize

Cada fila representa el nivel del tratamiento (fila 1 nivel \(A\) y fila
2 nivel \(B\)) y las columnas representan los parámetros del modelo. Los
valores son los niveles de tratamiento (0 ó 1). Para obtener el
significado de cada parámetro, multiplicamos el valor del contraste por
el parámetro. Así:

\begin{itemize}
\tightlist
\item
  De la primera fila obtenemos que el efecto del tratamiento \(A\) es el
  intercepto: \(A = 1 \cdot Intercept + 0 \cdot TreatB\).
\item
  De la segunda fila obtenemos que el valor del parámetro \(TreatB\) es
  la diferencia de los niveles de tratamiento.
  \(B = 1 \cdot Intercept + 1 \cdot TreatB \Rightarrow TreatB = B - Intercept\).
\end{itemize}

Esto quiere decir que existe una variable para codificar el efecto
tratamiento, y esta variable tiene el valor 0 para el nivel \(A\) por
ser el de referencia y 1 para el nivel \(B\). La pendiente se codifica
como la diferencia del efecto de los dos niveles (\(B - A\)).

\hypertarget{anuxe1lisis-con-un-dos-factores-tratamiento-y-periodo.}{%
\section{Análisis con un dos factores (tratamiento y
periodo).}\label{anuxe1lisis-con-un-dos-factores-tratamiento-y-periodo.}}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l2))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l2}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l2}Ajuste del modelo Response \textasciitilde{} Treat * Period con
contrasts treatment. }\tabularnewline

\toprule
X.Intercept. & TreatB & Period2 & TreatB.Period2 \\ 
\midrule
0.04138614 & -0.1076137 & -0.01125933 & 0.1343517 \\ 
\bottomrule
\end{longtable}

\normalsize

Vemos que el intercepto es la media del tratamiento \(A\) en el periodo
\(1\) por ser estos los valores que R usa como referencia \footnote{R
  utiliza como valor de referencia el nivel más bajo de factor.}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.04138614
\end{verbatim}

\normalsize

El parámetro \(TreatB\) es la diferencia de medias entre los
tratamientos en el periodo \(1\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.1076137
\end{verbatim}

\normalsize

El parámetro \(Period2\) es la diferencia de medias entre los periodos
en el nivel de tratamiento \(A\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.01125933
\end{verbatim}

\normalsize

Finalmente, \(TreatB:Period2\) es la diferencia entre el segundo periodo
y el primero del nivel de tratamiento \(B\) menos la diferencia entre
periodos del nivel de tratamiento \(A\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1343517
\end{verbatim}

\normalsize

La matriz de contraste nos permite razonar por qué esto es así:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, }\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{Treat =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\AttributeTok{Period =} \FunctionTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"2"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) TreatB Period2 TreatB:Period2
1           1      0       0              0
2           1      1       0              0
3           1      0       1              0
4           1      1       1              1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$Treat
[1] "contr.treatment"

attr(,"contrasts")$Period
[1] "contr.treatment"
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  La primera fila es el intercepto y corresponde con el tratamiento
  \(A\) y el periodo 1.
\item
  La segunda fila es el efecto del tratamiento \(B\) en el periodo 1 y
  se calcula con la suma del intercepto y el parámetro \(TreatB\). Luego
  \(TreatB\) es la diferencia del efecto de los tratamientos en el
  periodo 1.
\item
  Análogamente con la tercera fila concluimos que \(Period2\) es la
  deferencia entre periodos para el tratamiento \(A\).
\item
  Finalmente, la cuarta fila, es el tratamiento \(B\) en el periodo 2 y,
  por lo tanto, \(Treat2:Period2\) es la diferencia el nivel \(B\) de
  tratamiento y el periodo 2 y el nivel de tratamiento \(A\) en el
  periodo 1, menos la diferencia de niveles de tratamiento para el
  periodo 1 y menos la diferencia de periodos para el tratamiento \(A\).
\end{itemize}

Obsérvese que antes hemos calculado de forma diferente
\(TreatB:Period2\). Podemos aplicar la fórmula anterior y comprobar que
produce el mismo resultado:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]) }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1343517
\end{verbatim}

\normalsize

\hypertarget{factor-secuencia.}{%
\section{Factor secuencia.}\label{factor-secuencia.}}

Vamos a incorporar la secuencia como factor para ver si es equivalente a
la interacción entre periodo y tratamiento. En caso de serlo los
coeficientes del modelo ajustado deberían coincidir. Sin embargo vemos
que los modelos l2 (Tabla~\ref{tbl-l2}) y l3 (Tabla~\ref{tbl-l3}) tienen
distintos coeficientes.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l3))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l3}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l3}Ajuste del modelo Response \textasciitilde{} Treat + Period + Seq con
contrasts treatment. }\tabularnewline

\toprule
X.Intercept. & TreatB & Period2 & SeqBA \\ 
\midrule
0.04138614 & -0.04043786 & 0.05591654 & -0.06717587 \\ 
\bottomrule
\end{longtable}

\normalsize

Los coeficientes no coinciden debido a que estamos usando el contraste
con \texttt{codificación\ de\ tratamientos}. Pero si cambiamos a
\texttt{codificación\ de\ sumas}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.sum"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\normalsize

Y volvemos a ajustar los modelos que ya usarán el
\texttt{contraste\ suma}, podemos comprobar que ahora tienen los mismos
coeficientes y el coeficiente \(Seq1\) del modelo que incorpora el
efecto secuencia (Tabla~\ref{tbl-l4}) es igual que el coeficiente
\(Treat1:Period1\) del modelo que incorpora la interacción entre
tratamiento y periodo (Tabla~\ref{tbl-l5}). Obsérvese que los nombres de
los coeficientes han cambiado respecto al
\texttt{contraste\ de\ tratamiento}. Esto sucede porque la
interpretación de los coeficientes varía como se explica a continuación.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l4))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l4}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l4}Ajuste del modelo Response \textasciitilde{} Treat + Period + Seq con
contrasts sum. }\tabularnewline

\toprule
X.Intercept. & Treat1 & Period1 & Seq1 \\ 
\midrule
0.01553755 & 0.02021893 & -0.02795827 & 0.03358794 \\ 
\bottomrule
\end{longtable}

\normalsize

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l5 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l5))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l5}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l5}Ajuste del modelo Response \textasciitilde{} Treat * Period con
contrasts sum. }\tabularnewline

\toprule
X.Intercept. & Treat1 & Period1 & Treat1.Period1 \\ 
\midrule
0.01553755 & 0.02021893 & -0.02795827 & 0.03358794 \\ 
\bottomrule
\end{longtable}

\normalsize

La interpretación de los contrastes es diferente. Para explicarlo,
mostramos la matriz de contraste:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, }\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{Treat =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\AttributeTok{Period =} \FunctionTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"2"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) Treat1 Period1 Treat1:Period1
1           1      1       1              1
2           1     -1       1             -1
3           1      1      -1             -1
4           1     -1      -1              1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$Treat
[1] "contr.sum"

attr(,"contrasts")$Period
[1] "contr.sum"
\end{verbatim}

\normalsize

Vemos que ahora los niveles son 1 y -1 \footnote{El nivel de referencia
  del factor tendrá valor 1 y el otro -1. Por ejemplo, en la variable
  \texttt{Treat}, \(A\) tendrá +1 y \(B\) tendrá valor -1.} en vez de 0
y 1 que se utilizan en el contraste de tratamiento. La interpretación es
la siguiente:

\begin{itemize}
\tightlist
\item
  El interceptor es la media de la media de cada uno de los niveles de
  factor. ¿Por qué?. El interceptor es el valor de la variable de
  respuesta cuando cuando todas las variables explicativas valen 0. Esto
  sucede en la media de la variable de respuesta ya que cero es el valor
  que está en la mitad de +1 y -1. Podemos comprobar que la media global
  coincide con el interceptor del modelo l4 (Tabla~\ref{tbl-l4}):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.01553755
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(Treat1\) es la mitad la diferencia de la media entre
  niveles de tratamiento (\(TreatA-TreatB\)). La media de cada
  tratamiento se calcula como la media del tratamiento en cada periodo.
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{1}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         B 
0.02021893 
\end{verbatim}

\normalsize

Otra forma de entender el coeficiente \(Treat1\) es como la cuarta parte
de la diferencia de los efectos de los tratamientos en cada periodo.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.02021893
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(Period1\) es la mitad la diferencia de la media entre
  periodos(\(Period1 - Period2\)). La media entre periodos se calcula
  como la media del periodo para cada tratamiento.
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{2}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          2 
-0.02795827 
\end{verbatim}

\normalsize

Otra forma de entender el coeficiente \(Period1\) es como la cuarta
parte de la diferencia de los efectos del periodo en cada tratamiento.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.02795827
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(Treat1:Period1\) es el coeficiente \(Treat1\) menos
  la mitad de la diferencia de la media entre tratamientos para el
  periodo 2 (\(TreatA-TreatB\)):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{1}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2} \SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[, }\StringTok{"2"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         B 
0.03358794 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(l5)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[, }\StringTok{"2"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Treat1 
0.03358794 
\end{verbatim}

\normalsize

El coeficiente \(Treat1:Period1\) también se puede calcular como
\(Period1\) menos la mitad de la diferencia de la media entre periodos
para el para el tratamiento \(B\) (\(Period1-Period2\)):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{2}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2} \SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[}\StringTok{"B"}\NormalTok{, ]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         2 
0.03358794 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(l5)[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[}\StringTok{"B"}\NormalTok{, ]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Period1 
0.03358794 
\end{verbatim}

\normalsize

Un tercera forma de interpretar el coeficiente \(Treat1:Period1\) es
como la cuarta parte de la suma de la diferencia cruzada del efecto de
cada tratamiento en cada periodo:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.03358794
\end{verbatim}

\normalsize

O reorganizando los términos de otra forma, sería la cuarta parte de la
suma de la diferencia cruzada del efecto de cada periodo en cada
tratamiento:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.03358794
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  Podemos obtener el coeficiente \(TreatB\) del modelo \(l2\)
  (Tabla~\ref{tbl-l2}) como \(-2 \cdot (Treat1 + Treat1:Period1)\):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1"}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1:Period1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Treat1 
-0.1076137 
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  Análogamente el coeficiente \(Period2\) del modelo \(l2\)
  (Tabla~\ref{tbl-l2}) se obtiene
  \(-2 \cdot (Period1 + Treat1:Period1)\):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Period1"}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1:Period1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Period1 
-0.01125933 
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(TreatB:Period2\) se obtiene como
  \(4 \cdot Treat1:Period1\):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{4} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1:Period1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Treat1:Period1 
     0.1343517 
\end{verbatim}

\normalsize


\backmatter
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\SmallMargins

\onecolumn


% Back cover
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Even page, small margins, no running head, no page number.
\evenpage
\SmallMargins
\thispagestyle{empty}




\end{document}
