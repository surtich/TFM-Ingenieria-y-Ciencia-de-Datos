% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
  a4paper,
  extrafontsizes,
  onecolumn,
  openright]{memoir}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[Extension=.otf,UprightFont=*-regular,BoldFont=*-bold,BoldItalicFont=*-bolditalic,ItalicFont=*-italic]{texgyretermes}
  \setmathfont[]{texgyretermes-math.otf}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
% pandoc tempate
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

% Add LaTeX code into the preamble of the document here
\hyphenation{bio-di-ver-si-ty sap-lings}

% Define colors for text boxes
\definecolor{grey}{HTML}{F5F5F5}

% Define text box environments
\usepackage[tikz]{bclogo}
\newmdenv[
  style=boxstyle,
  backgroundcolor=grey,
  frametitlebackgroundcolor=grey,
]{greybox}

\usepackage[automake]{glossaries-extra}
\makeglossaries


\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Tabla de contenidos}
\else
  \newcommand\contentsname{Tabla de contenidos}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Listado de Figuras}
\else
  \newcommand\listfigurename{Listado de Figuras}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Listado de Tablas}
\else
  \newcommand\listtablename{Listado de Tablas}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figura}
\else
  \newcommand\figurename{Figura}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabla}
\else
  \newcommand\tablename{Tabla}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listado}
\newcommand*\listoflistings{\listof{codelisting}{Listado de Listados}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother


% Additional content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\graphicspath{{images/}}


% Chapter Summary environment
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[tikz]{bclogo}
\newenvironment{Summary}
  {\begin{bclogo}[logo=\bctrombone, noborder=true, couleur=lightgray!50]{In
a Nutshell}\parindent0pt}
  {\end{bclogo}}
% Syntax:
%
%```{block, type='Summary'}
% Deliver message here.
% ```


% PDF title page to insert
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Fonts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Local toc
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{titletoc}
\newcommand{\toc}[1]{%
  \startcontents[chapters]%
  \printcontents[chapters]{}{1}[#1]{}%
  ~\newline%
}


% Text boxes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Define a style for mdframed boxes
\mdfdefinestyle{boxstyle}{
	skipabove=1.5\topskip,
	skipbelow=.5\topskip,
	rightmargin=0pt,
	leftmargin=0pt,
	innerrightmargin=7pt,
	innerleftmargin=7pt,
	topline=false,
	bottomline=false,
	rightline=false,
	leftline=false,
	frametitlerule=true,
	linecolor=black,
	fontcolor=black,
	frametitlealignment=\noindent
}


% Layout
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Based on memoir, style companion
\newcommand{\MemoirChapStyle}{daleif1}
\newcommand{\MemoirPageStyle}{Ruled}

% Space between paragraphs
\usepackage{parskip}
  \abnormalparskip{3pt}

% Adjust margin paragraphs vertical position
\usepackage{marginfix}


% Margins
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% allow use of '-',+','/' ans '*' to make simple length computation
\usepackage{calc}

% Full-width figures utilities
\newlength\widthw % full width
\newlength{\rf}
\newcommand*{\definesHSpace}{
  \strictpagecheck % slower but efficient detection of odd/even pages
  \checkoddpage
  \ifoddpage
  \setlength{\rf}{0mm}
  \else
  \setlength{\rf}{\marginparsep+\marginparwidth}
  \fi
}

\makeatletter
% 1" margins for the front matter.
\newcommand*{\SmallMargins}{
  \setlrmarginsandblock{1.5in}{1.5in}{*}
  \setmarginnotes{0.1in}{0.1in}{0.1in}
  \setulmarginsandblock{1.5in}{1in}{*}
  \checkandfixthelayout
  \ch@ngetext
  \clearpage
  \setlength{\widthw}{\textwidth+\marginparsep+\marginparwidth}
  \footnotesatfoot
  \chapterstyle{\MemoirChapStyle}  % Chapter and page styles must be recalled
  \pagestyle{\MemoirPageStyle}
}

% 3" outer margin for the main matter
\newcommand{\LargeMargins}{\SmallMargins}
\makeatother

% Figure captions and footnotes in outer margins


%% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Repeated citation as author-year-title instead of author-title (modification of footcite:note in verbose-inote.cbx)


% memoiR dalef3 chapter style
% https://ctan.crest.fr/tex-archive/info/latex-samples/MemoirChapStyles/MemoirChapStyles.pdf
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{soul}
\definecolor{nicered}{rgb}{.647,.129,.149}
\makeatletter
\newlength\dlf@normtxtw
\setlength\dlf@normtxtw{\textwidth}
\def\myhelvetfont{\def\sfdefault{mdput}}
\newsavebox{\feline@chapter}
% \so\protect\@chapapp replaces \so\@chapapp or \so will fail with babel
\newcommand\feline@chapter@marker[1][4cm]{%
  \sbox\feline@chapter{%
    \resizebox{!}{#1}{\fboxsep=1pt%
	  \colorbox{nicered}{\color{white}\bfseries\sffamily\thechapter}%
	}}%
  \rotatebox{90}{%
    \resizebox{%
	  \heightof{\usebox{\feline@chapter}}+\depthof{\usebox{\feline@chapter}}}%
	{!}{\scshape\so\protect\@chapapp}}\quad%
  \raisebox{\depthof{\usebox{\feline@chapter}}}{\usebox{\feline@chapter}}%
 }
\newcommand\feline@chm[1][4cm]{%
  \sbox\feline@chapter{\feline@chapter@marker[#1]}%
  \makebox[0pt][l]{% aka \rlap
    \makebox[1cm][r]{\usebox\feline@chapter}%
  }}
\makechapterstyle{daleif1}{
  \renewcommand\chapnamefont{\normalfont\Large\scshape\raggedleft\so}
  \renewcommand\chaptitlefont{\normalfont\huge\bfseries\scshape\color{nicered}}
  \renewcommand\chapternamenum{}
  \renewcommand\printchaptername{}
  \renewcommand\printchapternum{\null\hfill\feline@chm[2.5cm]\par}
  \renewcommand\afterchapternum{\par\vskip\midchapskip}
  \renewcommand\printchaptertitle[1]{\chaptitlefont\raggedleft ##1\par}
}
\makeatother


% scriptsize code
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\let\oldverbatim\verbatim
\def\verbatim{\oldverbatim\scriptsize}
% Applies to code blocks and R code results
% code chunk options size='scriptsize' applies only to R code and results
% if the code chunk sets a different size, \def\verbatim{...} is prioritary for code results


% Strict localized quotes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Comes before \usepackage{csquotes} in pandoc template
\usepackage[strict,autostyle]{csquotes}

% End of pandoc.tex. Two line feeds are necessary to avoid commenting the next command
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{spanish}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[backend=biber,style=authoryear-ibid,isbn=false,backref=true,giveninits=true,uniquename=init,maxcitenames=2,maxbibnames=150,sorting=nyt,sortcites=false]{biblatex}
\addbibresource{references.bib}
\usepackage{csquotes}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos},
  pdfauthor={Javier Pérez Arteaga},
  pdflang={es},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

% Title, author, date from YAML to LaTeX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Utilización de técnicas multivariantes para el estudio del
aprendizaje de la mejora de la accesibilidad en el subtitulado de
vídeos}

\author{Javier Pérez Arteaga}

\date{2023-10-03}


% Main title page with filigrane
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Text blocks
\usepackage[absolute,overlay]{textpos}
  \setlength{\TPHorizModule}{1mm}
  \setlength{\TPVertModule}{1mm}

\newcommand{\MainTitlePage}[2]{
  \pagestyle{empty}
    \begin{center}
		\includegraphics[width=10cm]{images/logo.png}
		\LARGE
		\mbox{Universidad Nacional de Educación a Distancia}
		\LARGE
		\mbox{Escuela Técnica Superior de Informática}

		\LARGE
		\mbox{Máster en Ingeniería y Ciencia de Datos}

		\vspace{2cm}
		
		\LARGE
		\textbf{Trabajo Fin de Máster}
		
		\LARGE
		\textbf{\thetitle}

		
		\vspace{2cm}		
		
	\end{center}  
	
	\begin{flushright}
		\LARGE
		\begin{tabular}{ r l }
			Autor: & \theauthor \\
			Directores: & Emilio Letón Molina \\
			& Jorge Pérez Martín \\
			Fecha de realización: & \thedate
		\end{tabular}
		
	\end{flushright}

  \SmallMargins % Margins
  \newpage
  \textblockorigin{\trimedge}{\trimtop} % verso
  \begin{textblock*}{\textwidth}(\paperwidth-\spinemargin-\textwidth, \uppermargin)
    #1
  \end{textblock*}
  \begin{textblock*}{\textwidth}[0,1](\paperwidth-\spinemargin-\textwidth, \uppermargin+\textheight+\footskip)
    \centering
          \includegraphics[width=\paperwidth/4]{logo}\\ \bigskip
        #2
  \end{textblock*}
 
}

% Clear page and open an even one (\clearpage opens an odd one)
\newcommand{\evenpage}{
  \clearpage
  \strictpagecheck % slower but efficient detection of odd/even pages
  \checkoddpage
  \ifoddpage
    \thispagestyle{empty}
    ~\\ % Print a character or the page will not exist
    \newpage
  \else
    % do nothing
  \fi

  
}
\begin{document}
\frontmatter

% Title page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\MainTitlePage{This document is reproducible thanks to:

\begin{itemize}
  \item \LaTeX and its class memoir (\url{http://www.ctan.org/pkg/memoir}).
  \item R (\url{http://www.r-project.org/}) and RStudio (\url{http://www.rstudio.com/})
  \item bookdown (\url{http://bookdown.org/}) and memoiR (\url{https://ericmarcon.github.io/memoiR/})
\end{itemize}}{Name of the owner of the logo

\url{http://www.company.com}

An explanatory sentence. Leave an empty line for line breaks.}


\phantomsection % Necesario con hyperref
\selectlanguage{spanish} % Selección de idioma del resumen.
\makeatletter
\begin{center} %
\chapter*{Resumen} % Opción con * para que no aparezca en TOC ni numerada
\addcontentsline{toc}{chapter}{Resumen} % Añade al TOC.
\end{center}   
\makeatother
TODO: Incluir un resumen del trabajo.

\phantomsection % Necesario con hyperref
\chapter*{Agradecimientos} % Opción con * para que no aparezca en TOC ni numerada
\addcontentsline{toc}{chapter}{Agradecimientos} % Añade al TOC.

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed malesuada nulla augue, ac facilisis risus pretium a. Ut bibendum risus id ex fermentum, at accumsan erat vulputate. In hac habitasse platea dictumst. Sed lobortis est a enim bibendum, ac pulvinar nulla aliquam. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Pellentesque efficitur justo id suscipit pretium. Proin iaculis sit amet nibh vel euismod. Aenean tincidunt faucibus ex, non vehicula ipsum tristique in. Fusce vel tincidunt lectus, vel rutrum nisi. Suspendisse malesuada lectus ac enim vehicula rhoncus. Nullam convallis justo in bibendum eleifend.

Phasellus vitae magna nec mi sagittis luctus vitae eu augue. Donec scelerisque laoreet arcu, eget tempor mi ultricies vel. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum at blandit ex. Vestibulum eu sagittis mauris. In hac habitasse platea dictumst. Duis eget ante vel lacus sollicitudin convallis quis eu velit. Sed auctor sem non nisi hendrerit, vel tincidunt tortor bibendum.

\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}, interior hidden, breakable, enhanced, sharp corners, frame hidden]}{\end{tcolorbox}}\fi

% Contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% fix the typesetting of the part number
\renewcommand\partnumberlinebox[2]{#2\ ---\ }


\LargeMargins
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}

% Tables (of tables, of figures)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\LargeMargins
\listoftables

\cleardoublepage
\LargeMargins
\listoffigures

\input{latex/glossary.tex}

\mainmatter
\bookmarksetup{startatroot}

\hypertarget{intro}{%
\chapter{Introducción}\label{intro}}

\hypertarget{motivaciuxf3n}{%
\section{Motivación}\label{motivaciuxf3n}}

\hypertarget{propuesta-y-objetivo}{%
\section{Propuesta y objetivo}\label{propuesta-y-objetivo}}

\hypertarget{estructura-del-documento}{%
\section{Estructura del documento}\label{estructura-del-documento}}

\bookmarksetup{startatroot}

\hypertarget{estado-del-arte}{%
\chapter{Estado del arte}\label{estado-del-arte}}

\bookmarksetup{startatroot}

\hypertarget{materiales}{%
\chapter{Materiales y métodos}\label{materiales}}

\bookmarksetup{startatroot}

\hypertarget{muxe9todos.}{%
\chapter{Métodos.}\label{muxe9todos.}}

\hypertarget{fuente-de-datos.}{%
\section{Fuente de datos.}\label{fuente-de-datos.}}

Los datos proceden de la edición de 2022 del curso MOOC Materiales
digitales accesibles de la UNED. Concretamente a los estudiantes
matriculados se les propuso que realizaran una actividad voluntaria
consistente en evaluar la calidad del subtitulado de dos vídeos. Los
vídeos eran idénticos y se diferenciaban únicamente en la calidad del
subtitulado. Los subtítulos de uno de los vídeos se realizaron
\autocites[ver][]{jperez1,jperez2} siguiendo las guía Web Content
Accessibility Guidelines 2.1 (WCAG 2.1) del W3C (World Wide Web
Consortium). El otro vídeo tenía un subtitulado similar pero se
introdujeron pequeñas deficiencias inapreciables para alguien que
carezca de conocimientos sobre accesibilidad. Los estudiantes fueron
clasificados en dos grupos. Al primer grupo se le presentó primero el
vídeo correctamente subtitulado y luego el otro. El segundo grupo
realizó la actividad cruzada: primero evaluó el vídeo mal subtitulado y
luego el bien subtitulado. Tras ver cada uno de los vídeos, los
estudiantes tuvieron la oportunidad de valorar la calidad del
subtitulado realizando un test en escala de Likert de 18 items y 5
niveles cada item \footnote{Para una descripción sobre cómo se debe
  realizar una escala de Likert consultar \textcite{likert1}.}. Los 18
items de Likert pretenden asegurar los criterios de la norma UNE 153010
\autocite[ver][]{aenor2012}.

En la Tabla~\ref{tbl-likert-levels} se muestran los 5 niveles de cada
uno de los items de la escala de Likert:

\clearpage

\hypertarget{tbl-likert-levels}{}
\begin{longtable}[]{@{}rl@{}}
\caption{\label{tbl-likert-levels}Niveles de los items de la escala de
Likert.}\tabularnewline
\toprule\noalign{}
values & levels \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
values & levels \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & No sé / No contesto \\
1 & Muy en desacuerdo \\
2 & En desacuerdo \\
3 & Neutral \\
4 & De acuerdo \\
5 & Muy de acuerdo \\
\end{longtable}

En la Tabla~\ref{tbl-likert-scale} se muestran los 18 items de la escala
de Likert que se propuso a los alumnos para que evaluaran cada uno de
los vídeos:

\hypertarget{tbl-likert-scale}{}
\begin{longtable}{ll}
\caption{\label{tbl-likert-scale}Items de la escala de Likert. }\tabularnewline

\toprule
Item & Texto \\ 
\midrule
Q01 & La posición de los subtítulos. \\ 
Q02 & El número de líneas por subtítulo. \\ 
Q03 & La disposición del texto respecto a la caja donde se muestran los subtítulos. \\ 
Q04 & El contraste entre los caracteres y el fondo. \\ 
Q05 & La corrección ortográfica y gramatical. \\ 
Q06 & La literalidad. \\ 
Q07 & La identificación de los personajes. \\ 
Q08 & La asignación de líneas a los personajes en los diálogos. \\ 
Q09 & La descripción de efectos sonoros. \\ 
Q10 & La sincronización de las entradas y salidas de los subtítulos. \\ 
Q11 & La velocidad de exposición de los subtítulos. \\ 
Q12 & El máximo número de caracteres por línea. \\ 
Q13 & La legibilidad de la tipografía. \\ 
Q14 & La separación en líneas diferentes de sintagmas nominales, verbales y preposicionales. \\ 
Q15 & La utilización de puntos suspensivos. \\ 
Q16 & La escritura de los números. \\ 
Q17 & Las incorrecciones en el habla. \\ 
Q18 & Los subtítulos del vídeo cumplen en general con los requisitos de accesibilidad. \\ 
\bottomrule
\end{longtable}

Los datos personales de los estudiantes se suministraron anonimizados
para evitar ninguna referencia a su identidad. Del estudio se han
eliminado a aquellos estudiantes que, a pesar de haber realizado la
actividad, no dieron su autorización para que sus datos se utilizaran en
un estudio científicos.

\clearpage

Se dispuso de los siguientes ficheros \texttt{csv}:

\begin{itemize}
\tightlist
\item
  El fichero \texttt{grade} contiene el identificador de estudiante y el
  grupo al que pertenece (campo \texttt{cohort}).
\item
  El fichero \texttt{abo} es la información socioeconómica que
  voluntariamente ha aportado el estudiante: sexo, año nacimiento, nivel
  de estudios, ocupación .
\item
  El fichero \texttt{conoc} contiene el test de evaluación inicial de
  conocimientos del estudiante.
\item
  El fichero \texttt{exp} es la evaluación del curso realizada por cada
  estudiante.
\item
  El fichero \texttt{acc} contiene la información sobre accesibilidad
  que utiliza el estudiante.
\item
  Los ficheros \texttt{test1} y \texttt{test2} son las repuestas al test
  de Likert sobre la calidad del subtitulado del primer y del segundo
  vídeo realizado por cada grupo respectivamente.
\end{itemize}

\hypertarget{sec-diseno}{%
\section{Características del diseño del experimento.}\label{sec-diseno}}

El diseño del experimento es completamente aleatorizado, de respuesta
ordinal, cruzado \(AB/BA\) y doble ciego. Es decir que la asignación de
los estudiantes a cada grupo fue aleatoria; cada grupo vio los vídeos en
orden inverso; los estudiantes no conocían a priori qué vídeo estaban
viendo en cada momento y tampoco se disponía de esta información en el
momento de realizar el análisis estadístico de los datos.

Un diseño completamente aleatorizado \autocite[pp.~18]{lawson2015}
\enquote{garantiza la validez del experimento contra sesgos causados por
otras variables ocultas. Cuando las unidades experimentales se asignan
aleatoriamente a los niveles de factor de tratamiento, se puede realizar
una prueba exacta de la hipótesis de que el efecto del tratamiento es
cero utilizando una prueba de aleatorización}.

Siguiendo a \textcite{senn2022}, para que el ensayo sea de tipo cruzado
no sería suficiente intercambiar las secuencias sino que debe ser objeto
del ensayo el estudio de las diferencias entre los tratamientos
individuales que componen las secuencias. Los principales problemas d
eun diseño cruzado son el abandono, \texttt{drop-out}, de alguno de los
participantes y la interacción entre el tratamiento y el periodo o
\texttt{carry-over}. Además el análisis estadístico es más complicado y
particularmente cuando la respuesta es ordinal y hay más de dos
tratamientos. En la misma línea, \textcite{lui2016} afirma que
\enquote{el objetivo principal de un diseño cruzado es estudiar la
diferencia entre tratamientos individuales (en lugar de la diferencia
entre secuencias de tratamiento). Debido a que cada paciente sirve como
su propio control, el diseño cruzado es una alternativa útil al diseño
de grupos paralelos para aumentar la potencia}.

Las respuestas a un test de Likert se realizan en escala ordinal. No es
adecuado realizar operaciones aritméticas para calcular medias con este
tipo de datos. Pero ellos los test estadísticos para analizar el efecto
de un tratamiento con respuesta continua como son \(ANOVA\) y \(t\)-test
no son adecuados con datos ordinales. Según la investigación de
\textcite{kruschke2018} ajustar datos ordinales con modelos
cuantitativos puede producir los siguientes problemas:

\begin{itemize}
\tightlist
\item
  Se pueden encontrar diferencias significativas entre grupos cuando no
  las hay: Error tipo I.
\item
  Se pueden obviar diferencias cuando en realidad sí existen: Error tipo
  II.
\item
  Incluso se pueden invertir los efectos de un tratamiento.
\item
  También puede malinterpretarse la interacción entre factores.
\end{itemize}

Una opción es tratar los datos ordinales como si se tratara de datos
categóricos y utilizar técnicas no paramétricas como el test de
\(Kruskal-Wallis\). El problema de este tipo de técnicas es que ignoran
que los datos tienen una escala y, en el caso particular del diseño que
nos ocupa se trata de datos longitudinales, es decir, que se toman
varias medidas de cada sujeto y, por lo tanto, los datos no son
independientes. \textcite{agresti2010} expone un catálogo de técnicas
para analizar datos categóricos y ordinales.

\hypertarget{objetivo.}{%
\section{Objetivo.}\label{objetivo.}}

El objetivo del estudio es responder a la pregunta de investigación:

Son los estudiantes de un curso de accesibilidad capaces de encontrar
los errores en el subtitulado de un vídeo. Para ello se propondrán
diversos test y modelos estadísticos que tengan en consideración las
características que se han comentado en el diseño del experimento (ver
Sección~\ref{sec-diseno}). Particularmente se tendrá en cuenta que se
trata de un diseño cruzado con variable respuesta ordinal y variables
explicativas longitudinales.

\hypertarget{sec-preprocesado}{%
\section{Preprocesamiento.}\label{sec-preprocesado}}

Partiendo de los ficheros suministrados (ver Sección~\ref{sec-diseno}),
se realiza el siguiente preprocesado (para ver el código ejecutado
consultar Apéndice~\ref{sec-preprocess}):

\begin{itemize}
\item
  Se lee el fichero de perfil del usuario. El número de fila con el que
  el usuario aparece en el fichero se utilizará como identificador del
  usuario para mantener la trazabilidad y comprobar que las
  transformaciones realizadas son correctas.
\item
  Se eliminan del estudio a los estudiantes que aún habiendo realizado
  la actividad, no han dado su consentimiento para participar en el
  estudio.
\item
  El valor del campo \texttt{cohort} se sustituye por una letra \(A\) o
  \(B\) en función del grupo asignado. En este momento se desconoce qué
  vídeo vio primero cada grupo.
\item
  Se lee el fichero \texttt{profile} y se añade a los usuarios
  información sobre el sexo, el año de nacimiento y el novel de
  estudios.
\item
  Se lee el fichero \texttt{conoc} y se calcula cuántas preguntas acertó
  cada usuario en el test de evaluación de conocimientos previos. Se
  añade esta información al perfil del usuario.
\item
  Se leen los ficheros de test y se procesan. Se utiliza el nombre del
  fichero (\texttt{test1} o \texttt{test2}) para saber de qué vídeo se
  está respondiendo el test \footnote{Se reitera que en este momento se
    desconoce si el vídeo es el correctamente subtitulado o el otro. La
    única información que se almacena es si se está respondiendo al
    vídeo que se voy primero o al que se vio después.}.
\item
  Se seleccionan las preguntas que contienen las respuestas y se
  renombran para que sea más fácil saber de qué pregunta se trata
  \footnote{En los fichero suministrados pla respuesta a cada pregunta
    ocupa varios campos y se selecciona en cada pregunta el que contiene
    el valor de la respuesta y se convierte a numérico.}. Se convierte
  el campo \texttt{LastTry}, que contiene la fecha y hora de realización
  del test, a formato fecha y hora.
\item
  Se realizan algunas comprobaciones como la ausencia de valores nulos
  en la variables más relevantes o que no existan inconsistencias ni
  errores de procesado.
\item
  Se eliminan los comentarios y se graban en fichero aparte para que no
  revelen información que podría descubrir el tipo de subtitulado que
  piensa que está evaluando el estudiante.
\item
  Se almacenan los resultados de los test preprocesado en un fichero
  \texttt{csv}.
\end{itemize}

\clearpage

\bookmarksetup{startatroot}

\hypertarget{modelo.}{%
\chapter{Modelo.}\label{modelo.}}

\hypertarget{variables}{%
\section{Variables del modelo.}\label{variables}}

En la Tabla~\ref{tbl-variables} se describen las características más
relevantes de las principales variables que se utilizarán en en modelado
y en el análisis estadístico. \footnotesize

\hypertarget{tbl-variables}{}
\setlength{\LTpost}{0mm}
\begin{longtable}{llll}
\caption{\label{tbl-variables}Descripción de las variables más importantes }\tabularnewline

\toprule
Nombre & Descripción & Tipo & Valores \\ 
\midrule
Response & Respuesta a las preguntas del test. & Factor ordenado & De 0 a 5\textsuperscript{1} \\ 
Level & Valoración de la respuesta. & Factor ordenado & Negative, Neutral, Positive\textsuperscript{2} \\ 
Treat & Subtítulos & Factor & A o B\textsuperscript{3} \\ 
Period & Periodo & Factor & 1 ó 2\textsuperscript{4} \\ 
Seq & Secuencia de aplicación de los tratamientos. & Factor & AB o BA \\ 
Subject & Identificación del estudiante & Factor & Numérico \\ 
Question & Número de la pregunta & Factor & Q01, Q02, ..., Q18\textsuperscript{5} \\ 
Cluster & Grupo de la pregunta & Factor & 1, 2, ó 3\textsuperscript{6} \\ 
\bottomrule
\end{longtable}
\begin{minipage}{\linewidth}
\textsuperscript{1}Se ha hecho una rotación sobre los valores originales. 0 = No sé, 1 = Muy en desacuerdo, ..., 5 Muy de acuerdo.\\
\textsuperscript{2}Positive cuando Response sea 4 ó 5, Negative cuando sea 1 ó 2 y Neutral para 3.\\
\textsuperscript{3}No se conoce si el tratamiento A es el subtitulado bueno o lo es el B.\\
\textsuperscript{4}1 para el primer vídeo visto y 2 el segundo.\\
\textsuperscript{5}Se ha reorganizado de tal forma que Q18, que es la pregunta resumen, sea el valor primero y de referencia.\\
\textsuperscript{6}Se aplicará una técnica estadística de agrupamiento para agregar las preguntas.\\
\end{minipage}

\normalsize

Partiendo del \texttt{dataframe} que se construyó en el preprocesado
(ver Sección~\ref{sec-preprocesado}) construimos el \texttt{dataframe}
que usaremos a partir de este momento. Las operaciones principales que
se han realizado han sido:

\begin{itemize}
\tightlist
\item
  Renombrar las variables para que se correspondan con las de nuestro
  modelo (ver Tabla~\ref{tbl-variables}).
\item
  Eliminar del estudio los usuarios que solo han realizado uno de los
  test como se explica en Sección~\ref{sec-eda-2}.
\item
  Transformar las variables que lo requieran en factores. La pregunta 18
  se usará como referencia en el factor \texttt{Question}.
\item
  Rotar los valores de respuesta para que \enquote{No sé / No contesto}
  tenga valor 0 y el resto de 1 a 5 desde \enquote{Muy en desacuerdo},
  1, hasta \enquote{Muy de acuerdo}, 5.
\item
  Agrupar las preguntas por similitud de respuesta (ver
  Sección~\ref{sec-cluster2}).
\item
  Crear el factor \texttt{Level} con los niveles \texttt{positive},
  \texttt{neutral} y \texttt{negative} dependiendo de si la respuesta es
  4 ó 5, 3, 1 ó 2 respectivamente.
\item
  Transformar el \texttt{dataframe} de formato ancho a largo: los
  ficheros de respuestas se suministran en formato ancho. Es decir, que
  cada fila es un test que contiene 18 columnas para las respuestas a
  cada pregunta. Los nombres de las columnas son \(Q01\), \(Q02\),
  \ldots, \(Q18\) y tendrán valores de 0 a 6 con las respuestas. La
  mayoría de los paquetes de R que vamos a usar requieren que los datos
  estén en formato largo. Esto que quiere decir que cada fila tendrá una
  única respuesta por lo que habrá únicamente dos columnas, \(Question\)
  y \(Response\). En la primera se almacenará el identificador de la
  pregunta (\(Q01\), \(Q02\), \ldots, \(Q18\)) y en la segunda el valor
  de la respuesta (de 0 a 6). De esta forma un test pasará de ocupar una
  fila y 18 columnas en el formato ancho a 18 filas y dos columnas en el
  largo.
\end{itemize}

En Apéndice~\ref{sec-setup} se puede consultar el código en R para
realizar el proceso descrito anteriormente. Con estas transformaciones
se crean los dos \texttt{dataframes} que se usarán en el análisis
estadístico de los datos:

\begin{itemize}
\tightlist
\item
  \texttt{df\_all} contiene en formato largo todas las respuestas a los
  test.
\item
  \texttt{df\_clean} tiene la misma estructura que \texttt{df\_all} pero
  en él se han eliminado las respuestas \enquote{No sé / No contesto}.
\end{itemize}

\texttt{df\_all} se utilizará cuando se traten las respuestas como
categóricas y, por lo tanto, como no ordenadas. \texttt{df\_clean} se
utilizará cuando se traten las respuestas como ordenadas y por ello no
contiene las respuestas con valor \enquote{No sé / No contesto}.

La estructura de estos \texttt{dataframes} es la siguiente:

\begin{verbatim}
tibble [2,980 x 8] (S3: tbl_df/tbl/data.frame)
 $ Seq     : Factor w/ 2 levels "AB","BA": 1 1 1 1 1 1 1 1 1 1 ...
 $ Period  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ Treat   : Factor w/ 2 levels "A","B": 1 1 1 1 1 1 1 1 1 1 ...
 $ Subject : Factor w/ 87 levels "4","33","35",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Question: Factor w/ 18 levels "Q18","Q01","Q02",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Cluster : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 1 1 1 1 1 ...
 $ Response: Ord.factor w/ 5 levels "1"<"2"<"3"<"4"<..: 3 3 3 3 3 3 3 3 3 3 ...
 $ Level   : Ord.factor w/ 3 levels "Negative"<"Neutral"<..: 2 2 2 2 2 2 2 2 2..
\end{verbatim}

En el Tabla~\ref{tbl-df_clean} se muestran algunos ejemplos de estos
\texttt{dataframes}.

\hypertarget{tbl-df_clean}{}
\begin{longtable}{cccccccc}
\caption{\label{tbl-df_clean}Muestra del dataframe preparado para el modelado estadístico en formato
largo. }\tabularnewline

\toprule
Seq & Period & Treat & Subject & Question & Cluster & Response & Level \\ 
\midrule
BA & 1 & B & 229 & Q17 & 3 & 4 & Positive \\ 
BA & 2 & A & 1023 & Q18 & 1 & 4 & Positive \\ 
BA & 1 & B & 765 & Q15 & 3 & 2 & Negative \\ 
BA & 2 & A & 229 & Q13 & 2 & 4 & Positive \\ 
BA & 2 & A & 320 & Q11 & 2 & 4 & Positive \\ 
AB & 1 & A & 75 & Q12 & 2 & 4 & Positive \\ 
BA & 1 & B & 220 & Q03 & 2 & 3 & Neutral \\ 
AB & 1 & A & 1153 & Q07 & 1 & 4 & Positive \\ 
AB & 1 & A & 1011 & Q12 & 2 & 4 & Positive \\ 
BA & 2 & A & 535 & Q01 & 2 & 4 & Positive \\ 
\bottomrule
\end{longtable}

\bookmarksetup{startatroot}

\hypertarget{sec-eda}{%
\chapter{Exploración inicial.}\label{sec-eda}}

\hypertarget{anuxe1lisis-de-la-calidad-de-los-datos.}{%
\section{Análisis de la calidad de los
datos.}\label{anuxe1lisis-de-la-calidad-de-los-datos.}}

\hypertarget{sec-eda-2}{%
\subsection{Respuestas a los test.}\label{sec-eda-2}}

Como se explica en la Tabla~\ref{tbl-variables}, al subtitulado le
denominamos tratamiento y a sus niveles (correcto e incorrecto) los
hemos llamado \(A\) y \(B\) sin hacer ninguna conjetura de cual de los
dos es el subtitulado correcto. El grupo con secuencia \(AB\) será el
que primero vio el vídeo con subtitulado \(A\) y luego el \(B\).
Análogamente, el grupo con secuencia \(BA\) vio los vídeos en orden
inverso. Recuérdese que el nivel 0 de respuesta se corresponde con
\enquote{No sé / No contesto} (ver Tabla~\ref{tbl-likert-levels}).

Hay 24 estudiantes que no realizaron el segundo test. De ellos 9
pertenecen al grupo AB y 15 al grupo BA. Debido a que no son muchos y a
que los grupos se mantienen balanceados, se ha decidido eliminar los
test de estos estudiantes.

Tras eliminar a los estudiantes que no realizaron uno de los test,
constatamos (ver Figura~\ref{fig-groups}) que los grupos están
balanceados en el número de estudiantes y que disponemos de suficientes
datos para realizar el análisis estadístico.

\begin{figure}[h]

{\centering \includegraphics{40-EDA1_files/figure-pdf/fig-groups-1.pdf}

}

\caption{\label{fig-groups}Estudiantes asignados a cada grupo.}

\end{figure}

El campo \texttt{LastTry} contiene la fecha y hora de realización del
test. Con esta información podemos conocer el tiempo que empleó cada
estudiante entre subtitulados. La Tabla~\ref{tbl-washout} muestra que
hay algunos test que se hicieron demasiado rápido \footnote{Hay que
  tener en cuenta que la duración de vídeo es de algo más de 40 segundos
  y que los estudiantes tienen que contestar un test de 18 preguntas.}.

\hypertarget{tbl-washout}{}
\begin{longtable}{c}
\caption{\label{tbl-washout}Tiempos de realización de la segunda actividad de duración inferior a 2
minutos. }\tabularnewline

\toprule
Minutes \\ 
\midrule
0.93 \\ 
1.3 \\ 
1.7 \\ 
1.72 \\ 
1.78 \\ 
1.97 \\ 
\bottomrule
\end{longtable}

La Figura~\ref{fig-distinct} muestra que hay 28 test en los que el
estudiante contestó a todas las preguntas usando únicamente 2 respuestas
diferentes. Además hay 13 test en los que se contestaron todas las
preguntas con 1 respuesta.

\begin{figure}[h]

{\centering \includegraphics{40-EDA1_files/figure-pdf/fig-distinct-1.pdf}

}

\caption{\label{fig-distinct}Número de respuestas diferentes en un mismo
test.}

\end{figure}

\clearpage

La tabla Tabla~\ref{tbl-distinct2} muestra la respuesta utilizada, el
grupo y el periodo de los test con respuesta única.

\hypertarget{tbl-distinct2}{}
\begin{longtable}{rlr}
\caption{\label{tbl-distinct2}Test en los que todas las preguntas se contestan el mismo valor de
respuesta. }\tabularnewline

\toprule
Response & Seq & Test \\ 
\midrule
2 & AB & 01 \\ 
2 & AB & 02 \\ 
3 & BA & 01 \\ 
3 & BA & 02 \\ 
3 & BA & 02 \\ 
3 & BA & 02 \\ 
4 & AB & 01 \\ 
4 & AB & 01 \\ 
4 & AB & 02 \\ 
4 & BA & 01 \\ 
4 & BA & 02 \\ 
4 & BA & 02 \\ 
4 & BA & 02 \\ 
\bottomrule
\end{longtable}

La Figura~\ref{fig-compare} presenta la distribución de la cantidad de
respuestas cuyo valor cambia entre los dos test que realiza cada
estudiante.

\begin{figure}[h]

{\centering \includegraphics{40-EDA1_files/figure-pdf/fig-compare-1.pdf}

}

\caption{\label{fig-compare}Número de respuestas diferentes entre los
test para cada estudiante.}

\end{figure}

\clearpage

Tan solo 1 estudiante respondió a todas las preguntas con el mismo valor
en los dos test. Por otro lado, no hay test que tengan un número
excesivo de contestaciones \enquote{No sé/No contesto} (ver
Tabla~\ref{tbl-noanswer}).

\hypertarget{tbl-noanswer}{}
\begin{longtable}{rr}
\caption{\label{tbl-noanswer}Los 5 test con más respuestas `No sé/No contesto' }\tabularnewline

\toprule
Test & Total respuesta por test \\ 
\midrule
01 & 5 \\ 
01 & 5 \\ 
02 & 5 \\ 
02 & 5 \\ 
01 & 4 \\ 
\bottomrule
\end{longtable}

\hypertarget{conclusiones.}{%
\subsubsection{Conclusiones.}\label{conclusiones.}}

No parece razonable realizar la actividad en menos de 2 minutos. Se
observa que en algunos test hay poca variabilidad. Sin embargo, no son
muchos los test con estas características así que se ha decidido
mantener estos datos a pesar de que se pueda dubar de si en ellos los
estudiantes contestaron con la debida atención y diligencia.

\hypertarget{valores-nulos-o-erruxf3neos.}{%
\subsection{Valores nulos o
erróneos.}\label{valores-nulos-o-erruxf3neos.}}

En los test no se ha detectado ningún valor nulo ni erróneo. Sin embargo
tenemos algunos de estos valores en la información socioeconómica de los
estudiantes (ver Tabla~\ref{tbl-contingencia}).

\begin{table}

\caption{\label{tbl-contingencia}Tablas de contingencia de la
información socioeconómica de los
estudiantes.}\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-1}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
gender & Freq \\ 
\midrule
f & 92 \\ 
m & 38 \\ 
NA & 44 \\ 
\bottomrule
\end{longtable}

Estudiantes por sexo.

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-2}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
year\_of\_birth & Freq \\ 
\midrule
None & 44 \\ 
NA & 2 \\ 
\bottomrule
\end{longtable}

Estudiantes con valor nulo en el campo año de nacimiento.

}

\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-3}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
level\_of\_education & Freq \\ 
\midrule
a & 50 \\ 
b & 16 \\ 
hs & 4 \\ 
m & 30 \\ 
other & 4 \\ 
p & 20 \\ 
NA & 50 \\ 
\bottomrule
\end{longtable}

Estudiantes por nivel educativo.

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{tbl-contingencia-4}{}
\begin{longtable}{cr}
\tabularnewline

\toprule
level\_of\_knowledge & Freq \\ 
\midrule
4 & 2 \\ 
6 & 4 \\ 
7 & 30 \\ 
8 & 44 \\ 
9 & 40 \\ 
10 & 32 \\ 
NA & 22 \\ 
\bottomrule
\end{longtable}

Estudiantes en función del número de preguntas acertadas en el test de
conocimiento.

}

\end{minipage}%

\end{table}

\hypertarget{sec-eda-3}{%
\section{\texorpdfstring{Comparación de los tratamientos \(A\) y \(B\)
entre
grupos.}{Comparación de los tratamientos A y B entre grupos.}}\label{sec-eda-3}}

La Figura~\ref{fig-diff} presenta una forma de comparar los dos test que
realizados por los estudiantes. Para cada estudiante se comparó pregunta
a pregunta sus dos test y se contabilizó la diferencia entre el número
de preguntas en que la puntuación en el segundo vídeo fue superior y en
las que lo fue inferior (las que no variaron de puntuación no se
consideraron). En el eje \(x\) se muestra la diferencia entre preguntas.
Cantidades negativas indican que hay más respuestas en el segundo de los
test que han empeorado respecto al primero de las que han mejorado. En
el eje \(y\) se representa el número de estudiantes para cada
diferencia. Esta frecuencia se representa en negativo cuando la
diferencia es negativa \footnote{En la comparación se han omitido
  aquellas preguntas en las que el estudiante contestó \enquote{No sé/No
  contesto} en la pregunta correspondiente de uno de los test.}. Esto es
una forma de evaluar si el estudiante valoró mejor o no el segundo vídeo
que el primero.

\begin{figure}[h]

{\centering \includegraphics{40-EDA1_files/figure-pdf/fig-diff-1.pdf}

}

\caption{\label{fig-diff}Frecuencias absolutas de las diferencias en las
respuestas entre test por estudiante y grupo.}

\end{figure}

Vemos que en el grupo \(AB\) las diferencias tienden a ser negativas y
en el \(BA\) positivas. Esto estaría indicando que los estudiantes
valoran mejor el subtitulado de nivel \(A\). Por ello es esperable que
las respuestas de los estudiantes del grupo \(AB\) hayan empeorado y que
las diferencias sean negativas y que lo contrario haya sucedido con las
del grupo \(BA\). La diferencia más frecuente en el grupo \(AB\) es 12 y
en el grupo \(BA\) este valor es 11.

Resulta llamativo que haya estudiantes cuyas contestaciones estén tan
alejadas de la tendencia de su grupo. En la Tabla~\ref{tbl-diff} se
muestran los tiempos que han transcurrido entre la realización de los
test de aquellos estudiantes cuyas respuestas difieren de forma
importante de su grupo. Se observa que casi todos son tiempos entre
actividades muy cortos. En cualquier caso y, como no son muchos, se ha
decidido no eliminarlos y realizar el análisis con ellos.

\hypertarget{tbl-diff}{}
\begin{longtable}{lrc}
\caption{\label{tbl-diff}Estudiantes que tienen diferencias en sus respuestas muy alejadas de la
tendencia de su grupo. }\tabularnewline

\toprule
Seq & Diff & Minutes \\ 
\midrule
AB & 17 & 1.3 \\ 
AB & 7 & 3.33 \\ 
BA & -10 & 50345.95 \\ 
BA & -12 & 1.7 \\ 
\bottomrule
\end{longtable}

En la Figura~\ref{fig-freqs} representamos la frecuencia relativa del
valor de respuesta para cada grupo y test en todas la preguntas
\footnote{En el Tabla~\ref{tbl-resume} se presenta la misma información
  con los valores absolutos.}. Esta es otra forma de comparar los
niveles de subtitulado.

\hypertarget{tbl-resume}{}
\begin{longtable}{cccrrrrrr}
\caption{\label{tbl-resume}Resumen de frecuencias de respuesta. }\tabularnewline

\toprule
 &  &  &  & \multicolumn{5}{c}{Response} \\ 
\cmidrule(lr){5-9}
Seq & Period & Treat & 0 & 1 & 2 & 3 & 4 & 5 \\ 
\midrule
AB & 1 & A & 39 & 2 & 25 & 71 & 203 & 434 \\ 
AB & 2 & B & 43 & 87 & 185 & 121 & 172 & 166 \\ 
BA & 1 & B & 40 & 76 & 174 & 127 & 237 & 138 \\ 
BA & 2 & A & 30 & 2 & 30 & 64 & 345 & 321 \\ 
\bottomrule
\end{longtable}

La Figura~\ref{fig-freqs} muestra algunas cuestiones interesantes:

\begin{itemize}
\item
  El tratamiento (subtitulado) con nivel \(A\) presenta claramente
  mayores valores de respuesta que el \(B\) como ya habíamos visto (ver
  Figura~\ref{fig-diff}). Si en este momento tuviéramos que decidir qué
  subtitulado es cada uno parece claro que sería el de nivel \(A\). No
  obstante, ni en el análisis exploratorio ni en el modelado estadístico
  se hará ninguna suposición.
\item
  En general los dos grupos muestran bastante acuerdo en el subtitulado
  en ambos niveles: En el nivel de tratamiento \(A\) los dos grupos
  tienen una frecuencia relativa similar de respuestas positivas
  (valores 4 y 5). El grupo \(AB\) tiene un 82\% de respuestas positivas
  frente a un 84\% el grupo \(BA\). No obstante, el grupo \(AB\) tiene
  más respuestas con valor 5 que el grupo \(BA\) (56\% frente a 41\%).
  La valoración es también similar entre grupos en el nivel de
  tratamiento \(B\): el grupo \(AB\) tiene 44\% de respuestas positivas
  y 47\% el grupo \(BA\). Las valoraciones negativas (1, 2), la neutra
  (3) y la \enquote*{No sé / No contesto} (0) son también muy similares.
\item
  Las respuestas son similares entre periodos aunque ligeramente más
  negativas en el segundo. Así un 65\% de las respuestas son positivas
  en el primer periodo frente a un 64\% en el segundo.
\end{itemize}

\begin{figure}[h]

{\centering \includegraphics{40-EDA1_files/figure-pdf/fig-freqs-1.pdf}

}

\caption{\label{fig-freqs}Frecuencias relativas de las respuestas al
test.}

\end{figure}

El análisis marginalizado de tratamiento, secuencia y periodo tiene
estos resultados referidos a las preguntas con contestación positiva (4,
5):

\begin{itemize}
\item
  El tratamiento \(A\) tiene un 83\% marginalizado de respuestas
  positivas frente al 46\% del tratamiento \(B\).
\item
  El periodo 1 tiene un 65\% marginalizado de respuestas positivas
  frente al 64\% del periodo 2.
\item
  Finalmente, la secuencia \(AB\) tiene un 63\% de respuestas positivas
  frente 66\% de la secuencia \(BA\). Analizado por respuestas
  individuales, la respuesta 4 pasa de 24\% en la secuencia \(AB\) a
  37\% en la \(BA\) y, de forma contraria, en la respuesta 5 pasa de
  39\% en \(AB\) a 29\% en \(BA\). En las respuestas negativas y no
  contestadas y neutra no se aprecian estas variaciones.
\end{itemize}

\hypertarget{anuxe1lisis-de-las-preguntas.}{%
\section{Análisis de las
preguntas.}\label{anuxe1lisis-de-las-preguntas.}}

El gráfico Figura~\ref{fig-levels} muestra la frecuencia relativa por
grupo y por test de las preguntas clasificadas por niveles de respuesta,
considerando que:

\begin{itemize}
\tightlist
\item
  Los niveles 1 y 2 se consideran valoraciones negativas.
\item
  El nivel 3 se considera neutro.
\item
  Los niveles 4 y 5 se consideran positivos.
\item
  El nivel 0 (\enquote{No sé / No contesto}) se excluye en este
  análisis.
\end{itemize}

Se muestra en primer lugar la pregunta 18 por ser una valoración global
del subtitulado y que resume la opinión que sobre el mismo tiene el
estudiante. Volvemos a constatar que el subtitulado \(A\) es mejor
valorado por los estudiantes, pero ahora vemos que en las 18 preguntas
ambos grupos tienen mas puntuaciones positivas y menos negativas en el
subtitulado \(A\) que el \(B\). También volvemos a encontrar que los dos
grupos valoran de forma muy similar los dos niveles de subtitulado en
todas la preguntas. En el nivel de subtitulado \(A\) las preguntas
\(Q15\), \(Q16\) y \(Q17\) obtienen relativamente peores valoraciones
(consultar la Tabla~\ref{tbl-likert-scale} para ver los valores) y estas
son similares en ambos subtitulados. Hay algunas preguntas que son
valoradas de forma positiva incluso en el nivel de subtitulado \(B\)
(por ejemplo \(Q04\) o \(Q13\)) y que, por lo tanto, su valoración es
similar en ambos subtitulados. Por último, las preguntas \(Q05\) y
\(Q09\) (también la \(Q14\) pero solo para el grupo \(BA\)) tienen una
valoración muy negativa en el nivel de subtitulado \(B\).

\begin{figure}[h]

{\centering \includegraphics{40-EDA1_files/figure-pdf/fig-levels-1.pdf}

}

\caption{\label{fig-levels}Frecuencias relativas de las respuestas por
pregunta.}

\end{figure}

La figura Figura~\ref{fig-likert} clasifica la preguntas por valoración
y permite constatar lo que ya habíamos visto en el párrafo anterior con
mayor comodidad.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{40-EDA1_files/figure-pdf/fig-likert-1.pdf}

}

}

\subcaption{\label{fig-likert-1}Seq AB , Treat A}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{40-EDA1_files/figure-pdf/fig-likert-2.pdf}

}

}

\subcaption{\label{fig-likert-2}Seq AB , Treat B}
\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{40-EDA1_files/figure-pdf/fig-likert-3.pdf}

}

}

\subcaption{\label{fig-likert-3}Seq BA , Treat A}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{40-EDA1_files/figure-pdf/fig-likert-4.pdf}

}

}

\subcaption{\label{fig-likert-4}Seq BA , Treat B}
\end{minipage}%

\caption{\label{fig-likert}Preguntas ordenadas por valoración.}

\end{figure}

\bookmarksetup{startatroot}

\hypertarget{sec-analisis}{%
\chapter{Análisis estadístico.}\label{sec-analisis}}

\hypertarget{sec-cluster}{%
\section{Agrupamientos de preguntas.}\label{sec-cluster}}

\hypertarget{sec-cronbach}{%
\subsection{Correlación entre preguntas con el alfa de
Cronbach.}\label{sec-cronbach}}

Normalmente las preguntas de un cuestionario pretenden medir una
variable que está oculta o latente. En nuestro caso es la calidad del
subtitulado. Las respuestas a estas preguntas relacionadas deben ser
consistentes internamente, es decir, las respuestas deben
correlacionarse fuerte y positivamente.

Un índice que se utiliza habitualmente para medir la consistencia
interna de un cuestionario es el coeficiente
\texttt{alfa\ de\ Cronbach}, ver \textcite{schweinberger2020survey}. Se
define de esta forma:

\begin{equation}
\alpha = \frac{N}{N-1} \left(1 - \frac{\sum_{i=1}^{N} s_{i}^{2}}{s^{2}} \right)
\end{equation}

Donde:

\begin{itemize}
\tightlist
\item
  \(\alpha\) es el coeficiente \texttt{alfa\ de\ Cronbach}.
\item
  \(N\) es el número de items de la escala de Likert.
\item
  \(s_{i}^{2}\) es la varianza de la puntuación del item \(i\).
\item
  \(s^{2}\) es la varianza total de las puntuaciones de todos los items.
\end{itemize}

Valores cercanos 1 indican una fuerte correlación en las respuestas y se
admite que las preguntas del cuestionario están midiendo la misma
variable latente.

Para calcular en R este coeficiente podemos usar la función
\texttt{alpha} del paquete \texttt{psych}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha }\OtherTok{\textless{}{-}}\NormalTok{ df\_all }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pivot\_wider}\NormalTok{(}
        \AttributeTok{names\_from =}\NormalTok{ Question,}
        \AttributeTok{values\_from =}\NormalTok{ Response\_v,}
        \AttributeTok{id\_cols =} \FunctionTok{c}\NormalTok{(Treat, Subject)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(Treat, Subject)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    psych}\SpecialCharTok{::}\FunctionTok{alpha}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\normalsize

Se obtiene un coeficiente alfa de \texttt{alfa\ de\ Cronbach} de 0.92
que indica una muy buena correlación entre las respuestas a todas las
preguntas. Este valor apenas se ve alterado si se elimina una de las
preguntas (ver Tabla~\ref{tbl-drop-alpha}).

\scriptsize

\begin{table}

\caption{\label{tbl-drop-alpha}Valor del coeficiente alpha de Cronbach
si se elimina una pregunta.}\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-drop-alpha-1}}

{\centering 

\begin{longtable*}{rrrrrrrrr}
\toprule
Q18 & Q01 & Q02 & Q03 & Q04 & Q05 & Q06 & Q07 & Q08 \\ 
\midrule
0.91 & 0.92 & 0.92 & 0.92 & 0.92 & 0.91 & 0.91 & 0.91 & 0.91 \\ 
\bottomrule
\end{longtable*}

}

\end{minipage}%
\newline
\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-drop-alpha-2}}

{\centering 

\begin{longtable*}{rrrrrrrrr}
\toprule
Q09 & Q10 & Q11 & Q12 & Q13 & Q14 & Q15 & Q16 & Q17 \\ 
\midrule
0.91 & 0.91 & 0.92 & 0.91 & 0.92 & 0.92 & 0.92 & 0.93 & 0.92 \\ 
\bottomrule
\end{longtable*}

}

\end{minipage}%

\end{table}

\normalsize

En la Tabla~\ref{tbl-item-alpha} mostramos las preguntas que más
contribuyen al índice \texttt{alpha\ de\ Cronbach}. Es interesante que
la pregunta \(Q18\), que es la valoración general del cuestionario, sea
la que mejor contribución tiene al índice.

\scriptsize

\begin{table}

\caption{\label{tbl-item-alpha}Relación de cada pregunta con el índice
alpha de Cronbach.}\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-item-alpha-1}}

{\centering 

\begin{longtable*}{rrrrrrrrr}
\toprule
Q18 & Q05 & Q06 & Q09 & Q08 & Q07 & Q10 & Q12 & Q02 \\ 
\midrule
0.86 & 0.81 & 0.79 & 0.79 & 0.77 & 0.75 & 0.73 & 0.72 & 0.71 \\ 
\bottomrule
\end{longtable*}

}

\end{minipage}%
\newline
\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-item-alpha-2}}

{\centering 

\begin{longtable*}{rrrrrrrrr}
\toprule
Q03 & Q14 & Q01 & Q11 & Q15 & Q13 & Q04 & Q16 & Q17 \\ 
\midrule
0.68 & 0.66 & 0.65 & 0.64 & 0.56 & 0.51 & 0.46 & 0.44 & 0.42 \\ 
\bottomrule
\end{longtable*}

}

\end{minipage}%

\end{table}

\normalsize

\clearpage

\hypertarget{sec-cluster2}{%
\subsection{Agrupamiento jerárquico aglomerativo.}\label{sec-cluster2}}

En en la Sección~\ref{sec-cronbach} y en la Sección~\ref{sec-eda-3}
hemos visto que algunas de las preguntas tienen respuestas similares a
otras pero diferentes del resto. Puede ser interesante aplicar una
técnica de agrupamiento que nos permita crear grupos de preguntas que
podremos analizar por separado.

Vamos a realizar una agrupación jerárquica aglomerativa de las preguntas
en función de la tabla de contingencia de las respuestas utilizando la
distancia euclidea como medida de distancia y el método de aglomeración
de enlace completo para unir conglomerados \footnote{El método de enlace
  completo usa la distancia máxima entre dos conglomerados para
  seleccionar los más cercanos a unir.}. Para ello primero calculamos la
tabla de contingencia (ver Tabla~\ref{tbl-contingencia}) de preguntas y
respuestas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table }\OtherTok{\textless{}{-}}\NormalTok{ df\_all }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Question }\SpecialCharTok{+}\NormalTok{ Response, }\AttributeTok{data =}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\scriptsize

\hypertarget{tbl-contingencia}{}
\begin{longtable}{crrrrrr}
\caption{\label{tbl-contingencia}Tabla de contingencia de preguntas y respuestas. }\tabularnewline

\toprule
Question & Response\_0 & Response\_1 & Response\_2 & Response\_3 & Response\_4 & Response\_5 \\ 
\midrule
Q18 & 0 & 11 & 33 & 18 & 52 & 60 \\ 
Q01 & 0 & 10 & 20 & 10 & 59 & 75 \\ 
Q02 & 0 & 5 & 26 & 14 & 58 & 71 \\ 
Q03 & 5 & 5 & 26 & 11 & 60 & 67 \\ 
Q04 & 0 & 2 & 7 & 10 & 61 & 94 \\ 
Q05 & 1 & 29 & 31 & 12 & 34 & 67 \\ 
Q06 & 1 & 6 & 29 & 21 & 53 & 64 \\ 
Q07 & 0 & 13 & 32 & 14 & 54 & 61 \\ 
Q08 & 4 & 15 & 41 & 19 & 40 & 55 \\ 
Q09 & 1 & 39 & 29 & 12 & 42 & 51 \\ 
Q10 & 8 & 4 & 24 & 18 & 59 & 61 \\ 
Q11 & 3 & 2 & 14 & 23 & 75 & 57 \\ 
Q12 & 5 & 4 & 26 & 18 & 69 & 52 \\ 
Q13 & 1 & 2 & 2 & 19 & 62 & 88 \\ 
Q14 & 21 & 9 & 29 & 27 & 44 & 44 \\ 
Q15 & 26 & 5 & 25 & 36 & 47 & 35 \\ 
Q16 & 47 & 2 & 5 & 57 & 39 & 24 \\ 
Q17 & 29 & 4 & 15 & 44 & 49 & 33 \\ 
\bottomrule
\end{longtable}

\normalsize

Con la tabla de contingencia calculamos las distancias entre preguntas y
realizamos el agrupamiento. En el dendograma (ver
Figura~\ref{fig-dendo}) se aprecian claramente tres conglomerados. Es
muy interesante constatar que los tres grupos están formados por
preguntas que en su mayor parte son correlativas. Esto es consistente
con que al elaborar un test normalmente se colocan las preguntas por
unidades temáticas y con que el encuestado también suele hacerlo
teniendo en cuenta esta estructura y tiende a responder de forma similar
a las preguntas correlativas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(table, }\AttributeTok{method =} \StringTok{"euclidean"}\NormalTok{)}
\NormalTok{cluster }\OtherTok{\textless{}{-}} \FunctionTok{hclust}\NormalTok{(dist, }\AttributeTok{method =} \StringTok{"complete"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(cluster)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics[width=4.16667in,height=\textheight]{images/cluster.png}

}

\caption{\label{fig-dendo}Dendograma de aglomeramiento jerárquico de
preguntas en función de la tabla de contingencia de respuestas.}

\end{figure}

Podemos distinguir los siguientes grupos y subgrupos:

\begin{itemize}
\tightlist
\item
  Grupo 1: Trata sobre la corrección del subtítulo.

  \begin{itemize}
  \tightlist
  \item
    Subgrupo 05, 06, 07, 08, 09: preguntas sobre si la información que
    presenta el subtítulo es correcta y está bien escrita.
  \item
    Pregunta 18: valoración general del subtitulado. El que esta
    pregunta esté incluida en este grupo estaría indicando que este es
    el apartado al que más importancia dan los estudiantes a la hora de
    valorar la calidad del subtitulado.
  \end{itemize}
\item
  Grupo 2: Es el más numeroso. En general está formado por preguntas
  sobre el grado de dificultad que presenta la lectura del subtítulo.

  \begin{itemize}
  \tightlist
  \item
    Subgrupo preguntas Q01, Q02, Q03: colocación de los subtítulos.
  \item
    Subgrupo preguntas Q10, Q11, Q12: sincronización, velocidad y número
    de líneas.
  \item
    Subgrupo preguntas Q04, Q13: contraste y legibilidad.
  \end{itemize}
\item
  Grupo 3: son preguntas que tratan también sobre la corrección del
  subtítulo pero con la diferencia sobre el grupo uno de que se trata de
  cuestiones más sutiles y presumiblemente más difíciles de valorar para
  un novato. Está formado por las preguntas Q14, Q15, Q16 y Q17.
\end{itemize}

\hypertarget{anuxe1lisis-de-tablas-de-contingencia.}{%
\section{Análisis de tablas de
contingencia.}\label{anuxe1lisis-de-tablas-de-contingencia.}}

En esta sección se aplicarán técnicas estadísticas que se basan en
tablas de contingencia. Una descripción teórica de este tipo de técnicas
se pueden encontrar en \textcite{agresti_2018}. Un tratamiento aplicado
y basado en gráficos, que será el enfoque que seguiremos en este
trabajo, es realizado en \textcite{frienly2015}.

\hypertarget{asociaciuxf3n-de-variables-con-la-prueba-de-homogeneidad-chi2.}{%
\subsection{\texorpdfstring{Asociación de variables con la prueba de
homogeneidad
\(\chi^2\).}{Asociación de variables con la prueba de homogeneidad \textbackslash chi\^{}2.}}\label{asociaciuxf3n-de-variables-con-la-prueba-de-homogeneidad-chi2.}}

Podemos usar la prueba de homogeneidad \(\chi^2\) para saber si las
respuestas al cuestionario son independientes del nivel de subtitulado,
del periodo y de la secuencia. Constatamos que según esta prueba ninguna
de estas variables es independiente de la respuesta.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(df\_all}\SpecialCharTok{$}\NormalTok{Treat, df\_all}\SpecialCharTok{$}\NormalTok{Response)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  df_all$Treat and df_all$Response
X-squared = 621.5, df = 5, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(df\_all}\SpecialCharTok{$}\NormalTok{Period, df\_all}\SpecialCharTok{$}\NormalTok{Response)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  df_all$Period and df_all$Response
X-squared = 15.039, df = 5, p-value = 0.0102
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(df\_all}\SpecialCharTok{$}\NormalTok{Seq, df\_all}\SpecialCharTok{$}\NormalTok{Response)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  df_all$Seq and df_all$Response
X-squared = 64.904, df = 5, p-value = 1.173e-12
\end{verbatim}

\normalsize

\hypertarget{comparaciuxf3n-mediante-mosaicos.}{%
\subsection{Comparación mediante
mosaicos.}\label{comparaciuxf3n-mediante-mosaicos.}}

En el Figura~\ref{fig-mosaic} se representan en forma de mosaico las
tablas de contingencia de las respuestas por tratamiento y secuencia. La
información mostrada es similar a la que presentamos en la
Figura~\ref{fig-freqs}, aunque el gráfico es más intuitivo ya que la
anchura y altura de los rectángulos son proporcionales a la frecuencia
marginal de la secuencia y el tratamiento respectivamente y el área es
proporcional a la frecuencia conjunta. En esta ocasión hemos decidido
emparejar los tratamientos en lugar de hacerlo con la secuencia, como
hicimos anteriormente. Esto permite una mejor comparación de las
diferencias entre grupos. Con ello podemos ver fácilmente que el
tratamiento \(A\) es mejor valorado por los estudiantes y que el grupo
que realizó la secuencia \(AB\) tiene más respuestas 5 pero menor número
de respuestas positivas totales que el grupo de secuencia \(BA\) en
ambos niveles de tratamiento.

\begin{figure}[h]

{\centering \includegraphics{42-Analisis_files/figure-pdf/fig-mosaic-1.pdf}

}

\caption{\label{fig-mosaic}Mosaico de tratamientos y secuencias.}

\end{figure}

\hypertarget{sec-or}{%
\subsection{\texorpdfstring{Comparación con
\(Odds\ Ratio\).}{Comparación con Odds\textbackslash{} Ratio.}}\label{sec-or}}

Hasta este momento ha quedado claro que el nivel de subtitulado \(A\) es
preferido por los estudiantes y que las respuestas de ambos grupos son
similares. Pero, ¿cuánto de similares son? Una forma de contestar esta
pregunta es utilizar el \texttt{odds\ ratio} de tratamientos y grupos
para cada nivel de respuesta.

Es decir, calcular:

\begin{equation}
OR_{(Treat, Seq \mid Response=r)}=\frac{
    \frac{
            P(Treat=A \mid Seq=AB, Response=r)
        }{
            P(Treat=B \mid Seq=AB, Response=r)
        }
    }
    {\frac{
        P(Treat=A \mid Seq=BA, Response=r)
        }{
        P(Treat=B \mid Seq=BA, Response=r)
    }
}
\end{equation}

Si los \(OR\) son similares en todos los niveles de respuesta, podemos
afirmar que los grupos son homogéneos. Los resultados en R no producen
significación estadística en ningún nivel de respuesta por lo que según
esta prueba estadística la secuencia de subtitulado no influiría en la
respuesta de los estudiantes (ver Figura~\ref{fig-or-1}).

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{loddsratio}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Seq }\SpecialCharTok{+}\NormalTok{ Response\_l, }\AttributeTok{data =}\NormalTok{ df\_all))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

z test of coefficients:

                    Estimate Std. Error z value Pr(>|z|)
No sé / No contesto  0.19004    0.32746  0.5804   0.5617
Muy en desacuerdo   -0.13517    1.01225 -0.1335   0.8938
En desacuerdo       -0.24362    0.29066 -0.8382   0.4019
Neutral              0.15219    0.21412  0.7108   0.4772
De acuerdo          -0.20977    0.13363 -1.5698   0.1165
Muy de acuerdo       0.11687    0.13671  0.8549   0.3926
\end{verbatim}

\normalsize

\begin{figure}[h]

{\centering \includegraphics{42-Analisis_files/figure-pdf/fig-or-1-1.pdf}

}

\caption{\label{fig-or-1}OR entre tratamiento y grupo por nivel de
respuesta.}

\end{figure}

Sería interesante calcular el \(OR\) para cada nivel de respuesta y
pregunta pero por desgracia la muestra es demasiado pequeña para
hacerlo. Se ha calculado el \(OR\) sobre los agrupamientos de preguntas
y se ha obtenido significación estadística tan solo en el agrupamiento 2
y nivel de respuesta 2:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{loddsratio}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Seq }\SpecialCharTok{+}\NormalTok{ Cluster }\SpecialCharTok{+}\NormalTok{ Response\_l, }\AttributeTok{data =}\NormalTok{ df\_all))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

z test of coefficients:

                      Estimate Std. Error z value Pr(>|z|)  
1:No sé / No contesto -1.94591    1.75662 -1.1078  0.26797  
2:No sé / No contesto  0.41074    1.12569  0.3649  0.71520  
3:No sé / No contesto  0.29239    0.35972  0.8128  0.41632  
1:Muy en desacuerdo   -0.12516    1.17012 -0.1070  0.91482  
2:Muy en desacuerdo   -1.39488    1.66941 -0.8356  0.40341  
3:Muy en desacuerdo    1.19870    1.69327  0.7079  0.47900  
1:En desacuerdo        0.17829    0.49526  0.3600  0.71885  
2:En desacuerdo       -1.34796    0.57253 -2.3544  0.01855 *
3:En desacuerdo        0.23740    0.50928  0.4661  0.64111  
1:Neutral              0.62181    0.46172  1.3467  0.17807  
2:Neutral              0.53248    0.39619  1.3440  0.17895  
3:Neutral             -0.24146    0.31560 -0.7651  0.44421  
1:De acuerdo          -0.35125    0.25963 -1.3529  0.17609  
2:De acuerdo          -0.28064    0.18244 -1.5382  0.12399  
3:De acuerdo           0.22503    0.30663  0.7339  0.46303  
1:Muy de acuerdo       0.27860    0.26542  1.0497  0.29387  
2:Muy de acuerdo       0.23441    0.17892  1.3101  0.19015  
3:Muy de acuerdo      -0.61437    0.38071 -1.6137  0.10659  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

Sin embargo no podemos asumir que esta significación no se deba al azar
ya que estamos realizando 18 contrastes de hipótesis diferentes y cada
uno tiene un error tipo I asociado, con lo que la probabilidad de
encontrar una significación estadística por puro azar aumenta. Se han
propuesto correcciones del \(p\)-value como la de Bonferroni para
abordar este problema que no se aplican en este trabajo.

Otro \(OR\) que tiene interés calcular es el de tratamiento y periodo
para evaluar si las respuestas son homogéneas. Mostramos tanto la tabla
de resultados en R y también su representación visual (ver
Figura~\ref{fig-or-2}).

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{loddsratio}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Response\_l, }\AttributeTok{data =}\NormalTok{ df\_all))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

z test of coefficients:

                    Estimate Std. Error z value  Pr(>|z|)    
No sé / No contesto  0.33469    0.32746  1.0221 0.3067511    
Muy en desacuerdo    0.13517    1.01225  0.1335 0.8937673    
En desacuerdo       -0.12102    0.29067 -0.4164 0.6771467    
Neutral              0.05540    0.21412  0.2587 0.7958414    
De acuerdo          -0.85090    0.13363 -6.3674 1.922e-10 ***
Muy de acuerdo       0.48634    0.13671  3.5574 0.0003745 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

\begin{figure}[h]

{\centering \includegraphics{42-Analisis_files/figure-pdf/fig-or-2-1.pdf}

}

\caption{\label{fig-or-2}OR entre tratamiento y periodo por nivel de
respuesta.}

\end{figure}

Podemos constatar la existencia de un efecto periodo de signo contrario
para las preguntas 4 y 5. La razón de que se produzca este efecto
periodo es que algunas de las respuestas de valoración 5 en ambos
niveles de subtitulado y grupos en el primer periodo se convierten en
valoración 4 en el segundo periodo. Esto indica que los estudiantes de
ambos grupos prestaron más atención o fueron más exigentes en el segundo
visionado y decidieron no otorgar la puntuación máxima incluso en
algunos items al subtitulado correcto. Que el efecto periodo sea
contrario en dos preguntas no debe sorprendernos en este diseño de
experimento, ya que un test es un juego de suma cero: la valoraciones
que se ganan o se pierden en un nivel de respuesta necesariamente
provoca que el resto de niveles pierdan o ganen respectivamente la misma
cantidad. En cualquier caso, vemos que el efecto periodo es cuantitativa
y cualitativamente pequeño. Al afectar solo al intercambio de
valoraciones entre los niveles 4 y 5, y ser las dos positivas, es
simplemente una pequeña corrección en la valoración del subtitulado.

\bookmarksetup{startatroot}

\hypertarget{modelado-estaduxedstico.}{%
\chapter{Modelado estadístico.}\label{modelado-estaduxedstico.}}

Vamos a construir diversos modelos para analizar la asociación de la
variable respuesta sobre los dos niveles de subtitulado y la interacción
con el periodo y la secuencia de tratamientos.

\hypertarget{uxe1rboles-de-inferencia-condicional.}{%
\section{Árboles de inferencia
condicional.}\label{uxe1rboles-de-inferencia-condicional.}}

Los arboles de inferencia condicional (CIT) son un tipo de árbol de
decisión en el que la selección de variables y de los puntos de división
no se basan en medidas de homogeneidad como el índice de Gini, sino en
un contrastes de hipótesis no paramétricos. El algoritmo que se utiliza
es el siguiente, ver \textcite{Levshina2020}:

El algoritmo consiste en contrastar la hipótesis nula de si la variable
de respuesta \(Y\) es independiente de alguna variable explicativa
\(Y \mid X\). Para probar la hipótesis, se utiliza un algoritmo de
permutación de la variable respuesta y se mide la asociación con la
variable explicativa antes y después de la permutación. Si la asociación
no varía significativamente, podemos asumir que las variables de
respuesta y explicativa son independientes. De esta forma se selecciona
la variable explicativa que más influye en la respuesta y que se
utilizará en el particionado. Para elegir el valor de la variable
explicativa que dividirá el conjunto de datos, se procede de forma
análoga midiendo el cambio en la diferencia de asociación. De acuerdo
con \textcite{frienly2015-2}, los CIT resuelven los problemas de
sobreajuste de los árboles de decisión tradicionales.

Para realizar el particionado basado en CIT, vamos a usar la función
\texttt{ctree} del paquete \texttt{party} de R. Presentamos aquí
únicamente el modelo final elegido que incluye como variables
explicativas \texttt{Treat}, \texttt{Period}, \texttt{Seq} y
\texttt{Cluster} \footnote{Se han realizado simulaciones con otras
  combinaciones de variables explicativas que no se incluyen por no
  haber producido resultados relevantes.}.

En la Figura~\ref{fig-ctree} podemos ver que el nivel de subtitulado es
el efecto principal, seguido del grupo de preguntas y finalmente la
secuencia. En este modelo el periodo no aparece por no estar asociado
con la respuesta. Estos resultados son contradictorios con los que
obtuvimos en el análisis con el OR (ver Sección~\ref{sec-or}) en el que
el factor secuencia no era significativo pero sí lo era el factor
periodo. Por otro lado, vemos que la asociación más fuerte es el nivel
de respuesta 5 para subtitulado \(A\), grupos de preguntas 1 y 2 y
secuencia \(AB\) y de las respuestas 4 y 5 cuando la secuencia es
\(BA\). El tratamiento \(B\) está fuertemente asociado con el nivel de
respuesta 1 para el grupo de preguntas 1. Por último, con este modelo no
hay ninguna combinación de factores que prediga un nivel de respuesta 1.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{ctree}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Cluster }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq, }\AttributeTok{data =}\NormalTok{ df\_clean)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-ctree-1.pdf}

}

\caption{\label{fig-ctree}Modelo con árboles de inferencia condicional
(Response \textasciitilde{} Treat + Cluster + Period + Seq).}

\end{figure}

Aunque no es el objetivo del trabajo, podemos usar este modelo para
hacer predicciones. La matriz de contingencia resultante es la
siguiente:

\scriptsize

\begin{verbatim}
         Prediction
Reference   1   2   3   4   5
        1   0 111  19  36   1
        2   0 178  53 170  13
        3   0  67  94 181  41
        4   0  94  76 629 158
        5   0  70  44 560 385
\end{verbatim}

\normalsize

Como habíamos anticipado, nunca se predice el nivel de respuesta 1. Las
categorías que más probablemente predice nuestro modelo son la 4 y la 5
pero aún así hay mucha confusión entre ellas. La exactitud de predicción
es 43\%.

Un modelo alternativo sería usar las mismas variables explicativas pero
cambiado \texttt{Response} por \texttt{Level} como variable de
respuesta. Esta variable solo tiene tres niveles: positivo, negativo y
neutro. De esta forma no se producen confusiones entre los niveles 1 y 2
por un lado y 4 y 5 por otro:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree}\FloatTok{.2} \OtherTok{\textless{}{-}} \FunctionTok{ctree}\NormalTok{(Level }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Cluster }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq, }\AttributeTok{data =}\NormalTok{ df\_clean)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-ctree2-1.pdf}

}

\caption{\label{fig-ctree2}Modelo con árboles de inferencia condicional
(Level \textasciitilde{} Treat + Cluster + Period + Seq).}

\end{figure}

El árbol obtenido con variable respuesta \texttt{Level} (ver
Figura~\ref{fig-ctree2}) es muy similar al otro (ver
Figura~\ref{fig-ctree}) con la principal diferencia de que ahora la
secuencia ha desaparecido como factor relevante. Por otro lado, el
modelo siempre predice una respuesta positiva excepto para el
subtitulado \(B\) y grupo de preguntas 1, que es negativa (el nivel
neutro nunca se predice). La exactitud del modelo ha subido a 72\%. En
cualquier caso no es una gran mejora ya que un modelo que predijera
siempre la categoría mayoritaria (positiva), habría obtenido una
exactitud de 68\%. Se han hecho simulaciones consistentes en incluir
como factor las preguntas o usar como modelo un árbol de decisión
convencional con resultados similares.

\hypertarget{regresiuxf3n-ordinal.}{%
\section{Regresión ordinal.}\label{regresiuxf3n-ordinal.}}

El test de Likert es una escala ordinal. Los test estadísticos ANOVA o
MANOVA presuponen que la variable de respuesta es cuantitativa y con
distribución normal. Tratar las respuestas a un test de Likert como si
fueran cuantitativas no es correcto por las siguientes razones:

\begin{itemize}
\item
  Los niveles de respuesta no son necesariamente equidistantes: la
  distancia entre un par de opciones de respuesta puede no ser la misma
  para todos los pares de opciones de respuesta. Por ejemplo, la
  diferencia entre \enquote{Muy en desacuerdo} y \enquote{En desacuerdo}
  y la diferencia entre \enquote{De acuerdo} y \enquote{Muy de acuerdo}
  es de un nivel, pero psicológicamente puede ser percibida de forma
  diferente por cada sujeto.
\item
  La distribución de las respuestas ordinales puede ser no normal. En
  particular esto sucederá si hay muchas respuestas en los extremos del
  cuestionario.
\item
  Las varianzas de las variables no observadas que subyacen a las
  variables ordinales observadas pueden diferir entre grupos,
  tratamientos, periodos, etc.
\end{itemize}

En \textcite{kruschke2018} se han analizado los problemas potenciales de
tratar datos ordinales como si fueran cuantitativos constatando que se
pueden presentar las siguientes situaciones:

\begin{itemize}
\tightlist
\item
  Se pueden encontrar diferencias significativas entre grupos cuando no
  las hay: error tipo I.
\item
  Se pueden obviar diferencias cuando en realidad sí existen: error tipo
  II.
\item
  Incluso se pueden invertir los efectos de un tratamiento.
\item
  También puede malinterpretarse la interacción entre factores.
\end{itemize}

La Regresión Logística Multinomial es una extensión de la Regresión
Logística cuando la variable de respuesta es nominal. La Regresión
Ordinal tiene en consideración que los valores nominales de la variable
de respuesta están ordenados y por eso será el modelo que utilizaremos.

\hypertarget{variantes-de-la-regresiuxf3n-ordinal.}{%
\subsection{Variantes de la Regresión
Ordinal.}\label{variantes-de-la-regresiuxf3n-ordinal.}}

Los modelos lineales generalizados (\(GLM\)) son modelos en los que la
variable respuesta no es normal. Para especificar un \(GLM\) son
necesarios tres componentes \autocite[ver][]{oconnell2006}:

\begin{itemize}
\tightlist
\item
  Un componente aleatorio: será una distribución de probabilidad de la
  familia exponencial que se asume que sigue la variable respuesta (en
  la regresión logística será la distribución Binomial o la distribución
  de Bernoulli).
\item
  Un componente lineal y aditivo de predictores.
\item
  Una función de enlace que realiza transformación de los valores del
  componente lineal a los que puede tomar la variable respuesta. Por
  ejemplo en la función logística será la función \(logit^{-1}(x)\).
  Esta función permite pasar de un rango de valores
  \((-\infty, +\infty)\) a un rango \((0, 1)\).
\end{itemize}

La Regresión Ordinal es una extensión de la Regresión Logística y, por
lo tanto de \(GLM\). Según \textcite{burkner2019} hay tres clases de
Regresión Ordinal:

\begin{itemize}
\tightlist
\item
  Regresión ordinal acumulativa.
\item
  Regresión ordinal secuencial.
\item
  Regresión ordinal adyacente.
\end{itemize}

Nos centraremos en la primera ya que es la más habitual y adecuada para
nuestro caso \autocite[ver][pp.~23-24]{burkner2019}. El modelo
acumulativo, CM, presupone que la variable ordinal observada, \(Y\),
proviene de la categorización de una variable latente (no observada)
continua, \(\tilde{Y}\). Hay \(K\) umbrales \(\tau_k\) que particionan
\(\tilde{Y}\) en \(K + 1\) categorías ordenadas observables (ver
Figura~\ref{fig-cumulative}). Si asumimos que \(\tilde{Y}\) tiene una
cierta distribución (por ejemplo, normal) con distribución acumulada
\(F\), se puede calcular la probabilidad de que \(Y\) sea la categoría
\(k\) de esta forma:

\[Pr(Y = k) = F(\tau_k) - F(\tau_{k-1})\]

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-cumulative-1.pdf}

}

\caption{\label{fig-cumulative}Función latente en una regresión ordinal
acumulativa.}

\end{figure}

Por ejemplo en la Figura~\ref{fig-cumulative},

\[Pr(Y = 2) = F(\tau_2) - F(\tau_{1})\]

Si suponemos que \(\tilde{Y}\) tiene una relación lineal los
predictores:

\[\tilde{Y} = \eta + \epsilon = \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon\],

y que los errores son \(N(0,\sigma^2)\). Entonces la función de
probabilidad acumulada de los errores tendrá la misma forma que la de
\(\tilde{Y}\):

\[\mathrm{Pr}(\epsilon \leq z) = F(z)\]

Y podremos calcular la distribución de probabilidad acumulada de \(Y\):

\[\mathrm{Pr}(Y \leq k \mid \eta) = \mathrm{Pr}(\tilde{Y} \leq \tau_k \mid \eta) = \mathrm{Pr}(\eta + \epsilon \leq \tau_k) = \mathrm{Pr}(\epsilon \leq \tau_k - \eta) = F(\tau_k - \eta)\]

Por lo que asumiendo la normalidad de los errores:

\[\mathrm{Pr}(Y = k) = \Phi(\tau_k - \eta) - \Phi(\tau_{k - 1} - \eta)\]

Donde hay que estimar los umbrales y los coeficientes de regresión. La
función anterior es la conocida como la función de enlace
\texttt{probit}. Otra función de enlace popular es la función
\texttt{logit}. Es la que usaremos en este trabajo por ser más fácil su
interpretación \footnote{En la práctica los coeficientes estimados con
  las funciones de enlace \texttt{probit} y \texttt{logit} suelen
  similares.}. Con esta función de enlace la interpretación de los
coeficientes es parecida a de los coeficientes de la regresión
logística. Se parte del supuesto de que el \(logit\) de la función de
probabilidad es lineal:

\[logit [P(Y \le k)] = \tau_{k} - \eta = \tau_{k} - (\beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p)\]

En ese caso, se puede demostrar fácilmente que, por ejemplo:

\[\frac{\frac{\mathrm{Pr}(Y \leq k \mid \eta)}{\mathrm{Pr}(Y > k \mid \eta)}}{\frac{\mathrm{Pr}(Y \leq k+1 \mid \eta)}{\mathrm{Pr}(Y > k+1 \mid \eta)}} = \exp(\tau_{k} - \tau_{k+1})\]

Y que \footnote{En el siguiente apartado se demuestra esta fórmula.}:

\[\frac{\frac{\mathrm{Pr}(Y \leq k \mid x_i = 1)}{\mathrm{Pr}(Y > k \mid x_i = 1)}}{\frac{\mathrm{Pr}(Y \leq k \mid x_i=0)}{\mathrm{Pr}(Y > k \mid x_i = 0)}} = \exp(-\beta_{i})\]

o, equivalentemente:

\[\frac{\frac{\mathrm{Pr}(Y > k \mid x_i = x + 1)}{\mathrm{Pr}(Y \leq k \mid x_i = x + 1)}}{\frac{\mathrm{Pr}(Y > k \mid x_i = x)}{\mathrm{Pr}(Y \leq k \mid x_i = x)}} = \exp(\beta_{i})\]

Es decir, que \(\exp(\beta_{i})\) es el \(OR\) (cambio en \(odds\)) de
que la variable respuesta esté por encima de una determinada categoría
versus estar por debajo de ella para una unidad de incremento del
predictor \(x_i\). Este modelo se denomina proporcional ya que cada
predictor se asume que tiene los mismos efectos sobre todas las
categorías de la variable de respuesta ordinal
\autocite[ver][]{Liu2202}. Un valor del coeficiente \(\beta_i\) positivo
indica que la relación entre el predictor \(x_i\) y la función de
\(logit\) es positiva y, por lo tanto, se incrementa la posibilidad de
un mayor valor de la variable respuesta. Como veremos, esta suposición
se puede relajar y permitir que los coeficientes de todos o de algunos
de los predictores sean diferentes para cada pareja consecutiva de
valores de respuesta. Tendríamos entonces más parámetros a estimar con
una interpretación más compleja.

\hypertarget{ajuste-del-modelo-ordinal-response-treat.}{%
\subsection{\texorpdfstring{Ajuste del modelo ordinal
\texttt{Response\ \textasciitilde{}\ Treat}.}{Ajuste del modelo ordinal Response \textasciitilde{} Treat.}}\label{ajuste-del-modelo-ordinal-response-treat.}}

Existen varios paquetes en R que permiten ajustar una regresión ordinal
logística. El más popular es el paquete \texttt{Ordinal}
\autocite{ordinalR}. El paquete \texttt{VGAM} \autocite{VGAMR} es más
flexible y potente. Otra posibilidad es usar la función \texttt{polr}
del paquete \texttt{MASS} \autocite{MASSR}. Finalmente la función
\texttt{orm} del paquete \texttt{rms} también permite hacerlo
\autocite[ver][]{harrell2015}. En este trabajo usaremos el paquete
\texttt{Ordinal} por permitir también incluir efectos aleatorios que
utilizaremos en un apartado posterior. Comenzamos con un modelo simple
que tiene como único predictor el nivel de subtitulado por ser la
variable objetivo de nuestro modelo:

\[
\text{logit}(P(Response_i \leq k)) = \tau_k - \beta_1 \text{Treat}_i,
\]

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clm\_treat }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(clm\_treat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
formula: Response ~ Treat
data:    df_clean

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  2980 -3966.11 7942.21 5(0)  1.64e-10 3.1e+01

Coefficients:
       Estimate Std. Error z value Pr(>|z|)    
TreatB  -1.7206     0.0731  -23.54   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -3.97230    0.09678 -41.045
2|3 -2.45446    0.06812 -36.029
3|4 -1.66453    0.05936 -28.042
4|5 -0.10547    0.04946  -2.132
\end{verbatim}

\normalsize

El método \texttt{summary()} muestra la información resumen. Para su
interpretación vamos a seguir \textcite{christensen2018CumulativeLM}. El
número de condición Hessiano es inferior a \(10^4\) lo que es indicativo
de que no hay problemas de optimización \footnote{El número de condición
  de Hessiano es una medida de la curvatura de una función en un punto.
  Si el número de condición de Hessiano es grande, la función es muy
  sensible a pequeñas perturbaciones y puede ser difícil de optimizar.}.
La sección de coeficientes es la más importante. Se muestra la
estimación de parámetros, el error estándar y la significación
estadística de acuerdo al test de Wald \footnote{El test de Wald es un
  contraste de hipótesis estadístico en el que se evalúa si el valor
  estimado es cero suponiendo que
  \(W = \left(\frac{\hat{\theta} - \theta_0}{se(\hat{\theta})}\right)^2 \sim \chi^{2}\)
  .}. Comprobamos que el valor es claramente significativo. Es decir,
que los estudiantes han valorado de forma diferente la calidad del
subtitulado en ambos vídeos. El estimador de maxima verosimilitud del
coeficiente \texttt{TreatB} es -1.72. Siguiendo la deducción de
\textcite{bruin2011} podemos, por ejemplo, hacer la siguiente
interpretación del significado de este coeficiente referido a dos
niveles consecutivos de respuesta:

\[
\begin{aligned}
logit [P(Y \le 1)] & = & -3.97 - (-1.72 x_1) \\
logit [P(Y \le 2)] & = & -2.45 - (-1.72 x_1)
\end{aligned}
\]

Por lo tanto los \(odds\) serían:

\[
\begin{aligned}
\frac{P(Y \le 1 \mid x_1 = B)}{P(Y > 1 \mid x_1 = B)} & = & exp(-3.97)/exp(-1.72) \\
\frac{P(Y \le 1 \mid x_1 = A)}{P(Y > 1 \mid x_1 = A)} & = & exp(-3.97) \\
\frac{P(Y \le 2 \mid x_1 = B)}{P(Y > 2 \mid x_1 = B)} & = & exp(-2.45)/exp(-1.72) \\
\frac{P(Y \le 2 \mid x_1 = A)}{P(Y > 2 \mid x_1 = A)} & = & exp(-2.45)
\end{aligned}
\]

Y los \(OR\):

\[
\begin{aligned}
\frac{P(Y \le 1 | x_1=B)}{P(Y > 1 | x_1=B)} / \frac{P(Y \le 1 | x_1=A)}{P(Y > 1 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\
\frac{P(Y \le 2 | x_1=B)}{P(Y > 2 | x_1=B)} / \frac{P(Y \le 2 | x_1=A)}{P(Y > 2 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\
\end{aligned}
\]

Se comprueba que el \(OR\) es equivalente en todos los niveles de
respuesta al cuestionario. Esta es una de las suposiciones de la
regresión ordinal acumulativa. El \(odds\) de respuesta al cuestionario
entre los niveles inferiores y superiores a uno dado, \(k\), es 5.59
veces en el subtitulado \(B\) que en el \(A\). Esto indica que el
subtitulado \(B\) es percibido por los estudiantes como de peor calidad
que el subtitulado \(A\). Concretamente, el coeficiente \(\beta\) para
\texttt{Treat} es el \texttt{log\ odds} de observar una mejor respuesta
en una pregunta del test es 5.59 veces superior en el nivel de
subtitulado \(A\) que en el \(B\). Aunque no suele ser de interés la
interpretación de los coeficientes de los umbrales
(\texttt{Threshold\ coefficients}), se pueden utilizar para estimar las
probabilidades de respuesta. Por ejemplo, para el nivel de subtitulado
\(B\):

\[
\begin{aligned}
logit [P(Y \le 1)] & = & -3.97 - (-1.72) & = & -2.25 \\
odds (P(Y \le 1)) & = & exp(logit [P(Y \le 1)]) & = & 0.11 \\
P(Y \le 1) & = & \frac{exp(-2.25)}{1 + exp(-2.25)} & = & 0.10 \\
P(Y \le 2) & = & \frac{exp(-0.73)}{1 + exp(-0.73)} & = & 0.32 \\
P(Y = 2) & = & P(Y \le 2) - P(Y \le 1) & = &  0.23 
\end{aligned}
\]

Para el subtitulado \(A\) no se tiene en cuenta el coeficiente
\(TreatB\) ya que el valor \(x_1\) es cero:

\[
\begin{aligned}
logit [P(Y \le 1)] & = & & & -3.97\\
odds (P(Y \le 1)) & = & exp(logit [P(Y \le 1)]) & = & 0.02 \\
P(Y \le 1) & = & \frac{exp(-3.97)}{1 + exp(-3.97)} & = & 0.02
\end{aligned}
\]

En Tabla~\ref{tbl-probs-clm-treat} se muestran las probabilidades para
ambos niveles de subtitulado y todos los posibles valores de respuesta.

\hypertarget{tbl-probs-clm-treat}{}
\begin{longtable}[]{@{}lrrrrr@{}}
\caption{\label{tbl-probs-clm-treat}Probabilidades de respuesta para el
modelo ordinal Response \textasciitilde{} Treat}\tabularnewline
\toprule\noalign{}
& 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 0.018 & 0.061 & 0.08 & 0.315 & 0.526 \\
B & 0.095 & 0.229 & 0.19 & 0.320 & 0.166 \\
\end{longtable}

\hypertarget{ajuste-del-modelo-ordinal-response-treat-period.}{%
\subsection{\texorpdfstring{Ajuste del modelo ordinal
\texttt{Response\ \textasciitilde{}\ Treat\ +\ Period}.}{Ajuste del modelo ordinal Response \textasciitilde{} Treat + Period.}}\label{ajuste-del-modelo-ordinal-response-treat-period.}}

Para saber si existe un efecto periodo, añadimos como predictor la
variable \texttt{Period}.

\[
\text{logit}(P(Response_i \leq k)) = \tau_k - \beta_1 \text{Treat}_i - \beta_2 \text{Period}_i
\]

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clm\_treat\_period }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(clm\_treat\_period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
formula: Response ~ Treat + Period
data:    df_clean

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  2980 -3957.88 7927.76 5(0)  1.94e-10 4.1e+01

Coefficients:
        Estimate Std. Error z value Pr(>|z|)    
TreatB  -1.74090    0.07339  -23.72  < 2e-16 ***
Period2 -0.27560    0.06805   -4.05 5.12e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -4.13085    0.10507 -39.314
2|3 -2.60905    0.07872 -33.143
3|4 -1.81652    0.07073 -25.681
4|5 -0.25187    0.06153  -4.093
\end{verbatim}

\normalsize

Vemos que ambos coeficientes son significativos y con signo negativo. Un
signo negativo en el efecto periodo está asociado con que la valoración
del subtitulado empeora en el segundo periodo independientemente de si
se trata del subtitulado correcto o incorrecto. Aplicando el mismo
razonamiento del apartado anterior, el \(OR\) del efecto periodo es
\(1/exp(-0.28) = 1.32\). Lo que quiere decir que una vez controlado el
efecto principal del tratamiento, el subtitulado en el segundo periodo
es valorado como de inferior calidad que en el primero. Esto estaría
indicando que los estudiantes son más exigentes con el subtitulado en la
segunda actividad independientemente de su calidad real.

\hypertarget{ajuste-del-modelo-ordinal-response-treat-period.-1}{%
\subsection{\texorpdfstring{Ajuste del modelo ordinal
\texttt{Response\ \textasciitilde{}\ Treat\ *\ Period.}}{Ajuste del modelo ordinal Response \textasciitilde{} Treat * Period.}}\label{ajuste-del-modelo-ordinal-response-treat-period.-1}}

Añadimos al modelo la interacción entre subtitulado y periodo. Esta
interacción corresponde al efecto secuencia. Se puede demostrar que los
modelos \texttt{Response\ \textasciitilde{}\ Treat*Period} y
\texttt{Response\ \textasciitilde{}\ Treat\ +\ Period\ +\ Seq} son
equivalentes si se cambia el contraste por defecto utilizado en R, que
es \texttt{treatment}, a \texttt{sum} \footnote{Ver
  Apéndice~\ref{sec-contrasts} para una discusión sobre el significado y
  la interpretación de los contrastes \texttt{treatment} y \texttt{sum}.}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.sum"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{clm\_treat\_period\_seq.sum }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{coef}\NormalTok{(clm\_treat\_period\_seq.sum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       1|2        2|3        3|4        4|5     Treat1    Period1       Seq1 
-3.1266457 -1.6083838 -0.8184857  0.7499332  0.8739547  0.1396182  0.1062749 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.sum"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{clm\_treat.period.sum }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{coef}\NormalTok{(clm\_treat.period.sum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           1|2            2|3            3|4            4|5         Treat1 
    -3.1266457     -1.6083838     -0.8184857      0.7499332      0.8739547 
       Period1 Treat1:Period1 
     0.1396182      0.1062749 
\end{verbatim}

\normalsize

Vemos que los coeficientes \texttt{Seq1} y \texttt{Treat1:Period1} son
iguales y, por lo tanto, queda demostrado que la secuencia es la
interacción entre periodo y tratamiento. Sin embargo los coeficientes
son diferentes si el contraste es \texttt{treatment} \footnote{Los
  interceptores sí son iguales.}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.treatment"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{clm\_treat\_period\_seq }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{coef}\NormalTok{(clm\_treat\_period\_seq)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       1|2        2|3        3|4        4|5     TreatB    Period2      SeqBA 
-4.2464935 -2.7282315 -1.9383335 -0.3699146 -1.7479094 -0.2792363 -0.2125498 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.treatment"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{clm\_treat.period }\OtherTok{\textless{}{-}}
    \FunctionTok{clm}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period,}
        \AttributeTok{data =}\NormalTok{ df\_clean, }\AttributeTok{link =} \StringTok{"logit"}
\NormalTok{    )}
\FunctionTok{coef}\NormalTok{(clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           1|2            2|3            3|4            4|5         TreatB 
    -4.2464935     -2.7282315     -1.9383335     -0.3699146     -1.9604592 
       Period2 TreatB:Period2 
    -0.4917861      0.4250996 
\end{verbatim}

\normalsize

En el Apéndice~\ref{sec-contrasts} se explica como se pueden obtener los
coeficientes de un modelo a partir de los coeficientes de otro modelo.
Es decir, que se pueden obtener los coeficientes del modelo
\texttt{clm\_treat.period} a partir de los coeficientes del modelo
\texttt{clm\_treat.period.sum}. Por ejemplo, el coeficiente \(TreatB\)
del modelo \texttt{clm\_treat.period} se calcula:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(clm\_treat.period.sum)[}\StringTok{"Treat1"}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(clm\_treat.period.sum)[}\StringTok{"Treat1:Period1"}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Treat1 
-1.960459 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(clm\_treat.period)[}\StringTok{"TreatB"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   TreatB 
-1.960459 
\end{verbatim}

\normalsize

Sin embargo la interpretación de los coeficientes del segundo modelo,
\texttt{clm\_treat.period}, es más sencilla ya que es la que estamos
habituados a utilizar en R. Por ello en este análisis se utilizará el
modelo \texttt{clm\_treat.period}. El resumen del ajuste es:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
formula: Response ~ Treat * Period
data:    df_clean

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  2980 -3953.01 7920.03 5(0)  2.14e-10 8.1e+01

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB         -1.96046    0.10229 -19.166  < 2e-16 ***
Period2        -0.49179    0.09744  -5.047 4.49e-07 ***
TreatB:Period2  0.42510    0.13638   3.117  0.00183 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -4.24649    0.11182 -37.977
2|3 -2.72823    0.08821 -30.928
3|4 -1.93833    0.08167 -23.732
4|5 -0.36991    0.07308  -5.062
\end{verbatim}

\normalsize

Vemos que los tres coeficientes son significativos. El principal efecto
es el nivel de subtitulado obteniendo mejores puntuaciones el nivel
\(A\); el efecto periodo es negativo por lo que el primer periodo
obtiene mejores puntuaciones; por último, el efecto secuencia es
positivo pero de menor valor absoluto que el efecto periodo. Esto quiere
decir que el subtitulado de nivel \(B\) en el periodo 2 (secuencia
\(AB\)), tiene un efecto periodo inferior que el subtitulado \(A\) en el
mismo periodo. Matemáticamente:

\[
\begin{aligned}
logit [P(Y \le 1 \mid Treat = A, Period = 1)] & = & -4.25 \\
logit [P(Y \le 1 \mid Treat = B, Period = 1)] & = & -4.25 - (-1.96) \\
logit [P(Y \le 1 \mid Treat = A, Period = 2)] & = & -4.25 - (-0.49) \\
logit [P(Y \le 1 \mid Treat = B, Period = 2)] & = & -4.25 -(-1.96 -0.49 + 0.43)
\end{aligned}
\]

En definitiva, en el nivel de subtitulado \(B\) apenas encontramos
diferencias entre periodos, sin embargo, en el nivel de subtitulado
\(A\) existe un efecto periodo cuyo valor en \texttt{logits} es -0.49.
Es decir, que la valoración del subtitulado de nivel \(A\) es inferior
en el segundo periodo que en el primero. En la
Figura~\ref{fig-probs-clm-treat.period} podemos ver las predicciones del
modelo.

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-probs-clm-treat.period-1.pdf}

}

\caption{\label{fig-probs-clm-treat.period}Probabilidades de respuesta
para el modelo ordinal Response \textasciitilde{} Treat * Period}

\end{figure}

\hypertarget{elecciuxf3n-del-modelo-ordinal-mediante-el-test-de-razuxf3n-de-verosimilitud.}{%
\subsection{Elección del modelo ordinal mediante el test de razón de
verosimilitud.}\label{elecciuxf3n-del-modelo-ordinal-mediante-el-test-de-razuxf3n-de-verosimilitud.}}

Al ser los tres modelos anidados, podemos compararlos con la prueba de
razón de verosimilitud. Comprobamos que el tercer modelo (el que
incorpora la interacción entre los subtítulos y el periodo) reduce
significativamente el logaritmo de la función de verosimilitud y, por lo
tanto, debe ser aceptado:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(clm\_treat, clm\_treat\_period, clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Likelihood ratio tests of cumulative link models:
 
                 formula:                  link: threshold:
clm_treat        Response ~ Treat          logit flexible  
clm_treat_period Response ~ Treat + Period logit flexible  
clm_treat.period Response ~ Treat * Period logit flexible  

                 no.par    AIC  logLik LR.stat df Pr(>Chisq)    
clm_treat             5 7942.2 -3966.1                          
clm_treat_period      6 7927.8 -3957.9  16.448  1      5e-05 ***
clm_treat.period      7 7920.0 -3953.0   9.738  1   0.001805 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

\hypertarget{comprobaciuxf3n-de-las-hipuxf3tesis-del-modelo.}{%
\subsection{Comprobación de las hipótesis del
modelo.}\label{comprobaciuxf3n-de-las-hipuxf3tesis-del-modelo.}}

La principal hipótesis de un modelo de regresión logística ordinal
proporcional acumulativa es que los coeficientes son iguales entre
cualesquiera dos niveles de respuestas correlativos. Se han propuesto
diversas fórmulas para comprobar esta hipótesis. El paquete
\texttt{Ordinal} dispone de la función \texttt{nominal\_test()} que lo
que hace es realizar un test de razón de verosimilitud para cada
predictor ajustando un modelo en el que se ha relajado la condición de
proporcionalidad. Se constata que el test resulta significativo para
\texttt{Treat} y para \texttt{Treat:Period}, por lo que para estas dos
variables no se puede asumir que los coeficientes estimados se mantengan
constantes en todos los niveles de respuesta.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nominal\_test}\NormalTok{(clm\_treat.period)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Tests of nominal effects

formula: Response ~ Treat * Period
             Df  logLik    AIC     LRT Pr(>Chi)    
<none>          -3953.0 7920.0                     
Treat         3 -3904.4 7828.9  97.172   <2e-16 ***
Period        3 -3951.4 7922.7   3.307   0.3467    
Treat:Period  9 -3884.8 7801.6 136.408   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

Lo que procede es ajustar el modelo relajando la constante de
proporcionalidad de esas variables. Se ha realizado esto utilizando la
función \texttt{vglm} del paquete \texttt{VGAM}. Vemos que ahora hay
cuatro coeficientes para cada una de las variables \texttt{Treat} y
\texttt{Treat:Period} \footnote{Los umbrales tienen los mismo valores
  pero de signo contrario debido a diferencias en la parametrización del
  modelo en cada función utilizada.}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vglm\_treat.period }\OtherTok{\textless{}{-}} \FunctionTok{vglm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period,}
\NormalTok{    VGAM}\SpecialCharTok{::}\FunctionTok{cumulative}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{, }\AttributeTok{parallel =}\NormalTok{ F }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Treat}\SpecialCharTok{:}\NormalTok{Period, }\AttributeTok{reverse =}\NormalTok{ T),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{coef}\NormalTok{(vglm\_treat.period) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{data.frame}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                          .
(Intercept):1     6.2295614
(Intercept):2     3.5001281
(Intercept):3     2.2121438
(Intercept):4     0.2998788
TreatB:1         -4.0441016
TreatB:2         -2.8029889
TreatB:3         -2.2174630
TreatB:4         -1.7926200
Period2          -0.5345919
TreatB:Period2:1  0.3509228
TreatB:Period2:2  0.3607009
TreatB:Period2:3  0.3891474
TreatB:Period2:4  0.8024952
\end{verbatim}

\normalsize

En la Figura~\ref{fig-probs-vglm-treat.period} se muestran las
probabilidades de respuesta de este modelo.

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-probs-vglm-treat.period-1.pdf}

}

\caption{\label{fig-probs-vglm-treat.period}Probabilidades de respuesta
para el modelo ordinal no proporcional Response \textasciitilde{} Treat
* Period}

\end{figure}

\hypertarget{introducciuxf3n-a-los-modelos-multinivel.}{%
\subsection{Introducción a los modelos
multinivel.}\label{introducciuxf3n-a-los-modelos-multinivel.}}

Un modelo multinivel, jerárquico o mixto es un modelo en el que tenemos
datos de un nivel inferior anidados en estructuras de un nivel superior.
Por ejemplo, si quisiéramos evaluar el rendimiento de varios métodos de
enseñanza, poríamos seleccionar aleatoriamente varios colegios
participantes y en cada uno de ellos elegir varias clases en las que se
impartiría uno de los métodos de enseñanza. Los modelos multinivel se
utilizan cuando se incumple la hipótesis de independencia de entre las
observaciones. En el caso de los métodos de enseñanza, los alumnos de
una clase no son independientes de los alumnos de otra clase del mismo
colegio y tampoco lo son los alumnos de dos colegios diferentes. Otra
situación en la que se viola la condición de independencia entre
observaciones es cuando se toman varias medidas del mismo sujeto. Este
tipo de experimentos se llaman de medidas repetidas o longitudinales. En
este caso se consideran que las medidas están anidadas en el sujeto
\autocite[ver][]{Liu2202}. En un modelo multinivel no es necesario que
todas las variables tengan una estructura jerárquica. Distinguimos
entonces dos tipos de variables. Las conocidas como de efectos fijos son
aquellas variables que se consideran que tienen el mismo efecto en toda
la población y, por lo tanto, estimamos un único coeficiente. Las que
llamamos como variables de efectos aleatorios tienen un coeficiente
diferente para cada elemento de la población y se supone que son una
muestra de una población mucho mayor, como el caso de seleccionar
aleatoriamente una muestra de colegios. Normalmente el coeficiente
particular de cada elemento no es de interés para el investigador y se
supone que tienen una media centrada en cero. El mayor interés de los
efectos aleatorios es la estimación de su matriz de
varianzas-covarianzas.

La ecuación general de un modelo multinivel con dos niveles y un solo
predictor con efectos aleatorios es \autocite[ver][pp.~40]{chen2021}:

\[
\begin{aligned}
Level\ 1: & y_{ij}     & = & \beta_{0j} + \beta_{1j}x_{1ij} + \epsilon_{ij} \\
Level\ 2: & \beta_{0j} & = & \beta_{0} + U_{0j} & (intercepto\ aleatorio) \\
          & \beta_{1j} & = & \beta_{0} + U_{1j} & (pendiente\ aleatoria) \\
\end{aligned}
\]

Donde los errores del modelo se distribuyen,

\[
Error\ intra\ grupo:  \epsilon_{ij} \sim N(0, \sigma^2)
\]

\[
Error\ entre\ grupos: 
\begin{pmatrix}
     U_{0j} \\
     U_{1j} \\
\end{pmatrix} 
\sim
N
\begin{pmatrix}
\begin{pmatrix}
     0 \\
     0 \\
\end{pmatrix},
\begin{pmatrix}
     \tau_0^2 & \tau_0\tau_1\rho_{01} \\
     \tau_0\tau_1\rho_{01} &  \tau_1^2 \\
\end{pmatrix}
\end{pmatrix} 
\]

donde \(j\) son los grupos que varían \(j = 1,...,J\) (\(J\) es el
número de grupos); \(i\) es la observación \(i\) del grupo \(j\)
(\(i = 1,...,n_j\), \(n_j\) es el número de observaciones del grupo
\(j\)). El modelo se compone de una parte fija
\(\beta_0 + \beta_1 x_{ij}\) y una aleatoria
\(U_{0j} + U_{1j} x_{1ij} + \epsilon{ij}\). Los parámetros de este
modelo son el intercepto y la pendiente de efectos fijos (\(\beta_0\) y
\(\beta_1\)), la varianza intra-grupos (\(\sigma^2\)), la varianza
inter-grupos del intercepto aleatoria (\(\tau_0\)) y de la pendiente
aleatoria (\(\tau_1\)), y la correlación entre intercepto y pendiente
aleatorias (\(\rho_{01}\)). Cuando se introduce una estructura
multinivel se pueden omitir tanto el intercepto como la pendiente
aleatoria.

En \textcite{gelman2013} se evalúan tres posibilidades a la hora de
definir un modelo:

\begin{itemize}
\tightlist
\item
  \(Complete\ pooloing\): Consiste en estimar un único parámetro para
  todas las observaciones. Es equivalente a un modelo con efectos fijos.
\item
  \(No\ pooling\): Se estiman tantos paŕametros como grupos haya de
  forma independiente.
\item
  \(Partial\ pooling\): Es el modelo jerárquico. Es una mezcla de ambos,
  ya que aunque se estima un parámetro para cada grupo, esta estimación
  no es independiente, sino que se supone que las observaciones de un
  mismo grupo proceden de una misma distribución de probabilidad. Esto
  se traduce en que se produce una contracción (\(shrinkage\)) en la
  estimación de los parámetros. Al influir la estimación de unas
  observaciones en otras, la estimación es de menor valor absoluto que
  la que resultaría en un modelo de \(no\ pooling\). De esta forma
  podemos ver el \(complete\ pooling\) y el \(no\ pooling\) como dos
  casos particulares extremos del \(no\ pooling\). La contracción de
  coeficientes en los modelos multinivel actúa como una regularización
  que puede evitar el sobreajuste.
\end{itemize}

Los modelos multinivel requieren supuestos adicionales en el nivel
segundo y superiores que son similares a los supuestos para los modelos
de efectos fijos en el primer y único nivel
\autocite[ver][pp.~43]{chen2021}. Para estimar los parámetros en un
modelo multinivel se utiliza el método de máxima verosimilitud
restringida (RMLE) que es una variante de la estimación por máxima
verosimilitud (MLE) en la que se hacen ajustes en los grados de libertad
del modelo con efectos aleatorios.

\hypertarget{ajuste-del-modelo-multinivel-ordinal.}{%
\subsection{Ajuste del modelo multinivel
ordinal.}\label{ajuste-del-modelo-multinivel-ordinal.}}

El modelo multinivel aleatorio más simple que podemos considerar es el
que incorpora únicamente un interceptor aleatorio para los estudiantes
del curso. Que los estudiantes sean considerados un efecto aleatorio
está doblemente justificado. Por un lado, son una muestra de una
población más amplia que estaría constituida por todos los estudiantes
de todos los cursos de accesibilidad. Por otro, cada estudiante realiza
el test de evaluación dos veces y, por lo tanto, las respuestas a estos
cuestionarios no son independientes. La especificación del modelo será
la siguiente:

\[
\text{logit}(P(Response_{ij} \leq k)) = \tau_k +\tau_{kj} - \beta_1 \text{Treat}_{ij},
\]

donde \(Response_{ij}\) es la observación \(i\) del usuario \(j\),
\(\tau_k\) es el interceptor común a todos los usuarios para el nivel de
respuesta \(k\) y \(\tau_{kj}\) es el interceptor específico para el
usuario \(j\). Para ajustar el modelo, vamos a utilizar la función
\texttt{clmm()} del paquete \texttt{Ordinal} ya que permite la inclusión
de efectos aleatorios.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_subject }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject), }\AttributeTok{data =}\NormalTok{ df\_clean)}
\FunctionTok{summary}\NormalTok{(clmm\_subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ (1 | Subject)
data:    df_clean

 link  threshold nobs logLik   AIC     niter     max.grad cond.H 
 logit flexible  2980 -4053.61 8117.23 272(1093) 7.11e-04 8.3e+01

Random effects:
 Groups  Name        Variance Std.Dev.
 Subject (Intercept) 0.8385   0.9157  
Number of groups:  Subject 87 

No Coefficients

Threshold coefficients:
    Estimate Std. Error z value
1|2  -3.1597     0.1291 -24.481
2|3  -1.6869     0.1109 -15.212
3|4  -0.9383     0.1077  -8.713
4|5   0.6354     0.1068   5.951
\end{verbatim}

\normalsize

Vemos que el parámetro \(\widehat{\tau_0}\) tiene un valor 0.92 y que no
hay coeficientes que estimar. El siguiente modelo en orden de
complejidad es el que incorpora el predictor \texttt{Treat}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat\_subject }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject), }\AttributeTok{data =}\NormalTok{ df\_clean)}
\FunctionTok{summary}\NormalTok{(clmm\_treat\_subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat + (1 | Subject)
data:    df_clean

 link  threshold nobs logLik   AIC     niter     max.grad cond.H 
 logit flexible  2980 -3665.73 7343.47 395(1585) 4.97e-04 9.5e+01

Random effects:
 Groups  Name        Variance Std.Dev.
 Subject (Intercept) 1.265    1.125   
Number of groups:  Subject 87 

Coefficients:
       Estimate Std. Error z value Pr(>|z|)    
TreatB  -2.0747     0.0793  -26.16   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -4.7243     0.1638 -28.839
2|3  -3.0518     0.1453 -21.008
3|4  -2.1256     0.1392 -15.269
4|5  -0.2068     0.1325  -1.561
\end{verbatim}

\normalsize

En este modelo \(\widehat{\tau_0}\) vale 1.12 y la pendiente del
tratamiento, \texttt{TreatB} es -2.07. Podemos considerar un modelo en
la que la valoración de cada sujeto sea diferente para cada tratamiento:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat.subject }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject), }\AttributeTok{data =}\NormalTok{ df\_clean)}
\FunctionTok{summary}\NormalTok{(clmm\_treat.subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat + (1 + Treat | Subject)
data:    df_clean

 link  threshold nobs logLik   AIC     niter     max.grad cond.H 
 logit flexible  2980 -3431.27 6878.53 535(3741) 2.43e-03 1.7e+02

Random effects:
 Groups  Name        Variance Std.Dev. Corr   
 Subject (Intercept) 2.691    1.641           
         TreatB      4.295    2.072    -0.598 
Number of groups:  Subject 87 

Coefficients:
       Estimate Std. Error z value Pr(>|z|)    
TreatB  -2.5864     0.2425  -10.67   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -5.5561     0.2207 -25.173
2|3  -3.6249     0.2024 -17.914
3|4  -2.5581     0.1968 -12.999
4|5  -0.3271     0.1900  -1.721
\end{verbatim}

\normalsize

Ahora \(\widehat{\tau_0}\) vale 1.64 y \(\widehat{\tau_1}\) 2.07. La
correlación, \(\rho_{01}\), es -0.6. Podemos añadir el factor
\texttt{Period} al modelo:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat.period.subject }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(clmm\_treat.period.subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat * Period + (1 + Treat | Subject)
data:    df_clean

 link  threshold nobs logLik   AIC     niter       max.grad cond.H 
 logit flexible  2980 -3429.88 6879.76 1696(11676) 7.34e-05 6.4e+02

Random effects:
 Groups  Name        Variance Std.Dev. Corr   
 Subject (Intercept) 2.588    1.609           
         TreatB      4.168    2.042    -0.584 
Number of groups:  Subject 87 

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB          -2.8530     0.3795  -7.519 5.53e-14 ***
Period2         -0.5893     0.3685  -1.599    0.110    
TreatB:Period2   0.5307     0.5855   0.906    0.365    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -5.8518     0.2892 -20.236
2|3  -3.9206     0.2754 -14.234
3|4  -2.8541     0.2714 -10.515
4|5  -0.6226     0.2654  -2.345
\end{verbatim}

\normalsize

Vemos que, a diferencia de lo que sucedía en el modelo de efectos fijos,
el periodo y la interacción del periodo con el subtitulado son ahora no
significativos. Queda, por último, discutir cómo añadir las preguntas al
modelo. Consideramos que las respuestas a las preguntas no son
independientes unas de otras y que, por lo tanto, deben ser consideradas
efectos aleatorios. En \textcite{burkner2021}
\textcite[pp.~19-20]{burkner2019} podemos encontrar un ejemplo de esta
solución. Las preguntas como efecto aleatorio se pueden añadir
considerando únicamente el intercepto o el intercepto y la pendiente.
Ajustamos ambos modelos:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat.period.subject\_question }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(clmm\_treat.period.subject\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question)
data:    df_clean

 link  threshold nobs logLik   AIC     niter     max.grad cond.H 
 logit flexible  2980 -3309.04 6640.07 960(7467) 3.85e-04 6.6e+02

Random effects:
 Groups   Name        Variance Std.Dev. Corr   
 Subject  (Intercept) 3.0249   1.739           
          TreatB      4.8228   2.196    -0.591 
 Question (Intercept) 0.4651   0.682           
Number of groups:  Subject 87,  Question 18 

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB          -3.0562     0.4062  -7.525 5.29e-14 ***
Period2         -0.6163     0.3966  -1.554    0.120    
TreatB:Period2   0.5608     0.6266   0.895    0.371    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -6.2609     0.3506 -17.858
2|3  -4.1977     0.3375 -12.439
3|4  -3.0366     0.3334  -9.108
4|5  -0.6370     0.3276  -1.944
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat.period.subject.question }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(clmm\_treat.period.subject.question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat |  
    Question)
data:    df_clean

 link  threshold nobs logLik   AIC     niter      max.grad cond.H 
 logit flexible  2980 -3186.06 6398.11 1026(8128) 1.80e-04 6.1e+02

Random effects:
 Groups   Name        Variance Std.Dev. Corr   
 Subject  (Intercept) 3.1372   1.7712          
          TreatB      5.4601   2.3367   -0.552 
 Question (Intercept) 0.4474   0.6689          
          TreatB      1.8621   1.3646   -0.471 
Number of groups:  Subject 87,  Question 18 

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB          -3.1435     0.5358  -5.867 4.43e-09 ***
Period2         -0.6255     0.4028  -1.553    0.120    
TreatB:Period2   0.5590     0.6615   0.845    0.398    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -6.7481     0.3585 -18.821
2|3  -4.3947     0.3411 -12.884
3|4  -3.1106     0.3362  -9.252
4|5  -0.5610     0.3298  -1.701
\end{verbatim}

\normalsize

Un modelo más simple que el anterior que podemos considerar es eliminar
la pendiente del subtitulado en el efecto aleatorio \texttt{Subject}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat.period\_subject\_question }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(clmm\_treat.period\_subject\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat * Period + (1 | Subject) + (1 | Question)
data:    df_clean

 link  threshold nobs logLik   AIC     niter     max.grad cond.H 
 logit flexible  2980 -3559.48 7136.96 987(3952) 5.50e-04 5.9e+02

Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 1.4348   1.1978  
 Question (Intercept) 0.3394   0.5826  
Number of groups:  Subject 87,  Question 18 

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB          -2.5366     0.2815  -9.012   <2e-16 ***
Period2         -0.6203     0.2795  -2.219   0.0265 *  
TreatB:Period2   0.5958     0.5353   1.113   0.2657    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -5.3264     0.2655 -20.059
2|3  -3.5644     0.2530 -14.089
3|4  -2.5690     0.2488 -10.325
4|5  -0.5243     0.2434  -2.154
\end{verbatim}

\normalsize

E incluso eliminar completamente el efecto aleatorio \texttt{Subject} y
mantener solo las preguntas como efecto aleatorio.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clmm\_treat.period\_question }\OtherTok{\textless{}{-}} \FunctionTok{clmm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(clmm\_treat.period\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: Response ~ Treat * Period + (1 | Question)
data:    df_clean

 link  threshold nobs logLik   AIC     niter     max.grad cond.H 
 logit flexible  2980 -3883.04 7782.07 741(2226) 1.08e-04 1.3e+02

Random effects:
 Groups   Name        Variance Std.Dev.
 Question (Intercept) 0.2274   0.4769  
Number of groups:  Question 18 

Coefficients:
               Estimate Std. Error z value Pr(>|z|)    
TreatB         -2.04502    0.10378 -19.706  < 2e-16 ***
Period2        -0.50200    0.09929  -5.056 4.29e-07 ***
TreatB:Period2  0.43361    0.13747   3.154  0.00161 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -4.4008     0.1610 -27.337
2|3  -2.8298     0.1446 -19.575
3|4  -1.9983     0.1401 -14.259
4|5  -0.3609     0.1349  -2.675
\end{verbatim}

\normalsize

Mediante el test de razón de verosimilitud podemos seleccionar el modelo
con menor función de verosimilitud:

\tiny

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(}
\NormalTok{    clmm\_subject,}
\NormalTok{    clmm\_treat.subject,}
\NormalTok{    clmm\_treat.period.subject,}
\NormalTok{    clmm\_treat.period.subject\_question,}
\NormalTok{    clmm\_treat.period.subject.question,}
\NormalTok{    clmm\_treat.period\_subject\_question,}
\NormalTok{    clmm\_treat.period\_question}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Likelihood ratio tests of cumulative link models:
 
                                   formula:                                                                  
clmm_subject                       Response ~ (1 | Subject)                                                  
clmm_treat.subject                 Response ~ Treat + (1 + Treat | Subject)                                  
clmm_treat.period_question         Response ~ Treat * Period + (1 | Question)                                
clmm_treat.period_subject_question Response ~ Treat * Period + (1 | Subject) + (1 | Question)                
clmm_treat.period.subject          Response ~ Treat * Period + (1 + Treat | Subject)                         
clmm_treat.period.subject_question Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question)        
clmm_treat.period.subject.question Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question)
                                   link: threshold:
clmm_subject                       logit flexible  
clmm_treat.subject                 logit flexible  
clmm_treat.period_question         logit flexible  
clmm_treat.period_subject_question logit flexible  
clmm_treat.period.subject          logit flexible  
clmm_treat.period.subject_question logit flexible  
clmm_treat.period.subject.question logit flexible  

                                   no.par    AIC  logLik LR.stat df Pr(>Chisq)
clmm_subject                            5 8117.2 -4053.6                      
clmm_treat.subject                      8 6878.5 -3431.3 1244.69  3  < 2.2e-16
clmm_treat.period_question              8 7782.1 -3883.0 -903.54  0           
clmm_treat.period_subject_question      9 7137.0 -3559.5  647.12  1  < 2.2e-16
clmm_treat.period.subject              10 6879.8 -3429.9  259.20  1  < 2.2e-16
clmm_treat.period.subject_question     11 6640.1 -3309.0  241.69  1  < 2.2e-16
clmm_treat.period.subject.question     13 6398.1 -3186.1  245.96  2  < 2.2e-16
                                      
clmm_subject                          
clmm_treat.subject                 ***
clmm_treat.period_question            
clmm_treat.period_subject_question ***
clmm_treat.period.subject          ***
clmm_treat.period.subject_question ***
clmm_treat.period.subject.question ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\normalsize

Vemos que el modelo más complejo,
\texttt{clmm\_treat.period.subject.question}, presenta una menor funcion
de verosimilitud. Este modelo tiene un \(AIC\) menor que los modelos
ordinales ajustados en el apartado anterior incluso si a esos modelos se
les añade como factor predictor \texttt{Question}. En el
Tabla~\ref{tbl-question-intercepts} se muestran los interceptores y
pendientes estimadas para el efecto aleatorio \texttt{Question}.

\hypertarget{tbl-question-intercepts}{}
\begin{longtable}[]{@{}lrr@{}}
\caption{\label{tbl-question-intercepts}Intercepto y pendiente de
Question en el modelo Response \textasciitilde{} Treat * Period + (1 +
Treat \textbar{} Subject) + (1 + Treat \textbar{}
Question)}\tabularnewline
\toprule\noalign{}
& (Intercept) & TreatB \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& (Intercept) & TreatB \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Q18 & 0.3933757 & -1.1021051 \\
Q01 & 0.2726623 & 0.4752429 \\
Q02 & 0.6197324 & -0.3813147 \\
Q03 & 0.0640464 & 0.5063518 \\
Q04 & 0.5020005 & 1.9203520 \\
Q05 & 0.7498895 & -2.8118058 \\
Q06 & 0.5528685 & -0.8949249 \\
Q07 & -0.0106860 & -0.4533266 \\
Q08 & -0.1980169 & -0.8402323 \\
Q09 & 0.0184714 & -2.4698505 \\
Q10 & 0.0228628 & 0.1615350 \\
Q11 & 0.0782894 & 0.6223213 \\
Q12 & -0.2003100 & 0.3403381 \\
Q13 & 0.5516281 & 1.5330216 \\
Q14 & -0.2392607 & -0.4339893 \\
Q15 & -1.3380683 & 1.4804380 \\
Q16 & -1.3655878 & 1.7228905 \\
Q17 & -1.0044586 & 1.1760588 \\
\end{longtable}

Las preguntas Q16, Q15, Q17, Q05, Q02 son las 5 cuyo \texttt{log\ odds}
del intercepto tiene un valor mayor valor absoluto y, por lo tanto, las
que nuestro modelo considera más diferentes del resto. Por otro lado,
las preguntas Q05, Q09, Q04, Q16, Q13 son las que mayor valor absoluto
tienen en el coeficiente \texttt{TreatB} y, por ello, las que presentan
mayor diferencia entre tratamientos. En la
Figura~\ref{fig-probs-clmm_treat.period.subject.question} se muestran
las predicciones del modelo.

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-probs-clmm_treat.period.subject.question-1.pdf}

}

\caption{\label{fig-probs-clmm_treat.period.subject.question}Probabilidades
de respuesta para el modelo ordinal Response \textasciitilde{} Treat *
Period + (1 + Treat \textbar{} Subject) + (1 + Treat \textbar{}
Question)}

\end{figure}

\hypertarget{modelado-bayesiano.}{%
\section{Modelado Bayesiano.}\label{modelado-bayesiano.}}

En el apéndice se comparan diversas parametrizaciones de modelado
bayesiano utilizando la función \texttt{brm()} del paquete
\texttt{brms}. Analizamos aquí la que mejor resultado resultado produjo
con la validación cruzada bayesiana \texttt{leave-one-out}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_treat.period.subject.question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_treat.period.subject.question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

Esta parametrización coincide con la que elegimos en el apartado de
Regresión Ordinal con efectos mixtos. El modelo utiliza como factores
con efectos fijos (\texttt{complete\ pooling} en terminología bayesiana)
el nivel de subtitulado y el periodo y la interacción entre ambos; y
como efectos aleatorios (\texttt{partial\ pooling}) los sujetos y las
preguntas del test. Cada uno de ellos con un intercepto y un nivel de
subtitulado variable. El resumen del modelo es el siguiente:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(brm\_treat.period.subject.question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             0.74      0.16     0.50     1.11 1.00     1213
sd(TreatB)                1.50      0.29     1.05     2.21 1.00     1194
cor(Intercept,TreatB)    -0.41      0.21    -0.74     0.07 1.01      931
                      Tail_ESS
sd(Intercept)             2155
sd(TreatB)                1803
cor(Intercept,TreatB)     1691

~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             1.82      0.18     1.50     2.21 1.00      841
sd(TreatB)                2.39      0.21     2.01     2.84 1.00      685
cor(Intercept,TreatB)    -0.54      0.09    -0.70    -0.35 1.01      420
                      Tail_ESS
sd(Intercept)             1266
sd(TreatB)                1487
cor(Intercept,TreatB)      719

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -6.70      0.37    -7.43    -5.98 1.00      701     1417
Intercept[2]      -4.35      0.35    -5.03    -3.64 1.00      641     1231
Intercept[3]      -3.06      0.34    -3.73    -2.37 1.00      626     1271
Intercept[4]      -0.50      0.34    -1.17     0.18 1.00      623     1227
TreatB            -3.15      0.57    -4.28    -2.04 1.01      483     1112
Period2           -0.58      0.41    -1.41     0.21 1.01      492      943
TreatB:Period2     0.50      0.68    -0.82     1.83 1.00      428      888

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\normalsize

En el Tabla~\ref{tbl-model-comp} se comparan las estimaciones puntuales
que obtuvimos para este modelo con la función \texttt{clmm}. Se
comprueba que son muy similares. También se añaden los intervalos de
confianza. Vemos que los interceptores son claramente significativos y
también el coeficiente de \texttt{TreatB}. Sin embargo los coeficientes
correspondientes al efecto periodo, \texttt{Period2}, y al efecto
secuencia, \texttt{TreatB:Period}, incluyen el cero y además tienen
intervalos muy grandes por lo que hay mucha incertidumbre respecto a su
verdadero valor.

\tiny

\hypertarget{tbl-model-comp}{}
\begin{longtable}{lrrrrrr}
\caption{\label{tbl-model-comp}Comparación frecuentista/bayesiano de coeficientes estimados en el
modelo Response \textasciitilde{} Treat * Period + (1 + Treat \textbar{}
Subject) + (1 + Treat \textbar{} Question). }\tabularnewline

\toprule
 & \multicolumn{3}{c}{ordinal::clmm} & \multicolumn{3}{c}{brms::brm} \\ 
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
Name & Estimation.clmm & conf.2.5\% & conf.97.5\% & Estimation.brm & cred.2.5\% & cred.97.5\% \\ 
\midrule
1|2 & -6.75 & -7.45 & -6.05 & -6.71 & -7.43 & -5.98 \\ 
2|3 & -4.39 & -5.06 & -3.73 & -4.35 & -5.03 & -3.64 \\ 
3|4 & -3.11 & -3.77 & -2.45 & -3.06 & -3.73 & -2.37 \\ 
4|5 & -0.56 & -1.21 & 0.09 & -0.50 & -1.17 & 0.18 \\ 
TreatB & -3.14 & -4.19 & -2.09 & -3.14 & -4.28 & -2.04 \\ 
Period2 & -0.63 & -1.42 & 0.16 & -0.57 & -1.41 & 0.21 \\ 
TreatB:Period2 & 0.56 & -0.74 & 1.86 & 0.52 & -0.82 & 1.83 \\ 
Subject.sd(Intercept) & 0.67 &  &  & 0.72 & 0.50 & 1.11 \\ 
Subject.sd(TreatB) & 1.36 &  &  & 1.47 & 1.05 & 2.21 \\ 
Subject.cor(Intercept,TreatB) & 1.77 &  &  & 1.82 & 1.50 & 2.21 \\ 
Question.sd(Intercept) & 2.34 &  &  & 2.38 & 2.01 & 2.84 \\ 
Question.sd(TreatB) & -0.47 &  &  & -0.44 & -0.74 & 0.07 \\ 
Question.cor(Intercept,TreatB) & -0.55 &  &  & -0.54 & -0.70 & -0.35 \\ 
\bottomrule
\end{longtable}

\normalsize

Hemos mantenido las distribuciones de probabilidad a priori que por
defecto utiliza \texttt{brm} confiando en que sus parámetros por defecto
son adecuados. Sin embargo, conviene comprobar si realmente es así. En
el Tabla~\ref{tbl-priors} se muestran las distribuciones a priori de los
parámetros aleatorios del modelo. En la Figura~\ref{fig-priors} se
constata que toman valores razonables y no informativos.

\tiny

\hypertarget{tbl-priors}{}
\begin{longtable}{llllrrrrrl}
\caption{\label{tbl-priors}Distribuciones a priori del modelo Response \textasciitilde{} Treat *
Period + (1 + Treat \textbar{} Subject) + (1 + Treat \textbar{}
Question). }\tabularnewline

\toprule
prior & class & coef & group & resp & dpar & nlpar & lb & ub & source \\ 
\midrule
 & b &  &  &  &  &  &  &  & default \\ 
 & b & Period2 &  &  &  &  &  &  & default \\ 
 & b & TreatB &  &  &  &  &  &  & default \\ 
 & b & TreatB:Period2 &  &  &  &  &  &  & default \\ 
student\_t(3, 0, 2.5) & Intercept &  &  &  &  &  &  &  & default \\ 
 & Intercept & 1 &  &  &  &  &  &  & default \\ 
 & Intercept & 2 &  &  &  &  &  &  & default \\ 
 & Intercept & 3 &  &  &  &  &  &  & default \\ 
 & Intercept & 4 &  &  &  &  &  &  & default \\ 
lkj\_corr\_cholesky(1) & L &  &  &  &  &  &  &  & default \\ 
 & L &  & Question &  &  &  &  &  & default \\ 
 & L &  & Subject &  &  &  &  &  & default \\ 
student\_t(3, 0, 2.5) & sd &  &  &  &  &  & 0 &  & default \\ 
 & sd &  & Question &  &  &  &  &  & default \\ 
 & sd & Intercept & Question &  &  &  &  &  & default \\ 
 & sd & TreatB & Question &  &  &  &  &  & default \\ 
 & sd &  & Subject &  &  &  &  &  & default \\ 
 & sd & Intercept & Subject &  &  &  &  &  & default \\ 
 & sd & TreatB & Subject &  &  &  &  &  & default \\ 
\bottomrule
\end{longtable}

\normalsize

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-priors-1.pdf}

}

\caption{\label{fig-priors}Distribuciones a priori del modelo Response
\textasciitilde{} Treat * Period + (1 + Treat \textbar{} Subject) + (1 +
Treat \textbar{} Question).}

\end{figure}

Es importante asegurar que el entrenamiento ha convergido a su
distribución a posteriori. En la tabla de resumen constatamos que el
valor de \texttt{Rhat} es inferior a 1.1 y el de \texttt{ESS} superior a
400 en todos los parámetros, que son umbrales que no se deberían violar
\autocite[ver][]{burkner2019}. En la Figura~\ref{fig-trace} se comprueba
que las cadenas MCMC de muestreo de la distribución a posteriori se
mezclan correctamente y no se aprecia autocorrelación en ninguno de las
parámetros. Por último, en la Figura~\ref{fig-predictive} se muestra una
comparación entre los histogramas a partir de los datos con los
intervalos de confianza marginales de la función predictiva a posteriori
del modelo. En la mayoría de las preguntas, el muestreo reproduce
bastante bien el histograma en casi todas las preguntas excepto en
algunas como la \texttt{Q16} o la \texttt{Q17}.

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-trace-1.pdf}

}

\caption{\label{fig-trace}Cadenas MCMC del modelo Response
\textasciitilde{} Treat * Period + (1 + Treat \textbar{} Subject) + (1 +
Treat \textbar{} Question).}

\end{figure}

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-predictive-1.pdf}

}

\caption{\label{fig-predictive}Comparación de los valores reales con los
obtenidos a partir de la función predictiva a posteriori del modelo
Response \textasciitilde{} Treat * Period + (1 + Treat \textbar{}
Subject) + (1 + Treat \textbar{} Question).}

\end{figure}

En cuanto a las conclusiones que podemos extraer del modelo, la más
importante es que, como hemos constatado desde el principio de este
trabajo, los alumnos perciben claramente una diferencia entre los
niveles de subtitulado \(A\) y \(B\), siendo preferido el \(A\). En la
Figura~\ref{fig-predictive-2} se representa gráficamente los valores
esperados de la probabilidad de respuesta a cada pregunta por
tratamiento y periodo. Lo más interesante es confirmar (ver
Figura~\ref{fig-or-2}) la existencia de pequeños efectos periodo y
secuencia que se materializan en que, para el nivel de subtitulado
\(A\), son ligeramente más probables las respuestas 4 en el periodo 2
(secuencia \(BA\)) que en el 1 (secuencia \(AB\)). Con las respuestas de
valor 5 ocurre lo contrario: En el subtitulado \(A\) son más probables
en el periodo 1 (secuencia \(AB\)) que el 2 (secuencia \(BA\)).

\begin{figure}[h]

{\centering \includegraphics{43-Modelado_files/figure-pdf/fig-predictive-2-1.pdf}

}

\caption{\label{fig-predictive-2}Muestreo de la esperanza de la función
predictiva a posteriori por tratamiento, periodo y pregunta del modelo
Response \textasciitilde{} Treat * Period + (1 + Treat \textbar{}
Subject) + (1 + Treat \textbar{} Question).}

\end{figure}

Analizados los efectos periodo y secuencia, y sabiendo que son de
pequeña magnitud, pasamos ahora a hacer un análisis de las predicciones
que realiza el modelo sobre la distribución de respuestas en cada
pregunta. Para ello en la Figura~\ref{fig-pred-3} se representan 50
muestras de la esperanza de la distribución predictiva a posteriori para
cada pregunta y nivel de subtitulado marginalizadas por periodo y
estudiante. La primera conclusión que podemos extraer es que el modelo
tiene bastante incertidumbre sobre los valores de respuesta a cada
pregunta no superando casi nunca el 50\% de probabilidad para todas las
preguntas y niveles de tratamiento. En general se observa en la mayoría
de las preguntas del nivel de subtitulado \(A\) que los alumnos están
bastante seguros de que la respuesta a las preguntas debe ser 4 ó 5,
asignando una muy baja probabilidad a los valores 1, 2, ó 3, pero
habiendo bastante confusión respecto cuál de los dos valores (4 ó 5)
asignar. Enel nivel de subtitulado \(B\) la situación es bastante más
confusa. Aunque la opción de respuesta preferida es 4 y las menos
preferidas son la 5 y la 1, hay bastante mezcla entre las opciones de
respuesta 4, 2 y 3. En cuanto al análisis individualizado por pregunta
podemos extraer las siguientes conclusiones:

\begin{itemize}
\item
  En las preguntas \(Q04\) y \(Q13\) los estudiantes no aprecian
  defectos en el subtitulado ni diferencias entre un nivel y otro. Son
  valoradas en ambos niveles con puntuaciones de 4 y de 5.
\item
  En las preguntas \(Q15\), \(Q16\) y \(Q17\), la opción de respuesta
  más probable es 4 en ambos subtitulados. El modelo asigna una baja
  probabilidad de respuesta a la opción 1 y similares al resto. La
  probabilidad de la opción 5 decrece ligeramente entre subtitulado
  \(A\) y \(B\) y lo contrario ocurre con las opciones 2 y 3.
\item
  Las preguntas \(Q01\), \(Q02\), \(Q03\), \(Q10\), \(Q11\) y \(Q12\)
  son similares a las anteriores. Particularmente en lo referente a que
  la respuesta más probable en el subtitulado \(B\) es 4. En el
  subtitulado \(A\) hay preferencia por 4 y 5. El nivel 5 cae
  acusadamente en el subtitulado \(B\) y en este nivel aumenta
  ligeramente la probabilidad de respuesta 2 y 3.
\item
  Las Preguntas \(Q06\), \(Q07\), \(Q14\) y \(Q18\) no son muy
  diferentes de las anteriores. En general el modelo predice mayor
  probabilidad de respuesta para 5 en el subtitulado \(A\) pero este
  valor es con alta probabilidad cercano cero en el subtitulado \(B\).
  En el subtitulado \(B\) la probabilidad de respuesta 2, 3 ó 4 es
  similar.
\item
  Las preguntas \(Q05\), \(Q08\) y \(Q09\) son las que más diferencia
  entre subtitulados presentan. La respuesta más probable en el
  subtitulado \(A\) es 5 (en \(Q08\) y en \(Q09\) muy parecida a 4). Por
  contra, en el subtitulado \(B\) las respuestas 4 y 5 tienden a cero,
  siendo la más probable la respuesta 2. En \(Q05\) y en \(Q09\) la
  segunda respuesta más probable al subtitulado \(B\) es 1 y 4 en la
  \(Q08\).
\end{itemize}

En definitiva, nuestro modelo predice que los estudiantes están bastante
de acuerdo en que en las preguntas \(Q05\) y \(Q09\) hay una diferencia
de calidad en los subtitulados. También están de acuerdo en que en las
preguntas \(Q04\) y \(Q13\) no hay apenas cambio entre los subtitulados.
En las preguntas \(Q15\), \(Q16\) y \(Q17\) hay una gran confusión en
ambos niveles de subtitulado y en el resto la confusión se circunscribe
al nivel de subtitulado \(B\).

\begin{figure}[h]

{\centering \includegraphics[width=1\textwidth,height=\textheight]{images/bayes-preg.png}

}

\caption{\label{fig-pred-3}Muestreo de la función predictiva a
posteriori por tratamiento y pregunta del modelo Response
\textasciitilde{} Treat * Period + (1 + Treat \textbar{} Subject) + (1 +
Treat \textbar{} Question).}

\end{figure}

\bookmarksetup{startatroot}

\hypertarget{resultados}{%
\chapter{Resultados}\label{resultados}}

\bookmarksetup{startatroot}

\hypertarget{conclusiones}{%
\chapter{Conclusiones y trabajo futuro}\label{conclusiones}}

\bookmarksetup{startatroot}

\hypertarget{referencias}{%
\chapter*{Referencias}\label{referencias}}
\addcontentsline{toc}{chapter}{Referencias}

\markboth{Referencias}{Referencias}

\printbibliography[heading=none]

\cleardoublepage
\phantomsection
\addcontentsline{toc}{part}{Apéndices}
\appendix

\hypertarget{sec-preprocess}{%
\chapter{Preprocesado de los ficheros
suministrados.}\label{sec-preprocess}}

Este es el código en R con el que se transforman los ficheros que se
suministran (ver Sección~\ref{sec-diseno}).

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(purrr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(magrittr)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(forcats)}
\FunctionTok{library}\NormalTok{(testit)}
\FunctionTok{library}\NormalTok{(tidyr)}

\DocumentationTok{\#\#\#\#\# GRADE \#\#\#\#\#}
\DocumentationTok{\#\# Usuarios que no quieren participar}
\NormalTok{no\_want\_users }\OtherTok{\textless{}{-}} \FunctionTok{read\_lines}\NormalTok{(}\StringTok{"data/original/ids\_a\_eliminar.txt"}\NormalTok{)}

\CommentTok{\# Leemos todos los archivos de grade CSV}
\NormalTok{grade\_files }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}
    \StringTok{"data/original"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{".*grade.*.csv"}\NormalTok{, }\AttributeTok{full.names =} \ConstantTok{TRUE}
\NormalTok{)}

\NormalTok{grade\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(}
\NormalTok{    grade\_files, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{read\_delim}\NormalTok{(.x, }\AttributeTok{delim =} \StringTok{";"}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
        \CommentTok{\# Añadimos el número de fila para mantener la trazabilidad}
        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Userid =} \FunctionTok{row\_number}\NormalTok{() }\SpecialCharTok{+} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
        \CommentTok{\# Movemos las columnas de identificación de fila a la primera posición}
        \FunctionTok{relocate}\NormalTok{(Userid, }\AttributeTok{.before =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
        \CommentTok{\# Renombramos las columnas para que empiecen con mayúsculas}
        \FunctionTok{rename\_with}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \FunctionTok{str\_to\_title}\NormalTok{(.), }\FunctionTok{everything}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
        \CommentTok{\# Renombramos para que sea más fácil procesar el campo Cohort Name}
        \FunctionTok{rename}\NormalTok{(}\StringTok{"Cohort"} \OtherTok{=} \StringTok{"Cohort Name"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
        \CommentTok{\# Eliminamos valores nulos y los que no quieren participar}
        \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(Cohort) }\SpecialCharTok{\&} \SpecialCharTok{!}\NormalTok{Username }\SpecialCharTok{\%in\%}\NormalTok{ no\_want\_users) }
\NormalTok{)}

\FunctionTok{assert}\NormalTok{(}\StringTok{"Comprobamos que no hay usuarios duplicados"}\NormalTok{, grade\_df }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{nrow}\NormalTok{() }\SpecialCharTok{==}\NormalTok{ grade\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{distinct}\NormalTok{(Username) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{nrow}\NormalTok{())}

\CommentTok{\# Creamos un tibble que tiene un campo con letras en lugar del valor de Cohorte}
\NormalTok{(groups }\OtherTok{\textless{}{-}}\NormalTok{ grade\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{distinct}\NormalTok{(Cohort) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(Cohort) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Group =}\NormalTok{ LETTERS[}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{n}\NormalTok{()]))}

\CommentTok{\# Unimos los tibbles para asignar en grupo como letra en lugar de la cohorte}
\NormalTok{grade\_df }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(grade\_df, groups) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(Username, Userid, Group)}

\DocumentationTok{\#\#\#\#\# PROFILE \#\#\#\#\#}
\NormalTok{profile\_files }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}
    \StringTok{"data/original"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{".*student\_profile.*.csv"}\NormalTok{, }\AttributeTok{full.names =} \ConstantTok{TRUE}
\NormalTok{)}

\NormalTok{profile\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(}
\NormalTok{    profile\_files, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{read\_delim}\NormalTok{(.x, }\AttributeTok{delim =} \StringTok{";"}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{)}

\NormalTok{grade\_df }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    grade\_df, profile\_df }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cohort), }\AttributeTok{by =} \FunctionTok{join\_by}\NormalTok{(Username }\SpecialCharTok{==}\NormalTok{ username)}
\NormalTok{)}


\DocumentationTok{\#\#\#\#\# CONOC \#\#\#\#\#}
\NormalTok{conoc\_files }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}
    \StringTok{"data/original"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{".*conoc.*.csv"}\NormalTok{, }\AttributeTok{full.names =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{conoc\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(}
\NormalTok{    conoc\_files, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{read\_delim}\NormalTok{(.x, }\AttributeTok{delim =} \StringTok{";"}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{)}

\NormalTok{conoc\_df }\OtherTok{\textless{}{-}}\NormalTok{ conoc\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(Tries }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
        \AttributeTok{level\_of\_knowledge =} 
            \FunctionTok{sum}\NormalTok{(}\FunctionTok{c\_across}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Q"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\StringTok{"C"}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}\NormalTok{))) }\SpecialCharTok{==} \StringTok{"correct"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(User, level\_of\_knowledge)}

\NormalTok{grade\_df }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(grade\_df, conoc\_df, }\AttributeTok{by =} \FunctionTok{join\_by}\NormalTok{(Username }\SpecialCharTok{==}\NormalTok{ User))}

\DocumentationTok{\#\#\#\#\# }\AlertTok{TEST}\DocumentationTok{ \#\#\#\#\#}
\CommentTok{\# Leemos todos los archivos de test CSV}
\NormalTok{test\_files }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}
    \StringTok{"data/original"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{".*test.*.csv"}\NormalTok{, }\AttributeTok{full.names =} \ConstantTok{TRUE}
\NormalTok{)}

\CommentTok{\# Leer todos los archivos de test y los combinamos en un dataframe}
\NormalTok{test\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(}
\NormalTok{    test\_files, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{read\_delim}\NormalTok{(.x, }\AttributeTok{delim =} \StringTok{";"}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
        \CommentTok{\# Añadimos un número de fila para mantener la trazabilidad}
        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Row =} \FunctionTok{row\_number}\NormalTok{() }\SpecialCharTok{+} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
        \CommentTok{\# Añadimos la columna del número de test}
        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Test =} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"\%02d"}\NormalTok{, }\FunctionTok{as.integer}\NormalTok{(}\FunctionTok{str\_extract}\NormalTok{(.x, }\StringTok{"(?\textless{}=test)}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+"}\NormalTok{)))) }\SpecialCharTok{\%\textgreater{}\%}
        \CommentTok{\# Movemos las columnas de identificación de test y fila a la primera posición}
        \FunctionTok{relocate}\NormalTok{(}\FunctionTok{c}\NormalTok{(Test, Row), }\AttributeTok{.before =} \DecValTok{2}\NormalTok{) }
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \CommentTok{\# eliminamos los usuarios que no quieren participar}
    \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\NormalTok{User }\SpecialCharTok{\%in\%}\NormalTok{ no\_want\_users) }

\NormalTok{num\_questions }\OtherTok{\textless{}{-}} \DecValTok{18}

\CommentTok{\# Nombre de los campos que contienen las respuestas al test}
\NormalTok{questions\_original }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}
    \StringTok{"Q"}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ num\_questions), }\StringTok{"R"}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}
\NormalTok{) }

\CommentTok{\# Nombre de los campos que contienen las respuestas al test}
\NormalTok{comments\_original }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}
    \StringTok{"Q"}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{2}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ num\_questions }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{), }\StringTok{"R"}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}
\NormalTok{) }

\CommentTok{\# Nombre de los campos que se usarán para renombrar los campos de respuesta al test}
\NormalTok{questions }\OtherTok{\textless{}{-}} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"Q\%02d"}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ num\_questions)) }
\NormalTok{comments }\OtherTok{\textless{}{-}} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"C\%02d"}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{by =} \DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ num\_questions }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{columns }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
    \StringTok{"Row"}\NormalTok{, }\StringTok{"Test"}\NormalTok{, }\StringTok{"User"}\NormalTok{, }\StringTok{"LastTry"}\NormalTok{, questions\_original, comments\_original}
\NormalTok{)}

\CommentTok{\# Procesamos el dataframe}
\CommentTok{\# Con este operador del paquete magrittr hacemos las transformaciones in situ}
\NormalTok{test\_df }\SpecialCharTok{\%\textless{}\textgreater{}\%} 
    \CommentTok{\# Eliminamos las filas que no contienen información}
    \FunctionTok{filter}\NormalTok{(Tries }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
    \CommentTok{\# Convertimos LastTry a formato fecha}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{LastTry =} \FunctionTok{strptime}\NormalTok{(LastTry, }\AttributeTok{format =} \StringTok{"\%Y{-}\%m{-}\%dT\%H:\%M:\%SZ"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
    \CommentTok{\# Seleccionamos las columnas que nos interesan}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\FunctionTok{all\_of}\NormalTok{(columns)) }\SpecialCharTok{\%\textgreater{}\%} 
    \CommentTok{\# Extraemos la puntuación numérica de la pregunta}
    \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(questions\_original, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{if\_else}\NormalTok{(}
        \FunctionTok{startsWith}\NormalTok{(.x, }\StringTok{"choice\_"}\NormalTok{), }\FunctionTok{as.integer}\NormalTok{(}\FunctionTok{str\_extract}\NormalTok{(.x, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+"}\NormalTok{)), }\ConstantTok{NA\_integer\_}\NormalTok{)}
\NormalTok{    )) }\SpecialCharTok{\%\textgreater{}\%}
    \CommentTok{\# Renombramos los respuestas para que sean secuenciales}
    \FunctionTok{rename}\NormalTok{(}
        \FunctionTok{setNames}\NormalTok{(questions\_original, questions),}
        \FunctionTok{setNames}\NormalTok{(comments\_original, comments)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \CommentTok{\# nos aseguramos de que el orden filas es el mismo que el de los ficheros.}
    \FunctionTok{arrange}\NormalTok{(}\StringTok{"Test"}\NormalTok{, }\StringTok{"Row"}\NormalTok{) }

\CommentTok{\# Guardamos el número de filas para posterior comprobación}
\NormalTok{n\_test }\OtherTok{\textless{}{-}}\NormalTok{ test\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{nrow}\NormalTok{()}

\CommentTok{\# Unimos los dataframes para tener el grupo y el UserID secuencial}
\NormalTok{test\_df }\OtherTok{\textless{}{-}} \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{    test\_df, grade\_df, }\AttributeTok{by =} \FunctionTok{join\_by}\NormalTok{(User }\SpecialCharTok{==}\NormalTok{ Username)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{relocate}\NormalTok{(Group, }\AttributeTok{.before =} \DecValTok{2}\NormalTok{)}

\CommentTok{\# Cambiamos los valores del campo User por los del UserID}
\NormalTok{test\_df }\SpecialCharTok{\%\textless{}\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{User =}\NormalTok{ Userid) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Userid) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(User, Test) }\CommentTok{\# Ordenamos por usuario y test}


\DocumentationTok{\#\#\#\#\# CHECKS \#\#\#\#\#}
\FunctionTok{assert}\NormalTok{(}
    \StringTok{"Comprobamos que no hay preguntas duplicadas en el dataframe de test"}\NormalTok{,}
\NormalTok{    n\_test }\SpecialCharTok{==}\NormalTok{ test\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{distinct}\NormalTok{(Group, Test, User) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{nrow}\NormalTok{()}
\NormalTok{)}

\FunctionTok{assert}\NormalTok{(}
    \StringTok{"Comprobamos que no hay valores nulos"}\NormalTok{,}
\NormalTok{    test\_df }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}
        \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(comments, year\_of\_birth, gender, level\_of\_education, level\_of\_knowledge)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(}\FunctionTok{if\_any}\NormalTok{(}\FunctionTok{everything}\NormalTok{(), is.na)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{nrow}\NormalTok{() }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}


\FunctionTok{assert}\NormalTok{(}
    \StringTok{"Comprobamos que no hay respuestas con valores incorrectos"}\NormalTok{,}
    \FunctionTok{sum}\NormalTok{(}\FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(}
\NormalTok{        test\_df }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\FunctionTok{all\_of}\NormalTok{(questions))}
\NormalTok{    ))) }\SpecialCharTok{==} \DecValTok{0}\SpecialCharTok{:}\DecValTok{5}\NormalTok{) }\SpecialCharTok{==} \DecValTok{6}\NormalTok{)}


\NormalTok{comments\_df }\OtherTok{\textless{}{-}}\NormalTok{ test\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pivot\_longer}\NormalTok{(}
        \AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Q"}\NormalTok{, }\StringTok{"C"}\NormalTok{)),}
        \AttributeTok{names\_to =} \FunctionTok{c}\NormalTok{(}\StringTok{".value"}\NormalTok{, }\StringTok{"Question"}\NormalTok{),}
        \AttributeTok{names\_pattern =} \StringTok{"(Q|C)(.*)"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{Response =}\NormalTok{ Q, }\AttributeTok{Comment =}\NormalTok{ C) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(Comment) }\SpecialCharTok{\&} \FunctionTok{grepl}\NormalTok{(}\StringTok{"[a{-}zA{-}Z]"}\NormalTok{, Comment)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(Test, Row, Group, User, Question, Response, Comment) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(Test, Group, Response, Row)}


\FunctionTok{write\_csv}\NormalTok{(comments\_df, }\StringTok{"./data/preprocess/comments.csv"}\NormalTok{)}

\DocumentationTok{\#\#\#\#\# SAVE TO FILE \#\#\#\#\#}
\FunctionTok{write\_csv}\NormalTok{(}
\NormalTok{    test\_df }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{all\_of}\NormalTok{(comments)), }\StringTok{"./data/preprocess/test\_all.csv"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{sec-setup}{%
\chapter{\texorpdfstring{Creación de los \texttt{dataframes\ df\_all} y
\texttt{df\_clean}.}{Creación de los dataframes df\_all y df\_clean.}}\label{sec-setup}}

Código que transforma los datos preprocesados (ver
Apéndice~\ref{sec-preprocess}) en los \texttt{dataframes} que se usan en
el análisis estadístico.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Leemos el tibble preprocesado}
\NormalTok{test\_all\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_delim}\NormalTok{(}
    \StringTok{"./data/preprocess/test\_all.csv"}\NormalTok{,}
    \AttributeTok{delim =} \StringTok{","}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}
\NormalTok{)}

\CommentTok{\# Eliminamos aquellos usuarios que no han hecho uno de los test}
\NormalTok{test\_df }\OtherTok{\textless{}{-}}\NormalTok{ test\_all\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(User) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Rows =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(Rows }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{()}

\DocumentationTok{\#\#\#\#\# SAVE TO FILE \#\#\#\#\#}
\FunctionTok{write\_csv}\NormalTok{(test\_df, }\StringTok{"./data/preprocess/test.csv"}\NormalTok{)}

\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ test\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
        \AttributeTok{Period =} \FunctionTok{as.factor}\NormalTok{(}
            \FunctionTok{if\_else}\NormalTok{(Test }\SpecialCharTok{==} \StringTok{"01"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{        ),}
        \AttributeTok{Treat =} \FunctionTok{as.factor}\NormalTok{(}
            \FunctionTok{if\_else}\NormalTok{(Group }\SpecialCharTok{==} \StringTok{"A"} \SpecialCharTok{\&}\NormalTok{ Test }\SpecialCharTok{==} \StringTok{"01"} \SpecialCharTok{|}\NormalTok{ Group }\SpecialCharTok{==} \StringTok{"B"} \SpecialCharTok{\&}\NormalTok{ Test }\SpecialCharTok{==} \StringTok{"02"}\NormalTok{, }\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{)}
\NormalTok{        ),}
        \AttributeTok{Seq =} \FunctionTok{as.factor}\NormalTok{(}
            \FunctionTok{if\_else}\NormalTok{(Group }\SpecialCharTok{==} \StringTok{"A"}\NormalTok{, }\StringTok{"AB"}\NormalTok{, }\StringTok{"BA"}\NormalTok{)}
\NormalTok{        ),}
        \AttributeTok{Subject =} \FunctionTok{as.factor}\NormalTok{(User)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}
\NormalTok{        Seq, Period, Treat, Subject,}
\NormalTok{        gender, year\_of\_birth, level\_of\_education, }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"Q"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate\_at}\NormalTok{(}
        \FunctionTok{vars}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"Q"}\NormalTok{)), }\SpecialCharTok{\textasciitilde{}}\NormalTok{ (. }\SpecialCharTok{+} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\%} \DecValTok{6}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pivot\_longer}\NormalTok{(}
        \AttributeTok{cols =} \FunctionTok{all\_of}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"Q"}\NormalTok{)),}
        \AttributeTok{names\_to =} \StringTok{"Question"}\NormalTok{,}
        \AttributeTok{values\_to =} \StringTok{"Response"}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
        \AttributeTok{Question =} \FunctionTok{relevel}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(Question), }\AttributeTok{ref =} \StringTok{"Q18"}\NormalTok{),}
        \AttributeTok{Response =} \FunctionTok{factor}\NormalTok{(Response, }\AttributeTok{ordered =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(Subject, Period, Question)}

\NormalTok{response\_labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
    \StringTok{"No sé / No contesto"}\NormalTok{,}
    \StringTok{"Muy en desacuerdo"}\NormalTok{,}
    \StringTok{"En desacuerdo"}\NormalTok{,}
    \StringTok{"Neutral"}\NormalTok{,}
    \StringTok{"De acuerdo"}\NormalTok{,}
    \StringTok{"Muy de acuerdo"}
\NormalTok{)}

\NormalTok{question\_labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
    \StringTok{"Los subtítulos del vídeo cumplen en general con los requisitos de accesibilidad."}\NormalTok{,}
    \StringTok{"La posición de los subtítulos."}\NormalTok{,}
    \StringTok{"El número de líneas por subtítulo."}\NormalTok{,}
    \StringTok{"La disposición del texto respecto a la caja donde se muestran los subtítulos."}\NormalTok{,}
    \StringTok{"El contraste entre los caracteres y el fondo."}\NormalTok{,}
    \StringTok{"La corrección ortográfica y gramatical."}\NormalTok{,}
    \StringTok{"La literalidad."}\NormalTok{,}
    \StringTok{"La identificación de los personajes."}\NormalTok{,}
    \StringTok{"La asignación de líneas a los personajes en los diálogos."}\NormalTok{,}
    \StringTok{"La descripción de efectos sonoros."}\NormalTok{,}
    \StringTok{"La sincronización de las entradas y salidas de los subtítulos."}\NormalTok{,}
    \StringTok{"La velocidad de exposición de los subtítulos."}\NormalTok{,}
    \StringTok{"El máximo número de caracteres por línea."}\NormalTok{,}
    \StringTok{"La legibilidad de la tipografía."}\NormalTok{,}
    \StringTok{"La separación en líneas diferentes de sintagmas nominales, verbales y preposicionales."}\NormalTok{,}
    \StringTok{"La utilización de puntos suspensivos."}\NormalTok{,}
    \StringTok{"La escritura de los números."}\NormalTok{,}
    \StringTok{"Las incorrecciones en el habla."}
\NormalTok{)}

\NormalTok{question\_labels\_reduced }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
    \StringTok{"Valoración general"}\NormalTok{,}
    \StringTok{"Posición"}\NormalTok{,}
    \StringTok{"Número líneas"}\NormalTok{,}
    \StringTok{"Texto dentro caja"}\NormalTok{,}
    \StringTok{"Contraste"}\NormalTok{,}
    \StringTok{"Corrección"}\NormalTok{,}
    \StringTok{"Literalidad"}\NormalTok{,}
    \StringTok{"Identificación personajes"}\NormalTok{,}
    \StringTok{"Líneas/personajes"}\NormalTok{,}
    \StringTok{"Efectos sonoros"}\NormalTok{,}
    \StringTok{"Sincronización"}\NormalTok{,}
    \StringTok{"Velocidad"}\NormalTok{,}
    \StringTok{"Caracteres x línea"}\NormalTok{,}
    \StringTok{"Tipografía"}\NormalTok{,}
    \StringTok{"Separación sintagmas"}\NormalTok{,}
    \StringTok{"Puntos suspensivos"}\NormalTok{,}
    \StringTok{"Escritura números"}\NormalTok{,}
    \StringTok{"Incorrecciones habla"}
\NormalTok{)}

\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{Response\_v =} \FunctionTok{as.numeric}\NormalTok{(Response) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{,}
    \AttributeTok{Response\_l =} \FunctionTok{ordered}\NormalTok{(Response\_v, }\AttributeTok{labels =}\NormalTok{ response\_labels),}
    \AttributeTok{Question\_l =} \FunctionTok{factor}\NormalTok{(Question, }\AttributeTok{labels =}\NormalTok{ question\_labels),}
    \AttributeTok{Question\_lr =} \FunctionTok{factor}\NormalTok{(Question, }\AttributeTok{labels =}\NormalTok{ question\_labels\_reduced)}
\NormalTok{)}

\NormalTok{dist }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Question }\SpecialCharTok{+}\NormalTok{ Response, }\AttributeTok{data =}\NormalTok{ .) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{dist}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"euclidean"}\NormalTok{)}

\NormalTok{cluster }\OtherTok{\textless{}{-}} \FunctionTok{hclust}\NormalTok{(dist, }\AttributeTok{method =} \StringTok{"complete"}\NormalTok{)}
\NormalTok{cuts }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{cutree}\NormalTok{(cluster, }\AttributeTok{k =} \DecValTok{3}\NormalTok{))}

\CommentTok{\# Añadimos la columna cluster al dataframe}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{    df,}
    \FunctionTok{data.frame}\NormalTok{(}
        \AttributeTok{Question =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{names}\NormalTok{(cuts),}
            \AttributeTok{levels =} \FunctionTok{levels}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Question)}
\NormalTok{        ),}
        \AttributeTok{Cluster =} \FunctionTok{as.factor}\NormalTok{(cuts)}
\NormalTok{    ),}
    \AttributeTok{by =} \StringTok{"Question"}
\NormalTok{)}

\FunctionTok{write\_csv}\NormalTok{(df, }\StringTok{"./data/preprocess/test\_lg.csv"}\NormalTok{)}
\NormalTok{df\_all }\OtherTok{\textless{}{-}}\NormalTok{ df}

\NormalTok{df\_all}\SpecialCharTok{$}\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Response }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df\_all)}

\NormalTok{df\_clean }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(Response }\SpecialCharTok{!=} \DecValTok{0}\NormalTok{)}
\NormalTok{df\_clean }\OtherTok{\textless{}{-}}\NormalTok{ df\_clean }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{Response =} \FunctionTok{factor}\NormalTok{(Response, }\AttributeTok{levels =} \FunctionTok{levels}\NormalTok{(Response)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]),}
    \AttributeTok{Response\_l =} \FunctionTok{ordered}\NormalTok{(Response\_l, }\AttributeTok{levels =} \FunctionTok{levels}\NormalTok{(Response\_l)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]),}
    \AttributeTok{Level =} \FunctionTok{as.ordered}\NormalTok{(}
        \FunctionTok{ifelse}\NormalTok{(}
\NormalTok{            Response }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{),}
            \StringTok{"Negative"}\NormalTok{,}
            \FunctionTok{ifelse}\NormalTok{(}
\NormalTok{                Response }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{),}
                \StringTok{"Positive"}\NormalTok{,}
                \StringTok{"Neutral"}
\NormalTok{            )}
\NormalTok{        )}
\NormalTok{    )}
\NormalTok{)}
\NormalTok{df\_0 }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(Response }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{sec-contrasts}{%
\chapter{Efecto secuencia e interacción tratamiento
vs.~periodo.}\label{sec-contrasts}}

Vamos a demostrar que el efecto secuencia es equivalente a la
interacción de los factores tratamiento y periodo.

\hypertarget{preparaciuxf3n.}{%
\section{Preparación.}\label{preparaciuxf3n.}}

Partimos del siguiente conjunto de datos generado aleatoriamente
\footnote{Obsérvese que se la variable \texttt{Response} en esta
  simulación es cuantitativa y no ordinal. Se ha realizado de esta forma
  para poder usar un ajuste de mínimos cuadrados en lugar de una
  regresión ordinal para facilitar el cálculo y su interpretación.}:
\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{Response =} \FunctionTok{rnorm}\NormalTok{(n),}
    \AttributeTok{Treat =} \FunctionTok{as.factor}\NormalTok{(}\FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)),}
    \AttributeTok{Period =} \FunctionTok{as.factor}\NormalTok{(}\FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{)}

\NormalTok{df}\SpecialCharTok{$}\NormalTok{Seq }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(}
    \FunctionTok{ifelse}\NormalTok{(}
\NormalTok{        df}\SpecialCharTok{$}\NormalTok{Period }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Treat }\SpecialCharTok{==} \StringTok{"A"} \SpecialCharTok{|}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Period }\SpecialCharTok{==} \DecValTok{2} \SpecialCharTok{\&}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Treat }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{,}
        \StringTok{"AB"}\NormalTok{,}
        \StringTok{"BA"}
\NormalTok{    )}
\NormalTok{)}

\FunctionTok{head}\NormalTok{(df, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      Response Treat Period Seq
1  -0.50219235     B      2  AB
2   0.13153117     A      1  AB
3  -0.07891709     A      2  BA
4   0.88678481     A      2  BA
5   0.11697127     A      1  AB
6   0.31863009     A      2  BA
7  -0.58179068     A      2  BA
8   0.71453271     A      1  AB
9  -0.82525943     B      2  AB
10 -0.35986213     B      1  BA
\end{verbatim}

\normalsize

Calculamos las medias por cada nivel de factor y combinaciones de
niveles que utilizaremos luego en la interpretación de los coeficientes
de los modelos

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Response) }\CommentTok{\# 1 media de respuesta global}

\CommentTok{\# 2 medias de respuesta para tratamientos A y B}
\NormalTok{mTreat }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, Treat, mean))}

\CommentTok{\# 2 medias de respuesta para periodos 1 y 2}
\NormalTok{mPeriod }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, Period, mean))}

\CommentTok{\# 2 medias de respuesta para secuencias AB y BA}
\NormalTok{mSeq }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, Seq, mean))}

\CommentTok{\# 4 medias de respuesta para las cuatro combinaciones de tratamiento y periodo}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(df, }\FunctionTok{tapply}\NormalTok{(Response, }\FunctionTok{list}\NormalTok{(Treat, Period), mean))}

\NormalTok{dTreat }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(mTreat) }\CommentTok{\# diferencia de medias entre tratamientos A y B}

\NormalTok{dPeriod }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(mPeriod) }\CommentTok{\# diferencia de medias entre periodos 1 y 2}

\NormalTok{d2 }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(m2) }\CommentTok{\# diferencias entre niveles de tratamiento en cada nivel de periodo}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{anuxe1lisis-con-un-solo-factor-tratamiento.}{%
\section{Análisis con un solo factor
(tratamiento).}\label{anuxe1lisis-con-un-solo-factor-tratamiento.}}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l1))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l1}{}
\begin{longtable}{rr}
\caption{\label{tbl-l1}Ajuste del modelo Response \textasciitilde{} Treat con contrasts
treatment. }\tabularnewline

\toprule
X.Intercept. & TreatB \\ 
\midrule
0.03624217 & -0.03966751 \\ 
\bottomrule
\end{longtable}

\normalsize

Vemos que el intercepto es la media de la respuesta en el nivel de
tratamiento \(A\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mTreat[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         A 
0.03624217 
\end{verbatim}

\normalsize

Que la pendiente (parámetro \(TreatB\)) es la diferencia entre las
medias tratamientos:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dTreat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          B 
-0.03966751 
\end{verbatim}

\normalsize

Por ello, para conocer el efecto del tratamiento en el nivel \(B\) hay
que sumar intercepto y pendiente:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(l1)[[}\DecValTok{1}\NormalTok{]] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(l1)[[}\DecValTok{2}\NormalTok{]] }\SpecialCharTok{{-}}\NormalTok{ mTreat[[}\DecValTok{2}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.214306e-16
\end{verbatim}

\normalsize

Esto es así ya que por defecto R utiliza el contraste conocido como
\texttt{codificación\ de\ tratamiento}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{contr.treatment}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  2
1 0
2 1
\end{verbatim}

\normalsize

Podemos ver la matriz ampliada añadiendo el intercepto, que siempre será
una columna de 1's:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{Treat, }\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{Treat =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) TreatB
1           1      0
2           1      1
attr(,"assign")
[1] 0 1
attr(,"contrasts")
attr(,"contrasts")$Treat
[1] "contr.treatment"
\end{verbatim}

\normalsize

Cada fila representa el nivel del tratamiento (fila 1 nivel \(A\) y fila
2 nivel \(B\)) y las columnas representan los parámetros del modelo. Los
valores son los niveles de tratamiento (0 ó 1). Para obtener el
significado de cada parámetro, multiplicamos el valor del contraste por
el parámetro. Así:

\begin{itemize}
\tightlist
\item
  De la primera fila obtenemos que el efecto del tratamiento \(A\) es el
  intercepto: \(A = 1 \cdot Intercept + 0 \cdot TreatB\).
\item
  De la segunda fila obtenemos que el valor del parámetro \(TreatB\) es
  la diferencia de los niveles de tratamiento.
  \(B = 1 \cdot Intercept + 1 \cdot TreatB \Rightarrow TreatB = B - Intercept\).
\end{itemize}

Esto quiere decir que existe una variable para codificar el efecto
tratamiento, y esta variable tiene el valor 0 para el nivel \(A\) por
ser el de referencia y 1 para el nivel \(B\). La pendiente se codifica
como la diferencia del efecto de los dos niveles (\(B - A\)).

\hypertarget{anuxe1lisis-con-un-dos-factores-tratamiento-y-periodo.}{%
\section{Análisis con un dos factores (tratamiento y
periodo).}\label{anuxe1lisis-con-un-dos-factores-tratamiento-y-periodo.}}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l2))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l2}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l2}Ajuste del modelo Response \textasciitilde{} Treat * Period con
contrasts treatment. }\tabularnewline

\toprule
X.Intercept. & TreatB & Period2 & TreatB.Period2 \\ 
\midrule
0.04138614 & -0.1076137 & -0.01125933 & 0.1343517 \\ 
\bottomrule
\end{longtable}

\normalsize

Vemos que el intercepto es la media del tratamiento \(A\) en el periodo
\(1\) por ser estos los valores que R usa como referencia \footnote{R
  utiliza como valor de referencia el nivel más bajo de factor.}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.04138614
\end{verbatim}

\normalsize

El parámetro \(TreatB\) es la diferencia de medias entre los
tratamientos en el periodo \(1\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.1076137
\end{verbatim}

\normalsize

El parámetro \(Period2\) es la diferencia de medias entre los periodos
en el nivel de tratamiento \(A\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.01125933
\end{verbatim}

\normalsize

Finalmente, \(TreatB:Period2\) es la diferencia entre el segundo periodo
y el primero del nivel de tratamiento \(B\) menos la diferencia entre
periodos del nivel de tratamiento \(A\):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1343517
\end{verbatim}

\normalsize

La matriz de contraste nos permite razonar por qué esto es así:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, }\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{Treat =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\AttributeTok{Period =} \FunctionTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"2"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) TreatB Period2 TreatB:Period2
1           1      0       0              0
2           1      1       0              0
3           1      0       1              0
4           1      1       1              1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$Treat
[1] "contr.treatment"

attr(,"contrasts")$Period
[1] "contr.treatment"
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  La primera fila es el intercepto y corresponde con el tratamiento
  \(A\) y el periodo 1.
\item
  La segunda fila es el efecto del tratamiento \(B\) en el periodo 1 y
  se calcula con la suma del intercepto y el parámetro \(TreatB\). Luego
  \(TreatB\) es la diferencia del efecto de los tratamientos en el
  periodo 1.
\item
  Análogamente con la tercera fila concluimos que \(Period2\) es la
  deferencia entre periodos para el tratamiento \(A\).
\item
  Finalmente, la cuarta fila, es el tratamiento \(B\) en el periodo 2 y,
  por lo tanto, \(Treat2:Period2\) es la diferencia el nivel \(B\) de
  tratamiento y el periodo 2 y el nivel de tratamiento \(A\) en el
  periodo 1, menos la diferencia de niveles de tratamiento para el
  periodo 1 y menos la diferencia de periodos para el tratamiento \(A\).
\end{itemize}

Obsérvese que antes hemos calculado de forma diferente
\(TreatB:Period2\). Podemos aplicar la fórmula anterior y comprobar que
produce el mismo resultado:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{]) }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1343517
\end{verbatim}

\normalsize

\hypertarget{factor-secuencia.}{%
\section{Factor secuencia.}\label{factor-secuencia.}}

Vamos a incorporar la secuencia como factor para ver si es equivalente a
la interacción entre periodo y tratamiento. En caso de serlo los
coeficientes del modelo ajustado deberían coincidir. Sin embargo vemos
que los modelos l2 (Tabla~\ref{tbl-l2}) y l3 (Tabla~\ref{tbl-l3}) tienen
distintos coeficientes.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l3))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l3}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l3}Ajuste del modelo Response \textasciitilde{} Treat + Period + Seq con
contrasts treatment. }\tabularnewline

\toprule
X.Intercept. & TreatB & Period2 & SeqBA \\ 
\midrule
0.04138614 & -0.04043786 & 0.05591654 & -0.06717587 \\ 
\bottomrule
\end{longtable}

\normalsize

Los coeficientes no coinciden debido a que estamos usando el contraste
con \texttt{codificación\ de\ tratamientos}. Pero si cambiamos a
\texttt{codificación\ de\ sumas}:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.sum"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\normalsize

Y volvemos a ajustar los modelos que ya usarán el
\texttt{contraste\ suma}, podemos comprobar que ahora tienen los mismos
coeficientes y el coeficiente \(Seq1\) del modelo que incorpora el
efecto secuencia (Tabla~\ref{tbl-l4}) es igual que el coeficiente
\(Treat1:Period1\) del modelo que incorpora la interacción entre
tratamiento y periodo (Tabla~\ref{tbl-l5}). Obsérvese que los nombres de
los coeficientes han cambiado respecto al
\texttt{contraste\ de\ tratamiento}. Esto sucede porque la
interpretación de los coeficientes varía como se explica a continuación.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ Seq, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l4))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l4}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l4}Ajuste del modelo Response \textasciitilde{} Treat + Period + Seq con
contrasts sum. }\tabularnewline

\toprule
X.Intercept. & Treat1 & Period1 & Seq1 \\ 
\midrule
0.01553755 & 0.02021893 & -0.02795827 & 0.03358794 \\ 
\bottomrule
\end{longtable}

\normalsize

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l5 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l5))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-l5}{}
\begin{longtable}{rrrr}
\caption{\label{tbl-l5}Ajuste del modelo Response \textasciitilde{} Treat * Period con
contrasts sum. }\tabularnewline

\toprule
X.Intercept. & Treat1 & Period1 & Treat1.Period1 \\ 
\midrule
0.01553755 & 0.02021893 & -0.02795827 & 0.03358794 \\ 
\bottomrule
\end{longtable}

\normalsize

La interpretación de los contrastes es diferente. Para explicarlo,
mostramos la matriz de contraste:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period, }\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{Treat =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\AttributeTok{Period =} \FunctionTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"2"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) Treat1 Period1 Treat1:Period1
1           1      1       1              1
2           1     -1       1             -1
3           1      1      -1             -1
4           1     -1      -1              1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$Treat
[1] "contr.sum"

attr(,"contrasts")$Period
[1] "contr.sum"
\end{verbatim}

\normalsize

Vemos que ahora los niveles son 1 y -1 \footnote{El nivel de referencia
  del factor tendrá valor 1 y el otro -1. Por ejemplo, en la variable
  \texttt{Treat}, \(A\) tendrá +1 y \(B\) tendrá valor -1.} en vez de 0
y 1 que se utilizan en el contraste de tratamiento. La interpretación es
la siguiente:

\begin{itemize}
\tightlist
\item
  El interceptor es la media de la media de cada uno de los niveles de
  factor. ¿Por qué?. El interceptor es el valor de la variable de
  respuesta cuando cuando todas las variables explicativas valen 0. Esto
  sucede en la media de la variable de respuesta ya que cero es el valor
  que está en la mitad de +1 y -1. Podemos comprobar que la media global
  coincide con el interceptor del modelo l4 (Tabla~\ref{tbl-l4}):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.01553755
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(Treat1\) es la mitad la diferencia de la media entre
  niveles de tratamiento (\(TreatA-TreatB\)). La media de cada
  tratamiento se calcula como la media del tratamiento en cada periodo.
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{1}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         B 
0.02021893 
\end{verbatim}

\normalsize

Otra forma de entender el coeficiente \(Treat1\) es como la cuarta parte
de la diferencia de los efectos de los tratamientos en cada periodo.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.02021893
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(Period1\) es la mitad la diferencia de la media entre
  periodos(\(Period1 - Period2\)). La media entre periodos se calcula
  como la media del periodo para cada tratamiento.
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{2}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          2 
-0.02795827 
\end{verbatim}

\normalsize

Otra forma de entender el coeficiente \(Period1\) es como la cuarta
parte de la diferencia de los efectos del periodo en cada tratamiento.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ (m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.02795827
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(Treat1:Period1\) es el coeficiente \(Treat1\) menos
  la mitad de la diferencia de la media entre tratamientos para el
  periodo 2 (\(TreatA-TreatB\)):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{1}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2} \SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[, }\StringTok{"2"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         B 
0.03358794 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(l5)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[, }\StringTok{"2"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Treat1 
0.03358794 
\end{verbatim}

\normalsize

El coeficiente \(Treat1:Period1\) también se puede calcular como
\(Period1\) menos la mitad de la diferencia de la media entre periodos
para el para el tratamiento \(B\) (\(Period1-Period2\)):

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{diff}\NormalTok{(}\FunctionTok{apply}\NormalTok{(m2, }\DecValTok{2}\NormalTok{, mean)) }\SpecialCharTok{/} \DecValTok{2} \SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[}\StringTok{"B"}\NormalTok{, ]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         2 
0.03358794 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(l5)[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{diff}\NormalTok{(m2[}\StringTok{"B"}\NormalTok{, ]) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Period1 
0.03358794 
\end{verbatim}

\normalsize

Un tercera forma de interpretar el coeficiente \(Treat1:Period1\) es
como la cuarta parte de la suma de la diferencia cruzada del efecto de
cada tratamiento en cada periodo:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.03358794
\end{verbatim}

\normalsize

O reorganizando los términos de otra forma, sería la cuarta parte de la
suma de la diferencia cruzada del efecto de cada periodo en cada
tratamiento:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"2"}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ m2[}\StringTok{"A"}\NormalTok{, }\StringTok{"1"}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ m2[}\StringTok{"B"}\NormalTok{, }\StringTok{"1"}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.03358794
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  Podemos obtener el coeficiente \(TreatB\) del modelo \(l2\)
  (Tabla~\ref{tbl-l2}) como \(-2 \cdot (Treat1 + Treat1:Period1)\):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1"}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1:Period1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Treat1 
-0.1076137 
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  Análogamente el coeficiente \(Period2\) del modelo \(l2\)
  (Tabla~\ref{tbl-l2}) se obtiene
  \(-2 \cdot (Period1 + Treat1:Period1)\):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Period1"}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1:Period1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Period1 
-0.01125933 
\end{verbatim}

\normalsize

\begin{itemize}
\tightlist
\item
  El coeficiente \(TreatB:Period2\) se obtiene como
  \(4 \cdot Treat1:Period1\):
\end{itemize}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{4} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(l5)[}\StringTok{"Treat1:Period1"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Treat1:Period1 
     0.1343517 
\end{verbatim}

\normalsize

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.treatment"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{l6 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l6))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable*}{rrr}
\toprule
X.Intercept. & TreatB & Period2 \\ 
\midrule
0.01120158 & -0.04259114 & 0.05480989 \\ 
\bottomrule
\end{longtable*}

\normalsize

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{contrasts =} \FunctionTok{rep}\NormalTok{(}\StringTok{"contr.sum"}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{l7 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ Period, df)}
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{coef}\NormalTok{(l7))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable*}{rrr}
\toprule
X.Intercept. & Treat1 & Period1 \\ 
\midrule
0.01731095 & 0.02129557 & -0.02740495 \\ 
\bottomrule
\end{longtable*}

\normalsize

\hypertarget{modelado-bayesiano.-1}{%
\chapter{Modelado Bayesiano.}\label{modelado-bayesiano.-1}}

\tiny

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_subject\_formula }\OtherTok{\textless{}{-}}\NormalTok{ Response }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject)}
\NormalTok{brm\_subject }\OtherTok{\textless{}{-}}
    \FunctionTok{brm}\NormalTok{(}
\NormalTok{        brm\_subject\_formula,}
        \AttributeTok{data =}\NormalTok{ df\_clean,}
        \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
        \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
        \AttributeTok{file =} \StringTok{"models/brm\_subject"}\NormalTok{,}
        \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(brm\_subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ 1 + (1 | Subject) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Subject (Number of levels: 87) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.93      0.09     0.78     1.12 1.00      748     1502

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -3.15      0.13    -3.41    -2.89 1.01      643     1130
Intercept[2]    -1.68      0.11    -1.90    -1.46 1.01      489      823
Intercept[3]    -0.93      0.11    -1.14    -0.71 1.01      472      750
Intercept[4]     0.65      0.11     0.43     0.86 1.01      503      794

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_treat.period.subject.question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_treat.period.subject.question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_treat.period.subject.question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             0.74      0.16     0.50     1.11 1.00     1213
sd(TreatB)                1.50      0.29     1.05     2.21 1.00     1194
cor(Intercept,TreatB)    -0.41      0.21    -0.74     0.07 1.01      931
                      Tail_ESS
sd(Intercept)             2155
sd(TreatB)                1803
cor(Intercept,TreatB)     1691

~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             1.82      0.18     1.50     2.21 1.00      841
sd(TreatB)                2.39      0.21     2.01     2.84 1.00      685
cor(Intercept,TreatB)    -0.54      0.09    -0.70    -0.35 1.01      420
                      Tail_ESS
sd(Intercept)             1266
sd(TreatB)                1487
cor(Intercept,TreatB)      719

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -6.70      0.37    -7.43    -5.98 1.00      701     1417
Intercept[2]      -4.35      0.35    -5.03    -3.64 1.00      641     1231
Intercept[3]      -3.06      0.34    -3.73    -2.37 1.00      626     1271
Intercept[4]      -0.50      0.34    -1.17     0.18 1.00      623     1227
TreatB            -3.15      0.57    -4.28    -2.04 1.01      483     1112
Period2           -0.58      0.41    -1.41     0.21 1.01      492      943
TreatB:Period2     0.50      0.68    -0.82     1.83 1.00      428      888

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_treat.period.subject\_question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_treat.period.subject\_question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_treat.period.subject\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.75      0.15     0.52     1.11 1.01      599     1261

~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             1.80      0.18     1.48     2.18 1.01      609
sd(TreatB)                2.29      0.21     1.91     2.73 1.01      553
cor(Intercept,TreatB)    -0.58      0.08    -0.73    -0.40 1.01      409
                      Tail_ESS
sd(Intercept)             1378
sd(TreatB)                1002
cor(Intercept,TreatB)      864

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -6.27      0.36    -6.98    -5.58 1.01      403      700
Intercept[2]      -4.20      0.35    -4.89    -3.54 1.01      383      791
Intercept[3]      -3.04      0.34    -3.72    -2.38 1.01      377      730
Intercept[4]      -0.63      0.33    -1.28     0.01 1.02      376      735
TreatB            -3.09      0.42    -3.96    -2.27 1.01      323      532
Period2           -0.64      0.41    -1.47     0.16 1.02      267      656
TreatB:Period2     0.60      0.64    -0.61     1.87 1.01      291      765

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_cs.treat.subject.question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+} \FunctionTok{cs}\NormalTok{(Treat) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_cs.treat.subject.question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_cs.treat.subject.question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ 1 + cs(Treat) + (1 | Subject) + (1 | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.63      0.12     0.43     0.91 1.00      864     1618

~Subject (Number of levels: 87) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.17      0.10     0.99     1.40 1.01      700     1373

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -6.53      0.54    -7.68    -5.56 1.00     1024     1666
Intercept[2]    -3.75      0.24    -4.21    -3.30 1.01      721     1507
Intercept[3]    -2.35      0.21    -2.77    -1.91 1.01      624     1253
Intercept[4]    -0.02      0.20    -0.43     0.38 1.01      598     1189
TreatB[1]       -3.95      0.50    -5.05    -3.08 1.00     1328     1728
TreatB[2]       -2.91      0.15    -3.21    -2.63 1.00     1834     2438
TreatB[3]       -2.41      0.10    -2.61    -2.21 1.00     2375     2819
TreatB[4]       -1.82      0.10    -2.01    -1.62 1.00     3745     3037

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_treat\_question\_subject\_question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject}\SpecialCharTok{:}\NormalTok{Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_treat\_question\_subject\_question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_treat\_question\_subject\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ 1 + Treat + (1 | Question) + (1 | Subject:Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.58      0.12     0.39     0.88 1.00     1627     2121

~Subject:Question (Number of levels: 1529) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.73      0.09     0.55     0.89 1.01      791     1229

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -4.48      0.18    -4.85    -4.13 1.01     1271     2352
Intercept[2]    -2.81      0.16    -3.14    -2.49 1.01     1244     2546
Intercept[3]    -1.90      0.16    -2.22    -1.59 1.01     1256     2228
Intercept[4]    -0.10      0.15    -0.40     0.20 1.00     1312     2093
TreatB          -1.97      0.08    -2.14    -1.81 1.00     2761     3019

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_treat\_question\_subject }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_treat\_question\_subject"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_treat\_question\_subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ 1 + Treat + (1 | Question) + (1 | Subject) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.64      0.12     0.44     0.91 1.00      924     1940

~Subject (Number of levels: 87) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.21      0.10     1.02     1.43 1.00      843     1744

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -4.94      0.23    -5.40    -4.49 1.00      677     1423
Intercept[2]    -3.17      0.22    -3.60    -2.76 1.00      614     1363
Intercept[3]    -2.18      0.21    -2.60    -1.77 1.00      584     1330
Intercept[4]    -0.15      0.21    -0.55     0.26 1.00      556     1142
TreatB          -2.21      0.08    -2.37    -2.04 1.00     5832     3233

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\_

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_period.treat.subject\_question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Period }\SpecialCharTok{*}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_period.treat.subject\_question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_period.treat.subject\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Period * Treat + (1 + Treat | Subject) + (1 | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.74      0.15     0.52     1.08 1.00      744     1544

~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             1.80      0.17     1.48     2.15 1.02      585
sd(TreatB)                2.27      0.20     1.89     2.70 1.01      458
cor(Intercept,TreatB)    -0.58      0.08    -0.72    -0.40 1.00      460
                      Tail_ESS
sd(Intercept)             1462
sd(TreatB)                 811
cor(Intercept,TreatB)      818

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -6.22      0.35    -6.92    -5.55 1.00      502     1033
Intercept[2]      -4.15      0.33    -4.82    -3.51 1.00      472      931
Intercept[3]      -2.98      0.33    -3.65    -2.35 1.00      464      958
Intercept[4]      -0.58      0.32    -1.24     0.03 1.00      451      834
Period2           -0.59      0.39    -1.36     0.16 1.01      365      656
TreatB            -3.06      0.42    -3.88    -2.24 1.01      327      713
Period2:TreatB     0.53      0.63    -0.73     1.78 1.01      337      674

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_period.treat\_subject\_question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Period }\SpecialCharTok{*}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_period.treat\_subject\_question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_period.treat\_subject\_question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Period * Treat + (1 | Subject) + (1 | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.64      0.13     0.44     0.93 1.00     1169     2019

~Subject (Number of levels: 87) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.23      0.11     1.04     1.47 1.00      962     1901

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -5.32      0.28    -5.88    -4.80 1.00      752     1381
Intercept[2]      -3.55      0.26    -4.10    -3.05 1.01      702     1231
Intercept[3]      -2.56      0.26    -3.08    -2.06 1.01      681     1220
Intercept[4]      -0.51      0.25    -1.03    -0.02 1.01      663     1167
Period2           -0.63      0.29    -1.20    -0.06 1.01      464      919
TreatB            -2.54      0.29    -3.12    -1.98 1.01      473      952
Period2:TreatB     0.61      0.56    -0.50     1.68 1.01      447      803

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_period.treat.question\_subject }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Period }\SpecialCharTok{*}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_period.treat.question\_subject"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_period.treat.question\_subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Period * Treat + (1 | Subject) + (1 + Treat | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             0.64      0.13     0.42     0.95 1.01     1086
sd(TreatB)                1.30      0.26     0.89     1.90 1.01      852
cor(Intercept,TreatB)    -0.42      0.21    -0.75     0.05 1.00      558
                      Tail_ESS
sd(Intercept)             2145
sd(TreatB)                1540
cor(Intercept,TreatB)     1102

~Subject (Number of levels: 87) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.30      0.12     1.09     1.55 1.00      762     1292

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -5.67      0.29    -6.27    -5.12 1.01      382     1094
Intercept[2]      -3.72      0.28    -4.28    -3.20 1.01      341     1024
Intercept[3]      -2.64      0.28    -3.20    -2.13 1.01      337      967
Intercept[4]      -0.49      0.27    -1.04     0.02 1.01      319     1020
Period2           -0.67      0.30    -1.25    -0.08 1.01      300      665
TreatB            -2.70      0.45    -3.58    -1.83 1.01      312      805
Period2:TreatB     0.67      0.58    -0.44     1.80 1.02      286      592

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_thres.question\_period.treat.subject }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
    \FunctionTok{bf}\NormalTok{(Response }\SpecialCharTok{|} \FunctionTok{thres}\NormalTok{(}\AttributeTok{gr =}\NormalTok{ Question) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Period }\SpecialCharTok{*}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject)),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_thres.question\_period.treat.subject"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_thres.question\_period.treat.subject)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response | thres(gr = Question) ~ Period * Treat + (1 + Treat | Subject) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             2.20      0.27     1.74     2.77 1.00      548
sd(TreatB)                2.50      0.26     2.04     3.07 1.01      520
cor(Intercept,TreatB)    -0.62      0.09    -0.77    -0.44 1.01      482
                      Tail_ESS
sd(Intercept)              900
sd(TreatB)                1094
cor(Intercept,TreatB)      980

Population-Level Effects: 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[Q18,1]    -4.41      0.49    -5.40    -3.50 1.00      797     1843
Intercept[Q18,2]    -2.02      0.38    -2.74    -1.28 1.00      555     1224
Intercept[Q18,3]    -1.07      0.37    -1.80    -0.34 1.00      550     1001
Intercept[Q18,4]     1.25      0.38     0.53     2.00 1.00      540     1217
Intercept[Q01,1]    -4.40      0.49    -5.40    -3.44 1.00      805     1740
Intercept[Q01,2]    -2.57      0.40    -3.36    -1.79 1.00      588     1440
Intercept[Q01,3]    -1.96      0.38    -2.71    -1.20 1.00      542     1004
Intercept[Q01,4]     0.50      0.37    -0.22     1.23 1.00      527     1110
Intercept[Q02,1]    -5.41      0.63    -6.70    -4.22 1.00     1063     2056
Intercept[Q02,2]    -2.55      0.39    -3.31    -1.78 1.00      580     1201
Intercept[Q02,3]    -1.78      0.38    -2.51    -1.04 1.00      545     1330
Intercept[Q02,4]     0.69      0.38    -0.05     1.43 1.00      529     1116
Intercept[Q03,1]    -5.38      0.62    -6.65    -4.23 1.00     1228     2179
Intercept[Q03,2]    -2.45      0.40    -3.23    -1.68 1.00      599     1486
Intercept[Q03,3]    -1.79      0.39    -2.53    -1.04 1.00      569     1398
Intercept[Q03,4]     0.84      0.38     0.08     1.58 1.00      570     1297
Intercept[Q04,1]    -5.95      0.80    -7.65    -4.58 1.00     1381     2344
Intercept[Q04,2]    -4.10      0.48    -5.08    -3.17 1.00      836     1893
Intercept[Q04,3]    -3.10      0.42    -3.92    -2.27 1.00      646     1452
Intercept[Q04,4]    -0.32      0.37    -1.03     0.43 1.00      528      925
Intercept[Q05,1]    -2.82      0.39    -3.61    -2.06 1.00      582     1559
Intercept[Q05,2]    -1.21      0.37    -1.91    -0.46 1.00      538     1186
Intercept[Q05,3]    -0.61      0.37    -1.32     0.13 1.00      522     1156
Intercept[Q05,4]     0.91      0.38     0.19     1.65 1.00      522     1207
Intercept[Q06,1]    -5.21      0.57    -6.37    -4.13 1.00     1012     2125
Intercept[Q06,2]    -2.39      0.39    -3.16    -1.63 1.00      593     1587
Intercept[Q06,3]    -1.26      0.38    -1.99    -0.52 1.00      560     1300
Intercept[Q06,4]     1.03      0.38     0.30     1.80 1.00      563     1302
Intercept[Q07,1]    -4.07      0.46    -5.03    -3.21 1.00      702     1350
Intercept[Q07,2]    -1.84      0.37    -2.57    -1.11 1.00      554     1362
Intercept[Q07,3]    -1.14      0.37    -1.82    -0.43 1.00      527     1210
Intercept[Q07,4]     1.17      0.38     0.45     1.92 1.00      533     1260
Intercept[Q08,1]    -3.88      0.45    -4.76    -3.02 1.00      621     1612
Intercept[Q08,2]    -1.38      0.37    -2.11    -0.64 1.00      533     1303
Intercept[Q08,3]    -0.48      0.37    -1.19     0.25 1.00      506     1248
Intercept[Q08,4]     1.36      0.39     0.61     2.10 1.00      518     1140
Intercept[Q09,1]    -2.28      0.39    -3.02    -1.55 1.00      561     1146
Intercept[Q09,2]    -0.93      0.37    -1.66    -0.22 1.00      524     1056
Intercept[Q09,3]    -0.35      0.36    -1.07     0.36 1.00      525     1013
Intercept[Q09,4]     1.58      0.38     0.85     2.35 1.00      557     1268
Intercept[Q10,1]    -5.54      0.70    -7.07    -4.30 1.00     1369     2014
Intercept[Q10,2]    -2.48      0.40    -3.24    -1.71 1.00      600     1466
Intercept[Q10,3]    -1.42      0.38    -2.15    -0.68 1.00      559     1168
Intercept[Q10,4]     1.12      0.38     0.38     1.87 1.00      561     1221
Intercept[Q11,1]    -6.52      0.85    -8.37    -5.08 1.00     1441     2244
Intercept[Q11,2]    -3.55      0.43    -4.39    -2.72 1.00      707     1422
Intercept[Q11,3]    -2.02      0.38    -2.77    -1.28 1.00      558     1447
Intercept[Q11,4]     1.28      0.39     0.53     2.04 1.00      536     1104
Intercept[Q12,1]    -5.77      0.68    -7.19    -4.52 1.00     1236     2278
Intercept[Q12,2]    -2.56      0.40    -3.33    -1.77 1.00      590     1765
Intercept[Q12,3]    -1.48      0.38    -2.20    -0.73 1.00      532     1205
Intercept[Q12,4]     1.56      0.39     0.82     2.35 1.00      536     1152
Intercept[Q13,1]    -6.16      0.86    -8.02    -4.67 1.00     1547     1928
Intercept[Q13,2]    -5.16      0.62    -6.44    -4.00 1.00     1119     1791
Intercept[Q13,3]    -2.84      0.41    -3.65    -2.04 1.00      621     1215
Intercept[Q13,4]    -0.05      0.37    -0.77     0.67 1.00      532     1188
Intercept[Q14,1]    -4.56      0.52    -5.62    -3.57 1.00      860     1942
Intercept[Q14,2]    -2.07      0.39    -2.84    -1.31 1.00      588     1223
Intercept[Q14,3]    -0.62      0.38    -1.35     0.12 1.00      563     1135
Intercept[Q14,4]     1.64      0.40     0.87     2.42 1.00      595     1503
Intercept[Q15,1]    -5.08      0.64    -6.37    -3.87 1.00     1148     2531
Intercept[Q15,2]    -2.18      0.41    -2.96    -1.41 1.00      621     1277
Intercept[Q15,3]    -0.37      0.39    -1.12     0.38 1.00      548     1159
Intercept[Q15,4]     2.01      0.41     1.21     2.80 1.00      629     1274
Intercept[Q16,1]    -6.26      0.90    -8.16    -4.65 1.00     1593     2460
Intercept[Q16,2]    -4.19      0.54    -5.32    -3.17 1.00     1018     2280
Intercept[Q16,3]     0.00      0.38    -0.73     0.75 1.00      580     1148
Intercept[Q16,4]     2.27      0.44     1.42     3.16 1.00      695     1305
Intercept[Q17,1]    -5.28      0.66    -6.65    -4.06 1.00     1270     2323
Intercept[Q17,2]    -2.92      0.42    -3.76    -2.09 1.00      692     1701
Intercept[Q17,3]    -0.53      0.38    -1.25     0.20 1.00      567     1197
Intercept[Q17,4]     1.86      0.40     1.10     2.69 1.00      637     1536
Period2              1.21      0.52     0.29     2.30 1.01      337      889
TreatB              -1.28      0.46    -2.15    -0.38 1.00      417      869
Period2:TreatB      -1.75      0.82    -3.46    -0.29 1.00      388      657

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_period.treat.subject\_question.disc }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
    \FunctionTok{bf}\NormalTok{(}
\NormalTok{        Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Period }\SpecialCharTok{*}\NormalTok{ Treat }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ q }\SpecialCharTok{|}\NormalTok{ Question),}
\NormalTok{        disc }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ q }\SpecialCharTok{|}\NormalTok{ Question)}
\NormalTok{    ),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_period.treat.subject\_question.disc"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}\NormalTok{,}
    \AttributeTok{prior =} \FunctionTok{prior}\NormalTok{(}\StringTok{"constant(1)"}\NormalTok{, }\AttributeTok{class =} \StringTok{"sd"}\NormalTok{, }\AttributeTok{group =} \StringTok{"Subject"}\NormalTok{) }\SpecialCharTok{+}
        \FunctionTok{prior}\NormalTok{(}\StringTok{"normal(0, 3)"}\NormalTok{, }\AttributeTok{class =} \StringTok{"sd"}\NormalTok{, }\AttributeTok{group =} \StringTok{"Question"}\NormalTok{) }\SpecialCharTok{+}
        \FunctionTok{prior}\NormalTok{(}\StringTok{"normal(0, 1)"}\NormalTok{, }\AttributeTok{class =} \StringTok{"sd"}\NormalTok{, }\AttributeTok{group =} \StringTok{"Question"}\NormalTok{, }\AttributeTok{dpar =} \StringTok{"disc"}\NormalTok{)}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_period.treat.subject\_question.disc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = log 
Formula: Response ~ Period * Treat + (1 + Treat | Subject) + (1 | q | Question) 
         disc ~ 1 + (1 | q | Question)
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
                              Estimate Est.Error l-95% CI u-95% CI Rhat
sd(Intercept)                     0.41      0.09     0.27     0.61 1.00
sd(disc_Intercept)                0.21      0.05     0.13     0.33 1.00
cor(Intercept,disc_Intercept)    -0.06      0.26    -0.56     0.46 1.00
                              Bulk_ESS Tail_ESS
sd(Intercept)                     1097     2219
sd(disc_Intercept)                1780     2440
cor(Intercept,disc_Intercept)     2013     2323

~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             1.00      0.00     1.00     1.00   NA       NA
sd(TreatB)                1.00      0.00     1.00     1.00   NA       NA
cor(Intercept,TreatB)    -0.55      0.08    -0.70    -0.37 1.00     1071
                      Tail_ESS
sd(Intercept)               NA
sd(TreatB)                  NA
cor(Intercept,TreatB)     1851

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -3.23      0.30    -3.82    -2.66 1.01      726     1352
Intercept[2]      -2.14      0.24    -2.62    -1.66 1.01      677     1266
Intercept[3]      -1.55      0.21    -1.97    -1.12 1.01      658     1120
Intercept[4]      -0.32      0.19    -0.68     0.07 1.01      638     1149
disc_Intercept     0.67      0.09     0.49     0.86 1.00     1097     1383
Period2           -0.31      0.22    -0.74     0.12 1.00      565      881
TreatB            -1.57      0.24    -2.03    -1.12 1.00      662     1134
Period2:TreatB     0.28      0.36    -0.42     1.00 1.00      614     1036

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_acat\_cs.treat.subject.question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+} \FunctionTok{cs}\NormalTok{(Treat) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{acat}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_acat\_cs.treat.subject.question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_acat\_cs.treat.subject.question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: acat 
  Links: mu = logit; disc = identity 
Formula: Response ~ 1 + cs(Treat) + (1 | Subject) + (1 | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.40      0.08     0.27     0.59 1.00      793     1181

~Subject (Number of levels: 87) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.69      0.07     0.57     0.83 1.00      655     1621

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]    -3.54      0.54    -4.69    -2.57 1.00     1679     2078
Intercept[2]    -1.55      0.21    -1.97    -1.15 1.01      886     2036
Intercept[3]    -1.75      0.16    -2.07    -1.45 1.01      566     1235
Intercept[4]    -0.27      0.13    -0.53    -0.01 1.01      420     1200
TreatB[1]       -2.21      0.53    -3.34    -1.27 1.00     2333     2245
TreatB[2]       -1.65      0.19    -2.02    -1.29 1.00     2645     2810
TreatB[3]       -1.29      0.13    -1.55    -1.03 1.00     3283     3268
TreatB[4]       -1.03      0.10    -1.24    -0.83 1.00     4452     3192

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brm\_treat.period.subject.question }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{    Response }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Treat }\SpecialCharTok{*}\NormalTok{ Period }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Subject) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Treat }\SpecialCharTok{|}\NormalTok{ Question),}
    \AttributeTok{data =}\NormalTok{ df\_clean,}
    \AttributeTok{family =} \FunctionTok{cumulative}\NormalTok{(}\StringTok{"logit"}\NormalTok{),}
    \AttributeTok{sample\_prior =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{file =} \StringTok{"models/brm\_treat.period.subject.question"}\NormalTok{,}
    \AttributeTok{file\_refit =} \StringTok{"on\_change"}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(brm\_treat.period.subject.question)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Family: cumulative 
  Links: mu = logit; disc = identity 
Formula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question) 
   Data: df_clean (Number of observations: 2980) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~Question (Number of levels: 18) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             0.74      0.16     0.50     1.11 1.00     1213
sd(TreatB)                1.50      0.29     1.05     2.21 1.00     1194
cor(Intercept,TreatB)    -0.41      0.21    -0.74     0.07 1.01      931
                      Tail_ESS
sd(Intercept)             2155
sd(TreatB)                1803
cor(Intercept,TreatB)     1691

~Subject (Number of levels: 87) 
                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
sd(Intercept)             1.82      0.18     1.50     2.21 1.00      841
sd(TreatB)                2.39      0.21     2.01     2.84 1.00      685
cor(Intercept,TreatB)    -0.54      0.09    -0.70    -0.35 1.01      420
                      Tail_ESS
sd(Intercept)             1266
sd(TreatB)                1487
cor(Intercept,TreatB)      719

Population-Level Effects: 
               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept[1]      -6.70      0.37    -7.43    -5.98 1.00      701     1417
Intercept[2]      -4.35      0.35    -5.03    -3.64 1.00      641     1231
Intercept[3]      -3.06      0.34    -3.73    -2.37 1.00      626     1271
Intercept[4]      -0.50      0.34    -1.17     0.18 1.00      623     1227
TreatB            -3.15      0.57    -4.28    -2.04 1.01      483     1112
Period2           -0.58      0.41    -1.41     0.21 1.01      492      943
TreatB:Period2     0.50      0.68    -0.82     1.83 1.00      428      888

Family Specific Parameters: 
     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
disc     1.00      0.00     1.00     1.00   NA       NA       NA

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{LOO}\NormalTok{(}
\NormalTok{    brm\_subject,}
\NormalTok{    brm\_period.treat\_subject\_question,}
\NormalTok{    brm\_treat.period.subject.question,}
\NormalTok{    brm\_cs.treat.subject.question,}
\NormalTok{    brm\_treat\_question\_subject,}
\NormalTok{    brm\_treat\_question\_subject\_question,}
\NormalTok{    brm\_period.treat.subject\_question,}
\NormalTok{    brm\_thres.question\_period.treat.subject,}
\NormalTok{    brm\_period.treat.subject\_question.disc,}
\NormalTok{    brm\_acat\_cs.treat.subject.question,}
\NormalTok{    brm\_period.treat.question\_subject}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Output of model 'brm_subject':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -4004.3 38.3
p_loo        87.7  1.6
looic      8008.6 76.6
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k < 0.5).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_period.treat_subject_question':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3480.8 40.0
p_loo       108.7  2.1
looic      6961.5 80.0
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k < 0.5).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_treat.period.subject.question':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3011.0 46.2
p_loo       193.8  4.6
looic      6022.0 92.4
------
Monte Carlo SE of elpd_loo is 0.2.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     2978  99.9%   983       
 (0.5, 0.7]   (ok)          2   0.1%   1997      
   (0.7, 1]   (bad)         0   0.0%   <NA>      
   (1, Inf)   (very bad)    0   0.0%   <NA>      

All Pareto k estimates are ok (k < 0.7).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_cs.treat.subject.question':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3464.7 40.1
p_loo       107.1  2.1
looic      6929.4 80.2
------
Monte Carlo SE of elpd_loo is 0.2.

All Pareto k estimates are good (k < 0.5).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_treat_question_subject':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3490.1 39.8
p_loo       106.9  2.0
looic      6980.2 79.5
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k < 0.5).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_treat_question_subject_question':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3869.0 33.0
p_loo       357.0  5.5
looic      7738.0 65.9
------
Monte Carlo SE of elpd_loo is 0.3.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     2978  99.9%   1264      
 (0.5, 0.7]   (ok)          2   0.1%   6056      
   (0.7, 1]   (bad)         0   0.0%   <NA>      
   (1, Inf)   (very bad)    0   0.0%   <NA>      

All Pareto k estimates are ok (k < 0.7).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_period.treat.subject_question':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3158.0 45.2
p_loo       182.3  4.3
looic      6316.1 90.5
------
Monte Carlo SE of elpd_loo is 0.2.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     2979  100.0%  1140      
 (0.5, 0.7]   (ok)          1    0.0%  1411      
   (0.7, 1]   (bad)         0    0.0%  <NA>      
   (1, Inf)   (very bad)    0    0.0%  <NA>      

All Pareto k estimates are ok (k < 0.7).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_thres.question_period.treat.subject':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3058.6 46.4
p_loo       229.2  5.3
looic      6117.3 92.8
------
Monte Carlo SE of elpd_loo is NA.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     2970  99.7%   1328      
 (0.5, 0.7]   (ok)          8   0.3%   557       
   (0.7, 1]   (bad)         2   0.1%   274       
   (1, Inf)   (very bad)    0   0.0%   <NA>      
See help('pareto-k-diagnostic') for details.

Output of model 'brm_period.treat.subject_question.disc':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3131.4 45.2
p_loo       195.7  5.1
looic      6262.8 90.4
------
Monte Carlo SE of elpd_loo is 0.2.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     2978  99.9%   1172      
 (0.5, 0.7]   (ok)          2   0.1%   670       
   (0.7, 1]   (bad)         0   0.0%   <NA>      
   (1, Inf)   (very bad)    0   0.0%   <NA>      

All Pareto k estimates are ok (k < 0.7).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_acat_cs.treat.subject.question':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3468.1 39.2
p_loo       101.7  2.9
looic      6936.2 78.5
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k < 0.5).
See help('pareto-k-diagnostic') for details.

Output of model 'brm_period.treat.question_subject':

Computed from 4000 by 2980 log-likelihood matrix

         Estimate   SE
elpd_loo  -3361.7 41.4
p_loo       123.1  2.4
looic      6723.4 82.9
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k < 0.5).
See help('pareto-k-diagnostic') for details.

Model comparisons:
                                        elpd_diff se_diff
brm_treat.period.subject.question          0.0       0.0 
brm_thres.question_period.treat.subject  -47.7      20.0 
brm_period.treat.subject_question.disc  -120.4      17.2 
brm_period.treat.subject_question       -147.0      16.9 
brm_period.treat.question_subject       -350.7      28.0 
brm_cs.treat.subject.question           -453.7      31.1 
brm_acat_cs.treat.subject.question      -457.1      29.7 
brm_period.treat_subject_question       -469.8      30.5 
brm_treat_question_subject              -479.1      31.0 
brm_treat_question_subject_question     -858.0      39.0 
brm_subject                             -993.3      42.8 
\end{verbatim}

\normalsize


\backmatter
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\SmallMargins

\onecolumn


% Back cover
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Even page, small margins, no running head, no page number.
\evenpage
\SmallMargins
\thispagestyle{empty}

\begin{normalsize}

\begin{description}

\selectlanguage{spanish}
\item[Abstract]
English abstract, on the last page.

This is a bookdown template based on LaTeX memoir class.
\item[Keywords]
Keyword in English, As a list.
~\\

\end{description}

\end{normalsize}

\end{document}
