---
bibliography: references.bib
lang: es
toc: true

execute:
  echo: false
---

{{< include _setup.qmd >}}


```{r}
#| code-fold: true
#| code-summary: "R setup"
#| message: false

library(tidyverse)
library(dunnr)
library(gt)
library(broom)
library(patchwork)

extrafont::loadfonts(device = "all", quiet = TRUE)
# theme_set(theme_td(base_family = "Kalimati"))
set_geom_fonts()
set_palette()

wine_red <- "#58181F"
update_geom_defaults("point", list(color = wine_red))
update_geom_defaults("line", list(color = wine_red))
```


# Regresión ordinal

## Introducción

El test de Likert es una escala ordinal. Tratar las respuestas a un test de Likert como si fueran cuantitativas como se hizo en el análisis de la varianza del apartado anterior no es correcto por las siguientes razones:

* Los niveles de respuesta no son necesariamente equidistantes: la distancia entre un par de opciones de respuesta puede no ser la misma para todos los pares de opciones de respuesta. Por ejemplo, la diferencia entre "Muy en desacuerdo" y "En desacuerdo" y la diferencia entre "De acuerdo" y "Muy de acuerdo" es de un nivel, pero psicológicamente puede ser percibida de forma diferente para cada sujeto.

* La distribución de las respuestas ordinales puede ser no normal. En particular esto sucederá si hay hay muchas respuestas en los extremos del cuestionario.

* Las varianzas de las variables no observadas que subyacen a las variables ordinales observadas pueden diferir entre grupos, tratamientos, periodos, etc. 

En @kruschke2018328 se han analizado los problemas potenciales de tratar datos ordinales como si fueran cuantitativos constatando que se pueden presentar las siguientes situaciones:

* Se pueden encontrar diferencias significativas entre grupos cuando no las hay: Error tipo I.
* Se pueden obviar diferencias cuando en realidad sí existen: Error tipo II.
* Incluso se pueden invertir los efectos de un tratamiento.
* También puede malinterpretarse la interacción entre factores.

La regresión ordinal pretende dar respuesta a todos estos problemas.

## Variantes de la regresión ordinal.

Según @burkner hay tres clases de regresión ordinal:

* Regresión ordinal acumulativa.
* Regresión ordinal secuencial.
* Regresión ordinal adyacente.

Nos centraremos en la primera ya que es la más habitual y adecuada para nuestro caso.

```{r}
#| freeze: true
x <- seq(-4, 4, length.out = 500)
y <- dnorm(x, 0, 1.5)

x_cuts <- c(-2.5, -1.1, 1.8)
x_labels <- c(expression(tau[1]), expression(tau[2]), expression(tau[3]))

data <- tibble(x, y)

g <- data %>% ggplot(aes(x = x, y = y)) +
    geom_line() +
    theme(
        axis.line = element_line(color = "black", linewidth = 1),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(color = "black", size = 12, hjust = 0.5, vjust = -3)
    ) +
    ylab(NULL)

cumulative <- g + geom_vline(xintercept = x_cuts) +
    geom_label(size = 2, data = data.frame(x = x_cuts - 0.4, y = rep(0.22, 3), label = paste("Y = ", 1:3, sep = "")), aes(x = x, y = y, label = label)) +
    geom_label(size = 2, x = 2.5, y = 0.22, label = "Y = 4") +
    scale_x_continuous(breaks = x_cuts, labels = x_labels) +
    xlab(expression(tilde(Y))) +
    coord_fixed(ratio = 5)


sequencial <- list()
for (i in 1:3) {
    p <- g + geom_vline(xintercept = x_cuts[i]) +
        geom_label(size = 2, x = x_cuts[i] - 1, y = 0.22, label = paste("Y = ", i, sep = "")) +
        geom_label(size = 2, x = x_cuts[i] + 1, y = 0.22, label = paste("Y > ", i, sep = "")) +
        scale_x_continuous(breaks = x_cuts[i], labels = x_labels[i]) +
        xlab(bquote(tilde(Y)[.(i)])) +
        coord_fixed(ratio = 30)
    sequencial[[i]] <- p
}

adjacent <- list()
for (i in 1:3) {
    p <- g + geom_vline(xintercept = x_cuts[i]) +
        geom_label(size = 2, x = x_cuts[i] - 1, y = 0.22, label = paste("Y = ", i, sep = "")) +
        geom_label(size = 2, x = x_cuts[i] + 1, y = 0.22, label = paste("Y = ", i + 1, sep = "")) +
        scale_x_continuous(breaks = x_cuts[i], labels = x_labels[i]) +
        xlab(bquote(tilde(Y)[.(i)])) +
        coord_fixed(ratio = 30)
    adjacent[[i]] <- p
}

```

El modelo acumulativo, CM, presupone que la variable ordinal observada, $Y$, proviene de la categorización de una variable latente (no observada) continua, $\tilde{Y}$. Hay $K$ umbrales $\tau_k$ que particionan $\tilde{Y}$ en $K + 1$ categorías ordenadas observables (ver @fig-cumulative). Si asumimos que $\tilde{Y}$ tiene una cierta distribución (por ejemplo, normal) con distribución acumulada $F$, se puede calcular la probabilidad de que $Y$ sea la categoría $k$ de esta forma:

$$Pr(Y = k) = F(\tau_k) - F(\tau_{k-1})$$

Por ejemplo en la @fig-cumulative,

$$Pr(Y = 2) = F(\tau_2) - F(\tau_{1})$$

Si suponemos que, por ejemplo, $\tilde{Y}$ tiene una relación lineal con dos predictores:

$$\tilde{Y} = \eta + \epsilon = \beta_1 x_1 + \beta_2 x_2 + \epsilon$$

Y que los errores son $N(0,\sigma^2)$.

Entonces la función de probabilidad acumulada de los errores tendrá la misma forma que la de $\tilde{Y}$:

$$\mathrm{Pr}(\epsilon \leq z) = F(z)$$

Y podremos calcular la distribución de probabilidad acumulada de $Y$:

$$\mathrm{Pr}(Y \leq k \mid \eta) = \mathrm{Pr}(\tilde{Y} \leq \tau_k \mid \eta) = \mathrm{Pr}(\eta + \epsilon \leq \tau_k) = \mathrm{Pr}(\epsilon \leq \tau_k - \eta) = F(\tau_k - \eta)$$

Por lo que asumiendo la normalidad de los errores:

$$\mathrm{Pr}(Y = k) = \Phi(\tau_k - (\beta_1 x_1 + \beta_2 x_2)) - \Phi(\tau_{k - 1} - (\beta_1 x_1 + \beta_2 x_2))$$

Donde hay que estimar los umbrales y los coeficientes de regresión.

Otra popular elección, que usaremos en este trabajo, es suponer que la función acumulada se comporta como una logística. En ese caso, la interpretación de los coeficientes varía y se asemeja a la de la regresión logística. Se parte del supuesto de que el $logit$ de la función de probabilidad es lineal:

$$logit (P(Y \le k)) = \tau_{k} - \eta = \tau_{k} - (\beta_1 x_1 + \beta_2 x_2)$$

Se puede demostrar que, por ejemplo:

$$\frac{\frac{\mathrm{Pr}(Y \leq k \mid \eta)}{\mathrm{Pr}(Y > k \mid \eta)}}{\frac{\mathrm{Pr}(Y \leq k+1 \mid \eta)}{\mathrm{Pr}(Y > k+1 \mid \eta)}} = \exp(\tau_{k} - \tau_{k+1})$$

Y que
^[En el siguiente apartado se demuestra esta fórmula.]:

$$\frac{\frac{\mathrm{Pr}(Y \leq k \mid x_i = 1)}{\mathrm{Pr}(Y > k \mid x_i = 1)}}{\frac{\mathrm{Pr}(Y \leq k \mid x_i=0)}{\mathrm{Pr}(Y > k \mid x_i = 0)}} = \exp(-\beta_{i})$$



```{r}
#| label: fig-cumulative
#| fig-cap: Regresión ordinal acumulativa.
#| freeze: true
cumulative
```

```{r}
#| include: false
renv::use(lockfile = "renv.lock")
```

## Preparación

TODO: Comentar o llevar al EDA

```{r}
#| message: false
library(ordinal)
df <- as_tibble(df_clean)
glimpse(df)
```
```{r}
df_resume <- df %>%
    dplyr::select(Subject, Period, Group, Treat, Response, Item) %>%
    group_by(Group, Period, Treat) %>%
    count(Response) %>%
    ungroup()

min_freq_response <- min(df_resume$n)
max_freq_response <- max(df_resume$n)
```



```{r}
#| label: resume
#| tbl-cap: Resumen de frecuencias de respuesta.
#| fig-pos: h
df_resume %>%
    pivot_wider(id_cols = c(Group, Period, Treat), names_from = Response, values_from = n) %>%
    gt() %>%
    tab_spanner(columns = `1`:`5`, label = "Response") %>%
    data_color(
        columns = `1`:`5`,
        colors = scales::col_numeric(
            palette = c("white", wine_red), domain = c(min_freq_response, max_freq_response)
        )
    )
```
```{r}
#| label: resume2
#| fig-cap: Resumen de frecuencias de respuesta.
#| fig-pos: h
#| eval: false
df_resume %>%
    ggplot(aes(x = Treat, y = Response, color = Treat)) +
    geom_point(aes(group = Treat, size = n)) +
    facet_wrap(~Group,
        scales = "free_x"
    ) +
    add_facet_borders() +
    theme_bw() +
    theme(
        legend.position = "none", panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()
    )
```


## Modelo de enlace logit acumulado


Vamos a ajustar el modelo con la función de enlace logit:

$$
\text{logit} (P(y_i \leq k) = \log \frac{P(y_i \leq k)}{1 - P(y_i \leq k)}
$$ {#eq-link-logit}

La función de enlace logit acumulada (@eq-link-logit) no está definida para $k = K$, ya que $1 - P(Y_i \leq K) = 1 - 1 = 0$.

En nuestra escala de Likert tenemos $K$ = 5 niveles, el modelo mixto que vamos a plantear es el siguiente:

$$
\begin{aligned}
\text{logit}(p(y_i \leq k)) &= \tau_k - \beta_1 \text{Period}_i - \beta_2 \text{Treat}_i - \beta_3 \text{Item}_i - u( \text{Subject}_i) \\
i &= 1, \dots n \; \; \; \; \; \; k = 1, \dots, K - 1
\end{aligned}
$$

donde $\tau_k$ es el umbral de la categoría $k$ y son $K-1$ = 4 interceptores.
Los coeficientes de los efectos fijos, $\beta_1$, $\beta_2$ y $\beta_3$, son independientes, por lo que cada $\beta_i$ tiene el mismo efecto en los $K-1$ logits acumulados.
El efecto aleatorio, Subject, se presupone que sigue una distribución normal: $u(\text{Subject}_i) \sim N(0, \sigma_u^2)$.

En esencia lo que estamos haciendo es un modelo en cadena de regresiones logísticas donde la respuesta binaria se corresponde con "menor o igual que cierto nivel frente a mayor que ese nivel".

En el caso particular de $K$ = 5, los umbrales $\tau_k$ se interpretan como:

* $k$ = 1: log-odds del nivel = 1 vs. 2-5
* $k$ = 2: log-odds del nivel = 1-2 vs. 3-5
* $k$ = 3: log-odds del nivel = 1-3 vs. 4-5
* $k$ = 4: log-odds del nivel = 1-4 vs. 5

## Ajuste del modelo.

Su usarán las funciones `ordinal::clm` y `ordinal::clmm` que respectivamente permiten ajustar modelos únicamente con efectos fijos o modelos mixtos (que combinan efectos fijos y aleatorios).

Comenzamos con un modelo simple que tiene un único predictor:


$$
\text{logit}(p(y_i \leq k)) = \tau_k - \beta_2 \text{Treat}_i
$$

```{r}
#| echo: true
clm_likert_treat <-
    clm(
        Response ~ Treat,
        data = df, link = "logit"
    )
summary(clm_likert_treat)
```

```{r}
#| echo: true
#| include: false
intercept.1.2.coef <- round(coef(clm_likert_treat)["1|2"], 2)
intercept.2.3.coef <- round(coef(clm_likert_treat)["2|3"], 2)
treatB.coef <- round(coef(clm_likert_treat)["TreatB"], 2)
```

El método `summary` muestra la información resumen. Para su interpretación vamos a seguir @christensen2018CumulativeLM. 

El número de condición Hessiano es inferior a $10^4$ lo que es indicativo de que no hay problemas de optimización
^[El número de condición de Hessiano es una medida de la curvatura de una función en un punto.
Si el número de condición de Hessiano es grande, la función es muy sensible a pequeñas perturbaciones y puede ser difícil de optimizar.].

La sección de coeficientes es la más importante. Se muestra la estimación de parámetros, el error "stardard" y la significación estadística de acuerdo al test de Wald
^[El test de Wald es un contraste de hipótesis estadístico en el que se evalúa si el valor estimado es cero suponiendo que $W = \left(\frac{\hat{\theta} - \theta_0}{se(\hat{\theta})}\right)^2 \sim \chi^{2}$
.]. Comprobamos que el valor es claramente significativo. Es decir, que los estudiantes han valorado de forma diferente la calidad del subtitulado en ambos vídeos. El estimador de maxima verosimilitud del coeficiente `TreatB` es `r treatB.coef`. Siguiendo la deducción de @bruin2011 podemos, por ejemplo, hacer la siguiente interpretación del significado de este coeficiente referido a dos niveles consecutivos de respuesta:

$$
\begin{aligned}
logit (P(Y \le 1)) & = & `r intercept.1.2.coef` - (`r treatB.coef` x_2) \\
logit (P(Y \le 2)) & = & `r intercept.2.3.coef` - (`r treatB.coef` x_2)
\end{aligned}
$$

Por lo tanto los $odds$ serían:

$$
\begin{aligned}
\frac{P(Y \le 1 \mid x_2 = B)}{P(Y > 1 \mid x_2 = B)} & = & exp(`r intercept.1.2.coef`)/exp(`r treatB.coef`) \\
\frac{P(Y \le 1 \mid x_2 = A)}{P(Y > 1 \mid x_2 = A)} & = & exp(`r intercept.1.2.coef`) \\
\frac{P(Y \le 2 \mid x_2 = B)}{P(Y > 2 \mid x_2 = B)} & = & exp(`r intercept.2.3.coef`)/exp(`r treatB.coef`) \\
\frac{P(Y \le 2 \mid x_2 = A)}{P(Y > 2 \mid x_2 = A)} & = & exp(`r intercept.2.3.coef`)
\end{aligned}
$$

Y los $OR$:

$$
\begin{aligned}
\frac{P(Y \le 1 | x_2=B)}{P(Y > 1 | x_2=B)} / \frac{P(Y \le 1 | x_2=A)}{P(Y > 1 | x_2=A)} & = & 1/exp(`r treatB.coef`) & = & `r round(1/exp(coef(clm_likert_treat)["TreatB"]), 2)` \\
\frac{P(Y \le 2 | x_2=B)}{P(Y > 2 | x_2=B)} / \frac{P(Y \le 2 | x_2=A)}{P(Y > 2 | x_2=A)} & = & 1/exp(`r treatB.coef`) & = & `r round(1/exp(coef(clm_likert_treat)["TreatB"]), 2)` \\
\end{aligned}
$$

Se comprueba que el $OR$ es equivalente en todos los niveles de respuesta al cuestionario. Esta es una de las suposiciones de la regresión ordinal acumulativa. El $odds$ de respuesta al cuestionario entre los niveles inferiores y superiores a uno dado, $k$, es `r round(1/exp(coef(clm_likert_treat)["TreatB"]), 2)` veces en el subtitulado $B$ que en el $A$. Esto indica que el subtitulado $B$ es percibido por los estudiantes como de peor calidad que el subtitulado $A$.

## Efecto periodo.

Añadimos un segundo predictor para constatar si existe efecto periodo.

$$
\text{logit}(p(y_i \leq k)) = \tau_k - \beta_1 \text{Period}_i - \beta_2 \text{Treat}_i
$$


```{r}
#| echo: true
clm_likert_period_treat <-
    clm(
        Response ~ Period + Treat,
        data = df, link = "logit"
    )
summary(clm_likert_period_treat)
```

Vemos que ambos coeficientes son significativos y con signo negativo. Un signo negativo en el efecto periodo está asociado a que la valoración del subtitulado empeora en el segundo periodo independientemente de si se trata del subtitulado correcto o incorrecto. Aplicando el mismo razonamiento del apartado anterior, el $OR$ del efecto periodo es $1/exp(`r round(coef(clm_likert_period_treat)["Period2"], 2)`) = `r round(1/exp(coef(clm_likert_period_treat)["Period2"]),2)`$. Lo que quiere decir que una vez controlado el efecto principal del tratamiento, el subtitulado en el segundo periodo es valorado como de inferior calidad que en el primero. Esto estaría indicando que los estudiantes son más exigentes con el subtitulado en la segunda actividad independientemente de su calidad real.

Podemos comparar ambos modelos con la prueba de razón de verosimilitud y comprobamos que el modelo con efecto periodo reduce la función de verosimilitud y, por lo tanto, debe ser aceptado:

```{r}
#| echo: true
anova(clm_likert_treat, clm_likert_period_treat)
```

Con la función `drop1` se puede realizar este mismo test, razón de verosimilitudes, para cada variable explicativa del modelo controlando las restantes.

```{r}
#| echo: true
drop1(clm_likert_period_treat, test = "Chi")
```

Y con la función `add1`, que hace el test de cada variable explicativa ignorando las restantes:

```{r}
#| echo: true
# Fit the null model first
clm_likert_null <- clm(Response ~ 1, data = df, link = "logit")
add1(clm_likert_null, scope = ~ Period + Treat, test = "Chi")
```

En la @fig-clm_likert_period_treat-confint se muestran los intervalos de confianza de los parámetros del modelo.

```{r}
#| label: fig-clm_likert_period_treat-confint
#| fig-cap: Intervalos de confianza
tidy(clm_likert_period_treat, conf.int = TRUE, conf.type = "Wald") %>%
    ggplot(aes(y = term, x = estimate)) +
    geom_point(size = 2) +
    geom_linerange(linewidth = 1, aes(xmin = conf.low, xmax = conf.high))
```

## Modelo con interacción entre periodo y subtítulos.


$$
\text{logit}(p(y_i \leq k)) = \tau_k - \beta_1 \text{Period}_i - \beta_2 \text{Treat}_i - \beta_3 \text{Period}_i\text{Treat}_i
$$

```{r}
#| echo: true
clm_likert_period_treat_inter <-
    clm(
        Response ~ Period * Treat,
        data = df, link = "logit"
    )
summary(clm_likert_period_treat_inter)
anova(clm_likert_period_treat, clm_likert_period_treat_inter)
```

Vemos que hay evidencia de que existe una interacción entre periodo y subtítulos. Cuando esto sucede se tiende a dar mayor importancia a esta interacción que a los efectos principales de cada factor.

## Modelo con efectos mixtos.

Añadimos al modelo a los sujetos como efecto aleatorio.

```{r}
#| echo: true
clmm_likert_period_treat_inter_subject <-
    clmm(
        Response ~ Period * Treat + (1 | Subject),
        data = df, link = "logit"
    )
summary(clmm_likert_period_treat_inter_subject)
```

Vemos que ahora la interacción periodo y tratamiento no es significativa. Eliminamos la interacción tratamiento y periodo mantenemos el efecto aleatorio de los estudiantes.


```{r}
#| echo: true
clmm_likert_period_treat_subject <-
    clmm(
        Response ~ Period + Treat + (1 | Subject),
        data = df, link = "logit"
    )
summary(clmm_likert_period_treat_subject)
anova(clmm_likert_period_treat_subject, clmm_likert_period_treat_inter_subject)
```

## Factor preguntas.

Las preguntas se pueden incorporar al modelo como efecto fijo o como efecto aleatorio.

TODO: Comentar las implicaciones que tiene cada variante.

### Preguntas como efecto aleatorio.


```{r}
#| echo: true
clmm_likert_period_treat_subject_question <-
    clmm(
        Response ~ Period + Treat + (1 | Subject) + (1 | Item),
        data = df, link = "logit"
    )

summary(clmm_likert_period_treat_subject_question)
anova(clmm_likert_period_treat_subject, clmm_likert_period_treat_subject_question)
```

En la sección `Random effects` vemos que la varianza explicada por el efecto aleatorio preguntas es muy inferior a la explicada por los estudiantes. Sin embargo, la comparación entre modelos es altamente significativa.

### Preguntas como efecto fijo.

Se ha usado la pregunta 18 como nivel de referencia porque al ser una pregunta sobre la valoración general del subtitulado tiene más interés su comparación con cada pregunta individual. 

```{r}
#| echo: true
clmm_likert_period_treat_question_subject <-
    clmm(
        Response ~ Period + Treat + Item + (1 | Subject),
        data = df, link = "logit"
    )

summary(clmm_likert_period_treat_question_subject)
anova(clmm_likert_period_treat_subject, clmm_likert_period_treat_question_subject)
```

Vemos que la mayoría de los factores `Item` no son significativos.

### Análisis del efecto periodo.

En la sección anterior se ha constatado la existencia de efecto periodo. En este apartado nos planteamos si el efecto periodo afecta a todas las preguntas o podemos encontrar un grupo de preguntas que carezcan de efecto periodo.

Vamos a agrupar las preguntas por la similitud de su frecuencia de respuestas y aplicaremos una técnica de `clustering` jerárquico aglomerativo para encontrar los grupos de preguntas más parecidos.

En el dendograma (@fig-dendo) se aprecian claramente tres agrupamientos. Es muy interesante constatar que los tres grupos están formados por preguntas que en su mayor parte son correlativas. Esto es consistente con que al elaborar un test normalmente se colocan las preguntas por unidades temáticas y con que el que el encuestado también suele hacerlo teniendo en cuenta esta estructura y tiende a responder de forma similar a las preguntas correlativas.


```{r}
#| fig-cap: Dendograma del cluster de preguntas
#| label: fig-dendo


plot(cluster)
```


Podemos distinguir los siguientes grupos y subgrupos:

* Grupo 1: Es el más numeroso. En general está formado por preguntas sobre el grado de dificultad que presenta la lectura del subtítulo.
    * Subgrupo preguntas Q01, Q02, Q03: Colocación de los subtítulos.
    * Subgrupo preguntas Q10, Q11, Q12: Sincronización, velocidad y número de líneas.
    * Subgrupo preguntas Q04, Q13: Contraste y legibilidad.

* Grupo 2: Trata sobre la corrección del subtítulo.
    * Subgrupo 05, 06, 07, 08, 09: Preguntas sobre si la información que presenta el subtítulo es correcta y está bien escrita.
    * Pregunta 18: Valoración general del subtitulado. El que esta pregunta esté incluida en el grupo sobre corrección estaría indicando que este es el apartado al que más importancia dan los estudiantes a la hora de valorar la calidad del subtitulado.

* Grupo 3: Es un grupo con preguntas heterogéneas y cuyo nexo parece ser únicamente su colocación al final del cuestionario. Está formado por las preguntas Q14, Q15, Q16 y Q17.

Es interesante analizar si existe efecto periodo en cada grupo de preguntas. Si analizamos el efecto periodo en las preguntas de cada cluster, constatamos que el único grupo de preguntas sin efecto periodo son las del tercer grupo. Esto es consistente con que son preguntas que presentan una valoración muy similar para ambos grupos en el mismo nivel de tratamiento (TODO: Poner enlace a la sección de la exploración inicial).

```{r}
#| echo: true
df %>%
    filter(Cluster == 3) %>%
    clmm(
        Response ~ Period + Treat + Item + (1 | Subject),
        data = ., link = "logit"
    ) %>%
    summary()
```



## Predicciones

En la @fig-ordinal.pred mostramos la probabilidad de respuesta que produce el modelo ajustado para cada periodo y nivel de tratamiento. Constatamos que para ambos tratamientos en el segundo periodo las respuestas tienen mayor probabilidad de tener menor puntuación en el test de Likert.

```{r}
#| fig-cap: Predicción de la probabilidad de respuesta de la regresión ordinal para cada nivel de tratamiento y periodo.
#| label: fig-ordinal.pred
nd <-
    crossing(
        Period = factor(c(1, 2)),
        Treat = factor(c("A", "B")),
        Response = factor(1:5, ordered = T)
    )

nd %>%
    bind_cols(predict(clm_likert_period_treat, nd)) %>%
    ggplot(aes(x = glue::glue("{Treat}-{Period}"), y = fit, fill = Response)) +
    geom_col() +
    scale_fill_td(palette = "div5") +
    scale_y_continuous(expand = c(0, 0), labels = scales::percent) +
    labs(x = "Treat-Period", y = "predicted probability")
```

Con el paquete `emmeans` ponemos computar la diferencia estimada de medias marginales para niveles de tratamiento y periodos.

```{r}
library(emmeans)
emmeans(clmm_likert_period_treat_question_subject,
    specs = list(pairwise ~ Period, pairwise ~ Treat, pairwise ~ Period + Treat), mode = "latent"
)
```

Finalmente en la @fig-contint-ordinal mostramos los intervalos de confianza de las probabilidades de respuesta marginalizadas por periodo y tratamiento. 

```{r}
#| fig-cap: Intervalos de confianza de la probabilidad de respuesta marginalizada.
#| label: fig-contint-ordinal
emmeans(clmm_likert_period_treat_question_subject,
    ~ Period + Treat | Response,
    mode = "prob"
) %>%
    plot()
```

Es interesante comprobar que la probabilidad de responder con valor 4 (De Acuerdo) no varía demasiado con el nivel de tratamiento y periodo. TODO: Poner enlace al gráfico de la exploración inicial en la que esto se puede constatar.







#
#
#
#