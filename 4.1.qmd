## Comparación con $Odds\ Ratio$ {#sec-or-2}

En la sección @sec-or se explicó el fundamento teórico de esta técnica. Aquí se expone como se puede aplicar al diseño de experimento que se está analizando. En la sección de resultados se comentarán e interpretarán los valores producidos por este test. 

Dado que los factores $Treat$, $Period$ y $Seq$ tienen todos 2 niveles, podemos contrastar si hay interacción entre ellos para cada nivel de respuesta. Es decir, se contrasta la hipótesis $H_0: OR=1$ de ausencia de interacción frente a $H_1: $OR \neq 1$ de existencia de interacción en algún nivel de respuesta. Por ejemplo, el $OR$ para el nivel respuesta $r$ entre subtítulos y secuencias se define de la siguiente forma:

$$
OR_{(Treat, Seq \mid Response=r)}=\frac{
    \frac{
            P(Treat=A \mid Seq=AB, Response=r)
        }{
            P(Treat=B \mid Seq=AB, Response=r)
        }
    }
    {\frac{
        P(Treat=A \mid Seq=BA, Response=r)
        }{
        P(Treat=B \mid Seq=BA, Response=r)
    }
}
$$

Si los $odds$ son similares en cada nivel de respuesta, podemos aceptar que la hipótesis nula de que los grupos responden de forma similar a cada nivel de subtitulado. Se hará un test similar pero entre subtitulado y periodos.


## Regresión Logística {#sec-logistica-2}

En la @sec-logistica se presentó el fundamento teórico de la Regresión Logística. En esta sección se justifica el uso de este modelo y se ajustan y comparan varios modelos. La variable respuesta se compone de 5 valores ordenados. Esto imposibilita usar directamente la Regresión Logística. No obstante, podemos comparar la respuesta que cada estudiante dio a cada uno de los subtitulados y comprobar si ha mejorado. Esto producirá una variable de respuesta binaria que permitirá el uso de la Regresión Logística. No obstante, esta transformación reducirá la cantidad de datos disponibles a la mitad e impedirá analizar el efecto periodo ya que al comparar los subtitulados, desaparece el periodo. Se ha transformado el `dataframe` de tal forma que si un usuario valoró una pregunta mejor en el subtitulado $A$ que en el $B$, se consigna 1 en la variable respuesta, si empeoró o puntuó igual se consigna 0. Si en uno de los test valora una pregunta con "No sé / No contesto", se elimina esa pregunta.

Se ajusta el modelo con la secuencia como predictor. Se constata que el coeficiente del intercepto es positivo y significativo. El intercepto es el $log\ odds$ de mejorar la valoración en $A$ sobre $B$ respecto a empeorar la valoración. Sin embargo, la secuencia no resulta significativa y además añadirla apenas reduce la "deviance", por lo que el modelo nulo sin predictores resulta más parsimonioso. Se podrían añadir como predictores las preguntas y los estudiantes. No se hace aquí y se pospone la discusión hasta el uso de modelos mixtos.

```{r}
glm_improve_seq <- glm(Improve ~ 1 + Seq, family = "binomial", data = df_improve)
summary(glm_improve_seq)
```

## Regresión Ordinal {#sec-ordinal-2}

En la @sec-ordinal se presentó el fundamento teórico de la Regresión Ordinal Acumulativa. En esta sección se ajustan algunos modelos y se interpretan los resultados.

### Ajuste del modelo ordinal `Response ~ Treat`

Existen varios paquetes en R que permiten ajustar una regresión ordinal logística. El más popular es el paquete `Ordinal` [@ordinalR]. El paquete `VGAM` [@VGAMR] es más flexible y potente. Otra posibilidad es usar la función `polr` del paquete `MASS` [@MASSR]. Finalmente la función `orm` del paquete `rms` también permite hacerlo [ver @harrell2015]. En este trabajo usaremos el paquete `Ordinal` por permitir también incluir efectos aleatorios que utilizaremos en un apartado posterior. Comenzamos con un modelo simple que tiene como único predictor el nivel de subtitulado por ser la variable objetivo de nuestro modelo:

$$
\text{logit}(P(Response_i \leq k)) = \tau_k - \beta_1 \text{Treat}_i,
$$


\scriptsize
```{r}
#| echo: true
clm_treat <-
    clm(
        Response ~ Treat,
        data = df_clean, link = "logit"
    )
summary(clm_treat)
```
\normalsize

```{r}
intercept.1.2.coef <- round(coef(clm_treat)["1|2"], 2)
intercept.2.3.coef <- round(coef(clm_treat)["2|3"], 2)
treatB.coef <- round(coef(clm_treat)["TreatB"], 2)
logit.1 <- coef(clm_treat)["1|2"] - coef(clm_treat)["TreatB"]
logit.2 <- coef(clm_treat)["2|3"] - coef(clm_treat)["TreatB"]
```

El método `summary()` muestra la información resumen. Para su interpretación vamos a seguir @christensen2018CumulativeLM. El número de condición Hessiano es inferior a $10^4$ lo que es indicativo de que no hay problemas de optimización
^[El número de condición de Hessiano es una medida de la curvatura de una función en un punto.
Si el número de condición de Hessiano es grande, la función es muy sensible a pequeñas perturbaciones y puede ser difícil de optimizar.]. La sección de coeficientes es la más importante. Se muestra la estimación de parámetros, el error estándar y la significación estadística de acuerdo al test de Wald
^[El test de Wald es un contraste de hipótesis estadístico en el que se evalúa si el valor estimado es cero suponiendo que $W = \left(\frac{\hat{\theta} - \theta_0}{se(\hat{\theta})}\right)^2 \sim \chi^{2}$
.]. Comprobamos que el valor es claramente significativo. Es decir, que los estudiantes han valorado de forma diferente la calidad del subtitulado en ambos vídeos. El estimador de maxima verosimilitud del coeficiente `TreatB` es `r treatB.coef`. Siguiendo la deducción de @bruin2011 podemos, por ejemplo, hacer la siguiente interpretación del significado de este coeficiente referido a dos niveles consecutivos de respuesta:

$$
\begin{aligned}
logit [P(Y \le 1)] & = & `r intercept.1.2.coef` - (`r treatB.coef` x_1) \\
logit [P(Y \le 2)] & = & `r intercept.2.3.coef` - (`r treatB.coef` x_1)
\end{aligned}
$$

Por lo tanto los $odds$ serían:

$$
\begin{aligned}
\frac{P(Y \le 1 \mid x_1 = B)}{P(Y > 1 \mid x_1 = B)} & = & exp(`r intercept.1.2.coef`)/exp(`r treatB.coef`) \\
\frac{P(Y \le 1 \mid x_1 = A)}{P(Y > 1 \mid x_1 = A)} & = & exp(`r intercept.1.2.coef`) \\
\frac{P(Y \le 2 \mid x_1 = B)}{P(Y > 2 \mid x_1 = B)} & = & exp(`r intercept.2.3.coef`)/exp(`r treatB.coef`) \\
\frac{P(Y \le 2 \mid x_1 = A)}{P(Y > 2 \mid x_1 = A)} & = & exp(`r intercept.2.3.coef`)
\end{aligned}
$$

Y los $OR$:

$$
\begin{aligned}
\frac{P(Y \le 1 | x_1=B)}{P(Y > 1 | x_1=B)} / \frac{P(Y \le 1 | x_1=A)}{P(Y > 1 | x_1=A)} & = & 1/exp(`r treatB.coef`) & = & `r round(1/exp(coef(clm_treat)["TreatB"]), 2)` \\
\frac{P(Y \le 2 | x_1=B)}{P(Y > 2 | x_1=B)} / \frac{P(Y \le 2 | x_1=A)}{P(Y > 2 | x_1=A)} & = & 1/exp(`r treatB.coef`) & = & `r round(1/exp(coef(clm_treat)["TreatB"]), 2)` \\
\end{aligned}
$$

Se comprueba que el $OR$ es equivalente en todos los niveles de respuesta al cuestionario. Esta es una de las suposiciones de la regresión ordinal acumulativa. El $odds$ de respuesta al cuestionario entre los niveles inferiores y superiores a uno dado, $k$, es `r round(1/exp(coef(clm_treat)["TreatB"]), 2)` veces en el subtitulado $B$ que en el $A$. Esto indica que el subtitulado $B$ es percibido por los estudiantes como de peor calidad que el subtitulado $A$. Concretamente, el coeficiente $\beta$ para `Treat` es el `log odds` de observar una mejor respuesta en una pregunta del test es `r round(1/exp(coef(clm_treat)["TreatB"]), 2)` veces superior en el nivel de subtitulado $A$ que en el $B$. Aunque no suele ser de interés la interpretación de los coeficientes de los umbrales (`Threshold coefficients`), se pueden utilizar para estimar las probabilidades de respuesta. Por ejemplo, para el nivel de subtitulado $B$:

$$
\begin{aligned}
logit [P(Y \le 1)] & = & `r intercept.1.2.coef` - (`r treatB.coef`) & = & `r round(logit.1, 2)` \\
odds (P(Y \le 1)) & = & exp(logit [P(Y \le 1)]) & = & `r round(exp(logit.1),2)` \\
P(Y \le 1) & = & \frac{exp(`r round(logit.1, 2)`)}{1 + exp(`r round(logit.1, 2)`)} & = & `r sprintf("%.2f", exp(logit.1)/(1+ exp(logit.1)))` \\
P(Y \le 2) & = & \frac{exp(`r round(logit.2, 2)`)}{1 + exp(`r round(logit.2, 2)`)} & = & `r sprintf("%.2f", exp(logit.2)/(1+ exp(logit.2)))` \\
P(Y = 2) & = & P(Y \le 2) - P(Y \le 1) & = &  `r sprintf("%.2f", exp(logit.2)/(1+exp(logit.2)) - exp(logit.1)/(1+ exp(logit.1)))` 
\end{aligned}
$$

Para el subtitulado $A$ no se tiene en cuenta el coeficiente $TreatB$ ya que el valor $x_1$ es cero:


$$
\begin{aligned}
logit [P(Y \le 1)] & = & & & `r intercept.1.2.coef`\\
odds (P(Y \le 1)) & = & exp(logit [P(Y \le 1)]) & = & `r round(exp(coef(clm_treat)["1|2"]),2)` \\
P(Y \le 1) & = & \frac{exp(`r round(coef(clm_treat)["1|2"], 2)`)}{1 + exp(`r round(coef(clm_treat)["1|2"], 2)`)} & = & `r round(exp(coef(clm_treat)["1|2"])/(1+ exp(coef(clm_treat)["1|2"])), 2)`
\end{aligned}
$$

En @tbl-probs-clm-treat se muestran las probabilidades para ambos niveles de subtitulado y todos los posibles valores de respuesta.
```{r}
#| label: tbl-probs-clm-treat
#| tbl-cap: Probabilidades de respuesta para el modelo ordinal Response ~ Treat
probs_clm_treat <- predict(clm_treat, newdata = data.frame(Treat = c("A", "B")), type = "prob")$fit
rownames(probs_clm_treat) <- c("A", "B")

round(probs_clm_treat, 3) %>% knitr::kable()
```

### Ajuste del modelo ordinal `Response ~ Treat + Period`

Para saber si existe un efecto periodo, añadimos como predictor la variable `Period`.


$$
\text{logit}(P(Response_i \leq k)) = \tau_k - \beta_1 \text{Treat}_i - \beta_2 \text{Period}_i
$$


\scriptsize
```{r}
#| echo: true
clm_treat_period <-
    clm(
        Response ~ Treat + Period,
        data = df_clean, link = "logit"
    )
summary(clm_treat_period)
```
\normalsize

Vemos que ambos coeficientes son significativos y con signo negativo. Un signo negativo en el efecto periodo está asociado con que la valoración del subtitulado empeora en el segundo periodo independientemente de si se trata del subtitulado correcto o incorrecto. Aplicando el mismo razonamiento del apartado anterior, el $OR$ del efecto periodo es $1/exp(`r round(coef(clm_treat_period)["Period2"], 2)`) = `r round(1/exp(coef(clm_treat_period)["Period2"]),2)`$. Lo que quiere decir que una vez controlado el efecto principal del tratamiento, el subtitulado en el segundo periodo es valorado como de inferior calidad que en el primero. Esto estaría indicando que los estudiantes son más exigentes con el subtitulado en la segunda actividad independientemente de su calidad real.


### Ajuste del modelo ordinal `Response ~ Treat * Period`

Añadimos al modelo la interacción entre subtitulado y periodo. Esta interacción corresponde al efecto secuencia. Se puede demostrar que los modelos `Response ~ Treat*Period` y `Response ~ Treat + Period + Seq` [ver @sec-contrasts].

\scriptsize
```{r}
#| echo: true
options(contrasts = rep("contr.treatment", 2))
clm_treat.period <-
    clm(
        Response ~ Treat * Period,
        data = df_clean, link = "logit"
    )
summary(clm_treat.period)
```
\normalsize


Vemos que los tres coeficientes son significativos. El principal efecto es el nivel de subtitulado obteniendo mejores puntuaciones el nivel $A$; el efecto periodo es negativo por lo que el primer periodo obtiene mejores puntuaciones; por último, el efecto secuencia es positivo pero de menor valor absoluto que el efecto periodo. Esto quiere decir que el subtitulado de nivel $B$ en el periodo 2 (secuencia $AB$), tiene un efecto periodo inferior que el subtitulado $A$ en el mismo periodo. Matemáticamente:

```{r}
intercept.1.2.coef <- round(coef(clm_treat.period)["1|2"], 2)
treatB.coef <- round(coef(clm_treat.period)["TreatB"], 2)
period2.coef <- round(coef(clm_treat.period)["Period2"], 2)
treatB.period2.coef <- round(coef(clm_treat.period)["TreatB:Period2"], 2)
```


$$
\begin{aligned}
logit [P(Y \le 1 \mid Treat = A, Period = 1)] & = & `r intercept.1.2.coef` \\
logit [P(Y \le 1 \mid Treat = B, Period = 1)] & = & `r intercept.1.2.coef` - (`r treatB.coef`) \\
logit [P(Y \le 1 \mid Treat = A, Period = 2)] & = & `r intercept.1.2.coef` - (`r period2.coef`) \\
logit [P(Y \le 1 \mid Treat = B, Period = 2)] & = & `r intercept.1.2.coef` -(`r treatB.coef` `r  period2.coef` + `r treatB.period2.coef`)
\end{aligned}
$$

En definitiva, en el nivel de subtitulado $B$ apenas encontramos diferencias entre periodos, sin embargo, en el nivel de subtitulado $A$ existe un efecto periodo cuyo valor en `logits` es `r period2.coef`. Es decir, que la valoración del subtitulado de nivel $A$ es inferior en el segundo periodo que en el primero.

### Elección del modelo ordinal mediante el test de razón de verosimilitud

Al ser los tres modelos anidados, podemos compararlos con la prueba de razón de verosimilitud. Comprobamos que el tercer modelo (el que incorpora la interacción entre los subtítulos y el periodo) reduce significativamente el logaritmo de la función de verosimilitud y, por lo tanto, debe ser aceptado:

\scriptsize
```{r}
#| echo: true
anova(clm_treat, clm_treat_period, clm_treat.period)
```
\normalsize

### Comprobación de las hipótesis del modelo

La principal hipótesis de un modelo de regresión logística ordinal proporcional acumulativa es que los coeficientes son iguales entre cualesquiera dos niveles de respuestas correlativos. Se han propuesto diversas fórmulas para comprobar esta hipótesis. El paquete `Ordinal` dispone de la función `nominal_test()` que lo que hace es realizar un test de razón de verosimilitud para cada predictor ajustando un modelo en el que se ha relajado la condición de proporcionalidad. Se constata que el test resulta significativo para `Treat` y para `Treat:Period`, por lo que para estas dos variables no se puede asumir que los coeficientes estimados se mantengan constantes en todos los niveles de respuesta.

\scriptsize
```{r}
#| echo: true
nominal_test(clm_treat.period)
```
\normalsize

 Lo que procede es ajustar el modelo relajando la constante de proporcionalidad de esas variables. Se ha realizado esto utilizando la función `vglm` del paquete `VGAM`. Vemos que ahora hay cuatro coeficientes para cada una de las variables `Treat` y `Treat:Period`
 ^[Los umbrales tienen los mismos valores pero de signo contrario debido a diferencias en la parametrización del modelo en cada función utilizada.].


\scriptsize
```{r}
#| echo: true
vglm_treat.period <- vglm(
    Response ~ Treat * Period,
    VGAM::cumulative(link = "logit", parallel = F ~ Treat + Treat:Period, reverse = T),
    data = df_clean
)
coef(vglm_treat.period) %>% data.frame()
```
\normalsize

```{r}
accuracy.vglm_treat.period <- sum(apply(predict(vglm_treat.period, newdata = df_clean, type = "response"), 1, which.max) == df_clean$Response) / nrow(df_clean)
``` 
