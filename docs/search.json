[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "",
    "text": "1 Introducción"
  },
  {
    "objectID": "index.html#motivación",
    "href": "index.html#motivación",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.1 Motivación",
    "text": "1.1 Motivación"
  },
  {
    "objectID": "index.html#propuesta-y-objetivo",
    "href": "index.html#propuesta-y-objetivo",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.2 Propuesta y objetivo",
    "text": "1.2 Propuesta y objetivo"
  },
  {
    "objectID": "index.html#estructura-del-documento",
    "href": "index.html#estructura-del-documento",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.3 Estructura del documento",
    "text": "1.3 Estructura del documento"
  },
  {
    "objectID": "31-Preprocesamiento.html#fuente-de-datos.",
    "href": "31-Preprocesamiento.html#fuente-de-datos.",
    "title": "4  Métodos.",
    "section": "4.1 Fuente de datos.",
    "text": "4.1 Fuente de datos.\nLos datos proceden de la edición de 2022 del curso MOOC Materiales digitales accesibles de la UNED. Concretamente a los estudiantes matriculados se les propuso que realizaran una actividad voluntaria consistente en evaluar la calidad del subtitulado de dos vídeos. Los vídeos eran idénticos y se diferenciaban únicamente en la calidad del subtitulado. Los subtítulos de uno de los vídeos se realizaron (ver Pérez Martín, Rodríguez-Ascaso, y Molanes-López 2021; Molanes-López et al. 2021) siguiendo las guía Web Content Accessibility Guidelines 2.1 (WCAG 2.1) del W3C (World Wide Web Consortium). El otro vídeo tenía un subtitulado similar pero se introdujeron pequeñas deficiencias inapreciables para alguien que carezca de conocimientos sobre accesibilidad. Los estudiantes fueron clasificados en dos grupos. Al primer grupo se le presentó primero el vídeo correctamente subtitulado y luego el otro. El segundo grupo realizó la actividad cruzada: primero evaluó el vídeo mal subtitulado y luego el bien subtitulado. Tras ver cada uno de los vídeos, los estudiantes tuvieron la oportunidad de valorar la calidad del subtitulado realizando un test en escala de Likert de 18 items y 5 niveles cada item 1. Los 18 items de Likert pretenden asegurar los criterios de la norma UNE 153010 (ver AENOR 2012).\nEn la Tabla 4.1 se muestran los 5 niveles de cada uno de los items de la escala de Likert utilizados para valorar el subtitulado 2:\n\n\n\n  \n  \n\n\nTabla 4.1: Niveles de los items de la escala de Likert.\n\n\nvalues\nlevels\n\n\n\n\n0\nNo sé / No contesto\n\n\n1\nMuy en desacuerdo\n\n\n2\nEn desacuerdo\n\n\n3\nNeutral\n\n\n4\nDe acuerdo\n\n\n5\nMuy de acuerdo\n\n\n\n\n\n\n\n\nEn la Tabla 4.2 se muestran los 18 items de la escala de Likert que se propuso a los alumnos para que evaluaran cada uno de los vídeos:\n\n\n\n\n\n\n\n\nTabla 4.2: Items de la escala de Likert.\n\n\nItem\nTexto\n\n\n\n\nQ01\nLa posición de los subtítulos.\n\n\nQ02\nEl número de líneas por subtítulo.\n\n\nQ03\nLa disposición del texto respecto a la caja donde se muestran los subtítulos.\n\n\nQ04\nEl contraste entre los caracteres y el fondo.\n\n\nQ05\nLa corrección ortográfica y gramatical.\n\n\nQ06\nLa literalidad.\n\n\nQ07\nLa identificación de los personajes.\n\n\nQ08\nLa asignación de líneas a los personajes en los diálogos.\n\n\nQ09\nLa descripción de efectos sonoros.\n\n\nQ10\nLa sincronización de las entradas y salidas de los subtítulos.\n\n\nQ11\nLa velocidad de exposición de los subtítulos.\n\n\nQ12\nEl máximo número de caracteres por línea.\n\n\nQ13\nLa legibilidad de la tipografía.\n\n\nQ14\nLa separación en líneas diferentes de sintagmas nominales, verbales y preposicionales.\n\n\nQ15\nLa utilización de puntos suspensivos.\n\n\nQ16\nLa escritura de los números.\n\n\nQ17\nLas incorrecciones en el habla.\n\n\nQ18\nLos subtítulos del vídeo cumplen en general con los requisitos de accesibilidad.\n\n\n\n\n\n\n\n\nLos datos personales de los estudiantes se suministraron anonimizados para evitar ninguna referencia a su identidad. Del estudio se han eliminado a aquellos estudiantes que, a pesar de haber realizado la actividad, no dieron su autorización para que sus datos se utilizaran en un estudios científicos.\nSe dispuso de los siguientes ficheros csv:\n\nEl fichero grade contiene el identificador de estudiante y el grupo al que pertenece (campo cohort).\nEl fichero abo es la información socioeconómica que voluntariamente ha aportado el estudiante: sexo, año nacimiento, nivel de estudios, ocupación.\nEl fichero conoc contiene el test de evaluación inicial de conocimientos del estudiante.\nEl fichero exp es la evaluación del curso realizada por cada estudiante.\nEl fichero acc contiene la información sobre las necesidades/preferencias de accesibilidad que tiene el estudiante.\nLos ficheros test1 y test2 son las repuestas al test de Likert sobre la calidad del subtitulado del primer y del segundo vídeo realizado por cada grupo respectivamente."
  },
  {
    "objectID": "31-Preprocesamiento.html#sec-diseno",
    "href": "31-Preprocesamiento.html#sec-diseno",
    "title": "4  Métodos.",
    "section": "4.2 Características del diseño del experimento.",
    "text": "4.2 Características del diseño del experimento.\nEl diseño del experimento es completamente aleatorizado, de respuesta ordinal, cruzado \\(AB/BA\\) y doble ciego. Es decir, que la asignación de los estudiantes a cada grupo fue aleatoria; cada grupo vio los vídeos en orden inverso; los estudiantes no conocían a priori qué vídeo estaban viendo en cada momento y tampoco se disponía de esta información en el momento de realizar el análisis estadístico de los datos.\nUn diseño completamente aleatorizado (Lawson 2015, 18) “garantiza la validez del experimento contra sesgos causados por otras variables ocultas. Cuando las unidades experimentales se asignan aleatoriamente a los niveles de factor de tratamiento, se puede realizar una prueba exacta de la hipótesis de que el efecto del tratamiento es cero utilizando una prueba de aleatorización”.\nSiguiendo a Senn (2022), para que el ensayo sea de tipo cruzado no sería suficiente intercambiar las secuencias sino que debe ser objeto del ensayo el estudio de las diferencias entre los tratamientos individuales que componen las secuencias. Los principales problemas de un diseño cruzado son el abandono, drop-out, de alguno de los participantes y la interacción entre el tratamiento y el periodo o carry-over. Además, el análisis estadístico es más complicado y particularmente cuando la respuesta es ordinal y hay más de dos tratamientos. En la misma línea, Lui (2016) afirma que “el objetivo principal de un diseño cruzado es estudiar la diferencia entre tratamientos individuales (en lugar de la diferencia entre secuencias de tratamiento). Debido a que cada paciente sirve como su propio control, el diseño cruzado es una alternativa útil al diseño de grupos paralelos para aumentar la potencia”.\nLas respuestas a un test de Likert se realizan en escala ordinal. No es adecuado realizar operaciones aritméticas para calcular medias con este tipo de datos. Por ello, los test estadísticos para analizar el efecto de un tratamiento con respuesta continua como son ANOVA y \\(t\\)-test no son adecuados con datos ordinales. Una opción es tratar los datos ordinales como si se tratara de datos categóricos y utilizar técnicas no paramétricas como el test de Kruskal-Wallis. El problema de este tipo de técnicas es que ignoran que los datos tienen una escala y, en el caso particular del diseño que nos ocupa, se trata de datos longitudinales. Es decir, que se toman varias medidas de cada sujeto y, por lo tanto, los datos no son independientes. Agresti (2010) expone un catálogo de técnicas para analizar datos categóricos y ordinales."
  },
  {
    "objectID": "31-Preprocesamiento.html#objetivo.",
    "href": "31-Preprocesamiento.html#objetivo.",
    "title": "4  Métodos.",
    "section": "4.3 Objetivo.",
    "text": "4.3 Objetivo.\nEl objetivo del estudio es responder a la pregunta de investigación:\nSon los estudiantes de un curso de accesibilidad capaces de encontrar los errores en el subtitulado de un vídeo. Para ello se propondrán diversos test y modelos estadísticos que tengan en consideración las características que se han comentado en el diseño del experimento (ver Sección 4.2). Particularmente se tendrá en cuenta que se trata de un diseño cruzado con variable respuesta ordinal y variables explicativas longitudinales."
  },
  {
    "objectID": "31-Preprocesamiento.html#sec-preprocesado",
    "href": "31-Preprocesamiento.html#sec-preprocesado",
    "title": "4  Métodos.",
    "section": "4.4 Preprocesamiento.",
    "text": "4.4 Preprocesamiento.\nPartiendo de los ficheros suministrados (ver Sección 4.2), se realiza el siguiente preprocesado (para ver el código ejecutado consultar Apéndice A):\n\nSe lee el fichero de perfil del usuario. El número de fila con el que el usuario aparece en el fichero se utilizará como identificador del usuario para mantener la trazabilidad y comprobar que las transformaciones realizadas son correctas.\nSe eliminan los datos de los estudiantes que aún habiendo realizado la actividad, no han dado su consentimiento para participar en el estudio.\nEl valor del campo cohort se sustituye por una letra, \\(A\\) o \\(B\\), en función del grupo asignado. En el momento de realizar este proceso se desconoce qué vídeo vio primero cada grupo.\nSe lee el fichero profile y se añade información sobre el sexo, el año de nacimiento y el nivel de estudios.\nSe lee el fichero conoc y se calcula cuántas preguntas acertó cada usuario en el test de evaluación de conocimientos previos. Se añade esta información al perfil del usuario.\nSe leen los ficheros de test y se procesan. Se utiliza el nombre del fichero (test1 o test2) para saber de qué vídeo se está respondiendo el test 3.\nSe seleccionan las preguntas que contienen las respuestas y se renombran para que sea más fácil saber de qué pregunta se trata 4. Se convierte el campo LastTry, que contiene la fecha y hora de realización del test, a formato fecha y hora.\nSe realizan algunas comprobaciones como la ausencia de valores nulos en la variables más relevantes o que no existan inconsistencias ni errores de procesado.\nSe eliminan los comentarios y se graban en fichero aparte para que no revelen información que podría descubrir el tipo de subtitulado que piensa que está evaluando el estudiante.\nSe almacenan los resultados de los test preprocesados en un fichero csv.\n\n\n\n\n\nAENOR. 2012. «UNE 153010 Subtitulado para personas sordas y personas con discapacidad auditiva». Asociación Española de Normalización y Certificación.\n\n\nAgresti, Alan. 2010. Analysis of Ordinal Categorical Data. https://doi.org/10.1002/9780470594001.\n\n\nGuerra, Andrea, Thierry Gidel, y Enrico Vezzetti. 2016. «Toward a common procedure using likert and likert-type scales in small groups comparative design observations». En.\n\n\nLawson, J. 2015. Editado por Chapman y Hall/CRC. https://doi.org/10.1201/b17883.\n\n\nLui, Kung-Jong. 2016. Crossover Designs: Testing, Estimation, and Sample Size. Crossover designs: Testing, estimation, and sample size. https://doi.org/10.1002/9781119114710.\n\n\nMolanes-López, Elisa M., Alejandro Rodriguez-Ascaso, Emilio Letón, y Jorge Pérez-Martín. 2021. «Assessment of Video Accessibility by Students of a MOOC on Digital Materials for All». IEEE Access 9: 72357-67. https://doi.org/10.1109/ACCESS.2021.3079199.\n\n\nPérez Martín, Jorge, Alejandro Rodríguez-Ascaso, y Elisa Molanes-López. 2021. «Quality of the captions produced by students of an accessibility MOOC using a semi-automatic tool». Universal Access in the Information Society 20 (noviembre). https://doi.org/10.1007/s10209-020-00740-9.\n\n\nSenn, Stephen. 2022. Editado por Ltd John Wiley. https://doi.org/10.1002/0470854596."
  },
  {
    "objectID": "31-Preprocesamiento.html#footnotes",
    "href": "31-Preprocesamiento.html#footnotes",
    "title": "4  Métodos.",
    "section": "",
    "text": "Para una descripción sobre cómo se debe realizar una escala de Likert consultar Guerra, Gidel, y Vezzetti (2016).↩︎\nEn la codificación original los valores asignados a cada respuesta eran diferentes: la opción No sé / No contesto se codificó con 5 y las demás opciones con una unidad menos que la mostrada. En este trabajo se ha hecho una rotación para asignar valores más usuales en la literatura científica sobre el tema.↩︎\nSe reitera que en el momento de realizar este proceso se desconoce si el vídeo es el correctamente subtitulado o el otro. La única información que se almacena es si se está respondiendo al vídeo que se vio primero.↩︎\nEn los ficheros suministrados la respuesta a cada pregunta ocupa varios campos. e selecciona en cada pregunta el que contiene el valor de la respuesta y se convierte a numérico.↩︎"
  },
  {
    "objectID": "32-Modelo.html#variables",
    "href": "32-Modelo.html#variables",
    "title": "5  Modelo.",
    "section": "5.1 Variables del modelo.",
    "text": "5.1 Variables del modelo.\nEn la Tabla 5.1 se describen las características más relevantes de las principales variables que se utilizarán en en modelado y en el análisis estadístico. \n\n\n\n\n\n\n\n\nTabla 5.1: Descripción de las variables más importantes\n\n\nNombre\nDescripción\nTipo\nValores\n\n\n\n\nResponse\nRespuesta a las preguntas del test.\nFactor ordenado\nDe 0 a 51\n\n\nLevel\nValoración de la respuesta.\nFactor ordenado\nNegative, Neutral, Positive2\n\n\nTreat\nSubtítulos\nFactor\nA o B3\n\n\nPeriod\nPeriodo\nFactor\n1 ó 24\n\n\nSeq\nSecuencia de aplicación de los tratamientos.\nFactor\nAB o BA\n\n\nSubject\nIdentificación del estudiante\nFactor\nNumérico\n\n\nQuestion\nNúmero de la pregunta\nFactor\nQ01, Q02, ..., Q185\n\n\nCluster\nGrupo de la pregunta\nFactor\n1, 2, ó 36\n\n\n\n1 Se ha hecho una rotación sobre los valores originales. 0 = No sé, 1 = Muy en desacuerdo, ..., 5 Muy de acuerdo.\n\n\n2 Positive cuando Response sea 4 ó 5, Negative cuando sea 1 ó 2 y Neutral para 3.\n\n\n3 No se conoce si el tratamiento A es el subtitulado bueno o lo es el B.\n\n\n4 1 para el primer vídeo visto y 2 el segundo.\n\n\n5 Se ha reorganizado de tal forma que Q18, que es la pregunta resumen, sea el valor primero y de referencia.\n\n\n6 Se aplicará una técnica estadística de agrupamiento para agregar las preguntas.\n\n\n\n\n\n\n\n\n\nPartiendo del dataframe que se construyó en el preprocesado (ver Sección 4.4) construimos el dataframe que usaremos a partir de este momento. Las operaciones principales que se han realizado han sido:\n\nRenombrar las variables para que se correspondan con las de nuestro modelo (ver Tabla 5.1).\nEliminar del estudio los usuarios que solo han realizado uno de los test como se explica en Sección 6.1.1.\nTransformar las variables que lo requieran en factores. La pregunta 18 se usará como referencia en el factor Question.\nRotar los valores de respuesta para que “No sé / No contesto” tenga valor 0 y el resto de 1 a 5 desde “Muy en desacuerdo”, 1, hasta “Muy de acuerdo”, 5.\nAgrupar las preguntas por similitud de respuesta (ver Sección 7.1.2).\nCrear el factor Level con los niveles negative, neutral y positive dependiendo de si la respuesta es 1 ó 2, 3, 4 ó 5 respectivamente.\nTransformar el dataframe de formato ancho a largo: los ficheros de respuestas se suministran en formato ancho. Es decir, que cada fila es un test que contiene 18 columnas para las respuestas a cada pregunta. Los nombres de las columnas son \\(Q01\\), \\(Q02\\), …, \\(Q18\\) y tendrán valores de 0 a 5 con las respuestas. La mayoría de los paquetes de R que vamos a usar requieren que los datos estén en formato largo. Esto que quiere decir que cada fila tendrá una única respuesta por lo que habrá únicamente dos columnas, \\(Question\\) y \\(Response\\). En la primera se almacenará el identificador de la pregunta (\\(Q01\\), \\(Q02\\), …, \\(Q18\\)) y en la segunda el valor de la respuesta (de 0 a 5). De esta forma, un test pasará de ocupar una fila y 18 columnas en el formato ancho a 18 filas y dos columnas en el largo.\n\nEn Apéndice B se puede consultar el código en R para realizar el proceso descrito anteriormente. Con estas transformaciones se crean los dos dataframes que se usarán en el análisis estadístico de los datos:\n\ndf_all contiene en formato largo todas las respuestas a los test.\ndf_clean tiene la misma estructura que df_all pero en él se han eliminado las respuestas “No sé / No contesto”.\n\ndf_all se utilizará cuando se traten las respuestas como categóricas y, por lo tanto, como no ordenadas. df_clean se utilizará cuando se traten las respuestas como ordenadas y por ello no contiene las respuestas con valor “No sé / No contesto”.\nLa estructura de estos dataframes es la siguiente:\n\n\ntibble [2,980 × 8] (S3: tbl_df/tbl/data.frame)\n $ Seq     : Factor w/ 2 levels \"AB\",\"BA\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Period  : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Treat   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Subject : Factor w/ 87 levels \"4\",\"33\",\"35\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Question: Factor w/ 18 levels \"Q18\",\"Q01\",\"Q02\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Cluster : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 2 2 2 2 1 1 1 1 1 ...\n $ Response: Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 3 3 3 3 3 3 3 3 3 3 ...\n $ Level   : Ord.factor w/ 3 levels \"Negative\"&lt;\"Neutral\"&lt;..: 2 2 2 2 2 2 2 2 2..\n\n\nEn la Tabla 5.2 se muestran algunos ejemplos datos.\n\n\n\n\n\n\n\n\nTabla 5.2: Muestra del dataframe preparado para el modelado estadístico en formato largo.\n\n\nSeq\nPeriod\nTreat\nSubject\nQuestion\nCluster\nResponse\nLevel\n\n\n\n\nAB\n2\nB\n523\nQ14\n3\n5\nPositive\n\n\nBA\n1\nB\n74\nQ04\n2\n4\nPositive\n\n\nBA\n1\nB\n819\nQ14\n3\n2\nNegative\n\n\nBA\n1\nB\n520\nQ07\n1\n5\nPositive\n\n\nBA\n1\nB\n33\nQ17\n3\n2\nNegative\n\n\nBA\n1\nB\n112\nQ12\n2\n4\nPositive\n\n\nBA\n1\nB\n231\nQ05\n1\n3\nNeutral\n\n\nAB\n2\nB\n428\nQ06\n1\n1\nNegative\n\n\nAB\n2\nB\n1020\nQ03\n2\n4\nPositive\n\n\nAB\n1\nA\n428\nQ03\n2\n5\nPositive"
  },
  {
    "objectID": "40-EDA1.html#análisis-de-la-calidad-de-los-datos.",
    "href": "40-EDA1.html#análisis-de-la-calidad-de-los-datos.",
    "title": "6  Exploración inicial.",
    "section": "6.1 Análisis de la calidad de los datos.",
    "text": "6.1 Análisis de la calidad de los datos.\n\n6.1.1 Respuestas a los test.\nComo se explica en la Tabla 5.1, al subtitulado le denominamos tratamiento y a sus niveles (correcto e incorrecto) los hemos llamado \\(A\\) y \\(B\\) sin hacer ninguna conjetura de cual de los dos es el subtitulado correcto. El grupo con secuencia \\(AB\\) será el que primero vio el vídeo con subtitulado \\(A\\) y luego el \\(B\\). Análogamente, el grupo con secuencia \\(BA\\) vio los vídeos en orden inverso. Recuérdese que el nivel 0 de respuesta se corresponde con “No sé / No contesto” (ver Tabla 4.1).\nHay 24 estudiantes que no realizaron el segundo test. De ellos 9 pertenecen al grupo AB y 15 al grupo BA. Debido a que no son muchos y a que los grupos se mantienen balanceados, se ha decidido eliminar los test de estos estudiantes. Tras eliminar estos datos, constatamos (ver Figura 6.1) que los grupos están balanceados en el número de estudiantes y que disponemos de suficientes datos para realizar el análisis estadístico.\n\n\n\n\n\nFigura 6.1: Estudiantes asignados a cada grupo.\n\n\n\n\nEl campo LastTry contiene la fecha y hora de realización del test. Con esta información podemos conocer el tiempo que empleó cada estudiante entre subtitulados. La Tabla 6.1 muestra que hay algunos test que se hicieron demasiado rápido 1.\n\n\n\n\n\n\n\n\nTabla 6.1: Tiempos de realización de la segunda actividad de duración inferior a 2 minutos.\n\n\nMinutes\n\n\n\n\n0.93\n\n\n1.3\n\n\n1.7\n\n\n1.72\n\n\n1.78\n\n\n1.97\n\n\n\n\n\n\n\n\nLa Figura 6.2 muestra que hay 28 test en los que el estudiante contestó a todas las preguntas usando únicamente 2 respuestas diferentes. Además hay 13 test en los que se contestaron todas las preguntas con 1 respuesta.\n\n\n\n\n\nFigura 6.2: Número de respuestas diferentes en un mismo test.\n\n\n\n\nLa tabla Tabla 6.2 muestra la respuesta utilizada, el grupo y el periodo de los test con respuesta única.\n\n\n\n\n\n\n\n\nTabla 6.2: Test en los que todas las preguntas se contestan el mismo valor de respuesta.\n\n\nResponse\nSeq\nTest\n\n\n\n\n2\nAB\n01\n\n\n2\nAB\n02\n\n\n3\nBA\n01\n\n\n3\nBA\n02\n\n\n3\nBA\n02\n\n\n3\nBA\n02\n\n\n4\nAB\n01\n\n\n4\nAB\n01\n\n\n4\nAB\n02\n\n\n4\nBA\n01\n\n\n4\nBA\n02\n\n\n4\nBA\n02\n\n\n4\nBA\n02\n\n\n\n\n\n\n\n\nLa Figura 6.3 presenta la distribución de la cantidad de respuestas cuyo valor cambia entre los dos test que realiza cada estudiante.\n\n\n\n\n\nFigura 6.3: Número de respuestas diferentes entre los test para cada estudiante.\n\n\n\n\nTan solo 1 estudiante respondió a todas las preguntas con el mismo valor en los dos test. Por otro lado, no hay test que tengan un número excesivo de contestaciones “No sé/No contesto” (ver Tabla 6.3).\n\n\n\n\n\n\n\n\nTabla 6.3: Los 5 test con más respuestas ‘No sé/No contesto’\n\n\nTest\nTotal respuesta por test\n\n\n\n\n01\n5\n\n\n01\n5\n\n\n02\n5\n\n\n02\n5\n\n\n01\n4\n\n\n\n\n\n\n\n\n\n6.1.1.1 Conclusiones.\nNo parece razonable realizar la actividad en menos de 2 minutos. Se observa que en algunos test hay poca variabilidad. Sin embargo, no son muchos los test con estas características así que se ha decidido mantener estos datos a pesar de que se pueda dubar de si en ellos los estudiantes contestaron con la debida atención y diligencia.\n\n\n\n6.1.2 Valores nulos o erróneos.\nEn los test no se ha detectado ningún valor nulo ni erróneo. Sin embargo tenemos algunos de estos valores en la información socioeconómica de los estudiantes (ver Tabla 6.4).\n\n\nTabla 6.4: Tablas de contingencia de la información socioeconómica de los estudiantes.\n\n\n\n\n\n\n\n\n\n\n(a) Estudiantes por sexo. \n\n\ngender\nFreq\n\n\n\n\nf\n92\n\n\nm\n38\n\n\nNA\n44\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Estudiantes con valor nulo en el campo año de nacimiento. \n\n\nyear_of_birth\nFreq\n\n\n\n\nNone\n44\n\n\nNA\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Estudiantes por nivel educativo. \n\n\nlevel_of_education\nFreq\n\n\n\n\na\n50\n\n\nb\n16\n\n\nhs\n4\n\n\nm\n30\n\n\nother\n4\n\n\np\n20\n\n\nNA\n50\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Estudiantes en función del número de preguntas acertadas en el test de conocimiento. \n\n\nlevel_of_knowledge\nFreq\n\n\n\n\n4\n2\n\n\n6\n4\n\n\n7\n30\n\n\n8\n44\n\n\n9\n40\n\n\n10\n32\n\n\nNA\n22"
  },
  {
    "objectID": "40-EDA1.html#sec-eda-3",
    "href": "40-EDA1.html#sec-eda-3",
    "title": "6  Exploración inicial.",
    "section": "6.2 Comparación de los tratamientos \\(A\\) y \\(B\\) entre grupos.",
    "text": "6.2 Comparación de los tratamientos \\(A\\) y \\(B\\) entre grupos.\nLa Figura 6.4 presenta una forma de comparar los dos test que realizados por los estudiantes. Para cada estudiante se comparó pregunta a pregunta sus dos test y se contabilizó la diferencia entre el número de preguntas en que la puntuación en el segundo vídeo fue superior y en las que lo fue inferior (las que no variaron de puntuación no se consideraron). En el eje \\(x\\) se muestra la diferencia entre preguntas. Cantidades negativas indican que hay más respuestas en el segundo de los test que han empeorado respecto al primero de las que han mejorado. En el eje \\(y\\) se representa el número de estudiantes para cada diferencia. Esta frecuencia se representa en negativo cuando la diferencia es negativa 2. Esto es una forma de evaluar si el estudiante valoró mejor o no el segundo vídeo que el primero.\n\n\n\n\n\nFigura 6.4: Frecuencias absolutas de las diferencias en las respuestas entre test por estudiante y grupo.\n\n\n\n\nVemos que en el grupo \\(AB\\) las diferencias tienden a ser negativas y en el \\(BA\\) positivas. Esto estaría indicando que los estudiantes valoran mejor el subtitulado de nivel \\(A\\). Por ello es esperable que las respuestas de los estudiantes del grupo \\(AB\\) hayan empeorado y que las diferencias sean negativas y que lo contrario haya sucedido con las del grupo \\(BA\\). La diferencia más frecuente en el grupo \\(AB\\) es 12 y en el grupo \\(BA\\) este valor es 11.\nResulta llamativo que haya estudiantes cuyas contestaciones estén tan alejadas de la tendencia de su grupo. En la Tabla 6.5 se muestran los tiempos que han transcurrido entre la realización de los test de aquellos estudiantes cuyas respuestas difieren de forma importante de su grupo. Se observa que casi todos son tiempos entre actividades muy cortos. En cualquier caso y, como no son muchos, se ha decidido no eliminarlos y realizar el análisis con ellos.\n\n\n\n\n\n\n\n\nTabla 6.5: Estudiantes que tienen diferencias en sus respuestas muy alejadas de la tendencia de su grupo.\n\n\nSeq\nDiff\nMinutes\n\n\n\n\nAB\n17\n1.3\n\n\nAB\n7\n3.33\n\n\nBA\n-10\n50345.95\n\n\nBA\n-12\n1.7\n\n\n\n\n\n\n\n\nEn la Figura 6.5 representamos la frecuencia relativa del valor de respuesta para cada grupo y test en todas la preguntas 3. Esta es otra forma de comparar los niveles de subtitulado.\n\n\n\n\n\n\n\n\nTabla 6.6: Resumen de frecuencias de respuesta.\n\n\nSeq\nPeriod\nTreat\n0\nResponse\n\n\n1\n2\n3\n4\n5\n\n\n\n\nAB\n1\nA\n39\n2\n25\n71\n203\n434\n\n\nAB\n2\nB\n43\n87\n185\n121\n172\n166\n\n\nBA\n1\nB\n40\n76\n174\n127\n237\n138\n\n\nBA\n2\nA\n30\n2\n30\n64\n345\n321\n\n\n\n\n\n\n\n\nLa Figura 6.5 muestra algunas cuestiones interesantes:\n\nEl tratamiento (subtitulado) con nivel \\(A\\) presenta claramente mayores valores de respuesta que el \\(B\\) como ya habíamos visto (ver Figura 6.4). Si en este momento tuviéramos que decidir qué subtitulado es el correcto claro que sería el de nivel \\(A\\). No obstante, ni en el análisis exploratorio ni en el modelado estadístico se hará ninguna suposición.\nEn general los dos grupos muestran bastante acuerdo en el subtitulado en ambos niveles: En el nivel de tratamiento \\(A\\) los dos grupos tienen una frecuencia relativa similar de respuestas positivas (valores 4 y 5). El grupo \\(AB\\) tiene un 82% de respuestas positivas frente a un 84% el grupo \\(BA\\). No obstante, el grupo \\(AB\\) tiene más respuestas con valor 5 que el grupo \\(BA\\) (56% frente a 41%). La valoración es también similar entre grupos en el nivel de tratamiento \\(B\\): el grupo \\(AB\\) tiene 44% de respuestas positivas y 47% el grupo \\(BA\\). Las valoraciones negativas (1, 2), la neutra (3) y la ‘No sé / No contesto’ (0) son también muy similares.\nLas respuestas son similares entre periodos aunque ligeramente más negativas en el segundo. Así un 65% de las respuestas son positivas en el primer periodo frente a un 64% en el segundo.\n\n\n\n\n\n\nFigura 6.5: Frecuencias relativas de las respuestas al test.\n\n\n\n\nEl análisis marginalizado de tratamiento, secuencia y periodo tiene estos resultados referidos a las preguntas con contestación positiva (4, 5):\n\nEl tratamiento \\(A\\) tiene un 83% marginalizado de respuestas positivas frente al 46% del tratamiento \\(B\\).\nEl periodo 1 tiene un 65% marginalizado de respuestas positivas frente al 64% del periodo 2.\nFinalmente, la secuencia \\(AB\\) tiene un 63% de respuestas positivas frente 66% de la secuencia \\(BA\\). Analizado por respuestas individuales, la respuesta 4 pasa de 24% en la secuencia \\(AB\\) a 37% en la \\(BA\\) y, de forma contraria, en la respuesta 5 pasa de 39% en \\(AB\\) a 29% en \\(BA\\). En las respuestas negativas y no contestadas y neutra no se aprecian estas variaciones."
  },
  {
    "objectID": "40-EDA1.html#análisis-de-las-preguntas.",
    "href": "40-EDA1.html#análisis-de-las-preguntas.",
    "title": "6  Exploración inicial.",
    "section": "6.3 Análisis de las preguntas.",
    "text": "6.3 Análisis de las preguntas.\nEl gráfico Figura 6.6 muestra la frecuencia relativa por grupo y por test de las preguntas clasificadas por niveles de respuesta, considerando que:\n\nLos niveles 1 y 2 se consideran valoraciones negativas.\nEl nivel 3 se considera neutro.\nLos niveles 4 y 5 se consideran positivos.\nEl nivel 0 (“No sé / No contesto”) se excluye en este análisis.\n\nSe muestra en primer lugar la pregunta 18 por ser una valoración global del subtitulado y que resume la opinión que sobre el mismo tiene el estudiante. Volvemos a constatar que el subtitulado \\(A\\) es mejor valorado por los estudiantes, pero ahora vemos que en las 18 preguntas ambos grupos tienen más puntuaciones positivas y menos negativas en el subtitulado \\(A\\) que el \\(B\\). También volvemos a encontrar que los dos grupos valoran de forma muy similar los dos niveles de subtitulado en todas la preguntas. En el nivel de subtitulado \\(A\\) las preguntas \\(Q15\\), \\(Q16\\) y \\(Q17\\) obtienen relativamente peores valoraciones (consultar la Tabla 4.2 para ver los valores) y estas son similares en ambos subtitulados. Hay algunas preguntas que son valoradas de forma positiva incluso en el nivel de subtitulado \\(B\\) (por ejemplo \\(Q04\\) o \\(Q13\\)) y que, por lo tanto, su valoración es similar en ambos subtitulados. Por último, las preguntas \\(Q05\\) y \\(Q09\\) (también la \\(Q14\\) pero solo para el grupo \\(BA\\)) tienen una valoración muy negativa en el nivel de subtitulado \\(B\\).\n\n\n\n\n\nFigura 6.6: Frecuencias relativas de las respuestas por pregunta.\n\n\n\n\nLa figura Figura 6.7 clasifica la preguntas por valoración y permite constatar lo que ya habíamos visto en el párrafo anterior con mayor comodidad.\n\n\n\n\n\n\n\n(a) Seq AB , Treat A\n\n\n\n\n\n\n\n(b) Seq AB , Treat B\n\n\n\n\n\n\n\n\n\n(c) Seq BA , Treat A\n\n\n\n\n\n\n\n(d) Seq BA , Treat B\n\n\n\n\nFigura 6.7: Preguntas ordenadas por valoración."
  },
  {
    "objectID": "40-EDA1.html#footnotes",
    "href": "40-EDA1.html#footnotes",
    "title": "6  Exploración inicial.",
    "section": "",
    "text": "Hay que tener en cuenta que la duración de vídeo es de algo más de 40 segundos y que los estudiantes tienen que contestar un test de 18 preguntas.↩︎\nEn la comparación se han omitido aquellas preguntas en las que el estudiante contestó “No sé/No contesto” en la pregunta correspondiente de uno de los test.↩︎\nEn el Tabla 6.6 se presenta la misma información con los valores absolutos.↩︎"
  },
  {
    "objectID": "42-Analisis.html#sec-cluster",
    "href": "42-Analisis.html#sec-cluster",
    "title": "7  Análisis estadístico.",
    "section": "7.1 Agrupamientos de preguntas.",
    "text": "7.1 Agrupamientos de preguntas.\n\n7.1.1 Correlación entre preguntas con el alfa de Cronbach.\nNormalmente las preguntas de un cuestionario pretenden medir una variable que está oculta o latente. En nuestro caso es la calidad del subtitulado. Las respuestas a estas preguntas relacionadas deben ser consistentes internamente, es decir, las respuestas deben correlacionarse fuerte y positivamente.\nUn índice que se utiliza habitualmente para medir la consistencia interna de un cuestionario es el coeficiente alfa de Cronbach (ver Schweinberger 2020). Se define de esta forma:\n\\[\\begin{equation}\n\\alpha = \\frac{N}{N-1} \\left(1 - \\frac{\\sum_{i=1}^{N} s_{i}^{2}}{s^{2}} \\right)\n\\end{equation}\\]\nDonde:\n\n\\(\\alpha\\) es el coeficiente alfa de Cronbach.\n\\(N\\) es el número de items de la escala de Likert.\n\\(s_{i}^{2}\\) es la varianza de la puntuación del item \\(i\\).\n\\(s^{2}\\) es la varianza total de las puntuaciones de todos los items.\n\nValores cercanos 1 indican una fuerte correlación en las respuestas y se admite que las preguntas del cuestionario están midiendo la misma variable latente.\nPara calcular en R este coeficiente podemos usar la función alpha del paquete psych:\n\nalpha &lt;- df_all %&gt;%\n    pivot_wider(\n        names_from = Question,\n        values_from = Response_v,\n        id_cols = c(Treat, Subject)\n    ) %&gt;%\n    dplyr::select(-c(Treat, Subject)) %&gt;%\n    psych::alpha()\n\nSe obtiene un coeficiente alfa de alfa de Cronbach de 0.92 que indica una muy buena correlación entre las respuestas a todas las preguntas. Este valor apenas se ve alterado si se elimina una de las preguntas (ver ?tbl-drop-alpha).\n\n\nValor del coeficiente alpha de Cronbach si se elimina una pregunta.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ18\nQ01\nQ02\nQ03\nQ04\nQ05\nQ06\nQ07\nQ08\n\n\n\n\n0.91\n0.92\n0.92\n0.92\n0.92\n0.91\n0.91\n0.91\n0.91\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ09\nQ10\nQ11\nQ12\nQ13\nQ14\nQ15\nQ16\nQ17\n\n\n\n\n0.91\n0.91\n0.92\n0.91\n0.92\n0.92\n0.92\n0.93\n0.92\n\n\n\n\n\n\n\n\n\n\n\n\nEn la ?tbl-item-alpha mostramos las preguntas que más contribuyen al índice alpha de Cronbach. Es interesante que la pregunta \\(Q18\\), que es la valoración general del cuestionario, sea la que mejor contribución tiene al índice.\n\n\nRelación de cada pregunta con el índice alpha de Cronbach.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ18\nQ05\nQ06\nQ09\nQ08\nQ07\nQ10\nQ12\nQ02\n\n\n\n\n0.86\n0.81\n0.79\n0.79\n0.77\n0.75\n0.73\n0.72\n0.71\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ03\nQ14\nQ01\nQ11\nQ15\nQ13\nQ04\nQ16\nQ17\n\n\n\n\n0.68\n0.66\n0.65\n0.64\n0.56\n0.51\n0.46\n0.44\n0.42\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.2 Agrupamiento jerárquico aglomerativo.\nEn en la Sección 7.1.1 y en la Sección 6.2 hemos visto que algunas de las preguntas tienen respuestas similares a otras pero diferentes del resto. Puede ser interesante aplicar una técnica de agrupamiento que nos permita crear grupos de preguntas que podremos analizar por separado.\nVamos a realizar una agrupación jerárquica aglomerativa de las preguntas en función de la tabla de contingencia de las respuestas utilizando la distancia euclidea como medida de distancia y el método de aglomeración de enlace completo para unir conglomerados 1. Para ello primero calculamos la tabla de contingencia (ver Tabla 7.1) de preguntas y respuestas.\n\ntable &lt;- df_all %&gt;%\n    xtabs(~ Question + Response, data = .)\n\n\n\n\n\n\n\n\n\nTabla 7.1: Tabla de contingencia de preguntas y respuestas.\n\n\nQuestion\nResponse_0\nResponse_1\nResponse_2\nResponse_3\nResponse_4\nResponse_5\n\n\n\n\nQ18\n0\n11\n33\n18\n52\n60\n\n\nQ01\n0\n10\n20\n10\n59\n75\n\n\nQ02\n0\n5\n26\n14\n58\n71\n\n\nQ03\n5\n5\n26\n11\n60\n67\n\n\nQ04\n0\n2\n7\n10\n61\n94\n\n\nQ05\n1\n29\n31\n12\n34\n67\n\n\nQ06\n1\n6\n29\n21\n53\n64\n\n\nQ07\n0\n13\n32\n14\n54\n61\n\n\nQ08\n4\n15\n41\n19\n40\n55\n\n\nQ09\n1\n39\n29\n12\n42\n51\n\n\nQ10\n8\n4\n24\n18\n59\n61\n\n\nQ11\n3\n2\n14\n23\n75\n57\n\n\nQ12\n5\n4\n26\n18\n69\n52\n\n\nQ13\n1\n2\n2\n19\n62\n88\n\n\nQ14\n21\n9\n29\n27\n44\n44\n\n\nQ15\n26\n5\n25\n36\n47\n35\n\n\nQ16\n47\n2\n5\n57\n39\n24\n\n\nQ17\n29\n4\n15\n44\n49\n33\n\n\n\n\n\n\n\n\nCon la tabla de contingencia calculamos las distancias entre preguntas y realizamos el agrupamiento. En el dendograma (ver Figura 7.1) se aprecian claramente tres conglomerados. Es muy interesante constatar que los tres grupos están formados por preguntas que en su mayor parte son correlativas. Esto es consistente con que al elaborar un test normalmente se colocan las preguntas por unidades temáticas y con que el encuestado tiende a responder de forma similar a preguntas correlativas.\n\ndist &lt;- dist(table, method = \"euclidean\")\ncluster &lt;- hclust(dist, method = \"complete\")\nplot(cluster)\n\n\n\n\nFigura 7.1: Dendograma de aglomeramiento jerárquico de preguntas en función de la tabla de contingencia de respuestas.\n\n\nPodemos distinguir los siguientes grupos y subgrupos:\n\nGrupo 1: Trata sobre la corrección del subtítulo.\n\nSubgrupo 05, 06, 07, 08, 09: preguntas sobre si la información que presenta el subtítulo es correcta y está bien escrita.\nPregunta 18: valoración general del subtitulado. El que esta pregunta esté incluida en este grupo estaría indicando que este es el apartado al que más importancia dan los estudiantes a la hora de valorar la calidad del subtitulado.\n\nGrupo 2: Es el más numeroso. En general está formado por preguntas sobre el grado de dificultad que presenta la lectura del subtítulo.\n\nSubgrupo preguntas Q01, Q02, Q03: colocación de los subtítulos.\nSubgrupo preguntas Q10, Q11, Q12: sincronización, velocidad y número de líneas.\nSubgrupo preguntas Q04, Q13: contraste y legibilidad.\n\nGrupo 3: son preguntas que tratan también sobre la corrección del subtítulo pero se diferencia del grupo uno ya que ahora se trata de cuestiones más sutiles y presumiblemente más difíciles de valorar para un novato. Está formado por las preguntas Q14, Q15, Q16 y Q17."
  },
  {
    "objectID": "42-Analisis.html#análisis-de-tablas-de-contingencia.",
    "href": "42-Analisis.html#análisis-de-tablas-de-contingencia.",
    "title": "7  Análisis estadístico.",
    "section": "7.2 Análisis de tablas de contingencia.",
    "text": "7.2 Análisis de tablas de contingencia.\nEn esta sección se aplicarán técnicas estadísticas que se basan en tablas de contingencia. Una descripción teórica de este tipo de técnicas se pueden encontrar en Agresti (2018). Un tratamiento aplicado y basado en gráficos, que será el enfoque que seguiremos en este trabajo, es realizado en Friendly, Meyer, y Zeileis (2015).\n\n7.2.1 Asociación de variables con la prueba de homogeneidad \\(\\chi^2\\).\nPodemos usar la prueba de homogeneidad \\(\\chi^2\\) para saber si las respuestas al cuestionario son independientes del nivel de subtitulado, del periodo y de la secuencia. Constatamos que según esta prueba ninguna de estas variables es independiente de la respuesta.\n\nchisq.test(df_all$Treat, df_all$Response)\n\n\n    Pearson's Chi-squared test\n\ndata:  df_all$Treat and df_all$Response\nX-squared = 621.5, df = 5, p-value &lt; 2.2e-16\n\nchisq.test(df_all$Period, df_all$Response)\n\n\n    Pearson's Chi-squared test\n\ndata:  df_all$Period and df_all$Response\nX-squared = 15.039, df = 5, p-value = 0.0102\n\nchisq.test(df_all$Seq, df_all$Response)\n\n\n    Pearson's Chi-squared test\n\ndata:  df_all$Seq and df_all$Response\nX-squared = 64.904, df = 5, p-value = 1.173e-12\n\n\n\n\n7.2.2 Comparación mediante mosaicos.\nEn la Figura 7.2 se representan en forma de mosaico las tablas de contingencia de las respuestas por tratamiento y secuencia. La información mostrada es similar a la que presentamos en la Figura 6.5, aunque el gráfico es más intuitivo ya que la anchura y altura de los rectángulos son proporcionales a la frecuencia marginal de la secuencia y el tratamiento respectivamente y el área es proporcional a la frecuencia conjunta. En esta ocasión hemos decidido emparejar los tratamientos en lugar de hacerlo con la secuencia, como hicimos anteriormente. Esto permite una mejor comparación de las diferencias entre grupos. Con ello podemos ver fácilmente que el tratamiento \\(A\\) es mejor valorado por los estudiantes y que el grupo que realizó la secuencia \\(AB\\) tiene más respuestas 5 pero menor número de respuestas positivas totales (menos respuestas 4, por tanto) que el grupo de secuencia \\(BA\\) en ambos niveles de tratamiento.\n\n\n\n\n\nFigura 7.2: Mosaico de tratamientos y secuencias.\n\n\n\n\n\n\n7.2.3 Comparación con \\(Odds\\ Ratio\\).\nHasta este momento ha quedado claro que el nivel de subtitulado \\(A\\) es preferido por los estudiantes y que las respuestas de ambos grupos son similares. Pero, ¿cuánto de similares son? Una forma de contestar esta pregunta es utilizar el odds ratio de tratamientos y grupos para cada nivel de respuesta.\nEs decir, calcular:\n\\[\\begin{equation}\nOR_{(Treat, Seq \\mid Response=r)}=\\frac{\n    \\frac{\n            P(Treat=A \\mid Seq=AB, Response=r)\n        }{\n            P(Treat=B \\mid Seq=AB, Response=r)\n        }\n    }\n    {\\frac{\n        P(Treat=A \\mid Seq=BA, Response=r)\n        }{\n        P(Treat=B \\mid Seq=BA, Response=r)\n    }\n}\n\\end{equation}\\]\nSi los \\(OR\\) son similares en todos los niveles de respuesta, podemos afirmar que los grupos son homogéneos. Los resultados en R no producen significación estadística en ningún nivel de respuesta por lo que según esta prueba estadística la secuencia de subtitulado no influiría en la respuesta de los estudiantes (ver Figura 7.3).\n\nsummary(loddsratio(~ Treat + Seq + Response_l, data = df_all))\n\n\nz test of coefficients:\n\n                    Estimate Std. Error z value Pr(&gt;|z|)\nNo sé / No contesto  0.19004    0.32746  0.5804   0.5617\nMuy en desacuerdo   -0.13517    1.01225 -0.1335   0.8938\nEn desacuerdo       -0.24362    0.29066 -0.8382   0.4019\nNeutral              0.15219    0.21412  0.7108   0.4772\nDe acuerdo          -0.20977    0.13363 -1.5698   0.1165\nMuy de acuerdo       0.11687    0.13671  0.8549   0.3926\n\n\n\n\n\n\n\nFigura 7.3: OR entre tratamiento y grupo por nivel de respuesta.\n\n\n\n\nSería interesante calcular el \\(OR\\) para cada nivel de respuesta y pregunta pero por desgracia la muestra es demasiado pequeña para hacerlo. Se ha calculado el \\(OR\\) sobre los agrupamientos de preguntas y se ha obtenido significación estadística tan solo en el agrupamiento 2 y nivel de respuesta 2:\n\nsummary(loddsratio(~ Treat + Seq + Cluster + Response_l, data = df_all))\n\n\nz test of coefficients:\n\n                      Estimate Std. Error z value Pr(&gt;|z|)  \n1:No sé / No contesto -1.94591    1.75662 -1.1078  0.26797  \n2:No sé / No contesto  0.41074    1.12569  0.3649  0.71520  \n3:No sé / No contesto  0.29239    0.35972  0.8128  0.41632  \n1:Muy en desacuerdo   -0.12516    1.17012 -0.1070  0.91482  \n2:Muy en desacuerdo   -1.39488    1.66941 -0.8356  0.40341  \n3:Muy en desacuerdo    1.19870    1.69327  0.7079  0.47900  \n1:En desacuerdo        0.17829    0.49526  0.3600  0.71885  \n2:En desacuerdo       -1.34796    0.57253 -2.3544  0.01855 *\n3:En desacuerdo        0.23740    0.50928  0.4661  0.64111  \n1:Neutral              0.62181    0.46172  1.3467  0.17807  \n2:Neutral              0.53248    0.39619  1.3440  0.17895  \n3:Neutral             -0.24146    0.31560 -0.7651  0.44421  \n1:De acuerdo          -0.35125    0.25963 -1.3529  0.17609  \n2:De acuerdo          -0.28064    0.18244 -1.5382  0.12399  \n3:De acuerdo           0.22503    0.30663  0.7339  0.46303  \n1:Muy de acuerdo       0.27860    0.26542  1.0497  0.29387  \n2:Muy de acuerdo       0.23441    0.17892  1.3101  0.19015  \n3:Muy de acuerdo      -0.61437    0.38071 -1.6137  0.10659  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSin embargo no podemos asumir que esta significación no se deba al azar ya que estamos realizando 18 contrastes de hipótesis diferentes y cada uno tiene un error tipo I asociado, con lo que la probabilidad de encontrar una significación estadística por puro azar aumenta. Se han propuesto correcciones del \\(p\\)-value como la de Bonferroni para abordar este problema que no se aplican en este trabajo.\nOtro \\(OR\\) que tiene interés calcular es el de tratamiento y periodo para evaluar si las respuestas son homogéneas. Mostramos tanto la tabla de resultados en R y también su representación visual (ver Figura 7.4).\n\nsummary(loddsratio(~ Treat + Period + Response_l, data = df_all))\n\n\nz test of coefficients:\n\n                    Estimate Std. Error z value  Pr(&gt;|z|)    \nNo sé / No contesto  0.33469    0.32746  1.0221 0.3067511    \nMuy en desacuerdo    0.13517    1.01225  0.1335 0.8937673    \nEn desacuerdo       -0.12102    0.29067 -0.4164 0.6771467    \nNeutral              0.05540    0.21412  0.2587 0.7958414    \nDe acuerdo          -0.85090    0.13363 -6.3674 1.922e-10 ***\nMuy de acuerdo       0.48634    0.13671  3.5574 0.0003745 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\nFigura 7.4: OR entre tratamiento y periodo por nivel de respuesta.\n\n\n\n\nPodemos constatar la existencia de un efecto periodo de signo contrario para las preguntas 4 y 5. La razón de que se produzca este efecto periodo es que algunas de las respuestas de valoración 5 en ambos niveles de subtitulado y grupos en el primer periodo se convierten en valoración 4 en el segundo periodo. Esto indica que los estudiantes de ambos grupos prestaron más atención o fueron más exigentes en el segundo visionado y decidieron no otorgar la puntuación máxima incluso en algunos items al subtitulado correcto. Que el efecto periodo sea contrario en dos preguntas no debe sorprendernos en este diseño de experimento, ya que un test es un juego de suma cero: la valoraciones que se ganan o se pierden en un nivel de respuesta necesariamente provoca que el resto de niveles pierdan o ganen respectivamente la misma cantidad. En cualquier caso, vemos que el efecto periodo es cuantitativa y cualitativamente pequeño. Al afectar solo al intercambio de valoraciones entre los niveles 4 y 5, y ser las dos positivas, es simplemente una pequeña corrección en la valoración del subtitulado.\n\n\n\n\nAgresti, Alan. 2018. «An introduction to categorical data analysis, 3rd Edition». Wiley.com. https://www.wiley.com/en-us/An+Introduction+to+Categorical+Data+Analysis%2C+3rd+Edition-p-9781119405283.\n\n\nFriendly, Michael, David Meyer, y Achim Zeileis. 2015. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. https://doi.org/10.1201/b19022.\n\n\nSchweinberger, Martin. 2020. Questionnaires and Surveys: Analyses with R. 2020/12/11 ed. Brisbane: The University of Queensland, Australia. School of Languages; Cultures."
  },
  {
    "objectID": "42-Analisis.html#footnotes",
    "href": "42-Analisis.html#footnotes",
    "title": "7  Análisis estadístico.",
    "section": "",
    "text": "El método de enlace completo usa la distancia máxima entre dos conglomerados para seleccionar los más cercanos a unir.↩︎"
  },
  {
    "objectID": "43-Modelado.html#árboles-de-inferencia-condicional.",
    "href": "43-Modelado.html#árboles-de-inferencia-condicional.",
    "title": "8  Modelado estadístico.",
    "section": "8.1 Árboles de inferencia condicional.",
    "text": "8.1 Árboles de inferencia condicional.\nLos arboles de inferencia condicional (CIT) son un tipo de árbol de decisión en el que la selección de variables y de los puntos de división no se basan en medidas de homogeneidad como el índice de Gini, sino en un contrastes de hipótesis no paramétricos. El algoritmo que se utiliza es el siguiente, ver Levshina (2020):\nEl algoritmo consiste en contrastar la hipótesis nula de si la variable de respuesta \\(Y\\) es independiente de alguna variable explicativa \\(Y \\mid X\\). Para probar la hipótesis, se utiliza un algoritmo de permutación de la variable respuesta y se mide la asociación con la variable explicativa antes y después de la permutación. Si la asociación no varía significativamente, podemos asumir que las variables de respuesta y explicativa son independientes. De esta forma se selecciona la variable explicativa que más influye en la respuesta y que se utilizará en el particionado. Para elegir el valor de la variable explicativa que dividirá el conjunto de datos, se procede de forma análoga midiendo el cambio en la diferencia de asociación. De acuerdo con Friendly (2015), los CIT resuelven los problemas de sobreajuste de los árboles de decisión tradicionales.\nPara realizar el particionado basado en CIT, vamos a usar la función ctree del paquete party de R. Presentamos aquí únicamente el modelo final elegido que incluye como variables explicativas Treat, Period, Seq y Cluster 1.\nEn la Figura 8.1 podemos ver que el nivel de subtitulado es el efecto principal, seguido del grupo de preguntas y finalmente la secuencia. En este modelo el periodo no aparece por no estar asociado con la respuesta. Estos resultados son contradictorios con los que obtuvimos en el análisis con el OR (ver Sección 7.2.3) en el que el factor secuencia no era significativo pero sí lo era el factor periodo. Por otro lado, vemos que la asociación más fuerte es el nivel de respuesta 5 para subtitulado \\(A\\), grupos de preguntas 1 y 2 y secuencia \\(AB\\) y de las respuestas 4 y 5 cuando la secuencia es \\(BA\\). El tratamiento \\(B\\) está fuertemente asociado con el nivel de respuesta 1 para el grupo de preguntas 1. Por último, con este modelo no hay ninguna combinación de factores que prediga un nivel de respuesta 1.\n\ntree.1 &lt;- ctree(Response ~ Treat + Cluster + Period + Seq, data = df_clean)\n\n\n\n\n\n\nFigura 8.1: Modelo con árboles de inferencia condicional (Response ~ Treat + Cluster + Period + Seq).\n\n\n\n\nAunque no es el objetivo del trabajo, podemos usar este modelo para hacer predicciones. La matriz de contingencia resultante es la siguiente:\n\n\n         Prediction\nReference   1   2   3   4   5\n        1   0 111  19  36   1\n        2   0 178  53 170  13\n        3   0  67  94 181  41\n        4   0  94  76 629 158\n        5   0  70  44 560 385\n\n\nComo habíamos anticipado, nunca se predice el nivel de respuesta 1. Las categorías que más probablemente predice nuestro modelo son la 4 y la 5 pero aún así hay mucha confusión entre ellas. La exactitud de predicción es 43%.\nUn modelo alternativo sería usar las mismas variables explicativas pero cambiado Response por Level como variable de respuesta. Esta variable solo tiene tres niveles: positivo, negativo y neutro. De esta forma no se producen confusiones entre los niveles 1 y 2 por un lado y 4 y 5 por otro:\n\ntree.2 &lt;- ctree(Level ~ Treat + Cluster + Period + Seq, data = df_clean)\n\n\n\n\n\n\nFigura 8.2: Modelo con árboles de inferencia condicional (Level ~ Treat + Cluster + Period + Seq).\n\n\n\n\nEl árbol obtenido con variable respuesta Level (ver Figura 8.2) es muy similar al otro (ver Figura 8.1) con la principal diferencia de que ahora la secuencia ha desaparecido como factor relevante. Por otro lado, el modelo siempre predice una respuesta positiva excepto para el subtitulado \\(B\\) y grupo de preguntas 1, que es negativa (el nivel neutro nunca se predice). La exactitud del modelo ha subido a 72%. En cualquier caso no es una gran mejora ya que un modelo que predijera siempre la categoría mayoritaria (positiva), habría obtenido una exactitud de 68%. Se han hecho simulaciones consistentes en incluir como factor las preguntas o usar como modelo un árbol de decisión convencional con resultados similares."
  },
  {
    "objectID": "43-Modelado.html#regresión-ordinal.",
    "href": "43-Modelado.html#regresión-ordinal.",
    "title": "8  Modelado estadístico.",
    "section": "8.2 Regresión ordinal.",
    "text": "8.2 Regresión ordinal.\nEl test de Likert es una escala ordinal. Los test estadísticos ANOVA o MANOVA presuponen que la variable de respuesta es cuantitativa y con distribución normal. Tratar las respuestas a un test de Likert como si fueran cuantitativas no es correcto por las siguientes razones:\n\nLos niveles de respuesta no son necesariamente equidistantes: la distancia entre un par de opciones de respuesta puede no ser la misma para todos los pares de opciones de respuesta. Por ejemplo, la diferencia entre “Muy en desacuerdo” y “En desacuerdo” y la diferencia entre “De acuerdo” y “Muy de acuerdo” es de un nivel, pero psicológicamente puede ser percibida de forma diferente por cada sujeto.\nLa distribución de las respuestas ordinales puede ser no normal. En particular esto sucederá si hay muchas respuestas en los extremos del cuestionario.\nLas varianzas de las variables no observadas que subyacen a las variables ordinales observadas pueden diferir entre grupos, tratamientos, periodos, etc.\n\nEn Liddell y Kruschke (2018) se han analizado los problemas potenciales de tratar datos ordinales como si fueran cuantitativos constatando que se pueden presentar las siguientes situaciones:\n\nSe pueden encontrar diferencias significativas entre grupos cuando no las hay: error tipo I.\nSe pueden obviar diferencias cuando en realidad sí existen: error tipo II.\nIncluso se pueden invertir los efectos de un tratamiento.\nTambién puede malinterpretarse la interacción entre factores.\n\nLa Regresión Logística Multinomial es una extensión de la Regresión Logística cuando la variable de respuesta es nominal. La Regresión Ordinal tiene en consideración que los valores nominales de la variable de respuesta están ordenados y por eso será el modelo que utilizaremos.\n\n8.2.1 Variantes de la Regresión Ordinal.\nLos modelos lineales generalizados (\\(GLM\\)) son modelos en los que la variable respuesta no es normal. Para especificar un \\(GLM\\) son necesarios tres componentes (ver O’Connell 2006):\n\nUn componente aleatorio: será una distribución de probabilidad de la familia exponencial que se asume que sigue la variable respuesta (en la regresión logística será la distribución Binomial o la distribución de Bernoulli).\nUn componente lineal de predictores.\nUna función de enlace que realiza transformación de los valores del componente lineal a los que puede tomar la variable respuesta. Por ejemplo en la función logística será la función \\(logit^{-1}(x)\\). Esta función permite pasar de un rango de valores \\((-\\infty, +\\infty)\\) a un rango \\((0, 1)\\).\n\nLa Regresión Ordinal es una extensión de la Regresión Logística y, por lo tanto de \\(GLM\\). Según Bürkner y Vuorre (2019) hay tres clases de Regresión Ordinal:\n\nRegresión ordinal acumulativa.\nRegresión ordinal secuencial.\nRegresión ordinal adyacente.\n\nNos centraremos en la primera ya que es la más habitual y adecuada para nuestro caso (ver Bürkner y Vuorre 2019, 23-24). El modelo acumulativo, CM, presupone que la variable ordinal observada, \\(Y\\), proviene de la categorización de una variable latente (no observada) continua, \\(\\tilde{Y}\\). Hay \\(K\\) umbrales \\(\\tau_k\\) que particionan \\(\\tilde{Y}\\) en \\(K + 1\\) categorías ordenadas observables (ver Figura 8.3). Si asumimos que \\(\\tilde{Y}\\) tiene una cierta distribución (por ejemplo, normal) con distribución acumulada \\(F\\), se puede calcular la probabilidad de que \\(Y\\) sea la categoría \\(k\\) de esta forma:\n\\[Pr(Y = k) = F(\\tau_k) - F(\\tau_{k-1})\\]\n\n\n\n\n\nFigura 8.3: Función latente en una regresión ordinal acumulativa.\n\n\n\n\nPor ejemplo en la Figura 8.3,\n\\[Pr(Y = 2) = F(\\tau_2) - F(\\tau_{1})\\]\nSi suponemos que \\(\\tilde{Y}\\) tiene una relación lineal los predictores:\n\\[\\tilde{Y} = \\eta + \\epsilon = \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\epsilon\\],\ny que los errores son \\(N(0,\\sigma^2)\\). Entonces la función de probabilidad acumulada de los errores tendrá la misma forma que la de \\(\\tilde{Y}\\):\n\\[\\mathrm{Pr}(\\epsilon \\leq z) = F(z)\\]\nY podremos calcular la distribución de probabilidad acumulada de \\(Y\\):\n\\[\\mathrm{Pr}(Y \\leq k \\mid \\eta) = \\mathrm{Pr}(\\tilde{Y} \\leq \\tau_k \\mid \\eta) = \\mathrm{Pr}(\\eta + \\epsilon \\leq \\tau_k) = \\mathrm{Pr}(\\epsilon \\leq \\tau_k - \\eta) = F(\\tau_k - \\eta)\\]\nPor lo que asumiendo la normalidad de los errores:\n\\[\\mathrm{Pr}(Y = k) = \\Phi(\\tau_k - \\eta) - \\Phi(\\tau_{k - 1} - \\eta)\\]\nDonde hay que estimar los umbrales y los coeficientes de regresión. La función anterior es la conocida como la función de enlace probit. Otra función de enlace popular es la función logit. Es la que usaremos en este trabajo por ser más fácil su interpretación 2. Con esta función de enlace la interpretación de los coeficientes es parecida a la de los coeficientes de la regresión logística. Se parte del supuesto de que el \\(logit\\) de la función de probabilidad es lineal:\n\\[logit [P(Y \\le k)] = \\tau_{k} - \\eta = \\tau_{k} - (\\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p)\\]\nEn ese caso, se puede demostrar fácilmente que, por ejemplo:\n\\[\\frac{\\frac{\\mathrm{Pr}(Y \\leq k \\mid \\eta)}{\\mathrm{Pr}(Y &gt; k \\mid \\eta)}}{\\frac{\\mathrm{Pr}(Y \\leq k+1 \\mid \\eta)}{\\mathrm{Pr}(Y &gt; k+1 \\mid \\eta)}} = \\exp(\\tau_{k} - \\tau_{k+1})\\]\nY que 3:\n\\[\\frac{\\frac{\\mathrm{Pr}(Y \\leq k \\mid x_i = 1)}{\\mathrm{Pr}(Y &gt; k \\mid x_i = 1)}}{\\frac{\\mathrm{Pr}(Y \\leq k \\mid x_i=0)}{\\mathrm{Pr}(Y &gt; k \\mid x_i = 0)}} = \\exp(-\\beta_{i})\\]\no, equivalentemente:\n\\[\\frac{\\frac{\\mathrm{Pr}(Y &gt; k \\mid x_i = x + 1)}{\\mathrm{Pr}(Y \\leq k \\mid x_i = x + 1)}}{\\frac{\\mathrm{Pr}(Y &gt; k \\mid x_i = x)}{\\mathrm{Pr}(Y \\leq k \\mid x_i = x)}} = \\exp(\\beta_{i})\\]\nEs decir, que \\(\\exp(\\beta_{i})\\) es el \\(OR\\) (cambio en \\(odds\\)) de que la variable respuesta esté por encima de una determinada categoría versus estar por debajo de ella para una unidad de incremento del predictor \\(x_i\\). Este modelo se denomina proporcional ya que cada predictor se asume que tiene los mismos efectos sobre todas las categorías de la variable de respuesta ordinal (ver Liu 2022). Un valor del coeficiente \\(\\beta_i\\) positivo indica que la relación entre el predictor \\(x_i\\) y la función de \\(logit\\) es positiva y, por lo tanto, se incrementa la posibilidad de un mayor valor de la variable respuesta. Como veremos, esta suposición se puede relajar y permitir que los coeficientes de todos o de algunos de los predictores sean diferentes para cada pareja consecutiva de valores de respuesta. Tendríamos entonces más parámetros a estimar con una interpretación más compleja.\n\n\n8.2.2 Ajuste del modelo ordinal Response ~ Treat.\nExisten varios paquetes en R que permiten ajustar una regresión ordinal logística. El más popular es el paquete Ordinal (R. H. B. Christensen 2022). El paquete VGAM (Yee 2023) es más flexible y potente. Otra posibilidad es usar la función polr del paquete MASS (Venables y Ripley 2002). Finalmente la función orm del paquete rms también permite hacerlo (ver Harrell 2015). En este trabajo usaremos el paquete Ordinal por permitir también incluir efectos aleatorios que utilizaremos en un apartado posterior. Comenzamos con un modelo simple que tiene como único predictor el nivel de subtitulado por ser la variable objetivo de nuestro modelo:\n\\[\n\\text{logit}(P(Response_i \\leq k)) = \\tau_k - \\beta_1 \\text{Treat}_i,\n\\]\n\nclm_treat &lt;-\n    clm(\n        Response ~ Treat,\n        data = df_clean, link = \"logit\"\n    )\nsummary(clm_treat)\n\nformula: Response ~ Treat\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter max.grad cond.H \n logit flexible  2980 -3966.11 7942.21 5(0)  1.64e-10 3.1e+01\n\nCoefficients:\n       Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB  -1.7206     0.0731  -23.54   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -3.97230    0.09678 -41.045\n2|3 -2.45446    0.06812 -36.029\n3|4 -1.66453    0.05936 -28.042\n4|5 -0.10547    0.04946  -2.132\n\n\nEl método summary() muestra la información resumen. Para su interpretación vamos a seguir Rune Haubo Bojesen Christensen (2018). El número de condición Hessiano es inferior a \\(10^4\\) lo que es indicativo de que no hay problemas de optimización 4. La sección de coeficientes es la más importante. Se muestra la estimación de parámetros, el error estándar y la significación estadística de acuerdo al test de Wald 5. Comprobamos que el valor es claramente significativo. Es decir, que los estudiantes han valorado de forma diferente la calidad del subtitulado en ambos vídeos. El estimador de maxima verosimilitud del coeficiente TreatB es -1.72. Siguiendo la deducción de Bruin (2011) podemos, por ejemplo, hacer la siguiente interpretación del significado de este coeficiente referido a dos niveles consecutivos de respuesta:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1)] & = & -3.97 - (-1.72 x_1) \\\\\nlogit [P(Y \\le 2)] & = & -2.45 - (-1.72 x_1)\n\\end{aligned}\n\\]\nPor lo tanto los \\(odds\\) serían:\n\\[\n\\begin{aligned}\n\\frac{P(Y \\le 1 \\mid x_1 = B)}{P(Y &gt; 1 \\mid x_1 = B)} & = & exp(-3.97)/exp(-1.72) \\\\\n\\frac{P(Y \\le 1 \\mid x_1 = A)}{P(Y &gt; 1 \\mid x_1 = A)} & = & exp(-3.97) \\\\\n\\frac{P(Y \\le 2 \\mid x_1 = B)}{P(Y &gt; 2 \\mid x_1 = B)} & = & exp(-2.45)/exp(-1.72) \\\\\n\\frac{P(Y \\le 2 \\mid x_1 = A)}{P(Y &gt; 2 \\mid x_1 = A)} & = & exp(-2.45)\n\\end{aligned}\n\\]\nY los \\(OR\\):\n\\[\n\\begin{aligned}\n\\frac{P(Y \\le 1 | x_1=B)}{P(Y &gt; 1 | x_1=B)} / \\frac{P(Y \\le 1 | x_1=A)}{P(Y &gt; 1 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\\\\n\\frac{P(Y \\le 2 | x_1=B)}{P(Y &gt; 2 | x_1=B)} / \\frac{P(Y \\le 2 | x_1=A)}{P(Y &gt; 2 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\\\\n\\end{aligned}\n\\]\nSe comprueba que el \\(OR\\) es equivalente en todos los niveles de respuesta al cuestionario. Esta es una de las suposiciones de la regresión ordinal acumulativa. El \\(odds\\) de respuesta al cuestionario entre los niveles inferiores y superiores a uno dado, \\(k\\), es 5.59 veces en el subtitulado \\(B\\) que en el \\(A\\). Esto indica que el subtitulado \\(B\\) es percibido por los estudiantes como de peor calidad que el subtitulado \\(A\\). Concretamente, el coeficiente \\(\\beta\\) para Treat es el log odds de observar una mejor respuesta en una pregunta del test es 5.59 veces superior en el nivel de subtitulado \\(A\\) que en el \\(B\\). Aunque no suele ser de interés la interpretación de los coeficientes de los umbrales (Threshold coefficients), se pueden utilizar para estimar las probabilidades de respuesta. Por ejemplo, para el nivel de subtitulado \\(B\\):\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1)] & = & -3.97 - (-1.72) & = & -2.25 \\\\\nodds (P(Y \\le 1)) & = & exp(logit [P(Y \\le 1)]) & = & 0.11 \\\\\nP(Y \\le 1) & = & \\frac{exp(-2.25)}{1 + exp(-2.25)} & = & 0.10 \\\\\nP(Y \\le 2) & = & \\frac{exp(-0.73)}{1 + exp(-0.73)} & = & 0.32 \\\\\nP(Y = 2) & = & P(Y \\le 2) - P(Y \\le 1) & = &  0.23\n\\end{aligned}\n\\]\nPara el subtitulado \\(A\\) no se tiene en cuenta el coeficiente \\(TreatB\\) ya que el valor \\(x_1\\) es cero:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1)] & = & & & -3.97\\\\\nodds (P(Y \\le 1)) & = & exp(logit [P(Y \\le 1)]) & = & 0.02 \\\\\nP(Y \\le 1) & = & \\frac{exp(-3.97)}{1 + exp(-3.97)} & = & 0.02\n\\end{aligned}\n\\]\nEn Tabla 8.1 se muestran las probabilidades para ambos niveles de subtitulado y todos los posibles valores de respuesta.\n\n\n\n\nTabla 8.1: Probabilidades de respuesta para el modelo ordinal Response ~ Treat\n\n\n\n1\n2\n3\n4\n5\n\n\n\n\nA\n0.018\n0.061\n0.08\n0.315\n0.526\n\n\nB\n0.095\n0.229\n0.19\n0.320\n0.166\n\n\n\n\n\n\n\n\n8.2.3 Ajuste del modelo ordinal Response ~ Treat + Period.\nPara saber si existe un efecto periodo, añadimos como predictor la variable Period.\n\\[\n\\text{logit}(P(Response_i \\leq k)) = \\tau_k - \\beta_1 \\text{Treat}_i - \\beta_2 \\text{Period}_i\n\\]\n\nclm_treat_period &lt;-\n    clm(\n        Response ~ Treat + Period,\n        data = df_clean, link = \"logit\"\n    )\nsummary(clm_treat_period)\n\nformula: Response ~ Treat + Period\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter max.grad cond.H \n logit flexible  2980 -3957.88 7927.76 5(0)  1.94e-10 4.1e+01\n\nCoefficients:\n        Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB  -1.74090    0.07339  -23.72  &lt; 2e-16 ***\nPeriod2 -0.27560    0.06805   -4.05 5.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -4.13085    0.10507 -39.314\n2|3 -2.60905    0.07872 -33.143\n3|4 -1.81652    0.07073 -25.681\n4|5 -0.25187    0.06153  -4.093\n\n\nVemos que ambos coeficientes son significativos y con signo negativo. Un signo negativo en el efecto periodo está asociado con que la valoración del subtitulado empeora en el segundo periodo independientemente de si se trata del subtitulado correcto o incorrecto. Aplicando el mismo razonamiento del apartado anterior, el \\(OR\\) del efecto periodo es \\(1/exp(-0.28) = 1.32\\). Lo que quiere decir que una vez controlado el efecto principal del tratamiento, el subtitulado en el segundo periodo es valorado como de inferior calidad que en el primero. Esto estaría indicando que los estudiantes son más exigentes con el subtitulado en la segunda actividad independientemente de su calidad real.\n\n\n8.2.4 Ajuste del modelo ordinal Response ~ Treat * Period.\nAñadimos al modelo la interacción entre subtitulado y periodo. Esta interacción corresponde al efecto secuencia. Se puede demostrar que los modelos Response ~ Treat*Period y Response ~ Treat + Period + Seq son equivalentes si se cambia el contraste por defecto utilizado en R, que es treatment, a sum 6.\n\noptions(contrasts = rep(\"contr.sum\", 2))\nclm_treat_period_seq.sum &lt;-\n    clm(\n        Response ~ Treat + Period + Seq,\n        data = df_clean, link = \"logit\"\n    )\ncoef(clm_treat_period_seq.sum)\n\n       1|2        2|3        3|4        4|5     Treat1    Period1       Seq1 \n-3.1266457 -1.6083838 -0.8184857  0.7499332  0.8739547  0.1396182  0.1062749 \n\n\n\noptions(contrasts = rep(\"contr.sum\", 2))\nclm_treat.period.sum &lt;-\n    clm(\n        Response ~ Treat * Period,\n        data = df_clean, link = \"logit\"\n    )\ncoef(clm_treat.period.sum)\n\n           1|2            2|3            3|4            4|5         Treat1 \n    -3.1266457     -1.6083838     -0.8184857      0.7499332      0.8739547 \n       Period1 Treat1:Period1 \n     0.1396182      0.1062749 \n\n\nVemos que los coeficientes Seq1 y Treat1:Period1 son iguales y, por lo tanto, queda demostrado que la secuencia es la interacción entre periodo y tratamiento. Sin embargo los coeficientes son diferentes si el contraste es treatment 7:\n\noptions(contrasts = rep(\"contr.treatment\", 2))\nclm_treat_period_seq &lt;-\n    clm(\n        Response ~ Treat + Period + Seq,\n        data = df_clean, link = \"logit\"\n    )\ncoef(clm_treat_period_seq)\n\n       1|2        2|3        3|4        4|5     TreatB    Period2      SeqBA \n-4.2464935 -2.7282315 -1.9383335 -0.3699146 -1.7479094 -0.2792363 -0.2125498 \n\n\n\noptions(contrasts = rep(\"contr.treatment\", 2))\nclm_treat.period &lt;-\n    clm(\n        Response ~ Treat * Period,\n        data = df_clean, link = \"logit\"\n    )\ncoef(clm_treat.period)\n\n           1|2            2|3            3|4            4|5         TreatB \n    -4.2464935     -2.7282315     -1.9383335     -0.3699146     -1.9604592 \n       Period2 TreatB:Period2 \n    -0.4917861      0.4250996 \n\n\nEn el Apéndice C se explica como se pueden obtener los coeficientes de un modelo a partir de los coeficientes de otro modelo. Es decir, que se pueden obtener los coeficientes del modelo clm_treat.period a partir de los coeficientes del modelo clm_treat.period.sum. Por ejemplo, el coeficiente \\(TreatB\\) del modelo clm_treat.period se calcula:\n\n(-2 * (coef(clm_treat.period.sum)[\"Treat1\"] + coef(clm_treat.period.sum)[\"Treat1:Period1\"]))\n\n   Treat1 \n-1.960459 \n\ncoef(clm_treat.period)[\"TreatB\"]\n\n   TreatB \n-1.960459 \n\n\nSin embargo la interpretación de los coeficientes del segundo modelo, clm_treat.period, es más sencilla ya que es la que estamos habituados a utilizar en R. Por ello en este análisis se utilizará el modelo clm_treat.period. El resumen del ajuste es:\n\nsummary(clm_treat.period)\n\nformula: Response ~ Treat * Period\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter max.grad cond.H \n logit flexible  2980 -3953.01 7920.03 5(0)  2.14e-10 8.1e+01\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB         -1.96046    0.10229 -19.166  &lt; 2e-16 ***\nPeriod2        -0.49179    0.09744  -5.047 4.49e-07 ***\nTreatB:Period2  0.42510    0.13638   3.117  0.00183 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -4.24649    0.11182 -37.977\n2|3 -2.72823    0.08821 -30.928\n3|4 -1.93833    0.08167 -23.732\n4|5 -0.36991    0.07308  -5.062\n\n\nVemos que los tres coeficientes son significativos. El principal efecto es el nivel de subtitulado obteniendo mejores puntuaciones el nivel \\(A\\); el efecto periodo es negativo por lo que el primer periodo obtiene mejores puntuaciones; por último, el efecto secuencia es positivo pero de menor valor absoluto que el efecto periodo. Esto quiere decir que el subtitulado de nivel \\(B\\) en el periodo 2 (secuencia \\(AB\\)), tiene un efecto periodo inferior que el subtitulado \\(A\\) en el mismo periodo. Matemáticamente:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1 \\mid Treat = A, Period = 1)] & = & -4.25 \\\\\nlogit [P(Y \\le 1 \\mid Treat = B, Period = 1)] & = & -4.25 - (-1.96) \\\\\nlogit [P(Y \\le 1 \\mid Treat = A, Period = 2)] & = & -4.25 - (-0.49) \\\\\nlogit [P(Y \\le 1 \\mid Treat = B, Period = 2)] & = & -4.25 -(-1.96 -0.49 + 0.43)\n\\end{aligned}\n\\]\nEn definitiva, en el nivel de subtitulado \\(B\\) apenas encontramos diferencias entre periodos, sin embargo, en el nivel de subtitulado \\(A\\) existe un efecto periodo cuyo valor en logits es -0.49. Es decir, que la valoración del subtitulado de nivel \\(A\\) es inferior en el segundo periodo que en el primero. En la Figura 8.4 podemos ver las predicciones del modelo.\n\n\n\n\n\nFigura 8.4: Probabilidades de respuesta para el modelo ordinal Response ~ Treat * Period\n\n\n\n\n\n\n8.2.5 Elección del modelo ordinal mediante el test de razón de verosimilitud.\nAl ser los tres modelos anidados, podemos compararlos con la prueba de razón de verosimilitud. Comprobamos que el tercer modelo (el que incorpora la interacción entre los subtítulos y el periodo) reduce significativamente el logaritmo de la función de verosimilitud y, por lo tanto, debe ser aceptado:\n\nanova(clm_treat, clm_treat_period, clm_treat.period)\n\nLikelihood ratio tests of cumulative link models:\n \n                 formula:                  link: threshold:\nclm_treat        Response ~ Treat          logit flexible  \nclm_treat_period Response ~ Treat + Period logit flexible  \nclm_treat.period Response ~ Treat * Period logit flexible  \n\n                 no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)    \nclm_treat             5 7942.2 -3966.1                          \nclm_treat_period      6 7927.8 -3957.9  16.448  1      5e-05 ***\nclm_treat.period      7 7920.0 -3953.0   9.738  1   0.001805 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n8.2.6 Comprobación de las hipótesis del modelo.\nLa principal hipótesis de un modelo de regresión logística ordinal proporcional acumulativa es que los coeficientes son iguales entre cualesquiera dos niveles de respuestas correlativos. Se han propuesto diversas fórmulas para comprobar esta hipótesis. El paquete Ordinal dispone de la función nominal_test() que lo que hace es realizar un test de razón de verosimilitud para cada predictor ajustando un modelo en el que se ha relajado la condición de proporcionalidad. Se constata que el test resulta significativo para Treat y para Treat:Period, por lo que para estas dos variables no se puede asumir que los coeficientes estimados se mantengan constantes en todos los niveles de respuesta.\n\nnominal_test(clm_treat.period)\n\nTests of nominal effects\n\nformula: Response ~ Treat * Period\n             Df  logLik    AIC     LRT Pr(&gt;Chi)    \n&lt;none&gt;          -3953.0 7920.0                     \nTreat         3 -3904.4 7828.9  97.172   &lt;2e-16 ***\nPeriod        3 -3951.4 7922.7   3.307   0.3467    \nTreat:Period  9 -3884.8 7801.6 136.408   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLo que procede es ajustar el modelo relajando la constante de proporcionalidad de esas variables. Se ha realizado esto utilizando la función vglm del paquete VGAM. Vemos que ahora hay cuatro coeficientes para cada una de las variables Treat y Treat:Period 8.\n\nvglm_treat.period &lt;- vglm(\n    Response ~ Treat * Period,\n    VGAM::cumulative(link = \"logit\", parallel = F ~ Treat + Treat:Period, reverse = T),\n    data = df_clean\n)\ncoef(vglm_treat.period) %&gt;% data.frame()\n\n                          .\n(Intercept):1     6.2295614\n(Intercept):2     3.5001281\n(Intercept):3     2.2121438\n(Intercept):4     0.2998788\nTreatB:1         -4.0441016\nTreatB:2         -2.8029889\nTreatB:3         -2.2174630\nTreatB:4         -1.7926200\nPeriod2          -0.5345919\nTreatB:Period2:1  0.3509228\nTreatB:Period2:2  0.3607009\nTreatB:Period2:3  0.3891474\nTreatB:Period2:4  0.8024952\n\n\nEn la Figura 8.5 se muestran las probabilidades de respuesta de este modelo.\n\n\n\n\n\nFigura 8.5: Probabilidades de respuesta para el modelo ordinal no proporcional Response ~ Treat * Period\n\n\n\n\n\n\n8.2.7 Introducción a los modelos multinivel.\nUn modelo multinivel, jerárquico o mixto es un modelo en el que tenemos datos de un nivel inferior anidados en estructuras de un nivel superior. Por ejemplo, si quisiéramos evaluar el rendimiento de varios métodos de enseñanza, poríamos seleccionar aleatoriamente varios colegios participantes y en cada uno de ellos elegir varias clases en las que se impartiría uno de los métodos de enseñanza. Los modelos multinivel se utilizan cuando se incumple la hipótesis de independencia de entre las observaciones. En el caso de los métodos de enseñanza, los alumnos de una clase no son independientes de los alumnos de otra clase del mismo colegio y también es esperable que los alumnos de un mismo colegio sean más parecidos entre sí que los de otro colegio. Otra situación en la que se viola la condición de independencia entre observaciones es cuando se toman varias medidas del mismo sujeto. Este tipo de experimentos se llaman de medidas repetidas o longitudinales. En este caso se considera que las medidas están anidadas en el sujeto (ver Liu 2022). En un modelo multinivel no es necesario que todas las variables tengan una estructura jerárquica. Distinguimos entonces dos tipos de variables. Las conocidas como de efectos fijos son aquellas variables que se consideran que tienen el mismo efecto en toda la población y, por lo tanto, estimamos un único coeficiente. Las que llamamos como variables de efectos aleatorios tienen un coeficiente diferente para cada elemento de la población y se supone que son una muestra de una población mucho mayor, como el caso de seleccionar aleatoriamente una muestra de colegios. Normalmente el coeficiente particular de cada elemento no es de interés para el investigador y se asuma que tienen una media centrada en cero. El mayor interés de los efectos aleatorios es la estimación de su matriz de varianzas-covarianzas.\nLa ecuación general de un modelo multinivel con dos niveles y un solo predictor con efectos aleatorios es (ver Chen y Chen 2021, 40):\n\\[\n\\begin{aligned}\nLevel\\ 1: & y_{ij}     & = & \\beta_{0j} + \\beta_{1j}x_{1ij} + \\epsilon_{ij} \\\\\nLevel\\ 2: & \\beta_{0j} & = & \\beta_{0} + U_{0j} & (intercepto\\ aleatorio) \\\\\n          & \\beta_{1j} & = & \\beta_{0} + U_{1j} & (pendiente\\ aleatoria) \\\\\n\\end{aligned}\n\\]\nDonde los errores del modelo se distribuyen,\n\\[\nError\\ intra\\ grupo:  \\epsilon_{ij} \\sim N(0, \\sigma^2)\n\\]\n\\[\nError\\ entre\\ grupos:\n\\begin{pmatrix}\n     U_{0j} \\\\\n     U_{1j} \\\\\n\\end{pmatrix}\n\\sim\nN\n\\begin{pmatrix}\n\\begin{pmatrix}\n     0 \\\\\n     0 \\\\\n\\end{pmatrix},\n\\begin{pmatrix}\n     \\tau_0^2 & \\tau_0\\tau_1\\rho_{01} \\\\\n     \\tau_0\\tau_1\\rho_{01} &  \\tau_1^2 \\\\\n\\end{pmatrix}\n\\end{pmatrix}\n\\]\ndonde \\(j\\) son los grupos que varían \\(j = 1,...,J\\) (\\(J\\) es el número de grupos); \\(i\\) es la observación \\(i\\) del grupo \\(j\\) (\\(i = 1,...,n_j\\), \\(n_j\\) es el número de observaciones del grupo \\(j\\)). El modelo se compone de una parte fija \\(\\beta_0 + \\beta_1 x_{ij}\\) y una aleatoria \\(U_{0j} + U_{1j} x_{1ij} + \\epsilon{ij}\\). Los parámetros de este modelo son el intercepto y la pendiente de efectos fijos (\\(\\beta_0\\) y \\(\\beta_1\\)), la varianza intra-grupos (\\(\\sigma^2\\)), la varianza inter-grupos del intercepto aleatoria (\\(\\tau_0\\)) y de la pendiente aleatoria (\\(\\tau_1\\)), y la correlación entre intercepto y pendiente aleatorias (\\(\\rho_{01}\\)). Cuando se introduce una estructura multinivel se pueden omitir tanto el intercepto como la pendiente aleatoria.\nEn Gelman et al. (2013) se evalúan tres posibilidades a la hora de definir un modelo:\n\n\\(Complete\\ pooloing\\): Consiste en estimar un único parámetro para cada predictor. Es equivalente a un modelo con efectos fijos.\n\\(No\\ pooling\\): Se estiman tantos paŕametros como grupos haya de forma independiente.\n\\(Partial\\ pooling\\): Es el modelo jerárquico. Es una mezcla de ambos, ya que aunque se estima un parámetro para cada grupo, esta estimación no es independiente, sino que se supone que las observaciones de un mismo grupo proceden de una misma distribución de probabilidad. Esto se traduce en que se produce una contracción (\\(shrinkage\\)) en la estimación de los parámetros. Al influir la estimación de unas observaciones en otras, la estimación es de menor valor absoluto que la que resultaría en un modelo de \\(no\\ pooling\\). De esta forma podemos ver el \\(complete\\ pooling\\) y el \\(no\\ pooling\\) como dos casos particulares y extremos del \\(no\\ pooling\\). La contracción de coeficientes en los modelos multinivel actúa como una regularización que puede evitar el sobreajuste.\n\nLos modelos multinivel requieren supuestos adicionales en el nivel segundo y superiores que son similares a los supuestos para los modelos de efectos fijos en el primer y único nivel (ver Chen y Chen 2021, 43). Para estimar los parámetros en un modelo multinivel se suele utilizar el método de máxima verosimilitud restringida (RMLE), que es una variante de la estimación por máxima verosimilitud (MLE) en la que se hacen ajustes en los grados de libertad del modelo con efectos aleatorios.\n\n\n8.2.8 Ajuste del modelo multinivel ordinal.\nEl modelo multinivel aleatorio más simple que podemos considerar es el que incorpora únicamente un interceptor aleatorio para los estudiantes del curso. Que los estudiantes sean considerados un efecto aleatorio está doblemente justificado. Por un lado, son una muestra de una población más amplia que estaría constituida por todos los estudiantes de todos los cursos de accesibilidad. Por otro, cada estudiante realiza el test de evaluación dos veces y, por lo tanto, las respuestas a estos cuestionarios no son independientes. La especificación del modelo será la siguiente:\n\\[\n\\text{logit}(P(Response_{ij} \\leq k)) = \\tau_k +\\tau_{kj} - \\beta_1 \\text{Treat}_{ij},\n\\]\ndonde \\(Response_{ij}\\) es la observación \\(i\\) del usuario \\(j\\), \\(\\tau_k\\) es el interceptor común a todos los usuarios para el nivel de respuesta \\(k\\) y \\(\\tau_{kj}\\) es el interceptor específico para el usuario \\(j\\). Para ajustar el modelo, vamos a utilizar la función clmm() del paquete Ordinal ya que permite la inclusión de efectos aleatorios.\n\nclmm_subject &lt;- clmm(Response ~ (1 | Subject), data = df_clean)\nsummary(clmm_subject)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ (1 | Subject)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -4053.61 8117.23 272(1093) 7.11e-04 8.3e+01\n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n Subject (Intercept) 0.8385   0.9157  \nNumber of groups:  Subject 87 \n\nNo Coefficients\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -3.1597     0.1291 -24.481\n2|3  -1.6869     0.1109 -15.212\n3|4  -0.9383     0.1077  -8.713\n4|5   0.6354     0.1068   5.951\n\n\nVemos que el parámetro \\(\\widehat{\\tau_0}\\) tiene un valor 0.92 y que no hay coeficientes que estimar. El siguiente modelo en orden de complejidad es el que incorpora el predictor Treat:\n\nclmm_treat_subject &lt;- clmm(Response ~ Treat + (1 | Subject), data = df_clean)\nsummary(clmm_treat_subject)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat + (1 | Subject)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3665.73 7343.47 395(1585) 4.97e-04 9.5e+01\n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n Subject (Intercept) 1.265    1.125   \nNumber of groups:  Subject 87 \n\nCoefficients:\n       Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB  -2.0747     0.0793  -26.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -4.7243     0.1638 -28.839\n2|3  -3.0518     0.1453 -21.008\n3|4  -2.1256     0.1392 -15.269\n4|5  -0.2068     0.1325  -1.561\n\n\nEn este modelo \\(\\widehat{\\tau_0}\\) vale 1.12 y la pendiente del tratamiento, TreatB es -2.07. Podemos considerar un modelo en la que la valoración de cada sujeto sea diferente para cada tratamiento:\n\nclmm_treat.subject &lt;- clmm(Response ~ Treat + (1 + Treat | Subject), data = df_clean)\nsummary(clmm_treat.subject)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat + (1 + Treat | Subject)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3431.27 6878.53 535(3741) 2.43e-03 1.7e+02\n\nRandom effects:\n Groups  Name        Variance Std.Dev. Corr   \n Subject (Intercept) 2.691    1.641           \n         TreatB      4.295    2.072    -0.598 \nNumber of groups:  Subject 87 \n\nCoefficients:\n       Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB  -2.5864     0.2425  -10.67   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -5.5561     0.2207 -25.173\n2|3  -3.6249     0.2024 -17.914\n3|4  -2.5581     0.1968 -12.999\n4|5  -0.3271     0.1900  -1.721\n\n\nAhora \\(\\widehat{\\tau_0}\\) vale 1.64 y \\(\\widehat{\\tau_1}\\) 2.07. La correlación, \\(\\rho_{01}\\), es -0.6. Podemos añadir el factor Period al modelo:\n\nclmm_treat.period.subject &lt;- clmm(\n    Response ~ Treat * Period + (1 + Treat | Subject),\n    data = df_clean\n)\nsummary(clmm_treat.period.subject)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 + Treat | Subject)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter       max.grad cond.H \n logit flexible  2980 -3429.88 6879.76 1696(11676) 7.34e-05 6.4e+02\n\nRandom effects:\n Groups  Name        Variance Std.Dev. Corr   \n Subject (Intercept) 2.588    1.609           \n         TreatB      4.168    2.042    -0.584 \nNumber of groups:  Subject 87 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB          -2.8530     0.3795  -7.519 5.53e-14 ***\nPeriod2         -0.5893     0.3685  -1.599    0.110    \nTreatB:Period2   0.5307     0.5855   0.906    0.365    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -5.8518     0.2892 -20.236\n2|3  -3.9206     0.2754 -14.234\n3|4  -2.8541     0.2714 -10.515\n4|5  -0.6226     0.2654  -2.345\n\n\nVemos que, a diferencia de lo que sucedía en el modelo de efectos fijos, el periodo y la interacción del periodo con el subtitulado son ahora no significativos. Queda, por último, discutir cómo añadir las preguntas al modelo. Consideramos que las respuestas a las preguntas no son independientes unas de otras y que, por lo tanto, deben ser consideradas efectos aleatorios. En Bürkner (2021) Bürkner y Vuorre (2019, 19-20) podemos encontrar un ejemplo de esta solución. Las preguntas como efecto aleatorio se pueden añadir considerando únicamente el intercepto o el intercepto y la pendiente. Ajustamos ambos modelos:\n\nclmm_treat.period.subject_question &lt;- clmm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question),\n    data = df_clean\n)\nsummary(clmm_treat.period.subject_question)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3309.04 6640.07 960(7467) 3.85e-04 6.6e+02\n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr   \n Subject  (Intercept) 3.0249   1.739           \n          TreatB      4.8228   2.196    -0.591 \n Question (Intercept) 0.4651   0.682           \nNumber of groups:  Subject 87,  Question 18 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB          -3.0562     0.4062  -7.525 5.29e-14 ***\nPeriod2         -0.6163     0.3966  -1.554    0.120    \nTreatB:Period2   0.5608     0.6266   0.895    0.371    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -6.2609     0.3506 -17.858\n2|3  -4.1977     0.3375 -12.439\n3|4  -3.0366     0.3334  -9.108\n4|5  -0.6370     0.3276  -1.944\n\n\n\nclmm_treat.period.subject.question &lt;- clmm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),\n    data = df_clean\n)\nsummary(clmm_treat.period.subject.question)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat |  \n    Question)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter      max.grad cond.H \n logit flexible  2980 -3186.06 6398.11 1026(8128) 1.80e-04 6.1e+02\n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr   \n Subject  (Intercept) 3.1372   1.7712          \n          TreatB      5.4601   2.3367   -0.552 \n Question (Intercept) 0.4474   0.6689          \n          TreatB      1.8621   1.3646   -0.471 \nNumber of groups:  Subject 87,  Question 18 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB          -3.1435     0.5358  -5.867 4.43e-09 ***\nPeriod2         -0.6255     0.4028  -1.553    0.120    \nTreatB:Period2   0.5590     0.6615   0.845    0.398    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -6.7481     0.3585 -18.821\n2|3  -4.3947     0.3411 -12.884\n3|4  -3.1106     0.3362  -9.252\n4|5  -0.5610     0.3298  -1.701\n\n\nUn modelo más simple que el anterior que podemos considerar es eliminar la pendiente del subtitulado en el efecto aleatorio Subject.\n\nclmm_treat.period_subject_question &lt;- clmm(\n    Response ~ Treat * Period + (1 | Subject) + (1 | Question),\n    data = df_clean\n)\nsummary(clmm_treat.period_subject_question)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 | Subject) + (1 | Question)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3559.48 7136.96 987(3952) 5.50e-04 5.9e+02\n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Subject  (Intercept) 1.4348   1.1978  \n Question (Intercept) 0.3394   0.5826  \nNumber of groups:  Subject 87,  Question 18 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB          -2.5366     0.2815  -9.012   &lt;2e-16 ***\nPeriod2         -0.6203     0.2795  -2.219   0.0265 *  \nTreatB:Period2   0.5958     0.5353   1.113   0.2657    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -5.3264     0.2655 -20.059\n2|3  -3.5644     0.2530 -14.089\n3|4  -2.5690     0.2488 -10.325\n4|5  -0.5243     0.2434  -2.154\n\n\nE incluso eliminar completamente el efecto aleatorio Subject y mantener solo las preguntas como efecto aleatorio.\n\nclmm_treat.period_question &lt;- clmm(\n    Response ~ Treat * Period + (1 | Question),\n    data = df_clean\n)\nsummary(clmm_treat.period_question)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 | Question)\ndata:    df_clean\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3883.04 7782.07 741(2226) 1.08e-04 1.3e+02\n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Question (Intercept) 0.2274   0.4769  \nNumber of groups:  Question 18 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB         -2.04502    0.10378 -19.706  &lt; 2e-16 ***\nPeriod2        -0.50200    0.09929  -5.056 4.29e-07 ***\nTreatB:Period2  0.43361    0.13747   3.154  0.00161 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -4.4008     0.1610 -27.337\n2|3  -2.8298     0.1446 -19.575\n3|4  -1.9983     0.1401 -14.259\n4|5  -0.3609     0.1349  -2.675\n\n\nMediante el test de razón de verosimilitud podemos seleccionar el modelo con menor función de verosimilitud:\n\nanova(\n    clmm_subject,\n    clmm_treat.subject,\n    clmm_treat.period.subject,\n    clmm_treat.period.subject_question,\n    clmm_treat.period.subject.question,\n    clmm_treat.period_subject_question,\n    clmm_treat.period_question\n)\n\nLikelihood ratio tests of cumulative link models:\n \n                                   formula:                                                                  \nclmm_subject                       Response ~ (1 | Subject)                                                  \nclmm_treat.subject                 Response ~ Treat + (1 + Treat | Subject)                                  \nclmm_treat.period_question         Response ~ Treat * Period + (1 | Question)                                \nclmm_treat.period_subject_question Response ~ Treat * Period + (1 | Subject) + (1 | Question)                \nclmm_treat.period.subject          Response ~ Treat * Period + (1 + Treat | Subject)                         \nclmm_treat.period.subject_question Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question)        \nclmm_treat.period.subject.question Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question)\n                                   link: threshold:\nclmm_subject                       logit flexible  \nclmm_treat.subject                 logit flexible  \nclmm_treat.period_question         logit flexible  \nclmm_treat.period_subject_question logit flexible  \nclmm_treat.period.subject          logit flexible  \nclmm_treat.period.subject_question logit flexible  \nclmm_treat.period.subject.question logit flexible  \n\n                                   no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)\nclmm_subject                            5 8117.2 -4053.6                      \nclmm_treat.subject                      8 6878.5 -3431.3 1244.69  3  &lt; 2.2e-16\nclmm_treat.period_question              8 7782.1 -3883.0 -903.54  0           \nclmm_treat.period_subject_question      9 7137.0 -3559.5  647.12  1  &lt; 2.2e-16\nclmm_treat.period.subject              10 6879.8 -3429.9  259.20  1  &lt; 2.2e-16\nclmm_treat.period.subject_question     11 6640.1 -3309.0  241.69  1  &lt; 2.2e-16\nclmm_treat.period.subject.question     13 6398.1 -3186.1  245.96  2  &lt; 2.2e-16\n                                      \nclmm_subject                          \nclmm_treat.subject                 ***\nclmm_treat.period_question            \nclmm_treat.period_subject_question ***\nclmm_treat.period.subject          ***\nclmm_treat.period.subject_question ***\nclmm_treat.period.subject.question ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVemos que el modelo más complejo, clmm_treat.period.subject.question, presenta una menor funcion de verosimilitud. Este modelo tiene un \\(AIC\\) menor que los modelos ordinales ajustados en el apartado anterior incluso si a esos modelos se les añade como factor predictor Question. En el Tabla 8.2 se muestran los interceptores y pendientes estimadas para el efecto aleatorio Question.\n\n\n\n\nTabla 8.2: Intercepto y pendiente de Question en el modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question)\n\n\n\n(Intercept)\nTreatB\n\n\n\n\nQ18\n0.3933757\n-1.1021051\n\n\nQ01\n0.2726623\n0.4752429\n\n\nQ02\n0.6197324\n-0.3813147\n\n\nQ03\n0.0640464\n0.5063518\n\n\nQ04\n0.5020005\n1.9203520\n\n\nQ05\n0.7498895\n-2.8118058\n\n\nQ06\n0.5528685\n-0.8949249\n\n\nQ07\n-0.0106860\n-0.4533266\n\n\nQ08\n-0.1980169\n-0.8402323\n\n\nQ09\n0.0184714\n-2.4698505\n\n\nQ10\n0.0228628\n0.1615350\n\n\nQ11\n0.0782894\n0.6223213\n\n\nQ12\n-0.2003100\n0.3403381\n\n\nQ13\n0.5516281\n1.5330216\n\n\nQ14\n-0.2392607\n-0.4339893\n\n\nQ15\n-1.3380683\n1.4804380\n\n\nQ16\n-1.3655878\n1.7228905\n\n\nQ17\n-1.0044586\n1.1760588\n\n\n\n\n\n\nLas preguntas Q16, Q15, Q17, Q05, Q02 son las 5 cuyo log odds del intercepto tiene un valor mayor valor absoluto y, por lo tanto, las que nuestro modelo considera más diferentes del resto. Por otro lado, las preguntas Q05, Q09, Q04, Q16, Q13 son las que mayor valor absoluto tienen en el coeficiente TreatB y, por ello, las que presentan mayor diferencia entre tratamientos. En la Figura 8.6 se muestran las predicciones del modelo.\n\n\n\n\n\nFigura 8.6: Probabilidades de respuesta para el modelo ordinal Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question)"
  },
  {
    "objectID": "43-Modelado.html#modelado-bayesiano.",
    "href": "43-Modelado.html#modelado-bayesiano.",
    "title": "8  Modelado estadístico.",
    "section": "8.3 Modelado Bayesiano.",
    "text": "8.3 Modelado Bayesiano.\nEn el apéndice (ver Apéndice D) se comparan diversas parametrizaciones de modelado bayesiano utilizando la función brm() del paquete brms. Analizamos aquí la que mejor resultado produjo con la validación cruzada bayesiana leave-one-out:\n\nbrm_treat.period.subject.question &lt;- brm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_treat.period.subject.question\",\n    file_refit = \"on_change\"\n)\n\nEsta parametrización coincide con la que elegimos en el apartado de Regresión Ordinal con efectos mixtos. El modelo utiliza como factores con efectos fijos (complete pooling en terminología bayesiana) el nivel de subtitulado y el periodo y la interacción entre ambos; y como efectos aleatorios (partial pooling) los sujetos y las preguntas del test. Cada uno de ellos con un intercepto y un nivel de subtitulado variable. El resumen del modelo es el siguiente:\n\nsummary(brm_treat.period.subject.question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.74      0.16     0.50     1.11 1.00     1213\nsd(TreatB)                1.50      0.29     1.05     2.21 1.00     1194\ncor(Intercept,TreatB)    -0.41      0.21    -0.74     0.07 1.01      931\n                      Tail_ESS\nsd(Intercept)             2155\nsd(TreatB)                1803\ncor(Intercept,TreatB)     1691\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.82      0.18     1.50     2.21 1.00      841\nsd(TreatB)                2.39      0.21     2.01     2.84 1.00      685\ncor(Intercept,TreatB)    -0.54      0.09    -0.70    -0.35 1.01      420\n                      Tail_ESS\nsd(Intercept)             1266\nsd(TreatB)                1487\ncor(Intercept,TreatB)      719\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -6.70      0.37    -7.43    -5.98 1.00      701     1417\nIntercept[2]      -4.35      0.35    -5.03    -3.64 1.00      641     1231\nIntercept[3]      -3.06      0.34    -3.73    -2.37 1.00      626     1271\nIntercept[4]      -0.50      0.34    -1.17     0.18 1.00      623     1227\nTreatB            -3.15      0.57    -4.28    -2.04 1.01      483     1112\nPeriod2           -0.58      0.41    -1.41     0.21 1.01      492      943\nTreatB:Period2     0.50      0.68    -0.82     1.83 1.00      428      888\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nEn la Tabla 8.3 se comparan las estimaciones puntuales que obtuvimos para este modelo con la función clmm para ajustar el modelo con efectos mixtos. Se comprueba que son muy similares. Vemos que los interceptores son claramente significativos y también el coeficiente de TreatB. Sin embargo los coeficientes correspondientes al efecto periodo, Period2, y al efecto secuencia, TreatB:Period, incluyen el cero y además tienen intervalos muy grandes por lo que hay mucha incertidumbre respecto a su verdadero valor.\n\n\n\n\n\n\n\n\nTabla 8.3: Comparación frecuentista/bayesiano de coeficientes estimados en el modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\nName\nordinal::clmm\nbrms::brm\n\n\nEstimation.clmm\nconf.2.5%\nconf.97.5%\nEstimation.brm\ncred.2.5%\ncred.97.5%\n\n\n\n\n1|2\n-6.75\n-7.45\n-6.05\n-6.71\n-7.43\n-5.98\n\n\n2|3\n-4.39\n-5.06\n-3.73\n-4.35\n-5.03\n-3.64\n\n\n3|4\n-3.11\n-3.77\n-2.45\n-3.06\n-3.73\n-2.37\n\n\n4|5\n-0.56\n-1.21\n0.09\n-0.50\n-1.17\n0.18\n\n\nTreatB\n-3.14\n-4.19\n-2.09\n-3.14\n-4.28\n-2.04\n\n\nPeriod2\n-0.63\n-1.42\n0.16\n-0.57\n-1.41\n0.21\n\n\nTreatB:Period2\n0.56\n-0.74\n1.86\n0.52\n-0.82\n1.83\n\n\nSubject.sd(Intercept)\n0.67\n\n\n0.72\n0.50\n1.11\n\n\nSubject.sd(TreatB)\n1.36\n\n\n1.47\n1.05\n2.21\n\n\nSubject.cor(Intercept,TreatB)\n1.77\n\n\n1.82\n1.50\n2.21\n\n\nQuestion.sd(Intercept)\n2.34\n\n\n2.38\n2.01\n2.84\n\n\nQuestion.sd(TreatB)\n-0.47\n\n\n-0.44\n-0.74\n0.07\n\n\nQuestion.cor(Intercept,TreatB)\n-0.55\n\n\n-0.54\n-0.70\n-0.35\n\n\n\n\n\n\n\n\nHemos mantenido las distribuciones de probabilidad a priori que por defecto utiliza brm confiando en que sus parámetros son adecuados. Sin embargo, conviene comprobar que realmente sea así. En la Tabla 8.4 se muestran las distribuciones a priori de los parámetros aleatorios del modelo. En la Figura 8.7 se constata que toman valores razonables y no informativos.\n\n\n\n\n\n\n\n\nTabla 8.4: Distribuciones a priori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\nprior\nclass\ncoef\ngroup\nresp\ndpar\nnlpar\nlb\nub\nsource\n\n\n\n\n\nb\n\n\n\n\n\n\n\ndefault\n\n\n\nb\nPeriod2\n\n\n\n\n\n\ndefault\n\n\n\nb\nTreatB\n\n\n\n\n\n\ndefault\n\n\n\nb\nTreatB:Period2\n\n\n\n\n\n\ndefault\n\n\nstudent_t(3, 0, 2.5)\nIntercept\n\n\n\n\n\n\n\ndefault\n\n\n\nIntercept\n1\n\n\n\n\n\n\ndefault\n\n\n\nIntercept\n2\n\n\n\n\n\n\ndefault\n\n\n\nIntercept\n3\n\n\n\n\n\n\ndefault\n\n\n\nIntercept\n4\n\n\n\n\n\n\ndefault\n\n\nlkj_corr_cholesky(1)\nL\n\n\n\n\n\n\n\ndefault\n\n\n\nL\n\nQuestion\n\n\n\n\n\ndefault\n\n\n\nL\n\nSubject\n\n\n\n\n\ndefault\n\n\nstudent_t(3, 0, 2.5)\nsd\n\n\n\n\n\n0\n\ndefault\n\n\n\nsd\n\nQuestion\n\n\n\n\n\ndefault\n\n\n\nsd\nIntercept\nQuestion\n\n\n\n\n\ndefault\n\n\n\nsd\nTreatB\nQuestion\n\n\n\n\n\ndefault\n\n\n\nsd\n\nSubject\n\n\n\n\n\ndefault\n\n\n\nsd\nIntercept\nSubject\n\n\n\n\n\ndefault\n\n\n\nsd\nTreatB\nSubject\n\n\n\n\n\ndefault\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.7: Distribuciones a priori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\n\n\nEs importante asegurar que el entrenamiento ha convergido a su distribución a posteriori. En la tabla de resumen constatamos que el valor de Rhat es inferior a 1.1 y el de ESS superior a 400 en todos los parámetros, que son umbrales que no se deberían violar (ver Bürkner y Vuorre 2019). En la Figura 8.8 se comprueba que las cadenas MCMC de muestreo de la distribución a posteriori se mezclan correctamente y no se aprecia autocorrelación en ninguno de las parámetros. Por último, en la Figura 8.9 se muestra una comparación entre los histogramas construidos con los datos con los intervalos de confianza marginales de la función predictiva a posteriori del modelo. En la mayoría de las preguntas, el muestreo reproduce bastante bien el histograma de respuestas. En algunas preguntas, como la Q16 o la Q17, hay diferencias relevantes.\n\n\n\n\n\nFigura 8.8: Cadenas MCMC del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\n\n\n\n\n\n\n\nFigura 8.9: Comparación de los valores reales con los obtenidos a partir de la función predictiva a posteriori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\n\n\nEn cuanto a las conclusiones que podemos extraer del modelo, la más importante es que, como hemos constatado desde el principio de este trabajo, los alumnos perciben claramente una diferencia entre los niveles de subtitulado \\(A\\) y \\(B\\), siendo preferido el \\(A\\). En la Figura 8.10 se representan gráficamente los valores esperados de la probabilidad de respuesta a cada pregunta por tratamiento y periodo. Lo más interesante es confirmar la existencia de sendos efectos periodo y secuencia de pequeña magnitud que se materializan en que, para el nivel de subtitulado \\(A\\), son ligeramente más probables las respuestas con valor 4 en el periodo 2 (secuencia \\(BA\\)) que en el 1 (secuencia \\(AB\\)). Con las respuestas de valor 5 ocurre lo contrario: en el subtitulado \\(A\\) son más probables en el periodo 1 (secuencia \\(AB\\)) que el 2 (secuencia \\(BA\\)). Esto ya lo habíamos constatado antes en el análisis del \\(OR\\) (ver Sección 7.2.3).\n\n\n\n\n\nFigura 8.10: Muestreo de la esperanza de la función predictiva a posteriori por tratamiento, periodo y pregunta del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\n\n\nConstatados los efectos periodo y secuencia, y sabiendo que son de pequeña magnitud, pasamos ahora a hacer un análisis de las predicciones que realiza el modelo sobre la distribución de respuestas en cada pregunta. Para ello en la Figura 8.11 se representan 50 muestras de la esperanza de la distribución predictiva a posteriori para cada pregunta y nivel de subtitulado marginalizadas por periodo y estudiante. La primera conclusión que podemos extraer es que el modelo tiene bastante incertidumbre sobre los valores de respuesta a cada pregunta no superando casi nunca el 50% de probabilidad para todas las preguntas y niveles de subtitulado. En general se observa en la mayoría de las preguntas del nivel de subtitulado \\(A\\) que los alumnos están bastante seguros de que la respuesta a las preguntas debe ser 4 ó 5, asignando una muy baja probabilidad a los valores 1, 2, ó 3, pero habiendo bastante confusión respecto cuál de los dos valores (4 ó 5) asignar. En el nivel de subtitulado \\(B\\) la situación es bastante más confusa. Aunque la opción de respuesta preferida es 4 y las menos preferidas son la 5 y la 1, hay bastante mezcla entre las opciones de respuesta 2, 3 y 4. En cuanto al análisis individualizado por pregunta podemos extraer las siguientes conclusiones:\n\nEn las preguntas \\(Q04\\) y \\(Q13\\) los estudiantes no aprecian defectos en el subtitulado ni diferencias entre un nivel y otro. Son valoradas en ambos niveles con puntuaciones de 4 y de 5.\nEn las preguntas \\(Q15\\), \\(Q16\\) y \\(Q17\\), la opción de respuesta más probable es 4 en ambos subtitulados. El modelo asigna una baja probabilidad de respuesta a la opción 1 y similares al resto. La probabilidad de la opción 5 decrece ligeramente entre subtitulado \\(A\\) y \\(B\\) y lo contrario ocurre con las opciones 2 y 3.\nLas preguntas \\(Q01\\), \\(Q02\\), \\(Q03\\), \\(Q10\\), \\(Q11\\) y \\(Q12\\) son similares a las anteriores. Particularmente en lo referente a que la respuesta más probable en el subtitulado \\(B\\) es 4. En el subtitulado \\(A\\) hay preferencia por 4 y 5. El nivel 5 cae acusadamente en el subtitulado \\(B\\) y en este nivel aumenta ligeramente la probabilidad de respuesta 2 y 3.\nLas preguntas \\(Q06\\), \\(Q07\\), \\(Q14\\) y \\(Q18\\) no son muy diferentes de las anteriores. En general el modelo predice mayor probabilidad de respuesta para 5 en el subtitulado \\(A\\) pero este valor es con alta probabilidad cercano a cero en el subtitulado \\(B\\). En el subtitulado \\(B\\) la probabilidad de respuesta 2, 3 ó 4 es similar.\nLas preguntas \\(Q05\\), \\(Q08\\) y \\(Q09\\) son las que más diferencias entre subtitulados presentan. La respuesta más probable en el subtitulado \\(A\\) es 5 (en \\(Q08\\) y en \\(Q09\\) muy parecida a 4). Por contra, en el subtitulado \\(B\\) las respuestas 4 y 5 tienden a cero, siendo la más probable la respuesta 2. En \\(Q05\\) y en \\(Q09\\) la segunda respuesta más probable al subtitulado \\(B\\) es 1 y 4 en la \\(Q08\\).\n\nEn definitiva, nuestro modelo predice que los estudiantes están bastante de acuerdo en que en las preguntas \\(Q05\\) y \\(Q09\\) hay una diferencia de calidad importante entre subtitulados. También están de acuerdo en que en las preguntas \\(Q04\\) y \\(Q13\\) no hay apenas cambio entre los subtitulados. En las preguntas \\(Q15\\), \\(Q16\\) y \\(Q17\\) hay una gran confusión en ambos niveles de subtitulado y en el resto la confusión se circunscribe al nivel de subtitulado \\(B\\), ya que en el nivel \\(A\\) las opciones 4 y 5 predominan.\n\n\n\nFigura 8.11: Muestreo de la función predictiva a posteriori por tratamiento y pregunta del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question).\n\n\n\n\n\n\nBruin, J. 2011. «How do I interpret the coefficients in an ordinal logistic regression in R». 2011. https://stats.oarc.ucla.edu/r/faq/ologit-coefficients.\n\n\nBürkner, Paul-Christian. 2021. «Bayesian Item Response Modeling in R with brms and Stan». Journal of Statistical Software 100 (noviembre). https://doi.org/10.18637/jss.v100.i05.\n\n\nBürkner, Paul-Christian, y Matti Vuorre. 2019. «Ordinal Regression Models in Psychology: A Tutorial». Advances in Methods and Practices in Psychological Science 2 (febrero): 251524591882319. https://doi.org/10.1177/2515245918823199.\n\n\nChen, Ding-Geng, y Jenny Chen. 2021. Statistical Regression Modeling with R: Longitudinal and Multi-level Modeling. https://doi.org/10.1007/978-3-030-67583-7.\n\n\nChristensen, R. H. B. 2022. «ordinal—Regression Models for Ordinal Data».\n\n\nChristensen, Rune Haubo Bojesen. 2018. «Cumulative Link Models for Ordinal Regression with the R Package ordinal». En.\n\n\nFriendly, Michael. 2015. Classification and regression trees.\n\n\nGelman, Andrew, John Carlin, Hal Stern, David Dunson, Aki Vehtari, y Donald Rubin. 2013. Bayesian Data Analysis. https://doi.org/10.1201/b16018.\n\n\nHarrell, Frank. 2015. Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis. https://doi.org/10.1007/978-3-319-19425-7.\n\n\nLevshina, Natalia. 2020. «Conditional Inference Trees and Random Forests». En A Practical Handbook of Corpus Linguistics, editado por Magali Paquot y Stefan Th. Gries, 611-43. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-46216-1_25.\n\n\nLiddell, Torrin M., y John K. Kruschke. 2018. «Analyzing ordinal data with metric models: What could possibly go wrong?» Journal of Experimental Social Psychology 79: 328-48. https://doi.org/10.1016/j.jesp.2018.08.009.\n\n\nLiu, Xing. 2022. Categorical Data Analysis and Multilevel Modeling Using R. Editado por SAGE Publications Ltd.\n\n\nO’Connell, Ann. 2006. Logistic Regression Models for Ordinal Response Variables. https://doi.org/10.4135/9781412984812.\n\n\nVenables, W. N., y B. D. Ripley. 2002. Modern Applied Statistics with S. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nYee, T. W. 2023. VGAM: Vector Generalized Linear and Additive Models. https://CRAN.R-project.org/package=VGAM."
  },
  {
    "objectID": "43-Modelado.html#footnotes",
    "href": "43-Modelado.html#footnotes",
    "title": "8  Modelado estadístico.",
    "section": "",
    "text": "Se han realizado simulaciones con otras combinaciones de variables explicativas que no se incluyen por no haber producido resultados relevantes.↩︎\nEn la práctica los coeficientes estimados con las funciones de enlace probit y logit suelen similares.↩︎\nEn el siguiente apartado se demuestra esta fórmula.↩︎\nEl número de condición de Hessiano es una medida de la curvatura de una función en un punto. Si el número de condición de Hessiano es grande, la función es muy sensible a pequeñas perturbaciones y puede ser difícil de optimizar.↩︎\nEl test de Wald es un contraste de hipótesis estadístico en el que se evalúa si el valor estimado es cero suponiendo que \\(W = \\left(\\frac{\\hat{\\theta} - \\theta_0}{se(\\hat{\\theta})}\\right)^2 \\sim \\chi^{2}\\) .↩︎\nVer Apéndice C para una discusión sobre el significado y la interpretación de los contrastes treatment y sum.↩︎\nLos interceptores sí son iguales.↩︎\nLos umbrales tienen los mismos valores pero de signo contrario debido a diferencias en la parametrización del modelo en cada función utilizada.↩︎"
  },
  {
    "objectID": "99-Referencias.html",
    "href": "99-Referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "AENOR. 2012. “UNE 153010 Subtitulado Para Personas Sordas y\nPersonas Con Discapacidad Auditiva.” Asociación Española de\nNormalización y Certificación.\n\n\nAgresti, Alan. 2010. Analysis of Ordinal Categorical Data. https://doi.org/10.1002/9780470594001.\n\n\n———. 2018. “An Introduction to Categorical Data Analysis, 3rd\nEdition.” Wiley.com. https://www.wiley.com/en-us/An+Introduction+to+Categorical+Data+Analysis%2C+3rd+Edition-p-9781119405283.\n\n\nBruin, J. 2011. “How Do i Interpret the Coefficients in an Ordinal\nLogistic Regression in r.” 2011. https://stats.oarc.ucla.edu/r/faq/ologit-coefficients.\n\n\nBürkner, Paul-Christian. 2021. “Bayesian Item Response Modeling in\nr with Brms and Stan.” Journal of Statistical Software\n100 (November). https://doi.org/10.18637/jss.v100.i05.\n\n\nBürkner, Paul-Christian, and Matti Vuorre. 2019. “Ordinal\nRegression Models in Psychology: A Tutorial.” Advances in\nMethods and Practices in Psychological Science 2 (February):\n251524591882319. https://doi.org/10.1177/2515245918823199.\n\n\nChen, Ding-Geng, and Jenny Chen. 2021. Statistical Regression\nModeling with r: Longitudinal and Multi-Level Modeling. https://doi.org/10.1007/978-3-030-67583-7.\n\n\nChristensen, R. H. B. 2022. “Ordinal—Regression Models for Ordinal\nData.”\n\n\nChristensen, Rune Haubo Bojesen. 2018. “Cumulative Link Models for\nOrdinal Regression with the r Package Ordinal.” In.\n\n\nFriendly, Michael. 2015. Classification and Regression Trees.\n\n\nFriendly, Michael, David Meyer, and Achim Zeileis. 2015. Discrete\nData Analysis with r: Visualization and Modeling Techniques for\nCategorical and Count Data. Discrete Data Analysis with R:\nVisualization and Modeling Techniques for Categorical and Count\nData. https://doi.org/10.1201/b19022.\n\n\nGelman, Andrew, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and\nDonald Rubin. 2013. Bayesian Data Analysis. https://doi.org/10.1201/b16018.\n\n\nGuerra, Andrea, Thierry Gidel, and Enrico Vezzetti. 2016. “Toward\na Common Procedure Using Likert and Likert-Type Scales in Small Groups\nComparative Design Observations.” In.\n\n\nHarrell, Frank. 2015. Regression Modeling Strategies: With\nApplications to Linear Models, Logistic and Ordinal Regression, and\nSurvival Analysis. https://doi.org/10.1007/978-3-319-19425-7.\n\n\nLawson, J. 2015. Edited by Chapman and Hall/CRC. https://doi.org/10.1201/b17883.\n\n\nLevshina, Natalia. 2020. “Conditional Inference Trees and Random\nForests.” In A Practical Handbook of Corpus Linguistics,\nedited by Magali Paquot and Stefan Th. Gries, 611–43. Cham: Springer\nInternational Publishing. https://doi.org/10.1007/978-3-030-46216-1_25.\n\n\nLiddell, Torrin M., and John K. Kruschke. 2018. “Analyzing Ordinal\nData with Metric Models: What Could Possibly Go Wrong?”\nJournal of Experimental Social Psychology 79: 328–48. https://doi.org/10.1016/j.jesp.2018.08.009.\n\n\nLiu, Xing. 2022. Categorical Data Analysis and Multilevel Modeling\nUsing r. Edited by SAGE Publications Ltd.\n\n\nLui, Kung-Jong. 2016. Crossover Designs: Testing, Estimation, and\nSample Size. Crossover Designs: Testing, Estimation, and Sample\nSize. https://doi.org/10.1002/9781119114710.\n\n\nMolanes-López, Elisa M., Alejandro Rodriguez-Ascaso, Emilio Letón, and\nJorge Pérez-Martín. 2021. “Assessment of Video Accessibility by\nStudents of a MOOC on Digital Materials for All.” IEEE\nAccess 9: 72357–67. https://doi.org/10.1109/ACCESS.2021.3079199.\n\n\nO’Connell, Ann. 2006. Logistic Regression Models for Ordinal\nResponse Variables. https://doi.org/10.4135/9781412984812.\n\n\nPérez Martín, Jorge, Alejandro Rodríguez-Ascaso, and Elisa\nMolanes-López. 2021. “Quality of the Captions Produced by Students\nof an Accessibility MOOC Using a Semi-Automatic Tool.”\nUniversal Access in the Information Society 20 (November). https://doi.org/10.1007/s10209-020-00740-9.\n\n\nSchweinberger, Martin. 2020. Questionnaires and Surveys: Analyses\nwith r. 2020/12/11 ed. Brisbane: The University of Queensland,\nAustralia. School of Languages; Cultures.\n\n\nSenn, Stephen. 2022. Edited by Ltd John Wiley. https://doi.org/10.1002/0470854596.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics\nwith s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nYee, T. W. 2023. VGAM: Vector Generalized Linear and\nAdditive Models. https://CRAN.R-project.org/package=VGAM."
  },
  {
    "objectID": "75-Preprocesado.html",
    "href": "75-Preprocesado.html",
    "title": "Apéndice A — Preprocesado de los ficheros suministrados.",
    "section": "",
    "text": "Este es el código en R con el que se transforman los ficheros que se suministran (ver Sección 4.2).\n\nlibrary(readr)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(testit)\nlibrary(tidyr)\n\n##### GRADE #####\n## Usuarios que no quieren participar\nno_want_users &lt;- read_lines(\"data/original/ids_a_eliminar.txt\")\n\n# Leemos todos los archivos de grade CSV\ngrade_files &lt;- list.files(\n    \"data/original\", pattern = \".*grade.*.csv\", full.names = TRUE\n)\n\ngrade_df &lt;- map_dfr(\n    grade_files, ~ read_delim(.x, delim = \";\", show_col_types = FALSE) %&gt;%\n        # Añadimos el número de fila para mantener la trazabilidad\n        mutate(Userid = row_number() + 1) %&gt;% \n        # Movemos las columnas de identificación de fila a la primera posición\n        relocate(Userid, .before = 2) %&gt;%\n        # Renombramos las columnas para que empiecen con mayúsculas\n        rename_with(~ str_to_title(.), everything()) %&gt;% \n        # Renombramos para que sea más fácil procesar el campo Cohort Name\n        rename(\"Cohort\" = \"Cohort Name\") %&gt;%\n        # Eliminamos valores nulos y los que no quieren participar\n        filter(!is.na(Cohort) & !Username %in% no_want_users) \n)\n\nassert(\"Comprobamos que no hay usuarios duplicados\", grade_df %&gt;% \n    nrow() == grade_df %&gt;%\n    distinct(Username) %&gt;%\n    nrow())\n\n# Creamos un tibble que tiene un campo con letras en lugar del valor de Cohorte\n(groups &lt;- grade_df %&gt;%\n    distinct(Cohort) %&gt;%\n    arrange(Cohort) %&gt;%\n    mutate(Group = LETTERS[1:n()]))\n\n# Unimos los tibbles para asignar en grupo como letra en lugar de la cohorte\ngrade_df &lt;- left_join(grade_df, groups) %&gt;% dplyr::select(Username, Userid, Group)\n\n##### PROFILE #####\nprofile_files &lt;- list.files(\n    \"data/original\", pattern = \".*student_profile.*.csv\", full.names = TRUE\n)\n\nprofile_df &lt;- map_dfr(\n    profile_files, ~ read_delim(.x, delim = \";\", show_col_types = FALSE)\n)\n\ngrade_df &lt;- left_join(\n    grade_df, profile_df %&gt;% dplyr::select(-cohort), by = join_by(Username == username)\n)\n\n\n##### CONOC #####\nconoc_files &lt;- list.files(\n    \"data/original\", pattern = \".*conoc.*.csv\", full.names = TRUE)\n\nconoc_df &lt;- map_dfr(\n    conoc_files, ~ read_delim(.x, delim = \";\", show_col_types = FALSE)\n)\n\nconoc_df &lt;- conoc_df %&gt;%\n    filter(Tries == 1) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n        level_of_knowledge = \n            sum(c_across(starts_with(paste(\"Q\", 1:10, \"C\", sep = \"\"))) == \"correct\")\n    ) %&gt;%\n    dplyr::select(User, level_of_knowledge)\n\ngrade_df &lt;- left_join(grade_df, conoc_df, by = join_by(Username == User))\n\n##### TEST #####\n# Leemos todos los archivos de test CSV\ntest_files &lt;- list.files(\n    \"data/original\", pattern = \".*test.*.csv\", full.names = TRUE\n)\n\n# Leer todos los archivos de test y los combinamos en un dataframe\ntest_df &lt;- map_dfr(\n    test_files, ~ read_delim(.x, delim = \";\", show_col_types = FALSE) %&gt;%\n        # Añadimos un número de fila para mantener la trazabilidad\n        mutate(Row = row_number() + 1) %&gt;% \n        # Añadimos la columna del número de test\n        mutate(Test = sprintf(\"%02d\", as.integer(str_extract(.x, \"(?&lt;=test)\\\\d+\")))) %&gt;%\n        # Movemos las columnas de identificación de test y fila a la primera posición\n        relocate(c(Test, Row), .before = 2) \n) %&gt;%\n    # eliminamos los usuarios que no quieren participar\n    filter(!User %in% no_want_users) \n\nnum_questions &lt;- 18\n\n# Nombre de los campos que contienen las respuestas al test\nquestions_original &lt;- paste(\n    \"Q\", seq(from = 1, by = 2, length.out = num_questions), \"R\", sep = \"\"\n) \n\n# Nombre de los campos que contienen las respuestas al test\ncomments_original &lt;- paste(\n    \"Q\", seq(from = 2, by = 2, length.out = num_questions - 1), \"R\", sep = \"\"\n) \n\n# Nombre de los campos que se usarán para renombrar los campos de respuesta al test\nquestions &lt;- sprintf(\"Q%02d\", seq(from = 1, by = 1, length.out = num_questions)) \ncomments &lt;- sprintf(\"C%02d\", seq(from = 1, by = 1, length.out = num_questions - 1))\ncolumns &lt;- c(\n    \"Row\", \"Test\", \"User\", \"LastTry\", questions_original, comments_original\n)\n\n# Procesamos el dataframe\n# Con este operador del paquete magrittr hacemos las transformaciones in situ\ntest_df %&lt;&gt;% \n    # Eliminamos las filas que no contienen información\n    filter(Tries &gt; 0) %&gt;% \n    # Convertimos LastTry a formato fecha\n    mutate(LastTry = strptime(LastTry, format = \"%Y-%m-%dT%H:%M:%SZ\")) %&gt;% \n    # Seleccionamos las columnas que nos interesan\n    dplyr::select(all_of(columns)) %&gt;% \n    # Extraemos la puntuación numérica de la pregunta\n    mutate(across(questions_original, ~ if_else(\n        startsWith(.x, \"choice_\"), as.integer(str_extract(.x, \"\\\\d+\")), NA_integer_)\n    )) %&gt;%\n    # Renombramos los respuestas para que sean secuenciales\n    rename(\n        setNames(questions_original, questions),\n        setNames(comments_original, comments)\n    ) %&gt;%\n    # nos aseguramos de que el orden filas es el mismo que el de los ficheros.\n    arrange(\"Test\", \"Row\") \n\n# Guardamos el número de filas para posterior comprobación\nn_test &lt;- test_df %&gt;% nrow()\n\n# Unimos los dataframes para tener el grupo y el UserID secuencial\ntest_df &lt;- inner_join(\n    test_df, grade_df, by = join_by(User == Username)\n    ) %&gt;% relocate(Group, .before = 2)\n\n# Cambiamos los valores del campo User por los del UserID\ntest_df %&lt;&gt;%\n    mutate(User = Userid) %&gt;%\n    dplyr::select(-Userid) %&gt;%\n    arrange(User, Test) # Ordenamos por usuario y test\n\n\n##### CHECKS #####\nassert(\n    \"Comprobamos que no hay preguntas duplicadas en el dataframe de test\",\n    n_test == test_df %&gt;%\n    distinct(Group, Test, User) %&gt;%\n    nrow()\n)\n\nassert(\n    \"Comprobamos que no hay valores nulos\",\n    test_df %&gt;% \n    dplyr::select(\n        -c(comments, year_of_birth, gender, level_of_education, level_of_knowledge)\n    ) %&gt;% filter(if_any(everything(), is.na)) %&gt;% nrow() == 0)\n\n\nassert(\n    \"Comprobamos que no hay respuestas con valores incorrectos\",\n    sum(sort(unique(unlist(\n        test_df %&gt;% dplyr::select(all_of(questions))\n    ))) == 0:5) == 6)\n\n\ncomments_df &lt;- test_df %&gt;%\n    pivot_longer(\n        cols = starts_with(c(\"Q\", \"C\")),\n        names_to = c(\".value\", \"Question\"),\n        names_pattern = \"(Q|C)(.*)\") %&gt;%\n    rename(Response = Q, Comment = C) %&gt;%\n    filter(!is.na(Comment) & grepl(\"[a-zA-Z]\", Comment)) %&gt;%\n    dplyr::select(Test, Row, Group, User, Question, Response, Comment) %&gt;%\n    arrange(Test, Group, Response, Row)\n\n\nwrite_csv(comments_df, \"./data/preprocess/comments.csv\")\n\n##### SAVE TO FILE #####\nwrite_csv(\n    test_df %&gt;% dplyr::select(-all_of(comments)), \"./data/preprocess/test_all.csv\"\n)"
  },
  {
    "objectID": "76-Setup.html",
    "href": "76-Setup.html",
    "title": "Apéndice B — Creación de los dataframes df_all y df_clean.",
    "section": "",
    "text": "Código que transforma los datos preprocesados (ver Apéndice A) en los dataframes que se usan en el análisis estadístico.\n\n# Leemos el tibble preprocesado\ntest_all_df &lt;- read_delim(\n    \"./data/preprocess/test_all.csv\",\n    delim = \",\", show_col_types = FALSE\n)\n\n# Eliminamos aquellos usuarios que no han hecho uno de los test\ntest_df &lt;- test_all_df %&gt;%\n    group_by(User) %&gt;%\n    mutate(Rows = n()) %&gt;%\n    filter(Rows &gt; 1) %&gt;%\n    ungroup()\n\n##### SAVE TO FILE #####\nwrite_csv(test_df, \"./data/preprocess/test.csv\")\n\ndf &lt;- test_df %&gt;%\n    mutate(\n        Period = as.factor(\n            if_else(Test == \"01\", 1, 2)\n        ),\n        Treat = as.factor(\n            if_else(Group == \"A\" & Test == \"01\" | Group == \"B\" & Test == \"02\", \"A\", \"B\")\n        ),\n        Seq = as.factor(\n            if_else(Group == \"A\", \"AB\", \"BA\")\n        ),\n        Subject = as.factor(User)\n    ) %&gt;%\n    dplyr::select(\n        Seq, Period, Treat, Subject,\n        gender, year_of_birth, level_of_education, starts_with(\"Q\")\n    ) %&gt;%\n    mutate_at(\n        vars(starts_with(\"Q\")), ~ (. + 1) %% 6\n    ) %&gt;%\n    pivot_longer(\n        cols = all_of(starts_with(\"Q\")),\n        names_to = \"Question\",\n        values_to = \"Response\"\n    ) %&gt;%\n    mutate(\n        Question = relevel(as.factor(Question), ref = \"Q18\"),\n        Response = factor(Response, ordered = TRUE)\n    ) %&gt;%\n    arrange(Subject, Period, Question)\n\nresponse_labels &lt;- c(\n    \"No sé / No contesto\",\n    \"Muy en desacuerdo\",\n    \"En desacuerdo\",\n    \"Neutral\",\n    \"De acuerdo\",\n    \"Muy de acuerdo\"\n)\n\nquestion_labels &lt;- c(\n    \"Los subtítulos del vídeo cumplen en general con los requisitos de accesibilidad.\",\n    \"La posición de los subtítulos.\",\n    \"El número de líneas por subtítulo.\",\n    \"La disposición del texto respecto a la caja donde se muestran los subtítulos.\",\n    \"El contraste entre los caracteres y el fondo.\",\n    \"La corrección ortográfica y gramatical.\",\n    \"La literalidad.\",\n    \"La identificación de los personajes.\",\n    \"La asignación de líneas a los personajes en los diálogos.\",\n    \"La descripción de efectos sonoros.\",\n    \"La sincronización de las entradas y salidas de los subtítulos.\",\n    \"La velocidad de exposición de los subtítulos.\",\n    \"El máximo número de caracteres por línea.\",\n    \"La legibilidad de la tipografía.\",\n    \"La separación en líneas diferentes de sintagmas nominales, verbales y preposicionales.\",\n    \"La utilización de puntos suspensivos.\",\n    \"La escritura de los números.\",\n    \"Las incorrecciones en el habla.\"\n)\n\nquestion_labels_reduced &lt;- c(\n    \"Valoración general\",\n    \"Posición\",\n    \"Número líneas\",\n    \"Texto dentro caja\",\n    \"Contraste\",\n    \"Corrección\",\n    \"Literalidad\",\n    \"Identificación personajes\",\n    \"Líneas/personajes\",\n    \"Efectos sonoros\",\n    \"Sincronización\",\n    \"Velocidad\",\n    \"Caracteres x línea\",\n    \"Tipografía\",\n    \"Separación sintagmas\",\n    \"Puntos suspensivos\",\n    \"Escritura números\",\n    \"Incorrecciones habla\"\n)\n\ndf &lt;- df %&gt;% mutate(\n    Response_v = as.numeric(Response) - 1,\n    Response_l = ordered(Response_v, labels = response_labels),\n    Question_l = factor(Question, labels = question_labels),\n    Question_lr = factor(Question, labels = question_labels_reduced)\n)\n\ndist &lt;- df %&gt;%\n    xtabs(~ Question + Response, data = .) %&gt;%\n    dist(x = ., method = \"euclidean\")\n\ncluster &lt;- hclust(dist, method = \"complete\")\ncuts &lt;- factor(cutree(cluster, k = 3))\n\n# Añadimos la columna cluster al dataframe\ndf &lt;- inner_join(\n    df,\n    data.frame(\n        Question = factor(names(cuts),\n            levels = levels(df$Question)\n        ),\n        Cluster = as.factor(cuts)\n    ),\n    by = \"Question\"\n)\n\nwrite_csv(df, \"./data/preprocess/test_lg.csv\")\ndf_all &lt;- df\n\ndf_all$Y &lt;- model.matrix(~ Response - 1, data = df_all)\n\ndf_clean &lt;- df %&gt;% filter(Response != 0)\ndf_clean &lt;- df_clean %&gt;% mutate(\n    Response = factor(Response, levels = levels(Response)[-1]),\n    Response_l = ordered(Response_l, levels = levels(Response_l)[-1]),\n    Level = as.ordered(\n        ifelse(\n            Response %in% c(1, 2),\n            \"Negative\",\n            ifelse(\n                Response %in% c(4, 5),\n                \"Positive\",\n                \"Neutral\"\n            )\n        )\n    )\n)\ndf_0 &lt;- df %&gt;% filter(Response == 0)"
  },
  {
    "objectID": "77-Contrasts.html#preparación.",
    "href": "77-Contrasts.html#preparación.",
    "title": "Apéndice C — Efecto secuencia e interacción tratamiento vs. periodo.",
    "section": "C.1 Preparación.",
    "text": "C.1 Preparación.\nPartimos del siguiente conjunto de datos generado aleatoriamente 1: \n\nset.seed(100)\nn &lt;- 1000\ndf &lt;- data.frame(\n    Response = rnorm(n),\n    Treat = as.factor(sample(c(\"A\", \"B\"), n, replace = TRUE)),\n    Period = as.factor(sample(c(1, 2), n, replace = TRUE))\n)\n\ndf$Seq &lt;- as.factor(\n    ifelse(\n        df$Period == 1 & df$Treat == \"A\" | df$Period == 2 & df$Treat == \"B\",\n        \"AB\",\n        \"BA\"\n    )\n)\n\nhead(df, 10)\n\n      Response Treat Period Seq\n1  -0.50219235     B      2  AB\n2   0.13153117     A      1  AB\n3  -0.07891709     A      2  BA\n4   0.88678481     A      2  BA\n5   0.11697127     A      1  AB\n6   0.31863009     A      2  BA\n7  -0.58179068     A      2  BA\n8   0.71453271     A      1  AB\n9  -0.82525943     B      2  AB\n10 -0.35986213     B      1  BA\n\n\nCalculamos las medias por cada nivel de factor y combinaciones de niveles que utilizaremos luego en la interpretación de los coeficientes de los modelos\n\nM &lt;- mean(df$Response) # 1 media de respuesta global\n\n# 2 medias de respuesta para tratamientos A y B\nmTreat &lt;- with(df, tapply(Response, Treat, mean))\n\n# 2 medias de respuesta para periodos 1 y 2\nmPeriod &lt;- with(df, tapply(Response, Period, mean))\n\n# 2 medias de respuesta para secuencias AB y BA\nmSeq &lt;- with(df, tapply(Response, Seq, mean))\n\n# 4 medias de respuesta para las cuatro combinaciones de tratamiento y periodo\nm2 &lt;- with(df, tapply(Response, list(Treat, Period), mean))\n\ndTreat &lt;- diff(mTreat) # diferencia de medias entre tratamientos A y B\n\ndPeriod &lt;- diff(mPeriod) # diferencia de medias entre periodos 1 y 2\n\nd2 &lt;- diff(m2) # diferencias entre niveles de tratamiento en cada nivel de periodo"
  },
  {
    "objectID": "77-Contrasts.html#análisis-con-un-solo-factor-tratamiento.",
    "href": "77-Contrasts.html#análisis-con-un-solo-factor-tratamiento.",
    "title": "Apéndice C — Efecto secuencia e interacción tratamiento vs. periodo.",
    "section": "C.2 Análisis con un solo factor (tratamiento).",
    "text": "C.2 Análisis con un solo factor (tratamiento).\n\nl1 &lt;- lm(Response ~ Treat, df)\ndata.frame(t(coef(l1))) %&gt;% gt()\n\n\n\n\n\n\n\nTabla C.1: Ajuste del modelo Response ~ Treat con contrasts treatment.\n\n\nX.Intercept.\nTreatB\n\n\n\n\n0.03624217\n-0.03966751\n\n\n\n\n\n\n\n\nVemos que el intercepto es la media de la respuesta en el nivel de tratamiento \\(A\\):\n\nmTreat[1]\n\n         A \n0.03624217 \n\n\nQue la pendiente (parámetro \\(TreatB\\)) es la diferencia entre las medias tratamientos:\n\ndTreat\n\n          B \n-0.03966751 \n\n\nPor ello, para conocer el efecto del tratamiento en el nivel \\(B\\) hay que sumar intercepto y pendiente:\n\ncoef(l1)[[1]] + coef(l1)[[2]] - mTreat[[2]]\n\n[1] 1.214306e-16\n\n\nEsto es así ya que por defecto R utiliza el contraste conocido como codificación de tratamiento:\n\ncontr.treatment(2)\n\n  2\n1 0\n2 1\n\n\nPodemos ver la matriz ampliada añadiendo el intercepto, que siempre será una columna de 1’s:\n\nmodel.matrix(~Treat, expand.grid(Treat = c(\"A\", \"B\")))\n\n  (Intercept) TreatB\n1           1      0\n2           1      1\nattr(,\"assign\")\n[1] 0 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$Treat\n[1] \"contr.treatment\"\n\n\nCada fila representa el nivel del tratamiento (fila 1 nivel \\(A\\) y fila 2 nivel \\(B\\)) y las columnas representan los parámetros del modelo. Los valores son los niveles de tratamiento (0 ó 1). Para obtener el significado de cada parámetro, multiplicamos el valor del contraste por el parámetro. Así:\n\nDe la primera fila obtenemos que el efecto del tratamiento \\(A\\) es el intercepto: \\(A = 1 \\cdot Intercept + 0 \\cdot TreatB\\).\nDe la segunda fila obtenemos que el valor del parámetro \\(TreatB\\) es la diferencia de los niveles de tratamiento. \\(B = 1 \\cdot Intercept + 1 \\cdot TreatB \\Rightarrow TreatB = B - Intercept\\).\n\nEsto quiere decir que existe una variable para codificar el efecto tratamiento, y esta variable tiene el valor 0 para el nivel \\(A\\) por ser el de referencia y 1 para el nivel \\(B\\). La pendiente se codifica como la diferencia del efecto de los dos niveles (\\(B - A\\))."
  },
  {
    "objectID": "77-Contrasts.html#análisis-con-un-dos-factores-tratamiento-y-periodo.",
    "href": "77-Contrasts.html#análisis-con-un-dos-factores-tratamiento-y-periodo.",
    "title": "Apéndice C — Efecto secuencia e interacción tratamiento vs. periodo.",
    "section": "C.3 Análisis con un dos factores (tratamiento y periodo).",
    "text": "C.3 Análisis con un dos factores (tratamiento y periodo).\n\nl2 &lt;- lm(Response ~ Treat * Period, df)\ndata.frame(t(coef(l2))) %&gt;% gt()\n\n\n\n\n\n\n\nTabla C.2: Ajuste del modelo Response ~ Treat * Period con contrasts treatment.\n\n\nX.Intercept.\nTreatB\nPeriod2\nTreatB.Period2\n\n\n\n\n0.04138614\n-0.1076137\n-0.01125933\n0.1343517\n\n\n\n\n\n\n\n\nVemos que el intercepto es la media del tratamiento \\(A\\) en el periodo \\(1\\) por ser estos los valores que R usa como referencia 2:\n\nm2[\"A\", \"1\"]\n\n[1] 0.04138614\n\n\nEl parámetro \\(TreatB\\) es la diferencia de medias entre los tratamientos en el periodo \\(1\\):\n\nm2[\"B\", \"1\"] - m2[\"A\", \"1\"]\n\n[1] -0.1076137\n\n\nEl parámetro \\(Period2\\) es la diferencia de medias entre los periodos en el nivel de tratamiento \\(A\\):\n\nm2[\"A\", \"2\"] - m2[\"A\", \"1\"]\n\n[1] -0.01125933\n\n\nFinalmente, \\(TreatB:Period2\\) es la diferencia entre el segundo periodo y el primero del nivel de tratamiento \\(B\\) menos la diferencia entre periodos del nivel de tratamiento \\(A\\):\n\nm2[\"B\", \"2\"] - m2[\"B\", \"1\"] - (m2[\"A\", \"2\"] - m2[\"A\", \"1\"])\n\n[1] 0.1343517\n\n\nLa matriz de contraste nos permite razonar por qué esto es así:\n\nmodel.matrix(~ Treat * Period, expand.grid(Treat = c(\"A\", \"B\"), Period = c(\"1\", \"2\")))\n\n  (Intercept) TreatB Period2 TreatB:Period2\n1           1      0       0              0\n2           1      1       0              0\n3           1      0       1              0\n4           1      1       1              1\nattr(,\"assign\")\n[1] 0 1 2 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$Treat\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$Period\n[1] \"contr.treatment\"\n\n\n\nLa primera fila es el intercepto y corresponde con el tratamiento \\(A\\) y el periodo 1.\nLa segunda fila es el efecto del tratamiento \\(B\\) en el periodo 1 y se calcula con la suma del intercepto y el parámetro \\(TreatB\\). Luego \\(TreatB\\) es la diferencia del efecto de los tratamientos en el periodo 1.\nAnálogamente con la tercera fila concluimos que \\(Period2\\) es la deferencia entre periodos para el tratamiento \\(A\\).\nFinalmente, la cuarta fila, es el tratamiento \\(B\\) en el periodo 2 y, por lo tanto, \\(Treat2:Period2\\) es la diferencia el nivel \\(B\\) de tratamiento y el periodo 2 y el nivel de tratamiento \\(A\\) en el periodo 1, menos la diferencia de niveles de tratamiento para el periodo 1 y menos la diferencia de periodos para el tratamiento \\(A\\).\n\nObsérvese que antes hemos calculado de forma diferente \\(TreatB:Period2\\). Podemos aplicar la fórmula anterior y comprobar que produce el mismo resultado:\n\nm2[\"B\", \"2\"] - m2[\"A\", \"1\"] - (m2[\"B\", \"1\"] - m2[\"A\", \"1\"]) - (m2[\"A\", \"2\"] - m2[\"A\", \"1\"])\n\n[1] 0.1343517"
  },
  {
    "objectID": "77-Contrasts.html#factor-secuencia.",
    "href": "77-Contrasts.html#factor-secuencia.",
    "title": "Apéndice C — Efecto secuencia e interacción tratamiento vs. periodo.",
    "section": "C.4 Factor secuencia.",
    "text": "C.4 Factor secuencia.\nVamos a incorporar la secuencia como factor para ver si es equivalente a la interacción entre periodo y tratamiento. En caso de serlo los coeficientes del modelo ajustado deberían coincidir. Sin embargo vemos que los modelos l2 (Tabla C.2) y l3 (Tabla C.3) tienen distintos coeficientes.\n\nl3 &lt;- lm(Response ~ Treat + Period + Seq, df)\ndata.frame(t(coef(l3))) %&gt;% gt()\n\n\n\n\n\n\n\nTabla C.3: Ajuste del modelo Response ~ Treat + Period + Seq con contrasts treatment.\n\n\nX.Intercept.\nTreatB\nPeriod2\nSeqBA\n\n\n\n\n0.04138614\n-0.04043786\n0.05591654\n-0.06717587\n\n\n\n\n\n\n\n\nLos coeficientes no coinciden debido a que estamos usando el contraste con codificación de tratamientos. Pero si cambiamos a codificación de sumas:\n\noptions(contrasts = rep(\"contr.sum\", 2))\n\nY volvemos a ajustar los modelos que ya usarán el contraste suma, podemos comprobar que ahora tienen los mismos coeficientes y el coeficiente \\(Seq1\\) del modelo que incorpora el efecto secuencia (Tabla C.4) es igual que el coeficiente \\(Treat1:Period1\\) del modelo que incorpora la interacción entre tratamiento y periodo (Tabla C.5). Obsérvese que los nombres de los coeficientes han cambiado respecto al contraste de tratamiento. Esto sucede porque la interpretación de los coeficientes varía como se explica a continuación.\n\nl4 &lt;- lm(Response ~ Treat + Period + Seq, df)\ndata.frame(t(coef(l4))) %&gt;% gt()\n\n\n\n\n\n\n\nTabla C.4: Ajuste del modelo Response ~ Treat + Period + Seq con contrasts sum.\n\n\nX.Intercept.\nTreat1\nPeriod1\nSeq1\n\n\n\n\n0.01553755\n0.02021893\n-0.02795827\n0.03358794\n\n\n\n\n\n\n\n\n\nl5 &lt;- lm(Response ~ Treat * Period, df)\ndata.frame(t(coef(l5))) %&gt;% gt()\n\n\n\n\n\n\n\nTabla C.5: Ajuste del modelo Response ~ Treat * Period con contrasts sum.\n\n\nX.Intercept.\nTreat1\nPeriod1\nTreat1.Period1\n\n\n\n\n0.01553755\n0.02021893\n-0.02795827\n0.03358794\n\n\n\n\n\n\n\n\nLa interpretación de los contrastes es diferente. Para explicarlo, mostramos la matriz de contraste:\n\nmodel.matrix(~ Treat * Period, expand.grid(Treat = c(\"A\", \"B\"), Period = c(\"1\", \"2\")))\n\n  (Intercept) Treat1 Period1 Treat1:Period1\n1           1      1       1              1\n2           1     -1       1             -1\n3           1      1      -1             -1\n4           1     -1      -1              1\nattr(,\"assign\")\n[1] 0 1 2 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$Treat\n[1] \"contr.sum\"\n\nattr(,\"contrasts\")$Period\n[1] \"contr.sum\"\n\n\nVemos que ahora los niveles son 1 y -1 3 en vez de 0 y 1 que se utilizan en el contraste de tratamiento. La interpretación es la siguiente:\n\nEl interceptor es la media de la media de cada uno de los niveles de factor. ¿Por qué?. El interceptor es el valor de la variable de respuesta cuando cuando todas las variables explicativas valen 0. Esto sucede en la media de la variable de respuesta ya que cero es el valor que está en la mitad de +1 y -1. Podemos comprobar que la media global coincide con el interceptor del modelo l4 (Tabla C.4):\n\n\nmean(m2)\n\n[1] 0.01553755\n\n\n\nEl coeficiente \\(Treat1\\) es la mitad la diferencia de la media entre niveles de tratamiento (\\(TreatA-TreatB\\)). La media de cada tratamiento se calcula como la media del tratamiento en cada periodo.\n\n\n-diff(apply(m2, 1, mean)) / 2\n\n         B \n0.02021893 \n\n\nOtra forma de entender el coeficiente \\(Treat1\\) es como la cuarta parte de la diferencia de los efectos de los tratamientos en cada periodo.\n\n(m2[\"A\", \"1\"] + m2[\"A\", \"2\"] - (m2[\"B\", \"1\"] + m2[\"B\", \"2\"])) / 4\n\n[1] 0.02021893\n\n\n\nEl coeficiente \\(Period1\\) es la mitad la diferencia de la media entre periodos(\\(Period1 - Period2\\)). La media entre periodos se calcula como la media del periodo para cada tratamiento.\n\n\n-diff(apply(m2, 2, mean)) / 2\n\n          2 \n-0.02795827 \n\n\nOtra forma de entender el coeficiente \\(Period1\\) es como la cuarta parte de la diferencia de los efectos del periodo en cada tratamiento.\n\n(m2[\"A\", \"1\"] + m2[\"B\", \"1\"] - (m2[\"A\", \"2\"] + m2[\"B\", \"2\"])) / 4\n\n[1] -0.02795827\n\n\n\nEl coeficiente \\(Treat1:Period1\\) es el coeficiente \\(Treat1\\) menos la mitad de la diferencia de la media entre tratamientos para el periodo 2 (\\(TreatA-TreatB\\)):\n\n\n-diff(apply(m2, 1, mean)) / 2 + diff(m2[, \"2\"]) / 2\n\n         B \n0.03358794 \n\ncoef(l5)[2] + diff(m2[, \"2\"]) / 2\n\n    Treat1 \n0.03358794 \n\n\nEl coeficiente \\(Treat1:Period1\\) también se puede calcular como \\(Period1\\) menos la mitad de la diferencia de la media entre periodos para el para el tratamiento \\(B\\) (\\(Period1-Period2\\)):\n\n-diff(apply(m2, 2, mean)) / 2 + diff(m2[\"B\", ]) / 2\n\n         2 \n0.03358794 \n\ncoef(l5)[3] + diff(m2[\"B\", ]) / 2\n\n   Period1 \n0.03358794 \n\n\nUn tercera forma de interpretar el coeficiente \\(Treat1:Period1\\) es como la cuarta parte de la suma de la diferencia cruzada del efecto de cada tratamiento en cada periodo:\n\n(m2[\"A\", \"1\"] - m2[\"A\", \"2\"] + m2[\"B\", \"2\"] - m2[\"B\", \"1\"]) / 4\n\n[1] 0.03358794\n\n\nO reorganizando los términos de otra forma, sería la cuarta parte de la suma de la diferencia cruzada del efecto de cada periodo en cada tratamiento:\n\n(m2[\"B\", \"2\"] - m2[\"A\", \"2\"] + m2[\"A\", \"1\"] - m2[\"B\", \"1\"]) / 4\n\n[1] 0.03358794\n\n\n\nPodemos obtener el coeficiente \\(TreatB\\) del modelo \\(l2\\) (Tabla C.2) como \\(-2 \\cdot (Treat1 + Treat1:Period1)\\):\n\n\n-2 * (coef(l5)[\"Treat1\"] + coef(l5)[\"Treat1:Period1\"])\n\n    Treat1 \n-0.1076137 \n\n\n\nAnálogamente el coeficiente \\(Period2\\) del modelo \\(l2\\) (Tabla C.2) se obtiene \\(-2 \\cdot (Period1 + Treat1:Period1)\\):\n\n\n-2 * (coef(l5)[\"Period1\"] + coef(l5)[\"Treat1:Period1\"])\n\n    Period1 \n-0.01125933 \n\n\n\nEl coeficiente \\(TreatB:Period2\\) se obtiene como \\(4 \\cdot Treat1:Period1\\):\n\n\n4 * (coef(l5)[\"Treat1:Period1\"])\n\nTreat1:Period1 \n     0.1343517 \n\n\n\noptions(contrasts = rep(\"contr.treatment\", 2))\nl6 &lt;- lm(Response ~ Treat + Period, df)\ndata.frame(t(coef(l6))) %&gt;% gt()\n\n\n\n\n\n\n\n\nX.Intercept.\nTreatB\nPeriod2\n\n\n\n\n0.01120158\n-0.04259114\n0.05480989\n\n\n\n\n\n\n\n\noptions(contrasts = rep(\"contr.sum\", 2))\nl7 &lt;- lm(Response ~ Treat + Period, df)\ndata.frame(t(coef(l7))) %&gt;% gt()\n\n\n\n\n\n\n\n\nX.Intercept.\nTreat1\nPeriod1\n\n\n\n\n0.01731095\n0.02129557\n-0.02740495"
  },
  {
    "objectID": "77-Contrasts.html#footnotes",
    "href": "77-Contrasts.html#footnotes",
    "title": "Apéndice C — Efecto secuencia e interacción tratamiento vs. periodo.",
    "section": "",
    "text": "Obsérvese que se la variable Response en esta simulación es cuantitativa y no ordinal. Se ha realizado de esta forma para poder usar un ajuste de mínimos cuadrados en lugar de una regresión ordinal para facilitar el cálculo y su interpretación.↩︎\nR utiliza como valor de referencia el nivel más bajo de factor.↩︎\nEl nivel de referencia del factor tendrá valor 1 y el otro -1. Por ejemplo, en la variable Treat, \\(A\\) tendrá +1 y \\(B\\) tendrá valor -1.↩︎"
  },
  {
    "objectID": "78-Bayesiano.html",
    "href": "78-Bayesiano.html",
    "title": "Apéndice D — Modelado Bayesiano.",
    "section": "",
    "text": "brm_subject_formula &lt;- Response ~ 1 + (1 | Subject)\nbrm_subject &lt;-\n    brm(\n        brm_subject_formula,\n        data = df_clean,\n        family = cumulative(\"logit\"),\n        sample_prior = TRUE,\n        file = \"models/brm_subject\",\n        file_refit = \"on_change\"\n    )\nsummary(brm_subject)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ 1 + (1 | Subject) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Subject (Number of levels: 87) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.93      0.09     0.78     1.12 1.00      748     1502\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -3.15      0.13    -3.41    -2.89 1.01      643     1130\nIntercept[2]    -1.68      0.11    -1.90    -1.46 1.01      489      823\nIntercept[3]    -0.93      0.11    -1.14    -0.71 1.01      472      750\nIntercept[4]     0.65      0.11     0.43     0.86 1.01      503      794\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_treat.period.subject.question &lt;- brm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_treat.period.subject.question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_treat.period.subject.question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.74      0.16     0.50     1.11 1.00     1213\nsd(TreatB)                1.50      0.29     1.05     2.21 1.00     1194\ncor(Intercept,TreatB)    -0.41      0.21    -0.74     0.07 1.01      931\n                      Tail_ESS\nsd(Intercept)             2155\nsd(TreatB)                1803\ncor(Intercept,TreatB)     1691\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.82      0.18     1.50     2.21 1.00      841\nsd(TreatB)                2.39      0.21     2.01     2.84 1.00      685\ncor(Intercept,TreatB)    -0.54      0.09    -0.70    -0.35 1.01      420\n                      Tail_ESS\nsd(Intercept)             1266\nsd(TreatB)                1487\ncor(Intercept,TreatB)      719\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -6.70      0.37    -7.43    -5.98 1.00      701     1417\nIntercept[2]      -4.35      0.35    -5.03    -3.64 1.00      641     1231\nIntercept[3]      -3.06      0.34    -3.73    -2.37 1.00      626     1271\nIntercept[4]      -0.50      0.34    -1.17     0.18 1.00      623     1227\nTreatB            -3.15      0.57    -4.28    -2.04 1.01      483     1112\nPeriod2           -0.58      0.41    -1.41     0.21 1.01      492      943\nTreatB:Period2     0.50      0.68    -0.82     1.83 1.00      428      888\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_treat.period.subject_question &lt;- brm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_treat.period.subject_question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_treat.period.subject_question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.75      0.15     0.52     1.11 1.01      599     1261\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.80      0.18     1.48     2.18 1.01      609\nsd(TreatB)                2.29      0.21     1.91     2.73 1.01      553\ncor(Intercept,TreatB)    -0.58      0.08    -0.73    -0.40 1.01      409\n                      Tail_ESS\nsd(Intercept)             1378\nsd(TreatB)                1002\ncor(Intercept,TreatB)      864\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -6.27      0.36    -6.98    -5.58 1.01      403      700\nIntercept[2]      -4.20      0.35    -4.89    -3.54 1.01      383      791\nIntercept[3]      -3.04      0.34    -3.72    -2.38 1.01      377      730\nIntercept[4]      -0.63      0.33    -1.28     0.01 1.02      376      735\nTreatB            -3.09      0.42    -3.96    -2.27 1.01      323      532\nPeriod2           -0.64      0.41    -1.47     0.16 1.02      267      656\nTreatB:Period2     0.60      0.64    -0.61     1.87 1.01      291      765\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_cs.treat.subject.question &lt;- brm(\n    Response ~ 1 + cs(Treat) + (1 | Subject) + (1 | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_cs.treat.subject.question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_cs.treat.subject.question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ 1 + cs(Treat) + (1 | Subject) + (1 | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.63      0.12     0.43     0.91 1.00      864     1618\n\n~Subject (Number of levels: 87) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.17      0.10     0.99     1.40 1.01      700     1373\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -6.53      0.54    -7.68    -5.56 1.00     1024     1666\nIntercept[2]    -3.75      0.24    -4.21    -3.30 1.01      721     1507\nIntercept[3]    -2.35      0.21    -2.77    -1.91 1.01      624     1253\nIntercept[4]    -0.02      0.20    -0.43     0.38 1.01      598     1189\nTreatB[1]       -3.95      0.50    -5.05    -3.08 1.00     1328     1728\nTreatB[2]       -2.91      0.15    -3.21    -2.63 1.00     1834     2438\nTreatB[3]       -2.41      0.10    -2.61    -2.21 1.00     2375     2819\nTreatB[4]       -1.82      0.10    -2.01    -1.62 1.00     3745     3037\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_treat_question_subject_question &lt;- brm(\n    Response ~ 1 + Treat + (1 | Question) + (1 | Subject:Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_treat_question_subject_question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_treat_question_subject_question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ 1 + Treat + (1 | Question) + (1 | Subject:Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.58      0.12     0.39     0.88 1.00     1627     2121\n\n~Subject:Question (Number of levels: 1529) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.73      0.09     0.55     0.89 1.01      791     1229\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -4.48      0.18    -4.85    -4.13 1.01     1271     2352\nIntercept[2]    -2.81      0.16    -3.14    -2.49 1.01     1244     2546\nIntercept[3]    -1.90      0.16    -2.22    -1.59 1.01     1256     2228\nIntercept[4]    -0.10      0.15    -0.40     0.20 1.00     1312     2093\nTreatB          -1.97      0.08    -2.14    -1.81 1.00     2761     3019\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_treat_question_subject &lt;- brm(\n    Response ~ 1 + Treat + (1 | Question) + (1 | Subject),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_treat_question_subject\",\n    file_refit = \"on_change\"\n)\nsummary(brm_treat_question_subject)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ 1 + Treat + (1 | Question) + (1 | Subject) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.64      0.12     0.44     0.91 1.00      924     1940\n\n~Subject (Number of levels: 87) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.21      0.10     1.02     1.43 1.00      843     1744\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -4.94      0.23    -5.40    -4.49 1.00      677     1423\nIntercept[2]    -3.17      0.22    -3.60    -2.76 1.00      614     1363\nIntercept[3]    -2.18      0.21    -2.60    -1.77 1.00      584     1330\nIntercept[4]    -0.15      0.21    -0.55     0.26 1.00      556     1142\nTreatB          -2.21      0.08    -2.37    -2.04 1.00     5832     3233\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n_\n\nbrm_period.treat.subject_question &lt;- brm(\n    Response ~ Period * Treat + (1 + Treat | Subject) + (1 | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_period.treat.subject_question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_period.treat.subject_question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Period * Treat + (1 + Treat | Subject) + (1 | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.74      0.15     0.52     1.08 1.00      744     1544\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.80      0.17     1.48     2.15 1.02      585\nsd(TreatB)                2.27      0.20     1.89     2.70 1.01      458\ncor(Intercept,TreatB)    -0.58      0.08    -0.72    -0.40 1.00      460\n                      Tail_ESS\nsd(Intercept)             1462\nsd(TreatB)                 811\ncor(Intercept,TreatB)      818\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -6.22      0.35    -6.92    -5.55 1.00      502     1033\nIntercept[2]      -4.15      0.33    -4.82    -3.51 1.00      472      931\nIntercept[3]      -2.98      0.33    -3.65    -2.35 1.00      464      958\nIntercept[4]      -0.58      0.32    -1.24     0.03 1.00      451      834\nPeriod2           -0.59      0.39    -1.36     0.16 1.01      365      656\nTreatB            -3.06      0.42    -3.88    -2.24 1.01      327      713\nPeriod2:TreatB     0.53      0.63    -0.73     1.78 1.01      337      674\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_period.treat_subject_question &lt;- brm(\n    Response ~ Period * Treat + (1 | Subject) + (1 | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_period.treat_subject_question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_period.treat_subject_question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Period * Treat + (1 | Subject) + (1 | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.64      0.13     0.44     0.93 1.00     1169     2019\n\n~Subject (Number of levels: 87) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.23      0.11     1.04     1.47 1.00      962     1901\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -5.32      0.28    -5.88    -4.80 1.00      752     1381\nIntercept[2]      -3.55      0.26    -4.10    -3.05 1.01      702     1231\nIntercept[3]      -2.56      0.26    -3.08    -2.06 1.01      681     1220\nIntercept[4]      -0.51      0.25    -1.03    -0.02 1.01      663     1167\nPeriod2           -0.63      0.29    -1.20    -0.06 1.01      464      919\nTreatB            -2.54      0.29    -3.12    -1.98 1.01      473      952\nPeriod2:TreatB     0.61      0.56    -0.50     1.68 1.01      447      803\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_period.treat.question_subject &lt;- brm(\n    Response ~ Period * Treat + (1 | Subject) + (1 + Treat | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_period.treat.question_subject\",\n    file_refit = \"on_change\"\n)\nsummary(brm_period.treat.question_subject)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Period * Treat + (1 | Subject) + (1 + Treat | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.64      0.13     0.42     0.95 1.01     1086\nsd(TreatB)                1.30      0.26     0.89     1.90 1.01      852\ncor(Intercept,TreatB)    -0.42      0.21    -0.75     0.05 1.00      558\n                      Tail_ESS\nsd(Intercept)             2145\nsd(TreatB)                1540\ncor(Intercept,TreatB)     1102\n\n~Subject (Number of levels: 87) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.30      0.12     1.09     1.55 1.00      762     1292\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -5.67      0.29    -6.27    -5.12 1.01      382     1094\nIntercept[2]      -3.72      0.28    -4.28    -3.20 1.01      341     1024\nIntercept[3]      -2.64      0.28    -3.20    -2.13 1.01      337      967\nIntercept[4]      -0.49      0.27    -1.04     0.02 1.01      319     1020\nPeriod2           -0.67      0.30    -1.25    -0.08 1.01      300      665\nTreatB            -2.70      0.45    -3.58    -1.83 1.01      312      805\nPeriod2:TreatB     0.67      0.58    -0.44     1.80 1.02      286      592\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_thres.question_period.treat.subject &lt;- brm(\n    bf(Response | thres(gr = Question) ~ Period * Treat + (1 + Treat | Subject)),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_thres.question_period.treat.subject\",\n    file_refit = \"on_change\"\n)\nsummary(brm_thres.question_period.treat.subject)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response | thres(gr = Question) ~ Period * Treat + (1 + Treat | Subject) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             2.20      0.27     1.74     2.77 1.00      548\nsd(TreatB)                2.50      0.26     2.04     3.07 1.01      520\ncor(Intercept,TreatB)    -0.62      0.09    -0.77    -0.44 1.01      482\n                      Tail_ESS\nsd(Intercept)              900\nsd(TreatB)                1094\ncor(Intercept,TreatB)      980\n\nPopulation-Level Effects: \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[Q18,1]    -4.41      0.49    -5.40    -3.50 1.00      797     1843\nIntercept[Q18,2]    -2.02      0.38    -2.74    -1.28 1.00      555     1224\nIntercept[Q18,3]    -1.07      0.37    -1.80    -0.34 1.00      550     1001\nIntercept[Q18,4]     1.25      0.38     0.53     2.00 1.00      540     1217\nIntercept[Q01,1]    -4.40      0.49    -5.40    -3.44 1.00      805     1740\nIntercept[Q01,2]    -2.57      0.40    -3.36    -1.79 1.00      588     1440\nIntercept[Q01,3]    -1.96      0.38    -2.71    -1.20 1.00      542     1004\nIntercept[Q01,4]     0.50      0.37    -0.22     1.23 1.00      527     1110\nIntercept[Q02,1]    -5.41      0.63    -6.70    -4.22 1.00     1063     2056\nIntercept[Q02,2]    -2.55      0.39    -3.31    -1.78 1.00      580     1201\nIntercept[Q02,3]    -1.78      0.38    -2.51    -1.04 1.00      545     1330\nIntercept[Q02,4]     0.69      0.38    -0.05     1.43 1.00      529     1116\nIntercept[Q03,1]    -5.38      0.62    -6.65    -4.23 1.00     1228     2179\nIntercept[Q03,2]    -2.45      0.40    -3.23    -1.68 1.00      599     1486\nIntercept[Q03,3]    -1.79      0.39    -2.53    -1.04 1.00      569     1398\nIntercept[Q03,4]     0.84      0.38     0.08     1.58 1.00      570     1297\nIntercept[Q04,1]    -5.95      0.80    -7.65    -4.58 1.00     1381     2344\nIntercept[Q04,2]    -4.10      0.48    -5.08    -3.17 1.00      836     1893\nIntercept[Q04,3]    -3.10      0.42    -3.92    -2.27 1.00      646     1452\nIntercept[Q04,4]    -0.32      0.37    -1.03     0.43 1.00      528      925\nIntercept[Q05,1]    -2.82      0.39    -3.61    -2.06 1.00      582     1559\nIntercept[Q05,2]    -1.21      0.37    -1.91    -0.46 1.00      538     1186\nIntercept[Q05,3]    -0.61      0.37    -1.32     0.13 1.00      522     1156\nIntercept[Q05,4]     0.91      0.38     0.19     1.65 1.00      522     1207\nIntercept[Q06,1]    -5.21      0.57    -6.37    -4.13 1.00     1012     2125\nIntercept[Q06,2]    -2.39      0.39    -3.16    -1.63 1.00      593     1587\nIntercept[Q06,3]    -1.26      0.38    -1.99    -0.52 1.00      560     1300\nIntercept[Q06,4]     1.03      0.38     0.30     1.80 1.00      563     1302\nIntercept[Q07,1]    -4.07      0.46    -5.03    -3.21 1.00      702     1350\nIntercept[Q07,2]    -1.84      0.37    -2.57    -1.11 1.00      554     1362\nIntercept[Q07,3]    -1.14      0.37    -1.82    -0.43 1.00      527     1210\nIntercept[Q07,4]     1.17      0.38     0.45     1.92 1.00      533     1260\nIntercept[Q08,1]    -3.88      0.45    -4.76    -3.02 1.00      621     1612\nIntercept[Q08,2]    -1.38      0.37    -2.11    -0.64 1.00      533     1303\nIntercept[Q08,3]    -0.48      0.37    -1.19     0.25 1.00      506     1248\nIntercept[Q08,4]     1.36      0.39     0.61     2.10 1.00      518     1140\nIntercept[Q09,1]    -2.28      0.39    -3.02    -1.55 1.00      561     1146\nIntercept[Q09,2]    -0.93      0.37    -1.66    -0.22 1.00      524     1056\nIntercept[Q09,3]    -0.35      0.36    -1.07     0.36 1.00      525     1013\nIntercept[Q09,4]     1.58      0.38     0.85     2.35 1.00      557     1268\nIntercept[Q10,1]    -5.54      0.70    -7.07    -4.30 1.00     1369     2014\nIntercept[Q10,2]    -2.48      0.40    -3.24    -1.71 1.00      600     1466\nIntercept[Q10,3]    -1.42      0.38    -2.15    -0.68 1.00      559     1168\nIntercept[Q10,4]     1.12      0.38     0.38     1.87 1.00      561     1221\nIntercept[Q11,1]    -6.52      0.85    -8.37    -5.08 1.00     1441     2244\nIntercept[Q11,2]    -3.55      0.43    -4.39    -2.72 1.00      707     1422\nIntercept[Q11,3]    -2.02      0.38    -2.77    -1.28 1.00      558     1447\nIntercept[Q11,4]     1.28      0.39     0.53     2.04 1.00      536     1104\nIntercept[Q12,1]    -5.77      0.68    -7.19    -4.52 1.00     1236     2278\nIntercept[Q12,2]    -2.56      0.40    -3.33    -1.77 1.00      590     1765\nIntercept[Q12,3]    -1.48      0.38    -2.20    -0.73 1.00      532     1205\nIntercept[Q12,4]     1.56      0.39     0.82     2.35 1.00      536     1152\nIntercept[Q13,1]    -6.16      0.86    -8.02    -4.67 1.00     1547     1928\nIntercept[Q13,2]    -5.16      0.62    -6.44    -4.00 1.00     1119     1791\nIntercept[Q13,3]    -2.84      0.41    -3.65    -2.04 1.00      621     1215\nIntercept[Q13,4]    -0.05      0.37    -0.77     0.67 1.00      532     1188\nIntercept[Q14,1]    -4.56      0.52    -5.62    -3.57 1.00      860     1942\nIntercept[Q14,2]    -2.07      0.39    -2.84    -1.31 1.00      588     1223\nIntercept[Q14,3]    -0.62      0.38    -1.35     0.12 1.00      563     1135\nIntercept[Q14,4]     1.64      0.40     0.87     2.42 1.00      595     1503\nIntercept[Q15,1]    -5.08      0.64    -6.37    -3.87 1.00     1148     2531\nIntercept[Q15,2]    -2.18      0.41    -2.96    -1.41 1.00      621     1277\nIntercept[Q15,3]    -0.37      0.39    -1.12     0.38 1.00      548     1159\nIntercept[Q15,4]     2.01      0.41     1.21     2.80 1.00      629     1274\nIntercept[Q16,1]    -6.26      0.90    -8.16    -4.65 1.00     1593     2460\nIntercept[Q16,2]    -4.19      0.54    -5.32    -3.17 1.00     1018     2280\nIntercept[Q16,3]     0.00      0.38    -0.73     0.75 1.00      580     1148\nIntercept[Q16,4]     2.27      0.44     1.42     3.16 1.00      695     1305\nIntercept[Q17,1]    -5.28      0.66    -6.65    -4.06 1.00     1270     2323\nIntercept[Q17,2]    -2.92      0.42    -3.76    -2.09 1.00      692     1701\nIntercept[Q17,3]    -0.53      0.38    -1.25     0.20 1.00      567     1197\nIntercept[Q17,4]     1.86      0.40     1.10     2.69 1.00      637     1536\nPeriod2              1.21      0.52     0.29     2.30 1.01      337      889\nTreatB              -1.28      0.46    -2.15    -0.38 1.00      417      869\nPeriod2:TreatB      -1.75      0.82    -3.46    -0.29 1.00      388      657\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_period.treat.subject_question.disc &lt;- brm(\n    bf(\n        Response ~ Period * Treat + (1 + Treat | Subject) + (1 | q | Question),\n        disc ~ 1 + (1 | q | Question)\n    ),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_period.treat.subject_question.disc\",\n    file_refit = \"on_change\",\n    prior = prior(\"constant(1)\", class = \"sd\", group = \"Subject\") +\n        prior(\"normal(0, 3)\", class = \"sd\", group = \"Question\") +\n        prior(\"normal(0, 1)\", class = \"sd\", group = \"Question\", dpar = \"disc\")\n)\nsummary(brm_period.treat.subject_question.disc)\n\n Family: cumulative \n  Links: mu = logit; disc = log \nFormula: Response ~ Period * Treat + (1 + Treat | Subject) + (1 | q | Question) \n         disc ~ 1 + (1 | q | Question)\n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n                              Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)                     0.41      0.09     0.27     0.61 1.00\nsd(disc_Intercept)                0.21      0.05     0.13     0.33 1.00\ncor(Intercept,disc_Intercept)    -0.06      0.26    -0.56     0.46 1.00\n                              Bulk_ESS Tail_ESS\nsd(Intercept)                     1097     2219\nsd(disc_Intercept)                1780     2440\ncor(Intercept,disc_Intercept)     2013     2323\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.00      0.00     1.00     1.00   NA       NA\nsd(TreatB)                1.00      0.00     1.00     1.00   NA       NA\ncor(Intercept,TreatB)    -0.55      0.08    -0.70    -0.37 1.00     1071\n                      Tail_ESS\nsd(Intercept)               NA\nsd(TreatB)                  NA\ncor(Intercept,TreatB)     1851\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -3.23      0.30    -3.82    -2.66 1.01      726     1352\nIntercept[2]      -2.14      0.24    -2.62    -1.66 1.01      677     1266\nIntercept[3]      -1.55      0.21    -1.97    -1.12 1.01      658     1120\nIntercept[4]      -0.32      0.19    -0.68     0.07 1.01      638     1149\ndisc_Intercept     0.67      0.09     0.49     0.86 1.00     1097     1383\nPeriod2           -0.31      0.22    -0.74     0.12 1.00      565      881\nTreatB            -1.57      0.24    -2.03    -1.12 1.00      662     1134\nPeriod2:TreatB     0.28      0.36    -0.42     1.00 1.00      614     1036\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_acat_cs.treat.subject.question &lt;- brm(\n    Response ~ 1 + cs(Treat) + (1 | Subject) + (1 | Question),\n    data = df_clean,\n    family = acat(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_acat_cs.treat.subject.question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_acat_cs.treat.subject.question)\n\n Family: acat \n  Links: mu = logit; disc = identity \nFormula: Response ~ 1 + cs(Treat) + (1 | Subject) + (1 | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.40      0.08     0.27     0.59 1.00      793     1181\n\n~Subject (Number of levels: 87) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.69      0.07     0.57     0.83 1.00      655     1621\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -3.54      0.54    -4.69    -2.57 1.00     1679     2078\nIntercept[2]    -1.55      0.21    -1.97    -1.15 1.01      886     2036\nIntercept[3]    -1.75      0.16    -2.07    -1.45 1.01      566     1235\nIntercept[4]    -0.27      0.13    -0.53    -0.01 1.01      420     1200\nTreatB[1]       -2.21      0.53    -3.34    -1.27 1.00     2333     2245\nTreatB[2]       -1.65      0.19    -2.02    -1.29 1.00     2645     2810\nTreatB[3]       -1.29      0.13    -1.55    -1.03 1.00     3283     3268\nTreatB[4]       -1.03      0.10    -1.24    -0.83 1.00     4452     3192\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nbrm_treat.period.subject.question &lt;- brm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question),\n    data = df_clean,\n    family = cumulative(\"logit\"),\n    sample_prior = TRUE,\n    file = \"models/brm_treat.period.subject.question\",\n    file_refit = \"on_change\"\n)\nsummary(brm_treat.period.subject.question)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Question) \n   Data: df_clean (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~Question (Number of levels: 18) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.74      0.16     0.50     1.11 1.00     1213\nsd(TreatB)                1.50      0.29     1.05     2.21 1.00     1194\ncor(Intercept,TreatB)    -0.41      0.21    -0.74     0.07 1.01      931\n                      Tail_ESS\nsd(Intercept)             2155\nsd(TreatB)                1803\ncor(Intercept,TreatB)     1691\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.82      0.18     1.50     2.21 1.00      841\nsd(TreatB)                2.39      0.21     2.01     2.84 1.00      685\ncor(Intercept,TreatB)    -0.54      0.09    -0.70    -0.35 1.01      420\n                      Tail_ESS\nsd(Intercept)             1266\nsd(TreatB)                1487\ncor(Intercept,TreatB)      719\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -6.70      0.37    -7.43    -5.98 1.00      701     1417\nIntercept[2]      -4.35      0.35    -5.03    -3.64 1.00      641     1231\nIntercept[3]      -3.06      0.34    -3.73    -2.37 1.00      626     1271\nIntercept[4]      -0.50      0.34    -1.17     0.18 1.00      623     1227\nTreatB            -3.15      0.57    -4.28    -2.04 1.01      483     1112\nPeriod2           -0.58      0.41    -1.41     0.21 1.01      492      943\nTreatB:Period2     0.50      0.68    -0.82     1.83 1.00      428      888\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nLOO(\n    brm_subject,\n    brm_period.treat_subject_question,\n    brm_treat.period.subject.question,\n    brm_cs.treat.subject.question,\n    brm_treat_question_subject,\n    brm_treat_question_subject_question,\n    brm_period.treat.subject_question,\n    brm_thres.question_period.treat.subject,\n    brm_period.treat.subject_question.disc,\n    brm_acat_cs.treat.subject.question,\n    brm_period.treat.question_subject\n)\n\nOutput of model 'brm_subject':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -4004.3 38.3\np_loo        87.7  1.6\nlooic      8008.6 76.6\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_period.treat_subject_question':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3480.8 40.0\np_loo       108.7  2.1\nlooic      6961.5 80.0\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_treat.period.subject.question':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3011.0 46.2\np_loo       193.8  4.6\nlooic      6022.0 92.4\n------\nMonte Carlo SE of elpd_loo is 0.2.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2978  99.9%   983       \n (0.5, 0.7]   (ok)          2   0.1%   1997      \n   (0.7, 1]   (bad)         0   0.0%   &lt;NA&gt;      \n   (1, Inf)   (very bad)    0   0.0%   &lt;NA&gt;      \n\nAll Pareto k estimates are ok (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_cs.treat.subject.question':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3464.7 40.1\np_loo       107.1  2.1\nlooic      6929.4 80.2\n------\nMonte Carlo SE of elpd_loo is 0.2.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_treat_question_subject':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3490.1 39.8\np_loo       106.9  2.0\nlooic      6980.2 79.5\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_treat_question_subject_question':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3869.0 33.0\np_loo       357.0  5.5\nlooic      7738.0 65.9\n------\nMonte Carlo SE of elpd_loo is 0.3.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2978  99.9%   1264      \n (0.5, 0.7]   (ok)          2   0.1%   6056      \n   (0.7, 1]   (bad)         0   0.0%   &lt;NA&gt;      \n   (1, Inf)   (very bad)    0   0.0%   &lt;NA&gt;      \n\nAll Pareto k estimates are ok (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_period.treat.subject_question':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3158.0 45.2\np_loo       182.3  4.3\nlooic      6316.1 90.5\n------\nMonte Carlo SE of elpd_loo is 0.2.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2979  100.0%  1140      \n (0.5, 0.7]   (ok)          1    0.0%  1411      \n   (0.7, 1]   (bad)         0    0.0%  &lt;NA&gt;      \n   (1, Inf)   (very bad)    0    0.0%  &lt;NA&gt;      \n\nAll Pareto k estimates are ok (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_thres.question_period.treat.subject':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3058.6 46.4\np_loo       229.2  5.3\nlooic      6117.3 92.8\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2970  99.7%   1328      \n (0.5, 0.7]   (ok)          8   0.3%   557       \n   (0.7, 1]   (bad)         2   0.1%   274       \n   (1, Inf)   (very bad)    0   0.0%   &lt;NA&gt;      \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_period.treat.subject_question.disc':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3131.4 45.2\np_loo       195.7  5.1\nlooic      6262.8 90.4\n------\nMonte Carlo SE of elpd_loo is 0.2.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2978  99.9%   1172      \n (0.5, 0.7]   (ok)          2   0.1%   670       \n   (0.7, 1]   (bad)         0   0.0%   &lt;NA&gt;      \n   (1, Inf)   (very bad)    0   0.0%   &lt;NA&gt;      \n\nAll Pareto k estimates are ok (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_acat_cs.treat.subject.question':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3468.1 39.2\np_loo       101.7  2.9\nlooic      6936.2 78.5\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'brm_period.treat.question_subject':\n\nComputed from 4000 by 2980 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -3361.7 41.4\np_loo       123.1  2.4\nlooic      6723.4 82.9\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n                                        elpd_diff se_diff\nbrm_treat.period.subject.question          0.0       0.0 \nbrm_thres.question_period.treat.subject  -47.7      20.0 \nbrm_period.treat.subject_question.disc  -120.4      17.2 \nbrm_period.treat.subject_question       -147.0      16.9 \nbrm_period.treat.question_subject       -350.7      28.0 \nbrm_cs.treat.subject.question           -453.7      31.1 \nbrm_acat_cs.treat.subject.question      -457.1      29.7 \nbrm_period.treat_subject_question       -469.8      30.5 \nbrm_treat_question_subject              -479.1      31.0 \nbrm_treat_question_subject_question     -858.0      39.0 \nbrm_subject                             -993.3      42.8"
  }
]