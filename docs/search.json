[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "",
    "text": "1 Introducción"
  },
  {
    "objectID": "index.html#motivación",
    "href": "index.html#motivación",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.1 Motivación",
    "text": "1.1 Motivación\nAlgunas personas tienen problemas de a contenidos multimedia. Por ejemplo, personas sordas o con discapacidad auditiva, personas que no dominen el idioma o que lo estén aprendiendo, situaciones en las que el contenido audiovisual se reproduce en entornos ruidosos o en los que el silencio es necesario. Añadir subtítulos a los vídeos facilita que se superen estas dificultades ya que permiten la percepción visual de información que originalmente era sonora. Por ello, los subtítulos constituyen uno de los componentes fundamentales de la accesibilidad audiovisual (ver Pérez Martín, Rodríguez-Ascaso, y Molanes-López 2021). En las Pautas de Accesibilidad para el Contenido Web, WCAG 2.1 (ver W3C 2018) se incluyen pautas y criterios que deben seguirse en el contenido web, como la obligatoriedad de tener subtítulos en los vídeos. La norma UNE 153010 (ver AENOR 2012) sobre Subtitulado para personas sordas y personas con discapacidad auditiva especifica requisitos y recomendaciones sobre subtitulado para facilitar la accesibilidad a los contenidos audiovisuales.\nLas plataformas de compartición de vídeos, como YouTube, permiten en la actualidad la generación de subtítulos automáticos. Además, existen comunidades que se dedican a subtitular todo tipo de material multimedia. No obstante, frecuentemente los subtítulos producidos de esta manera no tienen en cuenta los criterios de calidad y de accesibilidad del subtitulado. Un subtitulado de calidad consta de información interpretativa e incluye descripción textual de efectos sonoros junto con otros elementos como la perfecta sincronización con el hablante, el tiempo de permanencia de subtítulo en la pantalla, el número de caracteres por línea y el número de líneas, la exactitud del diálogo, la ubicación, el tamaño, el contraste del subtítulo, etc. Así, Parton (2016) realizó un estudio para determinar si los subtítulos automáticos generados por YouTube cumplen las necesidades de los estudiantes universitarios sordos. En el estudio se contabilizaron un total de 525 errores en 68 minutos de video (una tasa de 7.7 errores por minuto). Adecuar los subtítulos a las normas de accesibilidad es una tarea importante y compleja que requiere dedicación y conocimiento específico y va más allá de verificar si el vídeo tiene o no subtítulos.\nEste trabajo analiza datos que proceden de una actividad voluntaria sobre evaluación del subtitulado que se propuso a los estudiantes de la Sexta Edición de 2022 del curso MOOC Materiales Digitales Accesibles perteneciente al Canal Fundación ONCE en UNED. La Fundación ONCE, el Real Patronato sobre Discapacidad y la UNED colaboran para producir recursos educativos abiertos, gratuitos, de calidad y accesibles para todas las personas. El Canal se creó en 2016 y hasta marzo de 2023 casi 23.000 estudiantes se han inscrito en alguno de sus nueve cursos. En el año 2022 se matricularon 3.764 alumnos y aprobaron el 19,34% de los matriculados. Los cursos se realizan en formato y en ellos se ofrece formación en conocimientos y habilidades necesarios para diseñar productos, entornos, sistemas y servicios desde una perspectiva de diseño universal:\n\nReconocer las necesidades relacionadas con la accesibilidad.\nDar respuesta a estas necesidades, cada actor en la medida de sus posibilidades.\nIntegrar soluciones de accesibilidad universales y específicas utilizando la tecnología apropiada.\n\nEl curso de Materiales Digitales Accesibles está dirigido por los profesores Emilio Letón Molina y Alejandro Rodríguez Ascaso y se viene realizando desde 2017. Se han matriculado en alguna de sus siete ediciones (hasta mayo de 2023) más de 8.000 alumnos y tiene un porcentaje medio de aprobados sobre matriculados del 14,6%. En la Sexta Edición se matricularon 1.261 alumnos y aprobaron 165 (13,08%). El funcionamiento del Canal se articula en varias líneas de actuación. Las más cercanas a este trabajo son las de autoría y actualización de contenidos; diseño instruccional y producción de contenidos y actividades de aprendizaje; virtualización conforme a las WCAG y a las convenciones de open edX; difusión institucional y por canales digitales; atención docente y tutorial. Además, para monitorizar y optimizar la calidad de los materiales y del diseño, desde el Canal se realizan también labores de investigación en el campo de los materiales digitales y la accesibilidad, línea de investigación en la que se enmarca el trabajo presente.\nEl MOOC busca la formación de los estudiantes para generar materiales digitales accesibles y para que aprendan a evaluar la accesibilidad de los mismos. Este trabajo tiene como objetivo evaluar si los estudiantes son capaces de valorar adecuadamente la calidad del subtitulado. Molanes-López et al. (2021) realizaron una experiencia similar y llegaron a la conclusión de que evaluadores novatos pueden identificar problemas de accesibilidad en vídeos. En la misma línea de investigación, la evaluación social propuesta por Takagi et al. (2008) se podría aplicar a los contenidos de vídeo en la Web. A pesar de esto, ambos estudios constataron que los evaluadores novatos pueden pasar por alto problemas sutiles de accesibilidad que requieren un conocimiento experto como, por ejemplo, la evaluación del contraste, ya que requiere de herramientas de comprobación adecuadas."
  },
  {
    "objectID": "index.html#sec-objetivos",
    "href": "index.html#sec-objetivos",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.2 Objetivos",
    "text": "1.2 Objetivos\nA los estudiantes del MOOC se les propuso una actividad consistente en evaluar la calidad del subtitulado de dos vídeos, uno correctamente subtitulado y otro con errores (ver Sección 3.1).\nEl objetivo de este trabajo es responder a la siguiente pregunta de investigación:\n\n\n\n\n\n\nPregunta de investigación\n\n\n\n¿Son los estudiantes de un curso de creación de materiales accesibles capaces de evaluar las diferencias en la calidad del subtitulado de un vídeo?\n\n\nAdemás, también se responderá a los siguientes objetivos específicos:\n\n\n\n\n\n\nObjetivo específico\n\n\n\n¿En qué pautas de subtitulado los estudiantes tienen mayor facilidad para reconocer diferencias entre un subtitulado correcto y otro incorrecto?\n\n\n\n\n\n\n\n\nObjetivo específico\n\n\n\n¿En qué pautas de subtitulado los estudiantes tienen mayor dificultad para reconocer diferencias entre un subtitulado correcto y otro incorrecto?\n\n\n\n\n\n\n\n\nObjetivo específico\n\n\n\n¿Son los estudiantes capaces de valorar de forma similar los aspectos del subtitulado que no cambian en los vídeos?\n\n\n\n\n\n\n\n\nObjetivo específico\n\n\n\nEfecto secuencia: ¿El orden en el que vieron los vídeos los estudiantes influye en la calidad del subtitulado percibida?\n\n\n\n\n\n\n\n\nObjetivo específico\n\n\n\nEfecto periodo: ¿La evaluación del subtitulado del segundo vídeo visto está influida por haber evaluado un vídeo previamente?"
  },
  {
    "objectID": "index.html#organización-del-trabajo",
    "href": "index.html#organización-del-trabajo",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.3 Organización del trabajo",
    "text": "1.3 Organización del trabajo\nEn el capítulo Marco teórico y estado del arte (ver Capítulo 2) se enmarca la actividad de subtitulado en el contexto del modelado estadístico, describiendo sus principales características y proponiendo y justificando las técnicas y modelos que se van a utilizar. En este capítulo también se explica la forma en que se deben interpretar y evaluar los modelos.\nEl capítulo Materiales y métodos (ver Capítulo 3) describe la actividad de subtitulado evaluada por los alumnos, los ficheros de datos suministrados, la actividad de preprocesado realizada sobre los mismos y las variables que se utilizarán en el modelado estadístico.\nEl capítulo Modelado estadístico (ver Capítulo 4) comienza con un Análisis Exploratorio de los datos, tras el que se describe como se han aplicado las técnicas de modelado presentadas en el Marco Teórico al diseño del experimento de la actividad de subtitulado.\nEn el capítulo de Resultados (ver Capítulo 5) se presentan los resultados de los modelos seleccionados en el capítulo anterior.\nEn el capítulo Discusión (ver Capítulo 6) se utilizan los resultados del capítulo anterior para responder a la pregunta de investigación y a los objetivos específicos y se plantean las limitaciones del estudio.\nFinalmente, el capítulo Conclusión y trabajo futuro (ver Capítulo 7) se destina a recapitular los hallazgos encontrados aventurando posibles explicaciones a los mismos y propone líneas de investigación futuras en base a los resultados obtenidos."
  },
  {
    "objectID": "index.html#convenciones-usadas",
    "href": "index.html#convenciones-usadas",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "1.4 Convenciones usadas",
    "text": "1.4 Convenciones usadas\nEn este trabajo se ha evitado en la medida de lo posible el uso de anglicismos traduciendo al español los términos ingleses cuando su uso sea habitual en la publicación científica en español. No obstante, algunos términos se han mantenido en inglés por no tener una traducción fácil o frecuente. Es el caso, por ejemplo, de odds y de odds ratio. Se ha considerado que la utilización de los términos en español, disparidad y razón de disparidades respectivamente, dificultan la comprensión y se ha preferido el inglés en estos casos y otros similares. También se han introducido palabras como frecuentista, bayesiano, dicotomizar o instruccional que, aun cuando no figuren en el Diccionario de la RAE, tienen una construcción correcta en español.\nLos nombres de los modelos estadísticos se han escrito con la inicial de cada palabra en mayúscula. En los acrónimos generalmente se ha mantenido su correspondencia en inglés. Por ejemplo, Modelo Lineal Generalizado (GLM, Generalized Linear Model).\nPara denominar las variables utilizadas en el modelado estadístico se ha preferido el inglés. Por ejemplo, Treat para referirse a los subtitulados 1 y Response para las respuestas a los ítems de las escalas de Likert. La justificación de esta decisión es evitar la mezcla de idiomas en los resúmenes de los modelos o en los ejemplos de código.\nEl trabajo se ha elaborado siguiendo las pautas de reproducibilidad recomendadas en el desarrollo de una investigación científica. Se ha realizado con la herramienta de publicación científica Quarto que integra lenguajes como el lenguaje de programación y de publicación como Markdown o . Todas las figuras mostradas han sido generadas con R.\n\n\n\n\nAENOR. 2012. «UNE 153010 Subtitulado para personas sordas y personas con discapacidad auditiva». Asociación Española de Normalización y Certificación.\n\n\nMolanes-López, Elisa M., Alejandro Rodriguez-Ascaso, Emilio Letón, y Jorge Pérez-Martín. 2021. «Assessment of Video Accessibility by Students of a MOOC on Digital Materials for All». IEEE Access 9: 72357-67. https://doi.org/10.1109/ACCESS.2021.3079199.\n\n\nParton, Becky Sue. 2016. «Video Captions for Online Courses: Do YouTube’s Auto-generated Captions Meet Deaf Students’ Needs?» Journal of Open, Flexible and Distance Learning 20: 8-18.\n\n\nPérez Martín, Jorge, Alejandro Rodríguez-Ascaso, y Elisa Molanes-López. 2021. «Quality of the captions produced by students of an accessibility MOOC using a semi-automatic tool». Universal Access in the Information Society 20 (noviembre). https://doi.org/10.1007/s10209-020-00740-9.\n\n\nTakagi, Hironobu, Shinya Kawanaka, Masatomo Kobayashi, Takashi Itoh, y Chieko Asakawa. 2008. «Social Accessibility: Achieving Accessibility through Collaborative Metadata Authoring». En Proceedings of the 10th International ACM SIGACCESS Conference on Computers and Accessibility, 193-200. Assets ’08. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/1414471.1414507.\n\n\nW3C. 2018. «Web Content Accessibility Guidelines (WCAG) 2.1». https://www.w3.org/TR/WCAG21/."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Utilización de técnicas multivariantes para el estudio del aprendizaje de la mejora de la accesibilidad en el subtitulado de vídeos",
    "section": "",
    "text": "En investigación médica es habitual denominar tratamiento al medicamento en estudio. Por analogía, en este trabajo se llamará tratamiento al subtitulado.↩︎"
  },
  {
    "objectID": "2.html#características-del-diseño-del-experimento",
    "href": "2.html#características-del-diseño-del-experimento",
    "title": "2  Marco teórico y estado del arte",
    "section": "2.1 Características del diseño del experimento",
    "text": "2.1 Características del diseño del experimento\nEn este trabajo se estudiarán las diferencias existentes entre dos niveles de subtitulado (uno correcto y otro con errores) a través de las respuestas de los estudiantes a una escala de Likert de 18 ítems que fue respondida tras visualizar cada vídeo (ver Sección 3.1). Para ello se propondrán modelos estadísticos adecuados al diseño del experimento.\nEl diseño del experimento de la actividad de subtitulado fue completamente aleatorizado y cruzado AB/BA. En estos diseños se desea conocer el efecto de un factor con dos niveles sobre una variable respuesta. Para ello, se asigna aleatoriamente a los participantes a dos grupos y se mide la variable respuesta en dos periodos en cada grupo. En el primer periodo, a uno de los grupos se le asigna un nivel de factor y al otro grupo el otro nivel de factor. En el segundo periodo se intercambian los niveles de factor asignados a cada grupo (ver Figura 2.1). Este diseño se diferencia del diseño paralelo \\(AA/BB\\) en el que el nivel de factor asignado a cada grupo se mantiene entre periodos (ver Figura 2.2). El y paralelo se pueden combinar si los participantes se clasifican en cuatro grupos (\\(AA/AB/BA/BB\\)). Por último, se pueden hacer diseños con más periodos o/y con más factores o niveles de factor. Los diseños cruzados son habituales en estudios clínicos en investigación médica (ver Lim y In 2021) y farmacológica para la evaluación de medicamentos genéricos.\n\n\n\n\n\nflowchart LR\n  subgraph Primer Periodo\n  C[Tratamiento A]\n  D[Tratamiento B]\n  end\n  subgraph Segundo Periodo\n  E[Tratamiento B]\n  F[Tratamiento A]\n  end\n  A[Sujetos participantes] --&gt; B{Aleatorización}\n  B-- Secuencia AB --&gt; C-.-&gt;E\n  B-- Secuencia BA --&gt; D-.-&gt;F\n\n\nFigura 2.1: Diagrama de diseño cruzado AB/BA\n\n\n\n\n\n\n\n\n\nflowchart LR\n  subgraph Primer Periodo\n  C[Tratamiento A]\n  D[Tratamiento B]\n  end\n  subgraph Segundo Periodo\n  E[Tratamiento A]\n  F[Tratamiento B]\n  end\n  A[Sujetos participantes] --&gt; B{Aleatorización}\n  B-- Secuencia AA --&gt; C-.-&gt;E\n  B-- Secuencia BB --&gt; D-.-&gt;F\n\n\nFigura 2.2: Diagrama de diseño paralelo AA/BB\n\n\n\n\nUn  (Lawson 2015, 18) “garantiza la validez del experimento contra sesgos causados por otras variables ocultas. Cuando las unidades experimentales se asignan aleatoriamente a los niveles de factor de tratamiento, se puede realizar una prueba exacta de la hipótesis de que el efecto del tratamiento es cero utilizando una prueba de aleatorización”.\nSiguiendo a Senn (2022, 5-9), para que el ensayo sea de tipo cruzado no sería suficiente intercambiar las secuencias sino que debe ser objeto del ensayo el estudio de las diferencias entre los tratamientos individuales que componen las secuencias. En la misma línea, Lui (2016, 1-2) afirma que “el objetivo principal de un diseño cruzado es estudiar las diferencias entre tratamientos individuales (en lugar de las diferencias entre secuencias de tratamiento). Debido a que cada paciente sirve como su propio control, el diseño cruzado es una alternativa útil al diseño de grupos paralelos para aumentar la potencia”.\nLos principales problemas de un diseño cruzado son el abandono (drop-out), de alguno de los participantes y la interacción entre el tratamiento y el periodo o efecto secuencia (carry-over o contaminación). Además, el análisis estadístico es más complicado, particularmente cuando la respuesta es ordinal y hay más de dos tratamientos. Aplicado al experimento del subtitulado, se producirá efecto secuencia si las respuestas a los cuestionarios fueran diferentes cuando los vídeos se ven en un orden que cuando se ven en el otro. Además hay que tener en consideración de la existencia del efecto periodo, que se producirá si las respuestas del segundo periodo están influidas por haber realizado la primera actividad de subtitulado. Como ejemplo de estos efectos se puede ver Senn (2022, 35-53): Se analiza un experimento que consistió en medir el flujo espiratorio máximo (PEF, por sus siglas en inglés) en 13 niños con edades entre los 7 y los 14 años con asma a los que se les administró salbutamol (un conocido broncodilatador) y formoterol (un broncodilatador de reciente aparición en el momento en que se realizó el estudio). Se hicieron dos grupos a los que se les administró ambos tratamientos en orden inverso dejando un periodo de lavado (washout period) entre aplicaciones. El resulta de medir si el PEF medio de los dos grupos es diferente entre periodos, y el consiste en comprobar si hay diferencias significativas entre aplicar primero el tratamiento con salbutamol y luego con formoterol o hacerlo al revés.\nOtra cuestión de relevancia es que las respuestas a los ítems de una son de tipo ordinal. Los test estadísticos  o  presuponen que la variable de respuesta es cuantitativa y con distribución normal. Tratar las respuestas a una escala de Likert como si fueran cuantitativas no es correcto por las siguientes razones:\n\nLos niveles de respuesta no son necesariamente equidistantes: la distancia entre cada par de opciones de respuesta correlativos puede no ser la misma para todos los pares. Por ejemplo, la diferencia entre “Muy en desacuerdo” y “En desacuerdo” y la diferencia entre “De acuerdo” y “Muy de acuerdo” es de un nivel, pero psicológicamente puede ser percibida de forma diferente por cada sujeto.\nLa distribución de las respuestas ordinales puede ser no normal. En particular esto sucederá si hay muchas respuestas en los extremos del cuestionario.\nLas varianzas de las variables no observadas que subyacen a las variables ordinales observadas pueden diferir entre grupos, tratamientos, periodos, etc.\n\nEn Liddell y Kruschke (2018) se han analizado los problemas potenciales de tratar datos ordinales como si fueran cuantitativos constatando que se pueden presentar las siguientes situaciones:\n\nSe pueden encontrar diferencias significativas entre grupos cuando no las hay: .\nSe pueden obviar diferencias cuando en realidad sí existen: .\nIncluso se pueden invertir los efectos de un tratamiento.\nTambién puede malinterpretarse la interacción entre factores.\n\nOtra cuestión que hay que tener en cuenta es que, al tratarse de un diseño cruzado, es de medidas repetidas ya que cada sujeto realiza dos veces el test, uno con cada vídeo y que, por lo tanto, las respuestas a cada test de un mismo sujeto no son independientes. Además, tampoco se pueden considerar independientes los ítems que componen el test ya que los ítems pretenden medir la misma variable latente: la calidad del subtitulado.\nEn este trabajo se analiza si el nivel de subtitulado (correcto o defectuoso) influye en el nivel de respuesta a los ítems de la escala de Likert, que es la variable dependiente. Se evalúa también la existencia de efectos secuencia y periodo y la influencia que tienen sobre el nivel de respuesta el estudiante y el propio ítem."
  },
  {
    "objectID": "2.html#sec-glm",
    "href": "2.html#sec-glm",
    "title": "2  Marco teórico y estado del arte",
    "section": "2.2 Modelos Lineales Generalizados 1",
    "text": "2.2 Modelos Lineales Generalizados 1\nEl Modelo Lineal Generalizado (Generalized Linear Model, \\(GLM\\)) es un modelo en el que la variable respuesta no sigue una distribución Normal. Para especificar un son necesarios tres componentes (ver Agresti 2018, 66-67):\n\nUn componente aleatorio que será una distribución de probabilidad de la familia exponencial. Se asume que la variable respuesta \\(Y\\) se distribuye según este componente aleatorio.\nUn componente lineal de predictores: \\[\n\\tau+\\beta_1x_1+...+\\beta_px_p\n\\]\nUna función de enlace \\(g\\) que relaciona \\(\\mu=E(Y)\\) con los predictores, de tal forma que: \\[\ng(\\mu)=\\tau+\\beta_1x_1+...+\\beta_px_p\n\\]\n\nLa estimación de coeficientes en GLM se realiza maximizando la función de verosimilitud (Maximum Likelihood Estimation, ). Es decir, que los coeficientes del modelo son aquellos que maximizan la probabilidad de los datos.\n\n2.2.1 Regresión Logística\nLa es un caso particular de \\(GLM\\) en el que la variable respuesta es dicotómica. Aunque la Regresión Logística no es aplicable directamente a las respuestas de una escala de Likert por ser éstas ordinales, se introduce aquí por dos motivos:\n\nEn la sección de modelado (ver Sección 4.2.2), se propondrán dos transformaciones de la variable respuesta para convertirla en dicotómica.\nAdemás, en este capítulo se introducirá la Regresión Ordinal (ver Sección 2.2.2). Este modelo se puede considerar una extensión de la Regresión Logística y permitirá tratar la variable respuesta como ordinal. De ahí el interés en presentar previamente la Regresión Logística.\n\nComo se ha dicho, la (ver Agresti 2018, 68-69) es un caso particular de \\(GLM\\) donde la variable respuesta, \\(Y\\), es dicotómica o Bernoulli. Es decir, que \\(Y\\) toma valores 0 ó 1. En una función de Bernoulli de parámetro \\(\\pi\\) (\\(E[Y] = P(Y=1) = \\pi\\)), es necesaria una función que mapee los valores que puede tomar el componente lineal de rango \\((-\\infty, +\\infty)\\) a los valores que puede tomar \\(\\pi\\) en el rango \\((0, 1)\\). Una función que permite hacer esto es la :\n\\[\nlogit(Y=1) = log \\left[\\frac{P(Y=1)}{1-P(Y=1)} \\right] = \\tau+\\beta_1x_1+...+\\beta_px_p\n\\tag{2.1}\\]\nLa inversa de la función logit es la  y permite realizar el mapeo inverso para obtener la probabilidad:\n\\[\nP(Y=1) = \\frac{1}{1 + exp^{-\\tau-\\beta_1x_1...-\\beta_px_p}}\n\\]\nLa interpretación de los coeficientes es la siguiente (ver Friendly, Meyer, y Zeileis 2015, 260):\n\n\\(\\tau\\) es el logaritmo del  de \\(Y\\) cuando \\(x_j=0, \\forall j \\in 1...p\\).\n\\(\\beta_j\\) es el logaritmo del  asociado a una unidad de incremento de \\(x_j\\).\n\nEl contraste de hipótesis para los coeficientes \\(\\beta\\):\n\\[\n\\begin{aligned}\nH_0: \\beta_j =  0 \\\\\nH_1: \\beta_j \\ne  0\n\\end{aligned}\n\\]\nse puede realizar con el Test de Wald:\n\\[\n\\begin{aligned}\nW & = \\frac{\\hat\\beta_j - 0}{se(\\hat\\beta_j)} \\sim N(0,1)\n\\end{aligned}\n\\]\no con el Test de Razón de Verosimilitudes (Likelihood Ratio Test, ):\n\\[\n\\begin{aligned}\nLRT = \\Lambda &= -2 \\log \\frac{L(\\widehat{reducido})}{L(\\widehat{completo})}\\\\\n&= -2 \\log L(\\widehat{reducido}) + 2 \\log L(\\widehat{completo}) \\sim \\chi^2_r\n\\end{aligned}\n\\]\ndonde:\n\nr es el número de \\(\\beta's\\) iguales a cero.\n\\(L(\\widehat{reducido})\\) es el valor que maximiza la función de verosimilitud en la que algunos (\\(r\\)) de los \\(\\beta's\\) han sido igualados a cero.\n\\(L(\\widehat{completo})\\) es el valor que maximiza la función de verosimilitud en el modelo que incluye todos los \\(\\beta's\\).\n\n\\(LTR\\) permite comprobar la hipótesis de que uno o varios coeficientes sean cero. Para comparar modelos no anidados, se puede usar el Criterio de Información de Akaike (AIC) o el Criterio de Información Bayesiano (BIC), que se definen respectivamente:\n\\[\n\\begin{aligned}\nAIC &: -2 \\log L + 2p \\\\\nBIC &: -2 \\log L + p \\log(n)\n\\end{aligned}\n\\tag{2.2}\\]\ndonde \\(L\\) es el valor de maxima verosimilitud y el segundo sumando es una penalización que será mayor cuanto más complejo sea el modelo (p = número de parámetros, n = observaciones).\n\n\n2.2.2 Regresión Ordinal\nLas respuestas a los ítems de una escala de Likert son ordinales. La es una clase de \\(GLM\\) que comparte muchas similitudes con la Regresión Logística (ver Sección 2.2.1) pero que tiene en consideración que los valores de la variable de respuesta están ordenados 2. Según Bürkner y Vuorre (2019, 3-11) hay tres clases de Regresión Ordinal:\n\nRegresión Ordinal Acumulativa.\nRegresión Ordinal Secuencial.\nRegresión Ordinal Adyacente.\n\nLas regresiones ordinales secuencial y adyacente presuponen que para alcanzar un nivel se ha tenido que pasar previamente por los anteriores. En un ítem de Likert esto carece de sentido y, por lo tanto, se descartan estos modelos y se prefiere el Modelo Acumulativo (Cumulative Model, \\(CM\\)) que además es el más utilizado (ver Bürkner y Vuorre 2019, 23-24).\n\\(CM\\) presupone que la variable ordinal observada, \\(Y\\), proviene de la categorización de una variable latente (no observada) continua, \\(\\tilde{Y}\\). Hay \\(K\\) umbrales \\(\\tau_k\\) que particionan \\(\\tilde{Y}\\) en \\(K + 1\\) categorías ordenadas observables (ver Figura 2.3). Si se asume que \\(\\tilde{Y}\\) tiene una cierta distribución (por ejemplo, normal) con distribución acumulada \\(F\\), se calcula la probabilidad de que \\(Y\\) sea la categoría \\(k\\) de esta forma:\n\\[Pr(Y = k) = F(\\tau_k) - F(\\tau_{k-1})\\]\n\n\n\n\n\nFigura 2.3: Función latente en una regresión ordinal acumulativa.\n\n\n\n\nPor ejemplo en la Figura 2.3: \\(Pr(Y = 2) = F(\\tau_2) - F(\\tau_{1})\\). Suponiendo que \\(\\tilde{Y}\\) tenga una relación lineal los predictores:\n\\[\\tilde{Y} = \\eta + \\epsilon = \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\epsilon\\]\nentonces la función de probabilidad acumulada de los errores tendrá la misma forma que la de \\(\\tilde{Y}\\):\n\\[P(\\epsilon \\leq z) = F(z)\\]\nSe puede calcular la distribución de probabilidad acumulada de \\(Y\\):\n\\[P(Y \\leq k \\mid \\eta) = P(\\tilde{Y} \\leq \\tau_k \\mid \\eta) = P(\\eta + \\epsilon \\leq \\tau_k) = P(\\epsilon \\leq \\tau_k - \\eta) = F(\\tau_k - \\eta)\\]\nPor lo que asumiendo la normalidad de los errores:\n\\[P(Y = k) = \\Phi(\\tau_k - \\eta) - \\Phi(\\tau_{k - 1} - \\eta)\\]\ndonde hay que estimar los umbrales \\(\\tau_k\\) y las pendientes de cada variable explicativa. La función anterior es la conocida como la función de enlace probit. La interpretación de los coeficientes con esta función de enlace no resulta intuitiva. Por ello en este trabajo se va a utilizar la función de enlace logit. Con esta función de enlace la interpretación de los coeficientes es parecida a la de los coeficientes de la regresión logística. Además, en la práctica, los coeficientes estimados suelen tener valores similares a los de la función probit. Para entender como se deben interpretar los coeficientes del modelo \\(CM\\) se parte del supuesto de que el \\(logit\\) de la función de probabilidad es lineal:\n\\[\nlogit [P(Y \\le k)] = \\tau_{k} - \\eta = \\tau_{k} - (\\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p)\n\\tag{2.3}\\]\nEn ese caso, se puede demostrar fácilmente que, por ejemplo:\n\\[\\frac{\\frac{P(Y \\leq k \\mid \\eta)}{P(Y &gt; k \\mid \\eta)}}{\\frac{P(Y \\leq k+1 \\mid \\eta)}{P(Y &gt; k+1 \\mid \\eta)}} = \\exp(\\tau_{k} - \\tau_{k+1})\\]\nY que 3:\n\\[\\frac{\\frac{P(Y \\leq k \\mid x_j = 1)}{P(Y &gt; k \\mid x_j = 1)}}{\\frac{P(Y \\leq k \\mid x_j=0)}{P(Y &gt; k \\mid x_j = 0)}} = \\exp(-\\beta_{j})\\]\no, equivalentemente:\n\\[\\frac{\\frac{P(Y &gt; k \\mid x_j = x + 1)}{P(Y \\leq k \\mid x_j = x + 1)}}{\\frac{P(Y &gt; k \\mid x_j = x)}{P(Y \\leq k \\mid x_j = x)}} = \\exp(\\beta_{j})\\]\nEs decir, que \\(\\exp(\\beta_{j})\\) es el odds ratio (cambio relativo entre \\(odds\\), ) de que la variable respuesta esté por encima de una determinada categoría versus estar por debajo de ella para una unidad de incremento del predictor \\(x_j\\). Un valor del coeficiente \\(\\beta_j\\) positivo indica que la relación entre el predictor \\(x_j\\) y la función de \\(logit\\) es positiva y, por lo tanto, se incrementa la probabilidad de un mayor valor de la variable respuesta.\n\n2.2.2.1 Presunciones del modelo\nEste modelo se denomina proporcional ya que se asume que cada predictor tiene los mismos efectos sobre todos los niveles de la variable de respuesta ordinal (ver Liu 2022, chap. 5). Es decir, que los \\(odds\\) de los niveles de respuesta deben ser proporcionales para los mismos valores de las variables explicativas. Esta suposición frecuentemente no es realista y se puede relajar permitiendo estimar un coeficiente diferente para cada nivel de la variable respuesta. Sin embargo, el incremento del número de coeficientes dificulta la interpretabilidad del modelo. Harrell (2020) aboga por usar este modelo incluso aunque la suposición de proporcionalidad no se cumpla:\n\n“Ningún modelo se ajusta perfectamente a los datos, …, la aproximación ofrecida por el modelo \\(CM\\) sigue siendo bastante útil. Y un análisis unificado del modelo \\(CM\\) es decididamente mejor que recurrir a análisis ineficientes y arbitrarios de valores dicotomizados de Y.”\n\nMatemáticamente la presunción de la proporcionalidad de los \\(odds\\) se demuestra a partir de la Ecuación 2.3. Si se fijan los predictores en un valor arbitrario \\(X=x\\) y se consideran dos niveles de respuesta cualesquiera \\(k\\) y \\(l\\), entonces:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le k | X = x)] - logit [P(Y \\le l | X = x)] = \\tau_{k} - \\tau_{l} \\\\\n\\frac{odds(P(Y \\le k | X = x))}{odds(P(Y \\le l | X = x))}  =  \\exp(\\tau_{k} - \\tau_{l}) \\implies \\\\\nodds(P(Y \\le k | X = x))  \\propto odds(P(Y \\le l | X = x))\n\\end{aligned}\n\\tag{2.4}\\]\nEs decir, que la proporcionalidad de \\(odds\\) de dos niveles de respuesta es independiente de los valores concretos de los predictores, por lo que la constante de proporcionalidad debe ser similar para todos ellos."
  },
  {
    "objectID": "2.html#sec-multinivel",
    "href": "2.html#sec-multinivel",
    "title": "2  Marco teórico y estado del arte",
    "section": "2.3 Modelos Multinivel Generalizados",
    "text": "2.3 Modelos Multinivel Generalizados\nUn Modelo Multinivel Generalizado (, Generalized Linear Mixed Model), anidado, jerárquico o mixto es un modelo en el que los datos están anidados en una estructura jerárquica. Se utilizan cuando se incumple la hipótesis de independencia entre las observaciones. Por ejemplo, si se quisiera evaluar el rendimiento de varios métodos de enseñanza, se podrían seleccionar aleatoriamente varios colegios participantes y en cada uno de ellos elegir varias clases en las que se impartiría uno de los métodos de enseñanza. En este caso, los alumnos de una clase no son independientes de los alumnos de otra clase del mismo colegio y también es esperable que los alumnos de un mismo colegio sean más parecidos entre sí que los de otro colegio. Otra situación en la que se viola la condición de independencia entre observaciones es cuando se toman varias medidas del mismo sujeto. Este tipo de experimentos se llaman de medidas repetidas o longitudinales 4. Cuando se da este supuesto, se considera que las medidas están anidadas en el sujeto (ver Liu 2022). En un modelo multinivel no es necesario que todas las variables tengan una estructura jerárquica. Se distinguen entonces dos tipos de variables: Las conocidas como de efectos fijos son aquellas que se considera que tienen el mismo efecto en toda la población y, por lo tanto, se debe estimar un único coeficiente. Las variables de efectos aleatorios tienen un coeficiente diferente para cada elemento de la población y se supone que son una muestra de una población mucho mayor, como el caso de seleccionar aleatoriamente una muestra de colegios. Normalmente el coeficiente particular de cada elemento no es de interés para el investigador y se asume que tienen una media centrada en cero. El mayor interés de los efectos aleatorios es la estimación de su matriz de varianzas-covarianzas.\nLa ecuación general de un modelo multinivel con dos niveles y un solo predictor con efectos aleatorios es (ver Chen y Chen 2021, 40):\n\\[\n\\begin{aligned}\nNivel\\ 1: & y_{ij}     & = & \\beta_{0j} + \\beta_{1j}x_{1ij} + \\epsilon_{ij} \\\\\nNivel\\ 2: & \\beta_{0j} & = & \\beta_{0} + U_{0j} & (intercepto\\ aleatorio) \\\\\n          & \\beta_{1j} & = & \\beta_{1} + U_{1j} & (pendiente\\ aleatoria) \\\\\n\\end{aligned}\n\\]\nLos errores del modelo se distribuyen:\n\\[\n\\begin{aligned}\n\\text{Error intra grupo: } &  \\epsilon_{ij} \\sim N(0, \\sigma^2) \\\\\n\\text{Error entre grupos: } &\n\\begin{pmatrix}\n     U_{0j} \\\\\n     U_{1j} \\\\\n\\end{pmatrix}\n\\sim\nN\n\\begin{pmatrix}\n\\begin{pmatrix}\n     0 \\\\\n     0 \\\\\n\\end{pmatrix},\n\\begin{pmatrix}\n     \\tau_0^2 & \\tau_0\\tau_1\\rho_{01} \\\\\n     \\tau_0\\tau_1\\rho_{01} &  \\tau_1^2 \\\\\n\\end{pmatrix}\n\\end{pmatrix}\n\\end{aligned}\n\\]\ndonde \\(j\\) son los grupos que varían \\(j = 1,...,J\\) (\\(J\\) es el número de grupos); \\(ij\\) es la observación \\(i\\)-ésima del grupo \\(j\\) (\\(i = 1,...,n_j\\), \\(n_j\\) es el número de observaciones del grupo \\(j\\)). El modelo se compone de una parte fija \\(\\beta_0 + \\beta_1 x_{1ij}\\) y una aleatoria \\(U_{0j} + U_{1j} x_{1ij} + \\epsilon{ij}\\). Los parámetros de este modelo son el intercepto y la pendiente de efectos fijos (\\(\\beta_0\\) y \\(\\beta_1\\)), la varianza intra-grupos (\\(\\sigma^2\\)), la varianza inter-grupos del intercepto aleatoria (\\(\\tau_0\\)) y de la pendiente aleatoria (\\(\\tau_1\\)), y la correlación entre intercepto y pendiente aleatorias (\\(\\rho_{01}\\)).\nEn Gelman et al. (2013, 115) se evalúan tres posibilidades a la hora de definir un modelo:\n\n\\(Complete\\ pooling\\): Consiste en estimar un único parámetro para cada predictor. Es equivalente a un modelo con efectos fijos.\n\\(No\\ pooling\\): Se estiman tantos parámetros como grupos haya de forma independiente.\n\\(Partial\\ pooling\\): Es el modelo jerárquico. Es una mezcla de ambos, ya que, aunque se estima un parámetro para cada grupo (como en \\(no\\ pooling\\)), esta estimación no es independiente, sino que se supone que las observaciones de un mismo grupo proceden de una misma distribución de probabilidad. Esto se traduce en que se produce una contracción () en la estimación de los parámetros hacia la media. Al influir la estimación de unas observaciones en otras, la estimación es de menor valor absoluto que la que resultaría en un modelo de \\(no\\ pooling\\). De esta forma se puede ver el \\(complete\\ pooling\\) y el \\(no\\ pooling\\) como dos casos particulares y extremos del \\(partial\\ pooling\\). La contracción de coeficientes en los modelos multinivel actúa como una regularización que puede evitar el sobreajuste.\n\nLos modelos multinivel requieren supuestos adicionales en el nivel segundo y superiores que son similares a los supuestos para los modelos de efectos fijos (ver Chen y Chen 2021, 43). Para estimar los parámetros en un modelo multinivel se suele utilizar el método de Máxima Verosimilitud Restringida (\\(RMLE\\)), que es una variante de la estimación por Máxima Verosimilitud (\\(MLE\\)) en la que se hacen ajustes en los grados de libertad del modelo con efectos aleatorios para corregir el sesgo que se produce al usar \\(MLE\\) en estos modelos.\nPara evaluar si la estructura anidada es adecuada se utiliza la Correlación Intra-Clase (, Intra-Class Correlation). \\(ICC\\) se puede interpretar como la proporción de la varianza explicada por la estructura de agrupamiento de la población. Se diferencia del Coeficiente de Determinación (\\(R2\\)) en que éste es la proporción de la varianza explicada por el modelo completo, mientras que \\(ICC\\) es la varianza explicada por los efectos aleatorios (ver Lüdecke et al. 2021). La \\(ICC\\) se calcula como el ratio de la varianza entre grupos y la varianza total (ver Chen y Chen 2021, 29-33):\n\\[\nICC = \\rho = \\frac{\\tau^2}{\\tau^2+\\sigma^2}\n\\]\ndonde \\(\\tau^2\\) es la varianza poblacional entre grupos y \\(\\sigma^2\\) es la varianza de la población dentro del grupo. \\(ICC\\) oscila entre 0 (ausencia de varianza entre grupos) y 1 (no varianza intra-grupos). Cuanto más proxima a 1 sea \\(ICC\\) mayor evidencia hay de la existencia de una estructura anidada. Sin embargo, no hay un consenso sobre el umbral concreto que debe tener \\(ICC\\) para decidir si es preferible o no la estructura anidada (ver Chen y Chen 2021, 33). \\(ICC\\) se estima a partir de la varianza de los coeficientes y residual aleatorias calculadas por el modelo. En modelos \\(GLM\\) no se calcula la varianza residual y se recurre a métodos de simulación para estimar \\(ICC\\)."
  },
  {
    "objectID": "2.html#sec-bayesiano",
    "href": "2.html#sec-bayesiano",
    "title": "2  Marco teórico y estado del arte",
    "section": "2.4 Modelado bayesiano",
    "text": "2.4 Modelado bayesiano\nEl paradigma frecuentista parte de la suposición de que los datos son generados a partir de una variable aleatoria \\(Y\\) y para estimar los coeficientes se maximiza la función de verosimilitud \\(p(y | \\theta)\\) que depende del parámetro desconocido \\(\\theta\\). En el análisis bayesiano se considera que \\(\\theta\\) es una variable aleatoria ya que hay incertidumbre respecto a su valor. Esto se traduce en que se debe asignar una distribución de probabilidad \\(p(\\theta)\\), conocida como distribución a priori, que expresa nuestra creencia sobre los valores que puede tomar \\(\\theta\\). En la inferencia bayesiana se usa la distribución de probabilidad a posteriori \\(p(\\theta | y)\\) que es proporcional al producto de la función de verosimilitud y de la distribución de probabilidad a priori (ver Nicenboim Bruno 2023):\n\\[\n\\hbox{Posterior} = \\frac{\\hbox{Likelihood} \\times \\hbox{Prior}}{\\hbox{Marginal Likelihood}}\n\\Rightarrow p(\\theta|y) = \\cfrac{ p(y|\\theta) \\times p(\\theta) }{p(y)} \\propto p(y|\\theta) \\times p(\\theta)\n\\]\nEn la inferencia bayesiana hay dos fuentes de incertidumbre: Por un lado hay que contar con la variabilidad de \\(Y\\), ya que si se toman varias muestras, los valores \\(y_i\\) obtenidos serán diferentes. Además, existe otra incertidumbre que proviene del desconocimiento del valor de \\(\\theta\\). En la estimación frecuentista, debido a que se utilizan estimaciones puntuales de \\(\\theta\\), no se tiene en cuenta esta incertidumbre. La Ecuación 2.5 se corresponde con la distribución predictiva a posteriori que tiene en consideración ambas incertidumbres: \\[\n\\begin{aligned}\np(y_{pred}\\mid y ) & = \\int_{\\theta} p(y_{pred}, \\theta \\mid y)\\, d\\theta= \\int_{\\theta}\np(y_{pred}\\mid \\theta,y)p(\\theta \\mid y)\\, d\\theta \\\\\n& = \\int_{\\theta} p(y_{pred}\\mid \\theta) p(\\theta \\mid y)\\, d\\theta\n\\end{aligned}\n\\tag{2.5}\\]\ndonde la última igualdad resulta de la independencia condicional de \\(y_{pred}\\) e \\(y\\) dado \\(\\theta\\) (\\(y_{pred} \\perp\\!\\!\\!\\perp y \\mid \\theta\\)).\nUna crítica habitual a la inferencia bayesiana es que la elección de la distribución de probabilidad a priori es subjetiva. Aunque es cierto que hay un grado de subjetividad en esta elección, en realidad en el modelado frecuentista hay que tomar ciertas decisiones que también lo son, como por ejemplo la elección del nivel de significación o la forma que adopta la función de verosimilitud. En la práctica, si las observaciones son suficientemente informativas y la distribución a priori es poco informativa, la distribución de probabilidad a priori tendrá poca o nula influencia en la distribución a posteriori ya que estará dominada por la función de verosimilitud y los coeficientes estimados serán muy parecidos en ambos paradigmas. Sin embargo, en lo que diferirán es en la interpretación ya que, por ejemplo, en un modelo bayesiano se pueden interpretar los intervalos de confianza como la probabilidad de que el parámetro esté dentro del intervalo. Por eso a estos intervalos se les conoce como intervalos de credibilidad. Esa interpretación en un modelo frecuentista carecería de sentido ya que los parámetros del modelo no se consideran variables aleatorias y, por lo tanto, tendrán probabilidad 1 si el verdadero valor del parámetro cae dentro del intervalo y 0 si no lo hace. Para obtener la distribución de probabilidad a posteriori normalmente se recurre a métodos del simulación  (Métodos de Montecarlo basados en Cadenas de Markov). 5.\nPara comparar modelos entre sí se pueden usar varias medidas (ver Barreda S. 2023). Por ejemplo, la conocida como log pointwise predictive density o densidad predictiva puntal (\\(lpd\\)) se calcula como: \\[\n\\widehat{\\mathrm{lpd}} = \\sum_{i=1}^{N} \\mathrm{log} (p(y_{i} | \\theta))\n\\]\nLa \\(lpd\\) es la densidad conjunta de observar los datos dada la estructura del modelo y las estimaciones de los parámetros \\(\\theta\\). Aunque las probabilidades a priori no se incluyen en su cálculo, sí influyen en la estimación de \\(\\theta\\) y, por lo tanto, tienen un efecto en los valores de \\(lpd\\). Mayores valores de \\(lpd\\) estarían indicando un mejor modelo. El problema con esta métrica es que se utilizan los datos tanto para estimar el modelo como para seleccionar el mejor modelo. Esto va a producir un sobreajuste y tenderá a favorecer los modelos más complejos. Una métrica mejor es la expected log pointwise predictive density o densidad predictiva puntual esperada (\\(elpd\\)). Se define en términos de valores fuera de la muestra \\(\\tilde{y}\\) en lugar de con los valores de la muestra \\(y\\):\n\\[\n\\mathrm{elpd} = \\sum_{i=1}^{N} \\mathbb{E}(\\mathrm{log} (p(\\tilde{y}_i | \\theta)))\n\\]\nEn la práctica no se puede saber el valor de \\(elpd\\) ya que no se conoce el proceso que genera verdaderos valores \\(\\tilde{y}\\). Una forma de estimar \\(elpd\\) que empíricamente se ha demostrado que funciona es penalizar \\(lpd\\) con el número de parámetros \\(p\\) de forma análoga a lo que se hace en \\(AIC\\) (ver Ecuación 2.2):\n\\[\n\\widehat{\\mathrm{elpd}} = \\widehat{\\mathrm{lpd}} - \\mathrm{p}\n\\]\nEl problema es que en modelos multinivel conocer el número de parámetros no es sencillo ya que los parámetros asociados a efectos aleatorios no se pueden considerar que sean completamente independientes. El número efectivo de parámetros va a depender de la importancia de la regresión hacia la media que sufra cada parámetro. Además, en lugar de usar una estimación puntual, se puede utilizar toda la distribución de valores de la simulación. La métrica widely available information criterion o “criterio de información ampliamente disponible” (\\(WAIC\\)) es una forma de estimar \\(lpd\\) que usa toda la distribución de probabilidad a posteriori:\n\\[\n\\widehat{\\mathrm{lpd}} = \\sum_{i=1}^{n} \\mathrm{log} (\\frac{1}{S} \\sum_{s=1}^{S} p(y_{i} | \\theta^s))\n\\]\ndonde \\(S\\) es el tamaño de la muestra y el sumatorio interior es la media de densidad en un punto \\(i\\). Para penalizar los modelos más complejos, se usa la varianza de la función de densidad logarítmica:\n\\[\n\\begin{aligned}\n\\widehat{\\mathrm{elpd}}_{WAIC} &= \\widehat{\\mathrm{lpd}} - \\mathrm{p_{WAIC}} \\\\\n\\mathrm{p_{\\mathrm{WAIC}}} &= \\sum_{i=1}^{n} \\mathrm{Var}_{s=1}^{\\,S}(\\mathrm{log} (p(y_{i} | \\theta^s)))\n\\end{aligned}\n\\]\nUna forma alternativa de evaluar un modelo es mediante validación cruzada (\\(CV\\), Cross Validation). La validación cruzada más popular es K-fold-CV. Con esta técnica se divide el conjunto de datos en \\(K\\) partes y se entrena el modelo separando sucesivamente cada una de las partes que se usan para evaluar el modelo. Los valores estimados resultan de promediar los \\(K\\) resultados. El problema es que cuanto menor sea \\(K\\) más inestables son los resultados obtenidos, y cuanto mayor sea \\(K\\) más veces hay que reentrenar el modelo. Un caso extremo de validación cruzada, que produce gran estabilidad en las estimaciones, es dejar un dato fuera cada vez (Leave One Out, \\(LOO\\), \\(K\\) = \\(N\\)). La dificultad es que requiere estimar el modelo tantas veces como datos se tengan. Para evitar esto, hay formas de aproximar \\(\\widehat{\\mathrm{elpd}}\\) basadas en \\(LOO\\) sin tener que reentrenar el modelo. La fórmula es la siguiente:\n\\[\n\\begin{aligned}\n\\widehat{\\mathrm{elpd}}_{LOO} \\approx \\sum_{i=1}^{n} \\mathrm{log} (p(y_{i} | \\theta_{y_{-i}}))\n\\end{aligned}\n\\]\ndonde \\(\\theta_{y_{-i}}\\) es la estimación de \\(\\theta\\) que resulta tras eliminar la observación \\(y_{i}\\) (ver Gelman et al. 2013, 175-76).\n\n\n\n\nAgresti, Alan. 2018. «An introduction to categorical data analysis, 3rd Edition». Wiley.com. https://www.wiley.com/en-us/An+Introduction+to+Categorical+Data+Analysis%2C+3rd+Edition-p-9781119405283.\n\n\nBarreda S., Silbert N. 2023. Bayesian Multilevel Models for Repeated Measures Data: A Conceptual and Practical Introduction in R. 1st ed. Routledge. https://doi.org/10.4324/9781003285878.\n\n\nBürkner, Paul-Christian, y Matti Vuorre. 2019. «Ordinal Regression Models in Psychology: A Tutorial». Advances in Methods and Practices in Psychological Science 2 (febrero): 251524591882319. https://doi.org/10.1177/2515245918823199.\n\n\nChen, Ding-Geng, y Jenny Chen. 2021. Statistical Regression Modeling with R: Longitudinal and Multi-level Modeling. https://doi.org/10.1007/978-3-030-67583-7.\n\n\nFriendly, Michael, David Meyer, y Achim Zeileis. 2015. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data. https://doi.org/10.1201/b19022.\n\n\nGelman, Andrew, John Carlin, Hal Stern, David Dunson, Aki Vehtari, y Donald Rubin. 2013. Bayesian Data Analysis. https://doi.org/10.1201/b16018.\n\n\nHarrell, F. 2020. «Violation of Proportional Odds is Not Fatal». https://www.fharrell.com/post/po/.\n\n\nLawson, J. 2015. «Design and Analysis of Experiments with R (1st ed.)». Editado por Chapman y Hall/CRC. https://doi.org/10.1201/b17883.\n\n\nLiddell, Torrin M., y John K. Kruschke. 2018. «Analyzing ordinal data with metric models: What could possibly go wrong?» Journal of Experimental Social Psychology 79: 328-48. https://doi.org/10.1016/j.jesp.2018.08.009.\n\n\nLim, Chi-Yeon, y Junyong In. 2021. «Considerations for crossover design in clinical study». Korean Journal of Anesthesiology 74 (julio). https://doi.org/10.4097/kja.21165.\n\n\nLiu, Xing. 2022. Categorical Data Analysis and Multilevel Modeling Using R. Editado por SAGE Publications Ltd.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Philip Waggoner, y Dominique Makowski. 2021. «performance: An R Package for Assessment, Comparison and Testing of Statistical Models». Journal of Open Source Software 6 (60): 3139. https://doi.org/10.21105/joss.03139.\n\n\nLui, Kung-Jong. 2016. Crossover Designs: Testing, Estimation, and Sample Size. Crossover designs: Testing, estimation, and sample size. https://doi.org/10.1002/9781119114710.\n\n\nNicenboim Bruno, Vasishth Shravan, Schad Daniel. 2023. «An Introduction to Bayesian Data Analysis for Cognitive Science». 2023. https://vasishth.github.io/bayescogsci/book/.\n\n\nSenn, Stephen. 2022. «Cross‐over Trials In Clinical Research». Editado por Ltd John Wiley. https://doi.org/10.1002/0470854596."
  },
  {
    "objectID": "2.html#footnotes",
    "href": "2.html#footnotes",
    "title": "2  Marco teórico y estado del arte",
    "section": "",
    "text": "No se deben confundir los Modelos Lineales Generales con los Modelos Lineales Generalizados. En los primeros, también llamados Modelos de Regresión Multivariante, se presupone que las variables respuesta tienen una relación lineal con los predictores y sus valores se distribuyen normalmente. Los segundos son una generalización de los primeros y permiten que la variable respuesta admita otras distribuciones además de la normal.↩︎\nOtras variantes de la Regresión Logística son la Regresión Categórica y la Regresión Multinomial. En estos tipos de GLM la variable respuesta puede adoptar varios valores pero no se asume que estén ordenados. La Regresión Categórica y la Regresión Multinomial están relacionadas en el mismo sentido en que lo están la Regresión Logística con función de enlace Bernoulli y con función de enlace Binomial. Es decir, que la Regresión Categórica se usa cuando las observaciones no están agrupadas y la Multinomial cuando sí lo están.↩︎\nEn la Sección 4.2.3 se demuestra esta fórmula.↩︎\nHay una diferencia conceptual entre medidas repetidas y longitudinales. Una variable se dice que es longitudinal cuando se toman varias medidas de los sujetos objeto del estudio en diferentes momentos del tiempo. Para que sea considerada de medidas repetidas, las medidas de cada sujeto se toman con distintos niveles de factor. En la práctica la distinción es poco relevante ya que ambas situaciones se parametrizan de la misma forma.↩︎\nEn ocasiones se puede obtener una forma análitica de la distribución a posteriori si se elige una adecuada combinación de función de verosimilitud y distribución a priori conocidas como distribuciones conjugadas. Aunque esto evita la utilización de métodos de simulación, restringe las formas posibles de las distribuciones. En la actualidad, con el aumento de la capacidad de cálculo de los ordenadores, normalmente no es necesaria la utilización de distribuciones conjugadas.↩︎"
  },
  {
    "objectID": "3.html#sec-desc",
    "href": "3.html#sec-desc",
    "title": "3  Materiales y métodos",
    "section": "3.1 Descripción de la experiencia",
    "text": "3.1 Descripción de la experiencia\nLa actividad de subtitulado, cuyos resultados se analizan en este trabajo, ha sido cuidadosamente diseñada con un enfoque instruccional curado a través de las sucesivas ediciones del curso y así ofrecer los contenidos de forma alineada para que los estudiantes puedan realizar la evaluación del subtitulado de forma secuencial.\nLa actividad fue voluntaria y sin influencia en la calificación final del alumno. Se realizó en el módulo “Accesibilidad del material multimedia”. En este mismo módulo, y antes de la actividad de subtitulado, los alumnos hubieron completado las secciones “Accesibilidad de la información sonora” y “Accesibilidad de la información visual”. Estos módulos constan de las siguientes actividades relacionadas con la actividad de subtitulado:\n\nVídeo: “Accesibilidad audiovisual: subtítulos”.\nInvitación a la participación en el foro.\nTextos con referencias.\nTest de nivel 1 y nivel 2: “Accesibilidad de información sonora”\n\nSe estima que los estudiantes hubieron empleado unas tres horas de formación en accesibilidad multimedia (una de ellas específicamente en subtitulado) antes de realizar la actividad.\nDe acuerdo al compromiso ético del Canal Fundación ONCE en UNED, los datos de los estudiantes se han suministrado anonimizados usando un identificador generado con -512. Además, se han eliminado del estudio los datos de estudiantes que, a pesar de haber realizado la actividad de subtitulado, no dieron su consentimiento para que sus datos fueran utilizados en estudios científicos.\nLa actividad consistió en ver dos vídeos idénticos de 43 segundos que solo se diferencian en la calidad del subtitulado. El vídeo original fue diseñado de tal forma que su subtitulado presentara características específicas relacionadas con los requisitos incluidos en la norma de subtitulado. Por ejemplo, la existencia de sonidos relevantes para la trama sin correspondencia visual, la existencia de más de un interlocutor, o de diálogos que comprometían la velocidad máxima de subtitulado. Los subtítulos fueron realizados por una experta de FIAPAS (Confederación Española de Familias de Personas Sordas) siguiendo la norma UNE 153010 (ver AENOR 2012). El otro vídeo tenía un subtitulado similar pero se introdujeron pequeñas deficiencias, algunas de ellas inapreciables para alguien que carezca de conocimientos sobre accesibilidad. El orden de los vídeos fue aleatorio, de tal forma que una cohorte (grupo) de alumnos vio primero el vídeo bien subtitulado y luego el mal subtitulado y la otra lo hizo al revés. Después de ver cada uno de los vídeos, los alumnos respondieron a una de 5 niveles y 18 ítems. Los 18 ítems de Likert responden a criterios de la norma UNE 153010 (ver AENOR 2012).\nLos términos escala de Likert e ítem de Likert se prestan a menudo a confusión ya que se utilizan con distintos significados. En este trabajo se seguirá la convención más habitual (ver Uebersax 2006) de denominar ítem de Likert a cada una de las preguntas de que consta un cuestionario o test, siendo la escala de Likert el conjunto de todos los ítems del cuestionario. Cada ítem se contestó marcando una opción de entre un conjunto ordenado de respuestas o niveles propuesto e idéntico para todos los ítems. Por ello, se debe evitar denominar escala a los niveles de un ítem.\nEl diseño del experimento fue . Es decir, a los alumnos no se les informó de si estaban viendo el vídeo con mejor o con peor calidad de subtitulado; los directores del MOOC tampoco conocieron esta información, como tampoco se conocía en el momento de analizar los datos, ya que los vídeos tienen identificaciones ofuscadas con -32b y no contienen ninguna indicación del tipo de subtitulado del vídeo1. El “ciego fue liberado” en la fase de elaboración de la discusión de este trabajo (ver Capítulo 6)."
  },
  {
    "objectID": "3.html#ficheros-suministrados",
    "href": "3.html#ficheros-suministrados",
    "title": "3  Materiales y métodos",
    "section": "3.2 Ficheros suministrados",
    "text": "3.2 Ficheros suministrados\nSe dispuso de los siguientes ficheros csv:\n\nFichero grade: contiene el identificador de estudiante (ofuscado con -512 para no conocer su identidad real) y el grupo al que pertenece (campo cohort) ofuscado con -32b.\nFicheros test1 y test2: son las repuestas a las escalas de Likert sobre la calidad del subtitulado del primer y del segundo vídeo realizado por cada grupo respectivamente.\n\nEn la Tabla 3.1 se muestran los 18 ítems de la escala de Likert que se propuso a los alumnos para que evaluaran cada uno de los vídeos. En la Tabla 3.2 se muestran los 5 niveles de cada uno de los ítems de la utilizados para valorar el subtitulado 2.\n\n\n\n\n\n\nTabla 3.1:  Ítems de la escala de Likert. \n  \n    \n    \n      Item\n      Texto\n    \n  \n  \n    Q01\nLa posición de los subtítulos\n    Q02\nEl número de líneas por subtítulo\n    Q03\nLa disposición del texto respecto a la caja donde se muestran los subtítulos\n    Q04\nEl contraste entre los caracteres y el fondo\n    Q05\nLa corrección ortográfica y gramatical\n    Q06\nLa literalidad\n    Q07\nLa identificación de los personajes\n    Q08\nLa asignación de líneas a los personajes en los diálogos\n    Q09\nLa descripción de efectos sonoros\n    Q10\nLa sincronización de las entradas y salidas de los subtítulos\n    Q11\nLa velocidad de exposición de los subtítulos\n    Q12\nEl máximo número de caracteres por línea\n    Q13\nLa legibilidad de la tipografía\n    Q14\nLa separación en líneas diferentes de sintagmas nominales, verbales y preposicionales\n    Q15\nLa utilización de puntos suspensivos\n    Q16\nLa escritura de los números\n    Q17\nLas incorrecciones en el habla\n    Q18\nLos subtítulos del vídeo cumplen en general con los requisitos de accesibilidad\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n  \n  Tabla 3.2:  Niveles de los ítems de la escala de Likert. \n  \n    \n    \n      values\n      levels\n    \n  \n  \n    0\nNo sé / No contesto\n    1\nMuy en desacuerdo\n    2\nEn desacuerdo\n    3\nNeutral\n    4\nDe acuerdo\n    5\nMuy de acuerdo"
  },
  {
    "objectID": "3.html#sec-preprocesado",
    "href": "3.html#sec-preprocesado",
    "title": "3  Materiales y métodos",
    "section": "3.3 Preprocesado",
    "text": "3.3 Preprocesado\nLos datos personales de los estudiantes se suministraron anonimizados para evitar conocer su identidad. De acuerdo con el compromiso ético del Canal, del estudio se han eliminado 19 estudiantes que, a pesar de haber realizado la actividad, no dieron su consentimiento para que sus datos se utilizaran en estudios científicos. Tras este proceso, se dispone de 198 cuestionarios correspondientes a 111 alumnos. Hay 24 estudiantes que solo realizaron el primero de los test por lo que se han eliminado del estudio. De estos, 46 manifestaron tener sexo femenino, 19 masculino y el resto (22) prefirieron no suministrar esta información. Se constata que hay un claro sesgo hacia el sexo femenino entre los participantes en la actividad de subtitulado.\nEn esta sección se describen las transformaciones realizadas con los ficheros suministrados:\n\nSe leyó el fichero grade. El número de fila con el que el estudiante aparece en el fichero se utilizó como identificador del estudiante para mantener la trazabilidad y comprobar que las transformaciones realizadas son correctas.\nSe eliminaron los datos de los estudiantes que, aun habiendo realizado la actividad, no dieron su consentimiento para participar en el estudio.\nEl valor del campo cohort, que indica el valor anonimizado para el grupo, se sustituyó por una letra, \\(A\\) o \\(B\\). En el momento en que se realizó este proceso se desconocía qué vídeo vio primero cada cohorte.\nSe leyeron los ficheros de test y se procesaron. Se utilizó el nombre del fichero (test1 o test2) para saber de qué vídeo se estaba respondiendo el test 3.\nSe seleccionaron los ítems que contienen las respuestas y se renombraron para que fuera más fácil saber de qué ítem se trataba 4. Se convirtió el campo LastTry, que contiene la fecha y hora de realización del test, a formato fecha y hora.\nSe realizaron algunas comprobaciones como la ausencia de valores nulos en las variables más relevantes y la no existencia de inconsistencias o errores de procesado.\nSe eliminaron los comentarios y se grabaron en un fichero aparte para que no revelaran información que habría podido descubrir el tipo de subtitulado que piensa que estaba evaluando el estudiante.\nSe renombraron las variables (ver Tabla 3.3).\nSe eliminaron del estudio los estudiantes que solo han realizado uno de los test.\nSe transformaron las variables que lo requirieron en factores. El ítem 18 se fijó como referencia en el factor Item ya que es una valoración general del subtitulado.\nSe rotaron los valores de respuesta para que “No sé / No contesto” tenga valor 0 y el resto de 1 a 5 desde “Muy en desacuerdo”, 1, hasta “Muy de acuerdo”, 5.\nSe crearon los factores Level con los niveles negativo, neutral y positivo dependiendo de si la respuesta es 1 ó 2, 3, 4 ó 5 respectivamente e Improve con valores 0 ó 1, dependiendo de si la respuesta en el test \\(A\\) es mejor (1) o igual o peor (0) que la del \\(B\\) para cada ítem y estudiante.\nSe transformó el dataframe de formato ancho a largo. Los ficheros de respuestas originales se suministraron en formato ancho. Es decir, que cada fila es un test que contiene 18 columnas para las respuestas a cada ítem. Los nombres de las columnas son \\(Q01\\), \\(Q02\\), …, \\(Q18\\) y tienen valores de 0 a 5 con las respuestas. La mayoría de los paquetes de R utilizados requieren que los datos estén en formato largo. Esto que quiere decir que cada fila tendrá una única respuesta por lo que habrá únicamente dos columnas, \\(Item\\) y \\(Response\\). En la primera se almacena el identificador del ítem (\\(Q01\\), \\(Q02\\), …, \\(Q18\\)) y en la segunda el valor de la respuesta (de 0 a 5). De esta forma, un test pasó de ocupar una fila y 18 columnas en el formato ancho a 18 filas y dos columnas en el largo."
  },
  {
    "objectID": "3.html#variables-utilizadas",
    "href": "3.html#variables-utilizadas",
    "title": "3  Materiales y métodos",
    "section": "3.4 Variables utilizadas",
    "text": "3.4 Variables utilizadas\nEn la Tabla 3.3 se describen las características más relevantes de las principales variables que se utilizarán en el modelado y en el análisis estadístico. La variable dependiente o respuesta en los modelos ordinales es Response y contiene las respuestas a todos los ítems (de 0 a 5). En los modelos logísticos se usa como variable respuesta Level o Improve. La variable explicativa principal es el factor Treat y permite diferenciar los dos niveles de subtitulado (\\(A\\) o \\(B\\)). Los factores Period y Seq sirven para evaluar la presencia de efectos periodo y secuencia respectivamente. El factor Period toma valores 1 ó 2 en función de si trata del primer o del segundo periodo. El factor Seq toma valores \\(AB\\) o \\(BA\\) dependiendo de si se vio primero el vídeo con subtitulado \\(A\\) o con subtitulado \\(B\\). En este trabajo los términos secuencia y grupo se usan indistintamente. Por último, los factores Subject e Item son variables explicativas que se tratan como efectos aleatorios en el modelado multinivel (ver Sección 4.2.4) y corresponden respectivamente a los estudiantes y a los ítems de la escala de Likert.\n\n\n\n\n\n\nTabla 3.3:  Descripción de las variables más importantes. \n  \n    \n    \n      Nombre\n      Descripción\n      Tipo\n      Valores\n    \n  \n  \n    Response\nRespuesta a los ítems del test.\nFactor ordenado\nDe 0 a 5\n    Level\nValoración de la respuesta.\nFactor ordenado\nNegativo, Neutral, Positivo1\n    Improve\nMejor respuesta en test A que en B.\nFactor\n1 ó 0\n    Treat\nSubtítulos\nFactor\nA o B\n    Period\nPeriodo\nFactor\n1 ó 22\n    Seq\nSecuencia de aplicación de los tratamientos.\nFactor\nAB o BA\n    Subject\nIdentificación del estudiante\nFactor\nNumérico\n    Item\nNúmero del ítem\nFactor\nQ01, Q02, ..., Q18\n  \n  \n  \n    \n      1 Positivo cuando Response sea 4 ó 5, Negativo cuando sea 1 ó 2 y Neutral para 3.\n    \n    \n      2 1 para el primer vídeo visto y 2 el segundo."
  },
  {
    "objectID": "3.html#dataframes-utilizados",
    "href": "3.html#dataframes-utilizados",
    "title": "3  Materiales y métodos",
    "section": "3.5 Dataframes utilizados",
    "text": "3.5 Dataframes utilizados\nSe van a usar tres dataframes construidos en el preprocesado:\n\ndf_response contiene las respuestas con valor de 1 a 5. Se han eliminado las de valor 0 (“No sé / No contesto”). Se utiliza cuando se traten las respuestas como ordinales y, por lo tanto, como ordenadas.\ndf_all incluye todas las respuestas de 0 a 5. Se utiliza cuando se traten las respuestas como categóricas y no ordenadas.\ndf_improve: Es un dataframe en el que la variable respuesta es Improve usado en el modelado logístico. Es una variable dicotómica que muestra si la respuesta es mejor en el subtitulado \\(A\\) que en el \\(B\\) (Improve= Response \\(A\\) &gt; Response \\(B\\)).\n\nLa estructura de los dos primeros dataframes es la siguiente:\n\n\ntibble [2,980 × 7] (S3: tbl_df/tbl/data.frame)\n $ Seq     : Factor w/ 2 levels \"AB\",\"BA\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Period  : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Treat   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Subject : Factor w/ 87 levels \"4\",\"33\",\"35\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Item    : Factor w/ 18 levels \"Q18\",\"Q01\",\"Q02\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Response: Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 3 3 3 3 3 3 3 3 3 3 ...\n $ Level   : Ord.factor w/ 3 levels \"Negativo\"&lt;\"Neutral\"&lt;..: 2 2 2 2 2 2 2 2 2..\n\n\nEn la Tabla 3.4 se muestran algunos ejemplos de datos. Concretamente se muestran las respuestas a tres ítems de dos estudiantes que vieron los vídeos en distinto orden.\n\n\n\n\n\n\nTabla 3.4:  Muestra del dataframe preparado para el modelado estadístico en\nformato largo. \n  \n    \n    \n      Seq\n      Period\n      Treat\n      Subject\n      Item\n      Response\n      Level\n    \n  \n  \n    AB\n1\nA\n35\nQ18\n5\nPositivo\n    AB\n2\nB\n35\nQ18\n4\nPositivo\n    AB\n1\nA\n35\nQ01\n5\nPositivo\n    AB\n2\nB\n35\nQ01\n5\nPositivo\n    AB\n1\nA\n35\nQ02\n5\nPositivo\n    AB\n2\nB\n35\nQ02\n4\nPositivo\n    BA\n1\nB\n33\nQ18\n2\nNegativo\n    BA\n2\nA\n33\nQ18\n4\nPositivo\n    BA\n1\nB\n33\nQ01\n4\nPositivo\n    BA\n2\nA\n33\nQ01\n4\nPositivo\n    BA\n1\nB\n33\nQ02\n4\nPositivo\n    BA\n2\nA\n33\nQ02\n4\nPositivo\n  \n  \n  \n\n\n\n\n\n\n\n\n\nAENOR. 2012. «UNE 153010 Subtitulado para personas sordas y personas con discapacidad auditiva». Asociación Española de Normalización y Certificación.\n\n\nUebersax, John S. 2006. «Likert scales: dispelling the confusion». Statistical Methods for Rater Agreement website. https://www.john-uebersax.com/stat/likert.htm."
  },
  {
    "objectID": "3.html#footnotes",
    "href": "3.html#footnotes",
    "title": "3  Materiales y métodos",
    "section": "",
    "text": "En la respuesta a cada ítem, el alumno pudo añadir comentarios. Éstos fueron eliminados en la fase de análisis para que no filtren información referente al tipo de subtitulado que el alumno creyó estar contestando y solo se utilizaron en la fase de discusión (ver Capítulo 6).↩︎\nEn la codificación original los valores asignados a cada respuesta eran diferentes: la opción “No sé / No contesto” se codificó con 5 y las demás opciones con una unidad menos que la mostrada. En este trabajo se ha hecho una rotación para asignar valores más usuales en la literatura científica sobre el tema.↩︎\nSe reitera que en el momento de realizar este proceso se desconocía si el vídeo es el correctamente subtitulado o el otro. La única información que se almacenó es si se estaba respondiendo al vídeo que se vio primero.↩︎\nEn los ficheros suministrados la respuesta a cada ítem ocupaba varios campos. Se seleccionó en cada ítem el que contiene el valor de la respuesta y se convirtió a numérico.↩︎"
  },
  {
    "objectID": "4.html#sec-eda",
    "href": "4.html#sec-eda",
    "title": "4  Modelado estadístico",
    "section": "4.1 Análisis Exploratorio",
    "text": "4.1 Análisis Exploratorio\nComo se explica en la Tabla 3.3, al subtitulado se le denomina tratamiento y a sus niveles (correcto e incorrecto) se les ha llamado \\(A\\) y \\(B\\) sin hacer ninguna conjetura de cual de los dos es el subtitulado correcto. El grupo con secuencia \\(AB\\) será el que primero vio el vídeo con subtitulado \\(A\\) y luego el \\(B\\). Análogamente, el grupo con secuencia \\(BA\\) vio los vídeos en orden inverso. Recuérdese que el nivel 0 de respuesta se corresponde con “No sé / No contesto” (ver Tabla 3.2). Tras eliminar los test de los 19 estudiantes que no dieron su consentimiento para participar en el estudio y los de los 24 estudiantes que no realizaron el segundo test, las dos cohortes están equilibradas ya que hay 43 estudiantes que realizaron el test con secuencia \\(AB\\) y 44 con secuencia \\(BA\\).\n\n4.1.1 Análisis de la calidad de los datos\nEn esta sección se analiza si hay test que tienen valores de respuesta que puedan resultar anómalos. En los test no se ha observado ningún valor nulo ni erróneo.\nEl campo LastTry contiene la fecha y hora de realización del test. Con esta información se puede conocer el tiempo que transcurrió desde que un estudiante rellenó el primer test hasta que completó el segundo. Dado que los vídeos duran 43 segundos y hay 18 ítems, se puede estimar el tiempo medio que cada estudiante empleó en contestar cada ítem suponiendo que haya visto el segundo vídeo completo. La Tabla 4.1 muestra que hay algunos test en los que los estudiantes emplearon un tiempo muy breve en contestar 1.\n\n\n\n\n\n\nTabla 4.1:  Tiempos de realización de la segunda actividad de duración inferior a\n2 minutos. \n  \n    \n    \n      Subject\n      Test\n      Spent time (secs)\n      Time by Item (secs)\n    \n  \n  \n    893\nB\n56\n0.72\n    1020\nB\n78\n1.94\n    85\nA\n102\n3.28\n    4\nB\n103\n3.33\n    110\nA\n107\n3.56\n    1034\nA\n118\n4.17\n  \n  \n  \n\n\n\n\n\nLa Figura 4.1 muestra que hay 28 test en los que el estudiante contestó a todos los ítems usando únicamente 2 respuestas diferentes. Además hay 13 test en los que se contestaron todos los ítems con 1 respuesta.\n\n\n\n\n\nFigura 4.1: Número de respuestas diferentes en un mismo test.\n\n\n\n\nLa tabla Tabla 4.2 muestra los test de respuesta única y el valor de esa respuesta. Se aprecia que la mayoría de estos test tienen valor de respuesta 4, la secuencia mayoritaria es la \\(BA\\) y el test el \\(A\\). El estudiante 4 responde ambos test utilizando el mismo valor de respuesta en todos los ítems.\n\n\n\n\n\n\nTabla 4.2:  Test en los que todos los ítems se contestan con el mismo valor de\nrespuesta. \n  \n    \n    \n      Response\n      Seq\n      Test\n      Subject\n    \n  \n  \n    2\nAB\nA\n4\n    2\nAB\nB\n4\n    3\nBA\nB\n734\n    3\nBA\nA\n803\n    3\nBA\nA\n33\n    3\nBA\nA\n229\n    4\nAB\nA\n35\n    4\nAB\nA\n76\n    4\nAB\nB\n523\n    4\nBA\nB\n85\n    4\nBA\nA\n901\n    4\nBA\nA\n808\n    4\nBA\nA\n871\n  \n  \n  \n\n\n\n\n\nLa Figura 4.2 presenta la distribución de la cantidad de respuestas cuyo valor cambia entre los dos test que realiza cada estudiante. La mayoría de los estudiantes cambian entre uno y otro test entre 11 y 17 respuestas. Tan solo 1 estudiante respondió a todos los ítems con el mismo valor en los dos test. Por otro lado, no hay test que tengan un número excesivo de contestaciones “No sé/No contesto” (ver Tabla 4.3).\n\n\n\n\n\nFigura 4.2: Número de respuestas diferentes entre los test para cada estudiante.\n\n\n\n\n\n\n\n\n\n\nTabla 4.3:  Los 5 test con más respuestas ‘No sé / No contesto’ \n  \n    \n    \n      Test\n      Subject\n      Total answers by test\n    \n  \n  \n    A\n231\n5\n    B\n339\n5\n    B\n346\n5\n    B\n1174\n5\n    A\n1187\n4\n  \n  \n  \n\n\n\n\n\nEn resumen, se constata que algunos test tienen valores que no parecen muy razonables. Por ejemplo, no parece razonable realizar la actividad en menos de 120 segundos. Además en algunos test hay poca variabilidad en las respuestas. Sin embargo, no son muchos los test con estas características así que se ha decidido mantener estos datos a pesar de que se pueda dudar de si en ellos los estudiantes contestaron con la debida atención y diligencia.\n\n\n4.1.2 Comparación de los subtítulos \\(A\\) y \\(B\\) entre grupos\nLa Figura 4.3 presenta una forma de comparar los dos test realizados por los estudiantes. Para cada estudiante se comparó ítem a ítem sus dos test y se contabilizó la diferencia entre el número de ítems en los que la puntuación en el segundo vídeo fue superior y en los que lo fue inferior (las que no variaron de puntuación no se consideraron). En el eje \\(x\\) se muestran las diferencias entre respuestas. Cantidades negativas indican que hay más respuestas en el segundo de los test que han empeorado respecto al primero de las que han mejorado. En el eje \\(y\\) se representa el número de estudiantes para cada diferencia. Esta frecuencia se representa en negativo cuando la diferencia en el eje x sea negativa para facilitar la comparación2. Esto es una forma de evaluar si el estudiante valoró mejor el segundo vídeo que el primero.\n\n\n\n\n\nFigura 4.3: Diferencias en las respuestas entre test por estudiante y grupo.\n\n\n\n\nSe aprecia que en el grupo \\(AB\\) las diferencias tienden a ser negativas y en el \\(BA\\) positivas. Esto estaría indicando que los estudiantes valoran mejor el subtitulado de nivel \\(A\\) en ambas secuencias. Por ello, es esperable que las respuestas de los estudiantes del grupo \\(AB\\) hayan empeorado y que las diferencias sean negativas y que lo contrario haya sucedido con las del grupo \\(BA\\). La diferencia más frecuente en el grupo \\(AB\\) es 12 y en el grupo \\(BA\\) este valor es 11. Resulta llamativo que haya estudiantes cuyas contestaciones estén tan alejadas de la tendencia de su grupo. En la Tabla 4.4 se muestran los tiempos que han transcurrido entre la realización de los test de aquellos estudiantes cuyas respuestas difieren de forma importante de su grupo. Son aquellos que aparecen en azul en la secuencia \\(AB\\) y en rojo en la secuencia \\(BA\\). Se observa que casi todos son tiempos entre actividades muy cortos. En cualquier caso y, como no son muchos, se ha decidido no eliminarlos y realizar el análisis con ellos.\n\n\n\n\n\n\nTabla 4.4:  Estudiantes que tienen diferencias en sus respuestas muy alejadas de\nla tendencia de su grupo. \n  \n    \n    \n      Seq\n      Subject\n      Diff\n      Minutes\n    \n  \n  \n    AB\n1020\n17\n1.3\n    AB\n75\n7\n3.33\n    BA\n650\n-10\n50345.95\n    BA\n85\n-12\n1.7\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\nTabla 4.5:  Resumen de frecuencias de respuesta. \n  \n    \n    \n      Seq\n      Period\n      Treat\n      0\n      \n        Response\n      \n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n  \n  \n    AB\n1\nA\n39\n2\n25\n71\n203\n434\n    AB\n2\nB\n43\n87\n185\n121\n172\n166\n    BA\n1\nB\n40\n76\n174\n127\n237\n138\n    BA\n2\nA\n30\n2\n30\n64\n345\n321\n  \n  \n  \n\n\n\n\n\nEn la Tabla 4.5 se muestra la frecuencia absoluta del valor de respuesta para cada grupo y test en todos los ítems. Esta es otra forma de comparar los niveles de subtitulado. La Figura 4.4 muestra la misma información gráficamente y con frecuencias relativas. En esta figura se pueden apreciar algunas cuestiones interesantes:\n\nEl tratamiento (subtitulado) con nivel \\(A\\) presenta claramente mayores valores de respuesta que el \\(B\\) como ya se había visto (ver Figura 4.3).\nEn general los dos grupos (\\(AB\\) y \\(BA\\)) muestran bastante acuerdo en el subtitulado en ambos niveles: En el nivel de tratamiento \\(A\\) los dos grupos tienen una frecuencia relativa similar de respuestas positivas (valores 4 y 5). El grupo \\(AB\\) tiene un 82% de respuestas positivas y el grupo \\(BA\\) 84%. No obstante, el grupo \\(AB\\) tiene más respuestas con valor 5 que el grupo \\(BA\\) (56% frente a 41%). La valoración es también similar entre grupos en el nivel de tratamiento \\(B\\): el grupo \\(AB\\) tiene 44% de respuestas positivas y 47% el grupo \\(BA\\). Las valoraciones negativas (1, 2), la neutra (3) y la ‘No sé / No contesto’ (0) son también muy similares en ambos grupos.\n\n\n\n\n\n\nFigura 4.4: Frecuencias relativas de las respuestas al test.\n\n\n\n\nEl análisis marginalizado de tratamiento, secuencia y periodo tiene estos resultados referidos a los ítems con contestación positiva (4, 5):\n\nEl tratamiento \\(A\\) tiene un 83% marginalizado de respuestas positivas frente al 46% del tratamiento \\(B\\).\nEl periodo 1 tiene un 65% marginalizado de respuestas positivas frente al 64% del periodo 2.\nFinalmente, la secuencia \\(AB\\) tiene un 63% de respuestas positivas frente 66% de la secuencia \\(BA\\).\n\n\n\n4.1.3 Análisis de los ítems\nEl gráfico Figura 4.5 muestra la frecuencia relativa por grupo y por test de los ítems clasificados por niveles de respuesta, considerando que:\n\nLos niveles 1 y 2 se consideran valoraciones negativas.\nEl nivel 3 se considera neutro.\nLos niveles 4 y 5 se consideran positivos.\nEl nivel 0 (“No sé / No contesto”) se excluye en este análisis.\n\nSe muestra en primer lugar el ítem 18 por ser una valoración global del subtitulado y que resume la opinión que sobre el mismo tiene el estudiante. Se vuelve a constatar que el subtitulado \\(A\\) es mejor valorado por los estudiantes, pero ahora se confirma que en los 18 ítems ambos grupos tienen más puntuaciones positivas y menos negativas en el subtitulado \\(A\\) que en el \\(B\\). También se vuelve a constatar que los dos grupos valoran de forma muy similar los dos niveles de subtitulado en todos los ítems. En el nivel de subtitulado \\(A\\) los ítems \\(Q15\\), \\(Q16\\) y \\(Q17\\) obtienen relativamente peores valoraciones (consultar la Tabla 3.1 para ver el texto de los ítems) y estas son similares en ambos subtitulados. Hay algunos ítems que son valorados de forma muy positiva incluso en el nivel de subtitulado \\(B\\) (por ejemplo \\(Q04\\) o \\(Q13\\)). Por último, los ítems \\(Q05\\) y \\(Q09\\) (también la \\(Q14\\) pero solo para el grupo \\(BA\\)) tienen una valoración muy negativa en el nivel de subtitulado \\(B\\).\n\n\n\n\n\nFigura 4.5: Frecuencias relativas de las respuestas por ítem.\n\n\n\n\nEn la Tabla 4.6 se muestran las contestaciones “No sé / No contesto” por subtitulado e ítem 3. Se observa que hay relativamente pocas contestaciones “No sé / No contesto” y que éstas se concentran en los ítems \\(Q14\\), \\(Q15\\), \\(Q16\\) y \\(Q17\\). El número de respuestas “No sé / No contesto” está razonablemente equilibrado entre subtitulados excepto en el ítem \\(Q10\\).\n\n\n\n\n\n\nTabla 4.6:  Contestaciones “No sé / No contesto” por nivel de subtitulado e\nítem \n  \n    \n    \n      Q03\n      Q05\n      Q06\n      Q08\n      Q09\n      Q10\n      Q11\n      Q12\n      Q13\n      Q14\n      Q15\n      Q16\n      Q17\n    \n  \n  \n    \n      A\n    \n    1\n0\n1\n3\n1\n0\n1\n1\n0\n11\n11\n22\n17\n    \n      B\n    \n    4\n1\n0\n1\n0\n8\n2\n4\n1\n10\n15\n25\n12"
  },
  {
    "objectID": "4.html#sec-modelos-utilizados",
    "href": "4.html#sec-modelos-utilizados",
    "title": "4  Modelado estadístico",
    "section": "4.2 Modelos utilizados",
    "text": "4.2 Modelos utilizados\nEs esta sección se concreta la forma de aplicar los modelos presentados en el Marco teórico (ver Capítulo 2) en la actividad de subtitulado.\n\n4.2.1 Comparación con Odds Ratio 4\nLa métrica  (\\(OR\\)) permite medir la asociación entre dos variables con dos niveles cada una. En el diseño de experimento que se está analizando, los factores \\(Treat\\), \\(Period\\) y \\(Seq\\) tienen todos 2 niveles y se puede contrastar si hay interacción entre cada par de factores para cada nivel de respuesta. Es decir, se contrasta la hipótesis \\(H_0: OR=1\\) de ausencia de asociación frente a \\(H_1: OR \\neq 1\\) de existencia de asociación en algún nivel de respuesta. Por ejemplo, el \\(OR\\) para el nivel respuesta \\(r\\) entre subtítulos y secuencias se define de la siguiente forma:\n\\[\nOR_{(Treat, Seq \\mid Response=r)}=\\frac{\n    \\frac{\n            P(Treat=A \\mid Seq=AB, Response=r)\n        }{\n            P(Treat=B \\mid Seq=AB, Response=r)\n        }\n    }\n    {\\frac{\n        P(Treat=A \\mid Seq=BA, Response=r)\n        }{\n        P(Treat=B \\mid Seq=BA, Response=r)\n    }\n}\n\\]\nSi los \\(\\gls{odds}\\) son similares en cada nivel de respuesta, se acepta la hipótesis nula de que los grupos responden de forma similar a cada nivel de subtitulado y secuencia. En la Sección 5.0.1 se pueden consultar los resultados obtenidos. En esta misma sección se hace un test similar pero entre subtitulado y periodos. Para realizar el contraste de hipótesis se usa la función \\(loddsratio\\) del paquete vcd (ver Zeileis, Meyer, y Hornik 2007).\n\n\n4.2.2 Regresión Logística\nEn la Sección 2.2.1 se presentó el fundamento teórico de la . En esta sección se justifica el uso de este modelo y se ajustan y comparan varios modelos. La variable respuesta se compone de 5 valores ordenados. Esto imposibilita usar directamente la Regresión Logística ya que requiere que la variable de respuesta sea dicotómica. No obstante, se puede comparar la respuesta que cada estudiante dio a cada uno de los subtitulados y comprobar si ha mejorado. Esto producirá una variable de respuesta binaria que permitirá el uso de la Regresión Logística. No obstante, esta transformación reducirá la cantidad de datos disponibles a la mitad e impedirá analizar el ya que al comparar los subtitulados, desaparece el periodo. Se ha creado una variable Improve con dos valores posibles: 1 cuando el estudiante valoró el ítem mejor en el subtitulado \\(A\\) que en el \\(B\\), 0 si empeoró o puntuó igual. Si en uno de los test contestó un ítem con “No sé / No contesto”, se elimina ese ítem.\nSe ajusta el modelo con la secuencia como predictor:\n\nglm_improve_seq &lt;- glm(Improve ~ 1 + Seq, family = \"binomial\", data = df_improve)\nsummary(glm_improve_seq)\n\n\nCall:\nglm(formula = Improve ~ 1 + Seq, family = \"binomial\", data = df_improve)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.37858    0.07635   4.958 7.11e-07 ***\nSeqBA       -0.05137    0.10668  -0.481     0.63    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1967.2  on 1450  degrees of freedom\nResidual deviance: 1966.9  on 1449  degrees of freedom\nAIC: 1970.9\n\nNumber of Fisher Scoring iterations: 4\n\n\nSe constata que el coeficiente del intercepto es positivo y significativo (0.38). El intercepto es el \\(log\\ odds\\) de mejorar la valoración en \\(A\\) sobre \\(B\\) respecto a empeorar la valoración. La probabilidad de que la respuesta a un ítem sea mejor en el subtitulado \\(A\\) que en el \\(B\\) es 0.59. La secuencia no resulta significativa y además añadirla apenas reduce la “deviance”, por lo que el modelo nulo sin predictores resulta más parsimonioso.\nOtra forma de plantear una Regresión Logística es crear una variable de respuesta dicotómica que tenga valor 1 cuando la respuesta sea positiva (valores 4 ó 5) y cero cuando no lo sea (valores 1, 2 ó 3). En la Sección 5.0.2.2 se comentan los resultados de este modelo.\n\n\n4.2.3 Regresión Ordinal\nEn la Sección 2.2.2 se presentó el fundamento teórico de la Regresión Ordinal Acumulativa (\\(CM\\)). En esta sección se comprueban las hipótesis de este modelo para el experimento del subtitulado de vídeos y se ajustan varios modelos que tratan de predecir el nivel de respuesta (variable Response) obtenido en cada uno de los ítems de Likert. Concretamente, se compara el modelo que tenga como único predictor el nivel de subtitulado (Treat) con el modelo nulo (sin predictores) y también con el modelo en el que se han añadido los predictores Period y Seq para comprobar si hay significación estadística de la presencia de efectos periodo y secuencia respectivamente.\n\n4.2.3.1 Comprobación de las hipótesis del modelo \\(CM\\)\nEl modelo \\(CM\\) presupone que los \\(odds\\) entre dos niveles de respuesta son proporcionales para los mismos valores de variables explicativas. Como se vio en la Ecuación 2.4, es equivalente comprobar que los \\(odds\\) son proporcionales que comprobar que la diferencia en logits es constante.\nNo existe un acuerdo generalmente aceptado sobre como comprobar la proporcionalidad de \\(odds\\). Así, por ejemplo, el paquete ordinal (ver R. H. B. Christensen 2022) dispone de la función nominal_test() que lo que hace es realizar un test de razón de verosimilitud para cada predictor ajustando un modelo en el que se ha relajado la condición de proporcionalidad. Otra posibilidad es utilizar el Test de Brant (ver Brant 1990) que compara los coeficientes obtenidos con los que resultarían de ajustar cada nivel de respuesta mediante una Regresión Logística. Finalmente Harrell (2015, ver pp. 315-316) propone un método gráfico para verificar la hipótesis de proporcionalidad de \\(odds\\). En este trabajo se ha preferido esta última técnica. Para ello se calcula la diferencia en logits acumulados entre dos niveles de respuesta consecutivos en cada valor de cada variable predictiva y se comprueba si las diferencias son similares. En la Figura 4.6 se han calculado para los predictores Treat, Period, Seq y Item las diferencias de logits entre cada dos niveles consecutivos de respuesta. Se constata que las diferencias son pequeñas particularmente para el periodo y para la secuencia. También son moderadas para la mayoría de los ítems. La diferencia es mayor en el subtitulado en la comparación de los niveles de respuesta 1 y 2. Con esta evidencia, se acepta la hipótesis de proporcionalidad de \\(odds\\). En la Tabla 4.7 se muestra como se realiza el cálculo de la diferencia de \\(odds\\) para el predictor Seq y así facilitar la comprensión de la construcción de la figura. En caso de que la proporcinalidad de \\(odds\\) no se cumpla existen varias posibilidades. Una sería desechar el modelo ordinal y usar una Regresión Multinomial. Otra sería relajar la hipótesis de proporcionalidad de \\(odds\\) estimando un coeficiente distinto para cada nivel de respuesta y nivel de factor. La función vglm del paquete VGAM (ver Yee 2023) permite hacer esto.\n\n\n\n\n\nFigura 4.6: Comprobación de la proporcionalidad de odds.\n\n\n\n\n\n\n\n\n\n\nTabla 4.7:  Comprobación de la proporcionalidad de odds para Seq. \n  \n    \n    \n      Response\n      n\n      cum.sum\n      odds\n      log.odds\n      diff.log.odds\n    \n  \n  \n    \n      AB\n    \n    1\n89\n89\n0.06\n−2.74\n−1.38\n    2\n210\n299\n0.26\n−1.36\n−0.68\n    3\n192\n491\n0.50\n−0.69\n−1.05\n    4\n375\n866\n1.44\n0.37\n−Inf\n    5\n600\n1466\nInf\nInf\nNA\n    \n      BA\n    \n    1\n78\n78\n0.05\n−2.91\n−1.44\n    2\n204\n282\n0.23\n−1.47\n−0.69\n    3\n191\n473\n0.45\n−0.79\n−1.62\n    4\n582\n1055\n2.30\n0.83\n−Inf\n    5\n459\n1514\nInf\nInf\nNA\n  \n  \n  \n\n\n\n\n\n\n\n4.2.3.2 Ajuste del modelo ordinal Response ~ Treat\nExisten varios paquetes en R que permiten ajustar un modelo \\(CM\\) con función de enlace logística. El más popular es el paquete ordinal (ver R. H. B. Christensen 2022). El paquete VGAM (ver Yee 2023) es más flexible y potente. Otra posibilidad es usar la función polr del paquete MASS (ver Venables y Ripley 2002). Finalmente la función orm del paquete rms también permite hacerlo (ver Harrell 2015). En este trabajo se usa el paquete ordinal (ver R. H. B. Christensen 2022) por permitir también incluir efectos aleatorios que se utilizarán en el modelado multinivel. Se comienza con un modelo simple que tiene como único predictor el nivel de subtitulado por ser la variable más importante al ser el objeto de la pregunta de investigación:\n\\[\n\\text{logit}(P(Response_i \\leq k)) = \\tau_k - \\beta_1 \\text{Treat}_i,\n\\]\n\nclm_treat &lt;-\n    clm(\n        Response ~ Treat,\n        data = df_response, link = \"logit\"\n    )\nsummary(clm_treat)\n\nformula: Response ~ Treat\ndata:    df_response\n\n link  threshold nobs logLik   AIC     niter max.grad cond.H \n logit flexible  2980 -3966.11 7942.21 5(0)  1.64e-10 3.1e+01\n\nCoefficients:\n       Estimate Std. Error z value Pr(&gt;|z|)    \nTreatB  -1.7206     0.0731  -23.54   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -3.97230    0.09678 -41.045\n2|3 -2.45446    0.06812 -36.029\n3|4 -1.66453    0.05936 -28.042\n4|5 -0.10547    0.04946  -2.132\n\n\nLa función summary() muestra la información resumen. Para su interpretación se va a seguir Rune Haubo Bojesen Christensen (2018). El número de condición Hessiano es inferior a \\(10^4\\) lo que es indicativo de que no hay problemas de optimización 5. La sección de coeficientes es la más importante: Se muestra la estimación de parámetros, el error estándar y la significación estadística de acuerdo al Test de Wald para el parámetro TreatB. Se comprueba que el valor es claramente significativo. Es decir, que los estudiantes han valorado de forma diferente la calidad del subtitulado en ambos vídeos. El estimador de maxima verosimilitud del coeficiente TreatB es -1.72. Siguiendo la deducción de Bruin (2011) se puede, por ejemplo, hacer la siguiente interpretación del significado de este coeficiente referido a dos niveles consecutivos de respuesta, por ejemplo 1 y 2:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1)] & = & -3.97 - (-1.72 x_1) \\\\\nlogit [P(Y \\le 2)] & = & -2.45 - (-1.72 x_1)\n\\end{aligned}\n\\]\nPor lo tanto y teniendo en cuenta que \\(x_1 = 1\\) cuando \\(Treat = B\\) y \\(x_1 = 0\\) cuando \\(Treat = A\\), se pueden calcular los \\(odds\\) de \\(A\\) y de \\(B\\):\n\\[\n\\begin{aligned}\n\\frac{P(Y \\le 1 \\mid x_1 = B)}{P(Y &gt; 1 \\mid x_1 = B)} & = & exp(-3.97)/exp(-1.72) \\\\\n\\frac{P(Y \\le 1 \\mid x_1 = A)}{P(Y &gt; 1 \\mid x_1 = A)} & = & exp(-3.97) \\\\\n\\frac{P(Y \\le 2 \\mid x_1 = B)}{P(Y &gt; 2 \\mid x_1 = B)} & = & exp(-2.45)/exp(-1.72) \\\\\n\\frac{P(Y \\le 2 \\mid x_1 = A)}{P(Y &gt; 2 \\mid x_1 = A)} & = & exp(-2.45)\n\\end{aligned}\n\\]\nY los \\(OR\\) del subtitulado \\(B\\) sobre \\(A\\) para los niveles de respuesta 1 y 2:\n\\[\n\\begin{aligned}\n\\frac{P(Y \\le 1 | x_1=B)}{P(Y &gt; 1 | x_1=B)} / \\frac{P(Y \\le 1 | x_1=A)}{P(Y &gt; 1 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\\\\n\\frac{P(Y \\le 2 | x_1=B)}{P(Y &gt; 2 | x_1=B)} / \\frac{P(Y \\le 2 | x_1=A)}{P(Y &gt; 2 | x_1=A)} & = & 1/exp(-1.72) & = & 5.59 \\\\\n\\end{aligned}\n\\]\nSe comprueba que el \\(OR\\) es equivalente en todos los niveles de respuesta al cuestionario. Esta es la suposición principal de los modelos \\(CM\\). El \\(odds\\) de respuesta al cuestionario entre los niveles inferiores y superiores a uno dado, \\(k\\), es 5.59 veces en el subtitulado \\(B\\) que en el \\(A\\). Esto indica que el subtitulado \\(B\\) es percibido por los estudiantes como de peor calidad que el subtitulado \\(A\\). Concretamente, el \\(OR\\) de observar una mejor respuesta en un ítem del test es 5.59 veces superior en el nivel de subtitulado \\(A\\) que en el \\(B\\). Aunque no suele ser de interés, la interpretación de los coeficientes de los umbrales (Threshold coefficients), se pueden utilizar para estimar las probabilidades de respuesta. Por ejemplo, para el nivel de subtitulado \\(B\\) y nivel de respuesta 2:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1)] & = & -3.97 - (-1.72) & = & -2.25 \\\\\nP(Y \\le 1) & = & \\frac{exp(-2.25)}{1 + exp(-2.25)} & = & 0.10 \\\\\nlogit [P(Y \\le 2)] & = & -2.45 - (-1.72) & = & -0.73 \\\\\nP(Y \\le 2) & = & \\frac{exp(-0.73)}{1 + exp(-0.73)} & = & 0.32 \\\\\nP(Y = 2) & = & P(Y \\le 2) - P(Y \\le 1) & = &  0.23\n\\end{aligned}\n\\]\nPara el subtitulado \\(A\\) no se tiene en cuenta el coeficiente \\(TreatB\\) ya que el valor \\(x_1\\) es cero:\n\\[\n\\begin{aligned}\nlogit [P(Y \\le 1)] & = & & & -3.97 \\\\\nP(Y \\le 1) & = & \\frac{exp(-3.97)}{1 + exp(-3.97)} & = & 0.02 \\\\\nlogit [P(Y \\le 2)] & = & & & -2.45 \\\\\nP(Y \\le 2) & = & \\frac{exp(-2.45)}{1 + exp(-2.45)} & = & 0.08 \\\\\nP(Y = 2) & = & P(Y \\le 2) - P(Y \\le 1) & = &  0.06\n\\end{aligned}\n\\]\nEn Tabla 4.8 se muestran las probabilidades para ambos niveles de subtitulado y todos los posibles valores de respuesta. Se confirma que en el nivel de subtitulado \\(A\\) son más probables las respuestas 5 y 4, siendo poco probables el resto de niveles. Sin embargo, en el subtitulado \\(B\\) existe bastante incertidumbre, siendo el valor más probable el nivel 4 y muy similares los niveles 2, 3 y 5. Esto se corresponde con lo que ya se había constatado en el Análisis Exploratorio (ver Figura 4.4). Se debe tener en cuenta que este modelo tiene un único predictor y, por lo tanto, no es capaz de explicar las diferencias en el nivel de respuesta para distintos periodos, secuencias, ítems o estudiantes. En las siguientes secciones se investiga si en el nivel de respuesta influyen estos predictores.\n\n\n\n\nTabla 4.8: Probabilidades de respuesta para el modelo ordinal Response ~ Treat\n\n\n\n1\n2\n3\n4\n5\n\n\n\n\nA\n0.018\n0.061\n0.08\n0.315\n0.526\n\n\nB\n0.095\n0.229\n0.19\n0.320\n0.166\n\n\n\n\n\n\n\n\n\n\n4.2.3.3 Ajuste del modelo ordinal Response ~ Treat * Period\nPara saber si existe un efecto periodo, se añade como predictor la variable Period. También se añade la interacción entre subtitulado y periodo 6:\n\\[\n\\text{logit}(P(Response_i \\leq k)) = \\tau_k - \\beta_1 \\text{Treat}_i - \\beta_2 \\text{Period}_i - \\beta_3 \\text{Treat}_i : \\text{Period}_i\n\\tag{4.1}\\]\nEn el Apéndice A se demuestra que cuando el contraste es \\(sum\\) la interacción entre periodo y subtitulado es equivalente al . Es decir, que los modelos Response ~ Treat*Period y Response ~ Treat + Period + Seq son equivalentes. Esto no sucede cuando el contraste es \\(treatment\\), que es el utilizado por defecto en R. En la Tabla 4.9 se comparan los coeficientes de los cuatro modelos que se listan a continuación:\n\nResponse ~ Treat * Period con contraste treatment.\nResponse ~ Treat + Period + Seq con contraste treatment.\nResponse ~ Treat * Period con contraste sum.\nResponse ~ Treat + Period + Seq con contraste sum.\n\n\n\n\n\n\n\nTabla 4.9:  Comparación de los coeficientes con contraste “treatment” y\n“sum”. \n  \n    \n    \n      \n        contr.treatment\n      \n      \n        contr.sum\n      \n    \n    \n      \n        Response ~ Treat*Period\n      \n      \n        Response ~ Treat+Period+Seq\n      \n      \n        Response ~ Treat*Period\n      \n      \n        Response ~ Treat+Period+Seq\n      \n    \n    \n      coef\n      value\n      coef\n      value\n      coef\n      value\n      coef\n      value\n    \n  \n  \n    1|2\n−4.246\n1|2\n−4.246\n1|2\n−3.127\n1|2\n−3.127\n    2|3\n−2.728\n2|3\n−2.728\n2|3\n−1.608\n2|3\n−1.608\n    3|4\n−1.938\n3|4\n−1.938\n3|4\n−0.818\n3|4\n−0.818\n    4|5\n−0.370\n4|5\n−0.370\n4|5\n0.750\n4|5\n0.750\n    TreatB\n−1.960\nTreatB\n−1.748\nTreat1\n0.874\nTreat1\n0.874\n    Period2\n−0.492\nPeriod2\n−0.279\nPeriod1\n0.140\nPeriod1\n0.140\n    TreatB:Period2\n0.425\nSeqBA\n−0.213\nTreat1:Period1\n0.106\nSeq1\n0.106\n  \n  \n  \n\n\n\n\n\nSe comprueba que coinciden los coeficientes de los dos modelos con contraste sum y que el efecto secuencia es equivalente a la interacción de periodo y subtitulado con este contraste. Sin embargo, en el contraste treatment coinciden los coeficientes de los interceptores pero no así los de los factores. Además, estos tres últimos coeficientes tienen nombres diferentes en los dos contrastes. La diferencia en el nombre se corresponde con la distinta interpretación del significado de los coeficientes. En el contraste treatment los valores de los interceptos se refieren a los valores de los factores en el nivel de referencia de cada factor (en este caso \\(Treat = A\\) y \\(Period = 1\\)) y los valores de los otros coeficientes (\\(TreatB\\) y \\(Period2\\)) son la diferencia con el de referencia. Así, por ejemplo, \\(TreatB\\) es la diferencia con \\(TreatA\\) en el periodo 1. Con este tipo de contraste es más difícil aislar el efecto que produce un nivel de un factor independiente del otro factor. En el contraste sum los valores de los interceptos son el efecto medio 7, y los coeficientes \\(Treat1\\) y \\(Period1\\) son los efectos que sobre ese valor medio produce el nivel de factor de referencia, que en este caso es el primero (\\(Treat = A\\) y \\(Period = 1\\) respectivamente). Así por ejemplo en el contraste sum:\n\nEl coeficiente \\(1|2\\) tiene un valor -3.127 y es el logit medio de que la respuesta sea menor que 1 frente a que sea mayor que 1.\nEl coeficiente \\(Treat1\\) tiene un valor de 0.874 y es la diferencia en logits que se añade en el nivel de subtitulado \\(A\\) sin tener en cuenta el periodo. Es decir, que es el efecto del subtitulado \\(A\\). Su valor es positivo. Como en la Ecuación 4.1 aparece restando, el subtitulado \\(A\\) hace más pequeño el logit y, por lo tanto, disminuye la probabilidad de una respuesta inferior frente a una superior.\nPara obtener el efecto del subtitulado \\(B\\) se cambia el signo a \\(Treat1\\): -0.874. Por ello aumenta la probabilidad de un menor valor de respuesta.\nLa diferencia en logits de los efectos totales del subtitulado es el doble de 0.874.\nEl coeficiente \\(Period1\\) tiene un valor 0.14 y es la diferencia en logits que produce el periodo \\(1\\) sin tener en cuenta el subtitulado.\nEl efecto del periodo \\(2\\) se obtiene cambiado el signo al efecto del periodo 1: -0.14.\nEl efecto total del periodo es 0.279 logits.\nEl coeficiente \\(Treat1:Period1\\) tiene un valor de 0.106 y es la interacción entre el subtitulado \\(A\\) y el periodo \\(1\\). Es equivalente al efecto en logits de la secuencia \\(AB\\). El efecto de la secuencia \\(BA\\) será -0.106.\nPor lo tanto el efecto total en logits del subtitulado \\(A\\) en el periodo 1 será \\(1|2 - Treat1 - Period1 - Treat1:Period1 = -3.127 - 0.874 - 0.14 - 0.106 = -4.246\\). Obsérvese que este valor corresponde con el parámetro \\(1|2\\) de los modelos con contraste treatment.\nEl efecto total en logits del subtitulado \\(B\\) en el periodo 1 será \\(1|2 + Treat1 - Period1 + Treat1:Period1 = -3.127 + 0.874 - 0.14 + 0.106\\).\nEl efecto total en logits del subtitulado \\(A\\) en el periodo 2 será \\(1|2 - Treat1 + Period1 + Treat1:Period1 = -3.127 - 0.874 + 0.14 + 0.106\\).\nEl efecto total en logits del subtitulado \\(B\\) en el periodo 2 será \\(1|2 + Treat1 + Period1 - Treat1:Period1 = -3.127 + 0.874 + 0.14 - 0.106\\).\n\nEn la Tabla 4.10 se muestra la equivalencia de los coeficientes entre los modelos ajustados con cada contraste. La conclusión que se obtiene de todo esto es que cuando se usan dos o más factores, la interpretación con contraste sum resulta más intuitiva y sencilla y será el contraste utilizado en este trabajo.\n\n\nTabla 4.10: Equivalencia entre los coeficientes contr.treatment y contr.sum en el modelo Response ~ Treat*Period.\n\n\ncontr.treatment\ncontr.sum\nvalue\n\n\n\n\n1|2\n1|2 - Treat1 - Period1 - Treat1:Period1\n-4.246\n\n\n2|3\n2|3 - Treat1 - Period1 - Treat1:Period1\n-2.728\n\n\n3|4\n3|4 - Treat1 - Period1 - Treat1:Period1\n-1.938\n\n\n4|5\n4|5 - Treat1 - Period1 - Treat1:Period1\n-0.37\n\n\nTreatB\n-2(Treat1 + Treat1:Period1)\n-1.96\n\n\nPeriod2\n-2(Period1 + Treat1:Period1)\n-0.492\n\n\nTreatB:Period2\n4(Treat1:Period1)\n0.425\n\n\n\n\nA continuación se muestra el resumen del modelo con contraste sum para constatar que los tres coeficientes son significativos:\n\n\nformula: Response ~ Treat * Period\ndata:    df_response\n\n link  threshold nobs logLik   AIC     niter max.grad cond.H \n logit flexible  2980 -3953.01 7920.03 5(0)  2.13e-10 1.4e+01\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreat1          0.87395    0.03678  23.763  &lt; 2e-16 ***\nPeriod1         0.13962    0.03411   4.094 4.25e-05 ***\nTreat1:Period1  0.10627    0.03410   3.117  0.00183 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -3.12665    0.08242  -37.94\n2|3 -1.60838    0.04968  -32.38\n3|4 -0.81849    0.04225  -19.37\n4|5  0.74993    0.04194   17.88\n\n\n\n\n4.2.3.4 Elección del modelo ordinal mediante el test de razón de verosimilitud\nLa Tabla 4.11 compara tres modelos ordinales con el contraste \\(sum\\):\n\nModelo nulo.\nModelo con predictor Treat.\nModelo con predictores Treat y Period y su interacción (que es equivalente a incluir el predictor Seq).\n\nSe constata que los coeficientes estimados en los tres modelos son significativos y de similar valor.\n\n\n\n\n\n\nTabla 4.11:  Comparación de modelos ordinales. \n  \n    \n    \n       \n      \n        Response ~ 1    \n      \n      \n        Response ~ Treat    \n      \n      \n        Response ~ Treat:Period    \n      \n    \n    \n      Est.\n      S.E.\n      Est. \n      S.E. \n      Est.  \n      S.E.  \n    \n  \n  \n    1|2 \n-2.824***\n0.080\n-3.112***\n0.082\n-3.127***\n0.082\n    2|3 \n-1.418***\n0.046\n-1.594***\n0.049\n-1.608***\n0.050\n    3|4 \n-0.738***\n0.039\n-0.804***\n0.042\n-0.818***\n0.042\n    4|5 \n0.596***\n0.038\n0.755***\n0.042\n0.750***\n0.042\n    Treat1 \n\n\n0.860***\n0.037\n0.874***\n0.037\n    Period1 \n\n\n\n\n0.140***\n0.034\n    Treat1 × Period1 \n\n\n\n\n0.106**\n0.034\n    Num.Obs.\n2980\n\n2980\n\n2980\n\n    AIC\n8541.7\n\n7942.2\n\n7920.0\n\n    BIC\n8565.7\n\n7972.2\n\n7962.0\n\n    Log.Lik.\n-4266.851\n\n-3966.107\n\n-3953.013\n\n    edf\n4\n\n5\n\n7\n\n  \n  \n  \n\n\n\n\n\nAl ser los tres modelos anidados se pueden comparar con la prueba de razón de verosimilitud. Se comprueba que el tercer modelo reduce significativamente el logaritmo de la función de verosimilitud y, por lo tanto, debe ser aceptado:\n\n\nLikelihood ratio tests of cumulative link models:\n \n                     formula:                  link: threshold:\nclm_sum_null         Response ~ 1              logit flexible  \nclm_sum_treat        Response ~ Treat          logit flexible  \nclm_sum_treat.period Response ~ Treat * Period logit flexible  \n\n                     no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)    \nclm_sum_null              4 8541.7 -4266.9                          \nclm_sum_treat             5 7942.2 -3966.1 601.490  1  &lt; 2.2e-16 ***\nclm_sum_treat.period      7 7920.0 -3953.0  26.186  2  2.059e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEste modelo estima coeficientes positivos para Treat1, Period1 y Treat1:Period1 (equivalente a Seq1). Estos coeficientes indican que:\n\nSon más probables mayores niveles de respuesta en el subtitulado \\(A\\) que en el \\(B\\).\nSon más probables mayores niveles de respuesta en el periodo 1 que en el 2.\nSon más probables mayores niveles de respuesta en la secuencia \\(AB\\) que en la secuencia \\(BA\\).\nNo obstante, y a pesar de que el efecto periodo y el efecto secuencia son significativos, el efecto del nivel de subtitulado medido en logits es ocho veces más importante que estos efectos considerados individualmente y cuatro veces considerados de forma conjunta.\n\n\n\n\n4.2.4 Regresión Ordinal Multinivel\nEn la Sección 2.3 se expuso el fundamento teórico de los modelos multinivel. Aquí se justifica su interés aplicado al caso del subtitulado de vídeos. Hay dos variables susceptibles de ser incorporadas al modelo como efectos aleatorios. El primer candidato es el factor Subject. Es evidente que los estudiantes son una muestra de una población más amplia que estaría constituida por todos los estudiantes del curso de . Pero es que además cada estudiante responde a cada ítem dos veces y, por lo tanto, sus observaciones no son independientes. En la Figura 4.7 se muestran las respuestas de diez estudiantes a cada subtitulado. Se observa que las respuestas no son independientes ya que cada estudiante tiene un preferencia por uno o varios niveles de respuesta en cada test. Por otro lado, los ítems no son independientes unos de otros ya que pretenden medir la misma variable subyacente. Además, el interés no es conocer el valor concreto de sus coeficientes sino su valor en relación a los coeficientes de los otros ítems. En Bürkner (2021b, 14-16) y en Bürkner y Vuorre (2019, 19-20) se puede encontrar un ejemplo con esta parametrización aplicada a una .\n\n4.2.4.1 Modelo Response ~ Treat * Period + (1 | Subject)\nEl primer modelo que se propone es un modelo que mantiene los predictores Treat y Period y su interacción (equivalente al ) como efectos fijos que fueron seleccionadas en la sección anterior (ver Sección 4.2.3.4) e incorpora los estudiantes como efectos aleatorios sobre los interceptos:\n\\[\n\\begin{aligned}\nNivel\\ 1: & \\text{logit}(P(Response_{ij} \\leq k)) = \\tau_{kj} - \\beta_1 \\text{Treat}_{ij} - \\beta_2 \\text{Period}_{ij} - \\beta_3 \\text{Treat}_{ij} : \\text{Period}_{ij} \\\\\nNivel\\ 2: & \\tau_{kj}  =  \\tau_{k} + Subject_{0j}\n\\end{aligned}\n\\]\ndonde \\(ij\\) es la observación \\(i\\) del estudiante \\(j\\). Obsérvese que ahora los interceptos \\(\\tau_{kj}\\) se descomponen en una parte fija y común para cada nivel de respuesta \\(k\\), \\(\\tau_{k}\\) y una parte variable específica para cada estudiante \\(Subject_{0j}\\). Para ajustar el modelo se va a utilizar la función clmm del paquete ordinal (ver R. H. B. Christensen 2022) ya que permite la inclusión de efectos aleatorios.\n\n\n\n\n\nFigura 4.7: Respuestas de los estudiantes por nivel de subtitulado.\n\n\n\n\n\noptions(contrasts = rep(\"contr.sum\", 2))\nclmm_treat.period_subject &lt;- clmm(\n    Response ~ Treat * Period + (1 | Subject),\n    data = df_response\n)\nsummary(clmm_treat.period_subject)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 | Subject)\ndata:    df_response\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3655.71 7327.41 765(3046) 1.63e-03 8.1e+01\n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n Subject (Intercept) 1.278    1.131   \nNumber of groups:  Subject 87 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreat1          1.05368    0.03999  26.346  &lt; 2e-16 ***\nPeriod1         0.15662    0.03604   4.346 1.39e-05 ***\nTreat1:Period1  0.14262    0.12677   1.125    0.261    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -3.7046     0.1523 -24.332\n2|3  -2.0298     0.1349 -15.050\n3|4  -1.1012     0.1310  -8.406\n4|5   0.8281     0.1299   6.375\n\n\nEn la parte de efectos fijos: los interceptos tienen valores similares al modelo de efectos fijos (ver Sección 4.2.3.3) aunque los coeficientes incrementan ligeramente su valor. Esto indica una mayor distancia entre las respuestas de los subtitulados \\(A\\) y \\(B\\). En este modelo el efecto secuencia no es significativo. En cuanto a los efectos aleatorios: la varianza del intercepto aleatorio de los estudiantes es 1.28. En la Figura 4.8 se muestran los valores de los interceptos estimados de los estudiantes. La media de estos interceptos como se espera es cercana a cero (-0.008).\n\n\n\n\n\nFigura 4.8: Distribución de interceptos aleatorios por estudiante en el modelo Response ~ Treat * Period + (1 | Subject)\n\n\n\n\n\n\n4.2.4.2 Modelo Response ~ Treat * Period + (1 + Treat | Subject)\nEs posible que cada estudiante valore con diferente criterio cada subtitulado. Para estimarlo, se propone el siguiente modelo:\n\\[\n\\begin{aligned}\nNivel\\ 1: & \\text{logit}(P(Response_{ij} \\leq k)) = \\tau_{kj} - \\beta_{1j} \\text{Treat}_{ij} - \\beta_{2} \\text{Period}_{ij} - \\beta_{3} \\text{Treat}_{ij} * \\text{Period}_{ij} \\\\\nNivel\\ 2: & \\tau_{kj}  =  \\tau_{k} + Subject_{0j} \\\\\n          & \\beta_{1j}  =  \\beta_{1} + Subject_{1j}\n\\end{aligned}\n\\]\nAhora el parámetro \\(\\beta_{1j}\\) del subtitulado tiene dos componentes: Uno común a todos los niveles de respuesta \\(\\beta_{1}\\) y otro particular de cada estudiante \\(Subject_{1j}\\). El modelo ajustado ocasiona que solo Treat1 sea significativo, ya que ni el periodo ni la secuencia lo son. En los efectos aleatorios la correlación entre intercepto y pendiente es prácticamente nula.\n\noptions(contrasts = rep(\"contr.sum\", 2))\nclmm_treat.period_treat.subject &lt;- clmm(\n    Response ~ Treat * Period + (1 + Treat | Subject),\n    data = df_response\n)\nsummary(clmm_treat.period_treat.subject)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 + Treat | Subject)\ndata:    df_response\n\n link  threshold nobs logLik   AIC     niter     max.grad cond.H \n logit flexible  2980 -3429.88 6879.76 905(6264) 1.33e-03 8.2e+01\n\nRandom effects:\n Groups  Name        Variance Std.Dev. Corr   \n Subject (Intercept) 1.712    1.308           \n         Treat1      1.042    1.021    -0.062 \nNumber of groups:  Subject 87 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreat1           1.2938     0.1197  10.809   &lt;2e-16 ***\nPeriod1          0.1620     0.1171   1.383    0.167    \nTreat1:Period1   0.1327     0.1464   0.906    0.365    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -4.2633     0.1761 -24.210\n2|3  -2.3321     0.1562 -14.932\n3|4  -1.2656     0.1520  -8.324\n4|5   0.9659     0.1509   6.400\n\n\n\n\n4.2.4.3 Comparación de modelos\nSe pueden comparar los modelos con el test de razón de verosimilitud que se realiza con la función anova del paquete ordinal (ver R. H. B. Christensen 2022). Se comprueba que en este test resulta significativamente mejor el último modelo:\n\nanova(clmm_treat.period_subject, clmm_treat.period_treat.subject)\n\nLikelihood ratio tests of cumulative link models:\n \n                                formula:                                         \nclmm_treat.period_subject       Response ~ Treat * Period + (1 | Subject)        \nclmm_treat.period_treat.subject Response ~ Treat * Period + (1 + Treat | Subject)\n                                link: threshold:\nclmm_treat.period_subject       logit flexible  \nclmm_treat.period_treat.subject logit flexible  \n\n                                no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)    \nclmm_treat.period_subject            8 7327.4 -3655.7                          \nclmm_treat.period_treat.subject     10 6879.8 -3429.9  451.66  2  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n4.2.4.4 Elección del mejor modelo\nEn el apartado anterior se introdujo a los estudiantes como efecto aleatorio. Como se ha dicho, los ítems también pueden modelizarse como aleatorios. Esto produce una multiplicidad de modelos. Los siguientes son los que se han comparado:\n\nResponse ~ (1 | Subject)\nResponse ~ (1 + Treat | Subject)\nResponse ~ (1 + Treat | Item)\nResponse ~ Treat + (1 + Treat | Subject)\nResponse ~ Treat + (1 + Treat | Item)\nResponse ~ Treat*Period + (1 + Treat | Subject)\nResponse ~ Treat*Period + (1 + Treat | Item)\nResponse ~ Treat*Period + (1 + Period | Subject) + (1 + Treat | Item)\nResponse ~ Treat + (1 + Treat | Subject) + (1 + Treat | Item)\nResponse ~ Treat*Period + (1 + Treat | Subject) + (1 + Treat | Item)\n\nEl último de ellos produce un resultado significativo en el test de razón de verosimilitud con todos los demás. Sin embargo los parámetros de todos los modelos tienen valores similares por lo que no cambia la interpretación que se haga de ellos en cada modelo. Este modelo tiene un \\(AIC\\) menor que los modelos ordinales ajustados en el apartado anterior (ver Sección 4.2.3) incluso si a esos modelos se les añade como factor predictor Item. Será este, por lo tanto, el modelo seleccionado.\nLa Ecuación 4.2 del modelo seleccionado es la siguiente:\n\\[\n\\begin{aligned}\nNivel\\ 1: & \\text{logit}(P(Response_{ijl} \\leq k)) = \\tau_{kjl} - \\beta_{1jl} \\text{Treat}_{ijl} - \\beta_{2} \\text{Period}_{ijl} - \\beta_{3} \\text{Treat}_{ijl} : \\text{Period}_{ijl} \\\\\nNivel\\ 2: & \\tau_{kjl}  =  \\tau_{k} + Subject_{0j} + Item_{0l} \\\\\n          & \\beta_{1jl}  =  \\beta_{1} + Subject_{1j} + Item_{1l}\n\\end{aligned}\n\\tag{4.2}\\]\ndonde \\(ijl\\) se corresponde con la observación \\(i\\)-ésima del estudiante \\(j\\) e ítem \\(l\\). Ahora los interceptos y el coeficiente del subtitulado se componen de tres sumandos: una parte fija, una parte que depende del estudiante y una parte que depende del ítem de Likert.\nEl resumen de parámetros del modelo ajustado es el siguiente:\n\noptions(contrasts = rep(\"contr.sum\", 2))\nclmm_treat.period.subject.item &lt;- clmm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item),\n    data = df_response\n)\n\nsummary(clmm_treat.period.subject.item)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat |  \n    Item)\ndata:    df_response\n\n link  threshold nobs logLik   AIC     niter       max.grad cond.H \n logit flexible  2980 -3186.06 6398.11 1468(12273) 2.37e-03 1.5e+02\n\nRandom effects:\n Groups  Name        Variance Std.Dev. Corr   \n Subject (Intercept) 2.2176   1.4892          \n         Treat1      1.3650   1.1683   -0.128 \n Item    (Intercept) 0.4831   0.6950          \n         Treat1      0.4655   0.6823   -0.528 \nNumber of groups:  Subject 87,  Item 18 \n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \nTreat1           1.4320     0.2102   6.811  9.7e-12 ***\nPeriod1          0.1730     0.1325   1.306    0.192    \nTreat1:Period1   0.1397     0.1654   0.845    0.398    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -5.0033     0.2619 -19.104\n2|3  -2.6499     0.2417 -10.962\n3|4  -1.3659     0.2376  -5.748\n4|5   1.1837     0.2365   5.006\n\n\nCon este modelo los efectos secuencia y periodo no son significativos. En cualquier caso, se mantienen ya que el test de razón de verosimilitud resulta significativo en este modelo respecto al modelo sin estos predictores.\n\n\n\n4.2.5 Modelado bayesiano\nExisten muchos paquetes en R para hacer inferencia bayesiana. Algunos de los más populares son:\n\nOpenBUGS y WinBUGS: basado en el muestreo de Gibbs.\nJAGS: también utiliza el muestreo de Gibbs.\nStan: Más moderno y con una comunidad de desarrollo más activa que los anteriores. Utiliza muestreo HMC (Hamiltonian Monte Carlo) y NUTS (no U-turn sampler). Stan tiene un lenguaje similar a C para definir modelos aunque hay muchos paquetes basados en Stan que facilitan la especificación de modelos con una sintaxis más sencilla. En este trabajo se utilizará uno de ellos, brms (ver Bürkner 2021a) . La sintaxis de especificación de modelos con este paquete es idéntica a la que se ha utilizado en la sección anterior.\nINLA: Evita la simulación  haciendo más rápida la convergencia. Es menos flexible ya que solo se pueden especificar modelos de la familia exponencial.\n\nSe han comparado múltiples modelos usando la función LOO que realiza una validación cruzada bayesiana leave-one-out similar a la que se explicó en la Sección 2.4. El mejor modelo ha resultado ser el mismo que se seleccionó en modelos mixtos (ver Ecuación 4.2). Es decir:\n\nResponse ~ Treat*Period + (1 + Treat | Subject) + (1 + Treat | Item) \n\n\noptions(contrasts = rep(\"contr.sum\", 2))\nbrm_treat.period.subject.item &lt;- brm(\n    Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item),\n    data = df_response,\n    family = cumulative(\"logit\"),\n    iter = 4000,\n    sample_prior = TRUE,\n    file = \"models/brm_treat.period.subject.item\",\n    file_refit = \"on_change\"\n)\n\nEl modelo utiliza como factores con efectos fijos (complete pooling en terminología bayesiana) el nivel de subtitulado y el periodo y la interacción entre ambos; y como efectos aleatorios (partial pooling) los sujetos y los ítems del test, cada uno de ellos con un intercepto y un nivel de subtitulado variable. El resumen del modelo es el siguiente:\n\nsummary(brm_treat.period.subject.item)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item) \n   Data: df_response (Number of observations: 2980) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nGroup-Level Effects: \n~Item (Number of levels: 18) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.77      0.16     0.53     1.15 1.00     1468\nsd(Treat1)                0.77      0.15     0.53     1.12 1.00     1935\ncor(Intercept,Treat1)    -0.46      0.20    -0.78     0.01 1.00     1421\n                      Tail_ESS\nsd(Intercept)             2605\nsd(Treat1)                3580\ncor(Intercept,Treat1)     2555\n\n~Subject (Number of levels: 87) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             1.54      0.14     1.29     1.85 1.00     1484\nsd(Treat1)                1.21      0.11     1.01     1.45 1.00     1519\ncor(Intercept,Treat1)    -0.11      0.12    -0.34     0.14 1.00     1228\n                      Tail_ESS\nsd(Intercept)             2741\nsd(Treat1)                3081\ncor(Intercept,Treat1)     2475\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]      -4.95      0.28    -5.52    -4.42 1.00      785     1753\nIntercept[2]      -2.59      0.26    -3.11    -2.09 1.01      743     1636\nIntercept[3]      -1.30      0.26    -1.82    -0.82 1.01      726     1532\nIntercept[4]       1.25      0.26     0.74     1.75 1.00      745     1571\nTreat1             1.46      0.23     1.01     1.92 1.00     1046     2071\nPeriod1            0.17      0.14    -0.09     0.44 1.00      848     1714\nTreat1:Period1     0.14      0.17    -0.20     0.47 1.01      686     1127\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nSe han mantenido las distribuciones de probabilidad a priori que por defecto utiliza brm confiando en que sus parámetros son adecuados. Sin embargo, conviene comprobar que realmente sea así. En la Tabla 4.12 se muestran las distribuciones a priori de los parámetros aleatorios del modelo. En la Figura 4.9 se constata que toman valores razonables y no informativos.\n\n\n\n\n\n\nTabla 4.12:  Distribuciones a priori del modelo ordinal seleccionado. \n  \n    \n    \n      prior\n      class\n      coef\n      group\n      resp\n      dpar\n      nlpar\n      lb\n      ub\n      source\n    \n  \n  \n    \nb\n\n\n\n\n\n\n\ndefault\n    \nb\nPeriod1\n\n\n\n\n\n\ndefault\n    \nb\nTreat1\n\n\n\n\n\n\ndefault\n    \nb\nTreat1:Period1\n\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nIntercept\n\n\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nIntercept\n1\n\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nIntercept\n2\n\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nIntercept\n3\n\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nIntercept\n4\n\n\n\n\n\n\ndefault\n    lkj_corr_cholesky(1)\nL\n\n\n\n\n\n\n\ndefault\n    lkj_corr_cholesky(1)\nL\n\nItem\n\n\n\n\n\ndefault\n    lkj_corr_cholesky(1)\nL\n\nSubject\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nsd\n\n\n\n\n\n0\n\ndefault\n    student_t(3, 0, 2.5)\nsd\n\nItem\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nsd\nIntercept\nItem\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nsd\nTreat1\nItem\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nsd\n\nSubject\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nsd\nIntercept\nSubject\n\n\n\n\n\ndefault\n    student_t(3, 0, 2.5)\nsd\nTreat1\nSubject\n\n\n\n\n\ndefault\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nFigura 4.9: Distribuciones a priori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item).\n\n\n\n\nEs importante asegurar que el entrenamiento ha convergido a su distribución a posteriori. En la tabla de resumen se constata que el valor de Rhat 8 es inferior a 1.1 y el de ESS 9 superior a 400 en todos los parámetros, que son umbrales que no se deberían violar (ver Bürkner y Vuorre 2019). En la Figura 4.10 se comprueba que las cadenas \\(MCMC\\) de muestreo de la distribución a posteriori se mezclan correctamente y no se aprecia autocorrelación en ninguno de los parámetros. Por último, en la Figura 4.11 se muestra una comparación entre los histogramas construidos con los datos de las respuestas a los test con los intervalos de credibilidad marginales de la función predictiva a posteriori del modelo. En la mayoría de los ítems el muestreo se ajusta bastante bien al histograma de respuestas; aunque en algunos ítems, como el Q16 o el Q17, se aprecian diferencias relevantes.\n\n\n\n\n\nFigura 4.10: Cadenas MCMC del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item).\n\n\n\n\n\n\n\n\n\nFigura 4.11: Comparación de los valores reales con los obtenidos a partir de la función predictiva a posteriori del modelo Response ~ Treat * Period + (1 + Treat | Subject) + (1 + Treat | Item).\n\n\n\n\n\n\n\n\nAgresti, Alan. 2010. Analysis of Ordinal Categorical Data. https://doi.org/10.1002/9780470594001.\n\n\nBrant, Rollin. 1990. «Assessing Proportionality in the Proportional Odds Model for Ordinal Logistic Regression». Biometrics 46 (4): 1171-78. http://www.jstor.org/stable/2532457.\n\n\nBruin, J. 2011. «How do I interpret the coefficients in an ordinal logistic regression in R». 2011. https://stats.oarc.ucla.edu/r/faq/ologit-coefficients.\n\n\nBürkner, Paul-Christian. 2021a. «Bayesian Item Response Modeling in R with brms and Stan». Journal of Statistical Software 100 (5): 1-54. https://doi.org/10.18637/jss.v100.i05.\n\n\n———. 2021b. «Bayesian Item Response Modeling in R with brms and Stan». Journal of Statistical Software 100 (noviembre). https://doi.org/10.18637/jss.v100.i05.\n\n\nBürkner, Paul-Christian, y Matti Vuorre. 2019. «Ordinal Regression Models in Psychology: A Tutorial». Advances in Methods and Practices in Psychological Science 2 (febrero): 251524591882319. https://doi.org/10.1177/2515245918823199.\n\n\nChristensen, R. H. B. 2022. «ordinal—Regression Models for Ordinal Data».\n\n\nChristensen, Rune Haubo Bojesen. 2018. «Cumulative Link Models for Ordinal Regression with the R Package ordinal». En.\n\n\nHarrell, Frank. 2015. Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis. https://doi.org/10.1007/978-3-319-19425-7.\n\n\nVenables, W. N., y B. D. Ripley. 2002. Modern Applied Statistics with S. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nYee, T. W. 2023. VGAM: Vector Generalized Linear and Additive Models. https://CRAN.R-project.org/package=VGAM.\n\n\nZeileis, Achim, David Meyer, y Kurt Hornik. 2007. «vcd: Residual-based Shadings for Visualizing (Conditional) Independence». Journal of Computational and Graphical Statistics 16 (3): 507-25. https://doi.org/10.1198/106186007X237856."
  },
  {
    "objectID": "4.html#footnotes",
    "href": "4.html#footnotes",
    "title": "4  Modelado estadístico",
    "section": "",
    "text": "Hay que tener en cuenta que la duración de vídeo es de algo más de 40 segundos y que los estudiantes tienen que contestar un test de 18 ítems.↩︎\nEn la comparación se han omitido aquellas respuestas en las que el estudiante contestó “No sé / No contesto” en el ítem correspondiente de uno de los test.↩︎\nSolo se muestran los ítems que tienen respuestas “No sé / No contesto” en alguno de los subtitulados.↩︎\nEsta técnica se ha omitido en el Marco teórico por considerarla conocida por el lector. Si se desea ampliar información se puede consultar Agresti (2010, 18).↩︎\nEl número de condición de Hessiano es una medida de la curvatura de una función en un punto. Si el número de condición de Hessiano es grande, la función es muy sensible a pequeñas perturbaciones y puede ser difícil de optimizar.↩︎\nSe debe tener en cuenta que en R la interacción entre dos variables se puede añadir con los símbolos “\\(*\\)” y “\\(:\\)”. El símbolo “\\(*\\)” añade al modelo tanto los efectos principales como la interacción, mientras que el símbolo “\\(:\\)” tan solo añade la interacción. Por ello, los modelos \\(Response \\sim Treat*Period\\) y \\(Response \\sim Treat + Period + Treat:Period\\) son equivalentes en R↩︎\nSe calcula como la media de las medias de cada combinación de los niveles de factor.↩︎\nRhat es una medida utilizada para evaluar la convergencia de las Cadenas de Markov Monte Carlo (\\(MCMC\\)) en el muestreo bayesiano. Compara la varianza de cada cadena individual de \\(MCMC\\) con la varianza entre diferentes cadenas. Si las cadenas convergen, se espera que sus valores sean similares y, por lo tanto, el valor de Rhat será próximo a 1.↩︎\nESS (Efficient Sample Size) es una estimación del número de muestras independientes obtenidas en el muestreo \\(MCMC\\).↩︎"
  },
  {
    "objectID": "5.html",
    "href": "5.html",
    "title": "5  Resultados",
    "section": "",
    "text": "6 Discusión\nEn este capítulo se discuten los resultados una vez “descubierto el ciego” y se responde a la pregunta de investigación y a los objetivos específicos planteados en la Sección 1.2. Las respuestas a estas preguntas llevan a concluir que se ha cumplido el objetivo principal del estudio: los estudiantes del curso MOOC son capaces de evaluar las diferencias en la calidad del subtitulado de dos vídeos. Se discuten también las limitaciones del estudio y posibles mejoras al mismo.\nUna vez realizado el análisis estadístico y obtenidos los resultados (ver Capítulo 5) se reveló que el subtitulado que en este trabajo se ha denominado \\(A\\) se corresponde con el vídeo correctamente subtitulado. Adicionalmente se ha suministrado un documento que contiene los errores introducidos en el subtitulado \\(B\\). A partir del mismo, se ha elaborado la Tabla \\(\\ref{tbl-blind-errors}\\) en la que se muestra la correspondencia de cada error con los ítems de la a la que respondieron los estudiantes (ver en la Tabla 3.1 una descripción textual de cada ítem). Para 7 de los 18 ítems (Q01, Q03, Q04, Q13, Q15, Q16, Q17) no se ha encontrado una adscripción clara en el documento de errores y, por lo tanto, esos ítems sirven de control del test y sería esperable que en ellos las respuestas de los estudiantes fueran similares en ambos subtitulados.\nEste trabajo ha pretendido responder a la pregunta de investigación de si los estudiantes de un curso de son capaces de identificar los errores en el subtitulado de un vídeo, y como objetivos específicos averiguar qué aspectos del subtitulado han sido más fácilmente reconocidos por los estudiantes y en cuáles han tenido más dificultad. Para ello se ha partido de una Exploración Inicial (ver Sección 4.1) y se han propuesto varios modelos estadísticos que tengan en cuenta la naturaleza ordinal y dependiente de la variable respuesta (ver Sección 4.2). Como variables explicativas se ha considerado el nivel de subtitulado, el periodo en el que se ha realizado cada test, la secuencia u orden de realización de los test, el estudiante que ha realizado el test y el ítem al que se responde.\nLa conclusión más importante es que todos los análisis estadísticos realizados muestran que el nivel de subtitulado es la variable que mejor explica la respuesta a cada ítem. Los efectos secuencia y periodo son comparativamente de poca importancia y se traducen en que en general los estudiantes valoran peor el vídeo visto en el segundo periodo para un mismo nivel de subtitulado. Las variables estudiante e ítem se han tratado como efectos aleatorios por haber considerado que sus observaciones no son independientes. La varianza explicada por la variable estudiante ha sido más grande que la explicada por la variable ítem.\nLos estudiantes han identificado errores de subtitulado de los ítems \\(Q05\\) (la corrección ortográfica y gramatical), \\(Q06\\) (la literalidad), \\(Q07\\) (la identificación de los personajes), \\(Q08\\) (la asignación de líneas a los personajes en los diálogos), \\(Q09\\) (la descripción de efectos sonoros) y \\(Q14\\) (la separación en líneas diferentes de sintagmas nominales, verbales y preposicionales).\nSin embargo, han tenido más dificultades en identificar los errores introducidos en los ítems \\(Q02\\) (el número de líneas por subtítulo), \\(Q10\\) (la sincronización de las entradas y salidas de los subtítulos), \\(Q11\\) (la velocidad de exposición de los subtítulos) y \\(Q12\\) (el máximo número de caracteres por línea). El análisis realizado sobre los comentarios a estos ítems, evidencia que los estudiantes han aprendido las normas que debe regir el subtitulado en estos aspectos pero que no han evaluado minuciosamente si se cumplen realmente. Hay que tener en consideración que esta fue una actividad voluntaria sin incidencia en la calificación del curso, y que en una situación real esto probablemente no habría sucedido ya que habrían realizado una comprobación minuciosa.\nEn definitiva, los estudiantes conocen las normas de subtitulado y son capaces identificar los errores que no requieren una comprobación exhaustiva. En los que sí lo requieren, que son aquellos que tienen que ver con parámetros temporales (velocidad y sincronización) y espaciales (número de líneas y caracteres por línea), han tenido más dificultad. Esto está en consonancia con Khafik y Pratama (2022). En su estudio analizan el subtitulado en inglés producido por estudiantes cuya lengua nativa no es el inglés y concluyen que los errores más frecuentes son precisamente los que tienen que ver con parámetros temporales y espaciales.\nEn cuanto a los ítems que tratan aspectos en los que no hay errores en ninguno de los vídeos, los estudiantes han valorado positivamente ambos subtitulados en los ítems \\(Q04\\) (el contraste entre los caracteres y el fondo) y \\(Q13\\) (la legibilidad de la tipografía). Esto no implica necesariamente que, de haber habido deficiencias en estos aspectos, las hubieran reconocido. De hecho, hay evidencias de que los estudiantes noveles tienen dificultades en la identificación de deficiencias en el contraste (ver Molanes-López et al. 2021).\nLos ítems \\(Q15\\) (la utilización de puntos suspensivos), \\(Q16\\) (la escritura de los números) y \\(Q17\\) (las incorrecciones en el habla) preguntan cuestiones que no se producen en los vídeos y que son relativamente fáciles de verificar. En las respuestas de los estudiantes han confluido varios problemas verificables a través de los comentarios a los ítems. Por un lado, algunos estudiantes manifiestan que no recuerdan con seguridad la existencia de lo preguntado (puntos suspensivos, números, …). Este problema no es importante ya que es de suponer que en una situación de evaluación de subtitulado real realizarían un segundo visionado de los vídeos para asegurarse. Más preocupante resulta el segundo de los problemas detectados ya que podría estar también presente en otros ítems y haber pasado inadvertido en este trabajo. El problema en cuestión es que en estos ítems la respuesta esperable es “No sé / No contesto”. En la Tabla 4.6 se constató que estos son los ítems que más respuestas de este nivel reciben pero que esta respuesta no es masiva. Muchos estudiantes se decantan por valoraciones negativas, positivas o neutrales a pesar de haber indicado en los comentarios que la pregunta realizada no tiene aplicación en la actividad. Este problema es una preocupación general en análisis de escalas de Likert. Por ejemplo, ver Tutz (2020) para una propuesta de modelado estadístico de la categoría neutral en una escala de Likert. Un tercer problema detectado en estos ítems, que es probable que también haya tenido incidencia en otros ítems, es que, a pesar de que los comentarios revelan que los estudiantes piensan que estos ítems no tienen aplicación en ninguno de los vídeos, obtienen peor valoración en el subtitulado \\(B\\) que en el \\(A\\). Esto estaría indicando que las contestaciones de los estudiantes sufren cierto “efecto de ventana rota”. La hipótesis que aquí se plantea para explicar por qué el subtitulado \\(B\\) ha obtenido peores respuestas que el \\(A\\) incluso en ítems en los que el estudiante sabe que los subtitulados son idénticos es la siguiente: Hay ítems como \\(Q05\\) (la corrección ortográfica y gramatical) que son fáciles de evaluar y responder por los estudiantes. Si el estudiante encuentra una falta de ortografía en un subtitulado, estaría psicológicamente condicionado a ser más crítico con cualquier otro aspecto del subtitulado. Ante una pregunta que el estudiante no recuerda haber encontrado (por ejemplo, la presencia de puntos suspensivos) tiende a otorgar una valoración inferior en el subtitulado con faltas de ortografía porque considera que existe la posibilidad de haber pasado por alto la presencia de puntos suspensivos. Esto no sucede en todos los casos. Por ejemplo, en la pregunta sobre el contraste (ítem \\(Q04\\)), la diferencia entre subtitulados aunque existe es menor. La hipótesis expuesta es coherente con este hecho ya que, mientras que los puntos suspensivos son algo puntual cuya existencia el estudiante sabe que puede pasar inadvertida, el contraste es algo que afecta o puede afectar a todo el subtitulado del vídeo.\nEstas conclusiones abren varias vías de investigación que se enumeran aquí a modo de propuesta y sin ánimo de exhaustividad:"
  },
  {
    "objectID": "5.html#respuestas-a-las-preguntas-de-investigación-y-a-los-objetivos-específicos",
    "href": "5.html#respuestas-a-las-preguntas-de-investigación-y-a-los-objetivos-específicos",
    "title": "5  Resultados",
    "section": "6.1 Respuestas a las preguntas de investigación y a los objetivos específicos",
    "text": "6.1 Respuestas a las preguntas de investigación y a los objetivos específicos\nPara responder a las preguntas de investigación se van a utilizar los hallazgos del Análisis Exploratorio (ver Sección 4.1) y los resultados de los tres modelos comentados en el Capítulo 5:\n\n con variable respuesta Improve, que calcula la probabilidad de que la respuesta a un ítem mejore entre subtitulados \\(A\\) &gt; \\(B\\) (ver Sección 5.0.2.1).\n con variable respuesta Positive, que calcula la probabilidad de que la respuesta a un ítem sea positiva (4 ó 5).\n con variable Respuesta Response, que calcula la probabilidad de cada nivel de respuesta (ver Sección 5.0.2.2).\n\nPara mayor comodidad del lector se vuelven a plantear aquí la pregunta de investigación y los objetivos específicos:\n\n\n\n\n\n\nPregunta de investigación\n\n\n\n¿Son los estudiantes de un curso de creación de materiales accesibles capaces de evaluar las diferencias en la calidad del subtitulado de un vídeo?\n\n\nEl subtitulado \\(A\\), que es el correcto, ha sido mejor evaluado por los estudiantes. Esto se ha constatado tanto en la exploración inicial como en cada uno de los tres modelos propuestos. Por ejemplo, en la exploración inicial se vio que la respuesta más frecuente en el subtitulado \\(A\\) es 5 y en el \\(B\\) es 4 y en el modelo con variable respuesta Improve predice que la probabilidad de que se otorgue una mayor puntuación en \\(A\\) que en \\(B\\) es 61.42%. Por lo tanto, se concluye respondiendo afirmativamente a la pregunta: los estudiantes del curso han sabido evaluar las diferencias en el subtitulado de los vídeos.\n\n\n\n\n\n\nObjetivo específico\n\n\n\n¿En qué pautas de subtitulado los estudiantes tienen mayor facilidad para reconocer diferencias entre un subtitulado correcto y otro incorrecto?\n\n\nLa respuesta a esta pregunta requiere un análisis pormenorizado ítem a ítem. Se ha elaborado una tabla para los dos modelos logísticos y otra para el modelo de Regresión Ordinal. La Figura 6.1 contiene la tabla de los dos modelos logísticos. Para su correcta interpretación se deben tener en cuenta las siguientes premisas:\n\nEn la parte izquierda se presentan los resultados del modelo logístico con variable respuesta Improve y en la derecha el modelo logístico con variable respuesta Positive.\nEn la parte superior se presentan los ítems en los que hay diferencias en el subtitulado y que son objeto de este objetivo específico. En la parte inferior se muestran los ítems que se usan como control ya que no hay diferencias en ellos entre subtitulados y se analizan en el objetivo correspondiente.\nLa columna Freq es la frecuencia relativa de las tablas de contingencia que resultan del análisis exploratorio. La columna Prob son las probabilidades predichas por cada uno de los modelos.\nLos datos se muestran con un fondo coloreado con una tonalidad más oscura cuando más inesperado sea el resultado obtenido.\n\nEn el modelo con variable respuesta Improve (ver parte izquierda de Figura 6.1), los alumnos han valorado claramente de forma superior el subtitulado \\(A\\) que el \\(B\\) en los ítems \\(Q05\\) (la corrección ortográfica y gramatical), \\(Q06\\) (la literalidad), \\(Q08\\) (la asignación de líneas a los personajes en los diálogos), \\(Q09\\) (la descripción de efectos sonoros) y \\(Q14\\) (la separación en líneas diferentes de sintagmas nominales, verbales y preposicionales).\nEn la parte derecha de la Figura 6.1 se muestran las predicciones del modelo con variable respuesta Positive de obtener una respuesta con nivel 4 ó 5. Coincide con el modelo anterior en los ítems peor valorados en el subtitulado \\(B\\). Además, habría que añadir el ítem \\(Q07\\) (la identificación de los personajes), que tiene mayor probabilidad de valoración no positiva.\n\n\n\nFigura 6.1: Predicciones de los modelos de Regresión Logística\n\n\nEn la Figura \\(\\ref{fig-prob-compare}\\) se muestran las probabilidades por nivel de respuesta, ítem y nivel de subtitulado correspondiente al modelo de Regresión Ordinal y se comparan con las frecuencias de la tabla de contingencia. Los ítems con errores se presentan en negrita y recuadrados. Se observa que en el subtitulado \\(A\\) todas las respuestas a los ítems se concentran en valores positivos (4 ó 5). En el subtitulado \\(B\\) se espera que los ítems en los que se han introducido errores tengan peores valoraciones. Esto sucede claramente en \\(Q05\\) y en \\(Q09\\) y también aunque en menor medida en \\(Q06\\), \\(Q07\\), \\(Q08\\) y \\(Q14\\). Estos ítems coinciden con los que se han destacado anteriormente y son, por lo tanto, en los que los estudiantes reconocen más fácilmente diferencias entre subtitulados.\n\n\n\n\n\n\nObjetivo específico\n\n\n\n¿En qué pautas de subtitulado los estudiantes tienen mayor dificultad para reconocer diferencias entre un subtitulado correcto y otro incorrecto?\n\n\nLos dos modelos logísticos (ver Figura 6.1) coinciden en que los estudiantes tienen dificultad para reconocer diferencias en el subtitulado en los ítems:\n\n\\(Q02\\) (el número de líneas por subtítulo) con probabilidad predicha de mejorar la valoración de 68.56%.\n\\(Q10\\) (la sincronización de las entradas y salidas de los subtítulos) con probabilidad de mejora 55.34%.\n\\(Q11\\) (la velocidad de exposición de los subtítulos) con probabilidad 57.53%.\n\\(Q12\\) (el máximo número de caracteres por línea) con probabilidad 63.7%.\n\nEn estos mismos ítems, el modelo ordinal (ver Figura \\(\\ref{fig-prob-compare}\\)) predice más respuestas negativas en el subtitulado \\(B\\) que en el \\(A\\) pero aún así el subtitulado \\(B\\) tiene un alto número de respuestas positivas.\nPara entender las motivaciones de las valoraciones de los alumnos, se han analizado los comentarios que dejaron 2. La siguiente es una selección de los comentarios más relevantes en cada ítem:\n\n\\(Q02\\), el número de líneas por subtítulo: En los comentarios al subtitulado \\(A\\) hay bastantes que se quejan del número excesivo de líneas.\n\n\nSubtitulado \\(A\\): ‘Se pueden hasta 3 pero no es recomendable’, ‘en ocasiones son 3 innecesariamente’, ‘frases muy cortas’, ‘No superaba las dos (creo recordar)’, ‘Se cumple’.\n\n\n\\(Q10\\), la sincronización de las entradas y salidas de los subtítulos: En los comentarios al subtitulado \\(A\\) hay algunos que dicen que hay falta de sincronización y, por el contrario, en el \\(B\\) que estaban bien sincronizados. Hay por tanto una falta de atención de algunos estudiantes para evaluar este aspecto del subtitulado.\n\n\nSubtitulado \\(A\\): ‘Van a destiempo’, ‘a veces hay retardo del texto sobre el audio’, ‘No me dado cuenta.’, ‘Estaban desincronizadas’.\n\n\nSubtitulado \\(B\\): ‘Regular.’, ‘Sincronizado’, ‘bastante sincronizados’, ‘va a la paz texto y lenguaje’, ‘Estaba bien sincronizado’, ‘Fallos corregidos’, ‘sincronizadas con el audio y la imagen’.\n\n\n\\(Q11\\), la velocidad de exposición de los subtítulos: Los comentarios al subtitulado \\(B\\) indican que muchos estudiantes no han tenido en cuenta que el subtítulo debe permanecer al menos tres segundos en la pantalla.\n\n\nSubtitulado \\(B\\): ‘Sincronizado.’, ‘me ha parecido un tiempo suficiente’, ‘los pude leer bien’, ‘Buen tiempo para la lectura’, ‘Se corresponde con los 12 caracteres por segundo’, ‘velocidad apropiada’, ‘Velocidad adequada para una buena lectura’.\n\n\n\\(Q12\\), el máximo número de caracteres por línea: Los comentarios denotan que en general los alumnos conocen el número máximo de caracteres por línea, pero que no se han detenido a medir cuántos hay realmente.\n\n\nSubtitulado \\(A\\): ‘No sobrepasa los 40 caracteres’.\n\n\nSubtitulado \\(B\\): ‘No pasa de 37’, ‘Se encuentran entre 12 y 37’.\n\nSe aprecia que los alumnos tienen dificultades para valorar las diferencias en la calidad del subtitulado en estos aspectos principalmente porque, aunque conozcan las normas de subtitulado, no han comprobado que se estén cumpliendo en los vídeos de la actividad.\n\n\n\n\n\n\nObjetivo específico\n\n\n\n¿Son los estudiantes capaces de valorar de forma similar los aspectos del subtitulado que no cambian en los vídeos?\n\n\nLos ítems en los que no se han introducido errores deberían ser valorados de forma similar por los estudiantes. En los modelos logísticos las probabilidades y frecuencias de estos ítems se muestran en la parte inferior de la tabla de la Figura 6.1 y en el modelo ordinal son las filas no resaltadas de la tabla de la Figura \\(\\ref{fig-prob-compare}\\). Se comprueba que los ítems \\(Q04\\) (el contraste entre los caracteres y el fondo) y \\(Q13\\) (la legibilidad de la tipografía) se valoran, como se esperaba, de forma positiva y similar en ambos subtitulados. Los ítems \\(Q01\\) (la posición de los subtítulos) y \\(Q03\\) (la disposición del texto respecto a la caja donde se muestran los subtítulos) se valoran positivamente en el subtitulado \\(A\\), pero en el subtitulado \\(B\\) hay una polarización de las valoraciones habiendo muchas positivas y negativas y pocas neutras. Por último, los ítems \\(Q15\\) (la utilización de puntos suspensivos), \\(Q16\\) (la escritura de los números) y \\(Q17\\) (las incorrecciones en el habla) tienen una valoración comparativamente inferior al resto de ítems en el subtitulado \\(A\\). Esta valoración es incluso inferior en el subtitulado \\(B\\). Los estudiantes que han realizado comentarios en estos ítems indican que ninguno de ellos es aplicable a los vídeos. Ante esta circunstancia, los alumnos han consignado distintas valoraciones: algunos han contestado “No sé / No contesto”, otros han consignado valoraciones neutrales y, finalmente, otros han optado por valoraciones positivas y negativas.\n\n\n\n\n\n\nObjetivo específico\n\n\n\nEfecto secuencia: ¿El orden en el que vieron los vídeos los estudiantes influye en la calidad del subtitulado percibida?\n\n\n\n\n\n\n\n\nObjetivo específico\n\n\n\nEfecto periodo: ¿La evaluación del subtitulado del segundo vídeo visto está influida por haber evaluado un vídeo previamente?\n\n\nEstos objetivos se responden de forma conjunta por estar ambos efectos relacionados ya que, como se ha explicado, el efecto secuencia en un estudio cruzado \\(AB/BA\\) es la interacción entre el tratamiento y el periodo.\nEn el modelo ordinal Response ~ Treat * Period (ver Sección 4.2.3.3) se constató que tanto el periodo como la secuencia son significativos. No obstante, estos efectos son mucho menos importantes que los debidos al subtitulado. Al introducir como variables explicativas el estudiante y el ítem (ver Sección 4.2.4) tanto el periodo como la secuencia pasan a ser no significativos. En la Sección 5.0.1 se comprobó que estos efectos se producen porque la proporción de respuestas de nivel 5 en el subtitulado \\(A\\) sobre el \\(B\\) es superior en el primer periodo que en el segundo y lo contrario ocurre con las de nivel 4. Se concluye que ni el efecto secuencia ni el efecto periodo son importantes al no tener significación estadística."
  },
  {
    "objectID": "5.html#limitaciones-del-estudio",
    "href": "5.html#limitaciones-del-estudio",
    "title": "5  Resultados",
    "section": "6.2 Limitaciones del estudio",
    "text": "6.2 Limitaciones del estudio\nAunque el estudio ha permitido responder a la pregunta de investigación, tiene una serie de limitaciones cuya eliminación permitiría ampliar su ámbito:\n\nLos datos proceden de un MOOC y la actividad fue voluntaria. Hay que suponer que solo los estudiantes más altamente motivados habrán participado en ella.\nEl diseño cruzado no requirió un tiempo de lavado (tiempo entre tratamientos) como es habitual en este tipo de diseños. A pesar de que se ha descartado que el efecto periodo o el efecto secuencia hayan tenido una influencia importante en las respuestas a los test, sería interesante controlar el tiempo entre test y asegurar que los participantes han visto ambos vídeos e incluso que, cuando contestan al test, revisan el vídeo en lugar de fiarse de su memoria.\nEn el Análisis Exploratorio (ver Sección 4.1) se constató que algunos estudiantes emplearon muy poco tiempo en responder a la actividad y que algunos estudiantes responden siempre con el mismo nivel de respuesta. Sería interesante realizar el estudio eliminando los test de calidad dudosa, para lo cual se debería contar con una muestra mayor.\nSería interesante comprobar si las respuestas son diferentes si el estudiante dispone del test antes de ver el vídeo.\nEn los comentarios de los alumnos se reflejan la existencia de problemas en el subtitulado \\(B\\) del ítem \\(Q01\\) (la posición de los subtítulos) y en subtitulado \\(A\\) del ítem \\(Q03\\) (la disposición del texto respecto a la caja donde se muestran los subtítulos). En estos ítems no debería haber deficiencias de subtitulado. Sería conveniente que un experto en subtitulado evaluara si realmente los subtítulos son correctos en estos aspectos o si es que no han sido evaluados adecuadamente por los estudiantes.\nSe ha constatado, a través de los comentarios de los alumnos, que no utilizan criterios homogéneos cuando un ítem no es aplicable a los vídeos. Algunos alumnos contestan “No sé / No contesto”, como es esperable, pero otros contestan “Neutral” y otros lo hacen negativa o positivamente. Sería deseable dar una información previa a los alumnos de cómo contestar al test.\nIgualmente se ha constatado que los estudiantes tienden a dar puntuaciones más negativas a los ítems cuando saben que se trata del vídeo incorrectamente subtitulado incluso en aquellos ítems en que los vídeos son idénticos.\nHay ítems, como los relacionados con la tipografía, la posición de los subtítulos o el contraste, en los que al ser los vídeos idénticos, no es posible saber si los estudiantes son capaces de reconocer diferencias en la calidad del subtitulado.\nSería interesante comparar las respuestas de los estudiantes con las realizadas por un grupo de expertos."
  },
  {
    "objectID": "5.html#footnotes",
    "href": "5.html#footnotes",
    "title": "5  Resultados",
    "section": "",
    "text": "Por problemas de convergencia, no se ha podido ajustar el modelo I(Level == “Positivo”) ~ Treat*Period + (1 + Treat | Subject) + (1 + Treat | Item)↩︎\nEstos comentarios se separaron en la fase de preprocesado y no se han utilizado ni consultado hasta la realización de este capítulo.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "AENOR. 2012. “UNE 153010 Subtitulado Para Personas Sordas y\nPersonas Con Discapacidad Auditiva.” Asociación Española de\nNormalización y Certificación.\n\n\nAgresti, Alan. 2010. Analysis of Ordinal Categorical Data. https://doi.org/10.1002/9780470594001.\n\n\n———. 2018. “An Introduction to Categorical Data Analysis, 3rd\nEdition.” Wiley.com. https://www.wiley.com/en-us/An+Introduction+to+Categorical+Data+Analysis%2C+3rd+Edition-p-9781119405283.\n\n\nBarreda S., Silbert N. 2023. Bayesian Multilevel Models for Repeated\nMeasures Data: A Conceptual and Practical Introduction in r. 1st\ned. Routledge. https://doi.org/10.4324/9781003285878.\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.\n“Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical\nSoftware 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBrant, Rollin. 1990. “Assessing Proportionality in the\nProportional Odds Model for Ordinal Logistic Regression.”\nBiometrics 46 (4): 1171–78. http://www.jstor.org/stable/2532457.\n\n\nBruin, J. 2011. “How Do i Interpret the Coefficients in an Ordinal\nLogistic Regression in r.” 2011. https://stats.oarc.ucla.edu/r/faq/ologit-coefficients.\n\n\nBürkner, Paul-Christian. 2021a. “Bayesian Item Response Modeling\nin R with brms and\nStan.” Journal of Statistical Software 100\n(5): 1–54. https://doi.org/10.18637/jss.v100.i05.\n\n\n———. 2021b. “Bayesian Item Response Modeling in r with Brms and\nStan.” Journal of Statistical Software 100 (November).\nhttps://doi.org/10.18637/jss.v100.i05.\n\n\nBürkner, Paul-Christian, and Matti Vuorre. 2019. “Ordinal\nRegression Models in Psychology: A Tutorial.” Advances in\nMethods and Practices in Psychological Science 2 (February):\n251524591882319. https://doi.org/10.1177/2515245918823199.\n\n\nChen, Ding-Geng, and Jenny Chen. 2021. Statistical Regression\nModeling with r: Longitudinal and Multi-Level Modeling. https://doi.org/10.1007/978-3-030-67583-7.\n\n\nChristensen, R. H. B. 2022. “Ordinal—Regression Models for Ordinal\nData.”\n\n\nChristensen, Rune Haubo Bojesen. 2018. “Cumulative Link Models for\nOrdinal Regression with the r Package Ordinal.” In.\n\n\nFriendly, Michael, David Meyer, and Achim Zeileis. 2015. Discrete\nData Analysis with r: Visualization and Modeling Techniques for\nCategorical and Count Data. Discrete Data Analysis with R:\nVisualization and Modeling Techniques for Categorical and Count\nData. https://doi.org/10.1201/b19022.\n\n\nGelman, Andrew, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and\nDonald Rubin. 2013. Bayesian Data Analysis. https://doi.org/10.1201/b16018.\n\n\nHarrell, F. 2020. “Violation of Proportional Odds Is Not\nFatal.” https://www.fharrell.com/post/po/.\n\n\nHarrell, Frank. 2015. Regression Modeling Strategies: With\nApplications to Linear Models, Logistic and Ordinal Regression, and\nSurvival Analysis. https://doi.org/10.1007/978-3-319-19425-7.\n\n\nKhafik, Muhammad, and Ikke Dewi Pratama. 2022. “Analyzing Errors\nin Students’ Subtitle Products.” ELE Reviews: English\nLanguage Education Reviews 2 (1): 59–73. https://doi.org/10.22515/elereviews.v2i1.5180.\n\n\nLawson, J. 2015. “Design and Analysis of Experiments with r (1st\nEd.).” Edited by Chapman and Hall/CRC. https://doi.org/10.1201/b17883.\n\n\nLiddell, Torrin M., and John K. Kruschke. 2018. “Analyzing Ordinal\nData with Metric Models: What Could Possibly Go Wrong?”\nJournal of Experimental Social Psychology 79: 328–48. https://doi.org/10.1016/j.jesp.2018.08.009.\n\n\nLim, Chi-Yeon, and Junyong In. 2021. “Considerations for Crossover\nDesign in Clinical Study.” Korean Journal of\nAnesthesiology 74 (July). https://doi.org/10.4097/kja.21165.\n\n\nLiu, Xing. 2022. Categorical Data Analysis and Multilevel Modeling\nUsing r. Edited by SAGE Publications Ltd.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Philip\nWaggoner, and Dominique Makowski. 2021. “performance: An R Package for\nAssessment, Comparison and Testing of Statistical Models.”\nJournal of Open Source Software 6 (60): 3139. https://doi.org/10.21105/joss.03139.\n\n\nLui, Kung-Jong. 2016. Crossover Designs: Testing, Estimation, and\nSample Size. Crossover Designs: Testing, Estimation, and Sample\nSize. https://doi.org/10.1002/9781119114710.\n\n\nMolanes-López, Elisa M., Alejandro Rodriguez-Ascaso, Emilio Letón, and\nJorge Pérez-Martín. 2021. “Assessment of Video Accessibility by\nStudents of a MOOC on Digital Materials for All.” IEEE\nAccess 9: 72357–67. https://doi.org/10.1109/ACCESS.2021.3079199.\n\n\nNicenboim Bruno, Vasishth Shravan, Schad Daniel. 2023. “An\nIntroduction to Bayesian Data Analysis for Cognitive Science.”\n2023. https://vasishth.github.io/bayescogsci/book/.\n\n\nParton, Becky Sue. 2016. “Video Captions for Online Courses: Do\nYouTube’s Auto-Generated Captions Meet Deaf Students’ Needs?”\nJournal of Open, Flexible and Distance Learning 20: 8–18.\n\n\nPérez Martín, Jorge, Alejandro Rodríguez-Ascaso, and Elisa\nMolanes-López. 2021. “Quality of the Captions Produced by Students\nof an Accessibility MOOC Using a Semi-Automatic Tool.”\nUniversal Access in the Information Society 20 (November). https://doi.org/10.1007/s10209-020-00740-9.\n\n\nSenn, Stephen. 2022. “Cross‐over Trials in Clinical\nResearch.” Edited by Ltd John Wiley. https://doi.org/10.1002/0470854596.\n\n\nTakagi, Hironobu, Shinya Kawanaka, Masatomo Kobayashi, Takashi Itoh, and\nChieko Asakawa. 2008. “Social Accessibility: Achieving\nAccessibility Through Collaborative Metadata Authoring.” In\nProceedings of the 10th International ACM SIGACCESS Conference on\nComputers and Accessibility, 193–200. Assets ’08. New York, NY,\nUSA: Association for Computing Machinery. https://doi.org/10.1145/1414471.1414507.\n\n\nTutz, Gerhard. 2020. “Hierarchical Models for the Analysis of\nLikert Scales in Regression and Item Response Analysis: Hierarchical\nModels.” International Statistical Review 89 (July). https://doi.org/10.1111/insr.12396.\n\n\nUebersax, John S. 2006. “Likert Scales: Dispelling the\nConfusion.” Statistical Methods for Rater Agreement\nWebsite. https://www.john-uebersax.com/stat/likert.htm.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics\nwith s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nW3C. 2018. “Web Content Accessibility Guidelines (WCAG)\n2.1.” https://www.w3.org/TR/WCAG21/.\n\n\nYee, T. W. 2023. VGAM: Vector Generalized Linear and\nAdditive Models. https://CRAN.R-project.org/package=VGAM.\n\n\nZeileis, Achim, David Meyer, and Kurt Hornik. 2007. “vcd: Residual-Based Shadings for Visualizing\n(Conditional) Independence.” Journal of Computational and\nGraphical Statistics 16 (3): 507–25. https://doi.org/10.1198/106186007X237856."
  },
  {
    "objectID": "77-Contrasts.html#preparación",
    "href": "77-Contrasts.html#preparación",
    "title": "Apéndice A — Efecto secuencia e interacción tratamiento vs. periodo",
    "section": "A.1 Preparación",
    "text": "A.1 Preparación\nPartiendo del siguiente conjunto de datos generado aleatoriamente 1: \n\nset.seed(100)\nn &lt;- 1000\ndf &lt;- data.frame(\n    Response = rnorm(n),\n    Treat = as.factor(sample(c(\"A\", \"B\"), n, replace = TRUE)),\n    Period = as.factor(sample(c(1, 2), n, replace = TRUE))\n)\n\ndf$Seq &lt;- as.factor(\n    ifelse(\n        df$Period == 1 & df$Treat == \"A\" | df$Period == 2 & df$Treat == \"B\",\n        \"AB\",\n        \"BA\"\n    )\n)\n\nhead(df, 10)\n\n      Response Treat Period Seq\n1  -0.50219235     B      2  AB\n2   0.13153117     A      1  AB\n3  -0.07891709     A      2  BA\n4   0.88678481     A      2  BA\n5   0.11697127     A      1  AB\n6   0.31863009     A      2  BA\n7  -0.58179068     A      2  BA\n8   0.71453271     A      1  AB\n9  -0.82525943     B      2  AB\n10 -0.35986213     B      1  BA\n\n\nSe calculan las medias por cada nivel de factor y combinaciones de niveles que luego serán utilizadas en la interpretación de los coeficientes de los modelos:\n\nM &lt;- mean(df$Response) # 1 media de respuesta global\n\n# 2 medias de respuesta para tratamientos A y B\nmTreat &lt;- with(df, tapply(Response, Treat, mean))\n\n# 2 medias de respuesta para periodos 1 y 2\nmPeriod &lt;- with(df, tapply(Response, Period, mean))\n\n# 2 medias de respuesta para secuencias AB y BA\nmSeq &lt;- with(df, tapply(Response, Seq, mean))\n\n# 4 medias de respuesta para las cuatro combinaciones de tratamiento y periodo\nm2 &lt;- with(df, tapply(Response, list(Treat, Period), mean))\n\ndTreat &lt;- diff(mTreat) # diferencia de medias entre tratamientos A y B\n\ndPeriod &lt;- diff(mPeriod) # diferencia de medias entre periodos 1 y 2\n\nd2 &lt;- diff(m2) # diferencias entre niveles de tratamiento en cada nivel de periodo"
  },
  {
    "objectID": "77-Contrasts.html#análisis-con-un-solo-factor-tratamiento",
    "href": "77-Contrasts.html#análisis-con-un-solo-factor-tratamiento",
    "title": "Apéndice A — Efecto secuencia e interacción tratamiento vs. periodo",
    "section": "A.2 Análisis con un solo factor (tratamiento)",
    "text": "A.2 Análisis con un solo factor (tratamiento)\n\nl1 &lt;- lm(Response ~ Treat, df)\ndata.frame(t(coef(l1))) %&gt;% gt()\n\n\n\n\n\nTabla A.1:  Ajuste del modelo Response ~ Treat con contrasts treatment. \n  \n    \n    \n      X.Intercept.\n      TreatB\n    \n  \n  \n    0.03624217\n-0.03966751\n  \n  \n  \n\n\n\n\n\nSe comprueba que el intercepto es la media de la respuesta en el nivel de tratamiento \\(A\\):\n\nmTreat[1]\n\n         A \n0.03624217 \n\n\ny que la pendiente (parámetro \\(TreatB\\)) es la diferencia entre las medias tratamientos:\n\ndTreat\n\n          B \n-0.03966751 \n\n\nPor ello, para conocer el efecto del tratamiento en el nivel \\(B\\) hay que sumar intercepto y pendiente:\n\ncoef(l1)[[1]] + coef(l1)[[2]] - mTreat[[2]]\n\n[1] 1.214306e-16\n\n\nEsto es así ya que por defecto R utiliza el contraste conocido como codificación de tratamiento:\n\ncontr.treatment(2)\n\n  2\n1 0\n2 1\n\n\nLa matriz ampliada añadiendo el intercepto siempre tendrá una columna de 1’s:\n\nmodel.matrix(~Treat, expand.grid(Treat = c(\"A\", \"B\")))\n\n  (Intercept) TreatB\n1           1      0\n2           1      1\nattr(,\"assign\")\n[1] 0 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$Treat\n[1] \"contr.treatment\"\n\n\nCada fila representa el nivel del tratamiento (fila 1 nivel \\(A\\) y fila 2 nivel \\(B\\)) y las columnas representan los parámetros del modelo. Los valores son los niveles de tratamiento (0 ó 1). Para obtener el significado de cada parámetro, se multiplica el valor del contraste por el parámetro. Así:\n\nEn la primera fila se comprueba que el efecto del tratamiento \\(A\\) es el intercepto: \\(A = 1 \\cdot Intercept + 0 \\cdot TreatB\\).\nEn la segunda fila permite comprobar que el valor del parámetro \\(TreatB\\) es la diferencia de los niveles de tratamiento. \\(B = 1 \\cdot Intercept + 1 \\cdot TreatB \\Rightarrow TreatB = B - Intercept\\).\n\nEsto quiere decir que existe una variable para codificar el efecto tratamiento, y esta variable tiene el valor 0 para el nivel \\(A\\) por ser el de referencia y 1 para el nivel \\(B\\). La pendiente se codifica como la diferencia del efecto de los dos niveles (\\(B - A\\))."
  },
  {
    "objectID": "77-Contrasts.html#análisis-con-un-dos-factores-tratamiento-y-periodo",
    "href": "77-Contrasts.html#análisis-con-un-dos-factores-tratamiento-y-periodo",
    "title": "Apéndice A — Efecto secuencia e interacción tratamiento vs. periodo",
    "section": "A.3 Análisis con un dos factores (tratamiento y periodo)",
    "text": "A.3 Análisis con un dos factores (tratamiento y periodo)\n\nl2 &lt;- lm(Response ~ Treat * Period, df)\ndata.frame(t(coef(l2))) %&gt;% gt()\n\n\n\n\n\nTabla A.2:  Ajuste del modelo Response ~ Treat * Period con contrasts\ntreatment. \n  \n    \n    \n      X.Intercept.\n      TreatB\n      Period2\n      TreatB.Period2\n    \n  \n  \n    0.04138614\n-0.1076137\n-0.01125933\n0.1343517\n  \n  \n  \n\n\n\n\n\nSe comprueba que el intercepto es la media del tratamiento \\(A\\) en el periodo \\(1\\) por ser estos los valores que R usa como referencia 2:\n\nm2[\"A\", \"1\"]\n\n[1] 0.04138614\n\n\nEl parámetro \\(TreatB\\) es la diferencia de medias entre los tratamientos en el periodo \\(1\\):\n\nm2[\"B\", \"1\"] - m2[\"A\", \"1\"]\n\n[1] -0.1076137\n\n\nEl parámetro \\(Period2\\) es la diferencia de medias entre los periodos en el nivel de tratamiento \\(A\\):\n\nm2[\"A\", \"2\"] - m2[\"A\", \"1\"]\n\n[1] -0.01125933\n\n\nFinalmente, \\(TreatB:Period2\\) es la diferencia entre el segundo periodo y el primero del nivel de tratamiento \\(B\\) menos la diferencia entre periodos del nivel de tratamiento \\(A\\):\n\nm2[\"B\", \"2\"] - m2[\"B\", \"1\"] - (m2[\"A\", \"2\"] - m2[\"A\", \"1\"])\n\n[1] 0.1343517\n\n\nLa matriz de contraste nos permite razonar por qué esto es así:\n\nmodel.matrix(~ Treat * Period, expand.grid(Treat = c(\"A\", \"B\"), Period = c(\"1\", \"2\")))\n\n  (Intercept) TreatB Period2 TreatB:Period2\n1           1      0       0              0\n2           1      1       0              0\n3           1      0       1              0\n4           1      1       1              1\nattr(,\"assign\")\n[1] 0 1 2 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$Treat\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$Period\n[1] \"contr.treatment\"\n\n\n\nLa primera fila es el intercepto y corresponde con el tratamiento \\(A\\) y el periodo 1.\nLa segunda fila es el efecto del tratamiento \\(B\\) en el periodo 1 y se calcula con la suma del intercepto y el parámetro \\(TreatB\\). Luego \\(TreatB\\) es la diferencia del efecto de los tratamientos en el periodo 1.\nAnálogamente con la tercera fila cse concluye que \\(Period2\\) es la deferencia entre periodos para el tratamiento \\(A\\).\nFinalmente, la cuarta fila, es el tratamiento \\(B\\) en el periodo 2 y, por lo tanto, \\(Treat2:Period2\\) es la diferencia el nivel \\(B\\) de tratamiento y el periodo 2 y el nivel de tratamiento \\(A\\) en el periodo 1, menos la diferencia de niveles de tratamiento para el periodo 1 y menos la diferencia de periodos para el tratamiento \\(A\\).\n\nObsérvese que antes se ha calculado de forma diferente \\(TreatB:Period2\\). Aplicando la fórmula anterior y se comprueba que produce el mismo resultado:\n\nm2[\"B\", \"2\"] - m2[\"A\", \"1\"] - (m2[\"B\", \"1\"] - m2[\"A\", \"1\"]) - (m2[\"A\", \"2\"] - m2[\"A\", \"1\"])\n\n[1] 0.1343517"
  },
  {
    "objectID": "77-Contrasts.html#factor-secuencia",
    "href": "77-Contrasts.html#factor-secuencia",
    "title": "Apéndice A — Efecto secuencia e interacción tratamiento vs. periodo",
    "section": "A.4 Factor secuencia",
    "text": "A.4 Factor secuencia\nSe incorpora la secuencia como factor para ver si es equivalente a la interacción entre periodo y tratamiento. En caso de serlo los coeficientes del modelo ajustado deberían coincidir. Sin embargo se constata que los modelos l2 (Tabla A.2) y l3 (Tabla A.3) tienen distintos coeficientes.\n\nl3 &lt;- lm(Response ~ Treat + Period + Seq, df)\ndata.frame(t(coef(l3))) %&gt;% gt()\n\n\n\n\n\nTabla A.3:  Ajuste del modelo Response ~ Treat + Period + Seq con contrasts\ntreatment. \n  \n    \n    \n      X.Intercept.\n      TreatB\n      Period2\n      SeqBA\n    \n  \n  \n    0.04138614\n-0.04043786\n0.05591654\n-0.06717587\n  \n  \n  \n\n\n\n\n\nLos coeficientes no coinciden debido a que se está usando el contraste con codificación de tratamientos. Pero si se cambia a codificación de sumas:\n\noptions(contrasts = rep(\"contr.sum\", 2))\n\nY se vuelven a ajustar los modelos (que ya usarán el contraste suma), se comprueba que ahora tienen los mismos coeficientes y el coeficiente \\(Seq1\\) del modelo que incorpora el efecto secuencia (Tabla A.4) es igual que el coeficiente \\(Treat1:Period1\\) del modelo que incorpora la interacción entre tratamiento y periodo (Tabla A.5). Obsérvese que los nombres de los coeficientes han cambiado respecto al contraste de tratamiento. Esto sucede porque la interpretación de los coeficientes varía como se explica a continuación.\n\nl4 &lt;- lm(Response ~ Treat + Period + Seq, df)\ndata.frame(t(coef(l4))) %&gt;% gt()\n\n\n\n\n\nTabla A.4:  Ajuste del modelo Response ~ Treat + Period + Seq con contrasts\nsum. \n  \n    \n    \n      X.Intercept.\n      Treat1\n      Period1\n      Seq1\n    \n  \n  \n    0.01553755\n0.02021893\n-0.02795827\n0.03358794\n  \n  \n  \n\n\n\n\n\n\nl5 &lt;- lm(Response ~ Treat * Period, df)\ndata.frame(t(coef(l5))) %&gt;% gt()\n\n\n\n\n\nTabla A.5:  Ajuste del modelo Response ~ Treat * Period con contrasts sum. \n  \n    \n    \n      X.Intercept.\n      Treat1\n      Period1\n      Treat1.Period1\n    \n  \n  \n    0.01553755\n0.02021893\n-0.02795827\n0.03358794\n  \n  \n  \n\n\n\n\n\nLa interpretación de los coeficientes es diferente. Para explicarlo, se muestra la matriz de contraste:\n\nmodel.matrix(~ Treat * Period, expand.grid(Treat = c(\"A\", \"B\"), Period = c(\"1\", \"2\")))\n\n  (Intercept) Treat1 Period1 Treat1:Period1\n1           1      1       1              1\n2           1     -1       1             -1\n3           1      1      -1             -1\n4           1     -1      -1              1\nattr(,\"assign\")\n[1] 0 1 2 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$Treat\n[1] \"contr.sum\"\n\nattr(,\"contrasts\")$Period\n[1] \"contr.sum\"\n\n\nAhora los niveles son 1 y -1 3 en vez de 0 y 1 que se utilizan en el contraste de tratamiento. La interpretación es la siguiente:\n\nEl intercepto es la media de la media de cada uno de los niveles de factor. ¿Por qué?. El intercepto es el valor de la variable de respuesta cuando cuando todas las variables explicativas valen 0. Esto sucede en la media de la variable de respuesta ya que cero es el valor que está en la mitad de +1 y -1. Se comprueba que la media global coincide con el intercepto del modelo l4 (Tabla A.4):\n\n\nmean(m2)\n\n[1] 0.01553755\n\n\n\nEl coeficiente \\(Treat1\\) es la mitad la diferencia de la media entre niveles de tratamiento (\\(TreatA-TreatB\\)). La media de cada tratamiento se calcula como la media del tratamiento en cada periodo.\n\n\n-diff(apply(m2, 1, mean)) / 2\n\n         B \n0.02021893 \n\n\nOtra forma de entender el coeficiente \\(Treat1\\) es como la cuarta parte de la diferencia de los efectos de los tratamientos en cada periodo.\n\n(m2[\"A\", \"1\"] + m2[\"A\", \"2\"] - (m2[\"B\", \"1\"] + m2[\"B\", \"2\"])) / 4\n\n[1] 0.02021893\n\n\n\nEl coeficiente \\(Period1\\) es la mitad la diferencia de la media entre periodos(\\(Period1 - Period2\\)). La media entre periodos se calcula como la media del periodo para cada tratamiento.\n\n\n-diff(apply(m2, 2, mean)) / 2\n\n          2 \n-0.02795827 \n\n\nOtra forma de entender el coeficiente \\(Period1\\) es como la cuarta parte de la diferencia de los efectos del periodo en cada tratamiento.\n\n(m2[\"A\", \"1\"] + m2[\"B\", \"1\"] - (m2[\"A\", \"2\"] + m2[\"B\", \"2\"])) / 4\n\n[1] -0.02795827\n\n\n\nEl coeficiente \\(Treat1:Period1\\) es el coeficiente \\(Treat1\\) menos la mitad de la diferencia de la media entre tratamientos para el periodo 2 (\\(TreatA-TreatB\\)):\n\n\n-diff(apply(m2, 1, mean)) / 2 + diff(m2[, \"2\"]) / 2\n\n         B \n0.03358794 \n\ncoef(l5)[2] + diff(m2[, \"2\"]) / 2\n\n    Treat1 \n0.03358794 \n\n\nEl coeficiente \\(Treat1:Period1\\) también se puede calcular como \\(Period1\\) menos la mitad de la diferencia de la media entre periodos para el para el tratamiento \\(B\\) (\\(Period1-Period2\\)):\n\n-diff(apply(m2, 2, mean)) / 2 + diff(m2[\"B\", ]) / 2\n\n         2 \n0.03358794 \n\ncoef(l5)[3] + diff(m2[\"B\", ]) / 2\n\n   Period1 \n0.03358794 \n\n\nUn tercera forma de interpretar el coeficiente \\(Treat1:Period1\\) es como la cuarta parte de la suma de la diferencia cruzada del efecto de cada tratamiento en cada periodo:\n\n(m2[\"A\", \"1\"] - m2[\"A\", \"2\"] + m2[\"B\", \"2\"] - m2[\"B\", \"1\"]) / 4\n\n[1] 0.03358794\n\n\nO reorganizando los términos de otra forma, sería la cuarta parte de la suma de la diferencia cruzada del efecto de cada periodo en cada tratamiento:\n\n(m2[\"B\", \"2\"] - m2[\"A\", \"2\"] + m2[\"A\", \"1\"] - m2[\"B\", \"1\"]) / 4\n\n[1] 0.03358794\n\n\n\nSe puede obtener el coeficiente \\(TreatB\\) del modelo \\(l2\\) (Tabla A.2) como \\(-2 \\cdot (Treat1 + Treat1:Period1)\\):\n\n\n-2 * (coef(l5)[\"Treat1\"] + coef(l5)[\"Treat1:Period1\"])\n\n    Treat1 \n-0.1076137 \n\n\n\nAnálogamente el coeficiente \\(Period2\\) del modelo \\(l2\\) (Tabla A.2) se obtiene \\(-2 \\cdot (Period1 + Treat1:Period1)\\):\n\n\n-2 * (coef(l5)[\"Period1\"] + coef(l5)[\"Treat1:Period1\"])\n\n    Period1 \n-0.01125933 \n\n\n\nEl coeficiente \\(TreatB:Period2\\) se obtiene como \\(4 \\cdot Treat1:Period1\\):\n\n\n4 * (coef(l5)[\"Treat1:Period1\"])\n\nTreat1:Period1 \n     0.1343517"
  },
  {
    "objectID": "77-Contrasts.html#resumen-de-modelos-y-equivalencias-de-parámetros",
    "href": "77-Contrasts.html#resumen-de-modelos-y-equivalencias-de-parámetros",
    "title": "Apéndice A — Efecto secuencia e interacción tratamiento vs. periodo",
    "section": "A.5 Resumen de modelos y equivalencias de parámetros",
    "text": "A.5 Resumen de modelos y equivalencias de parámetros\nEn la Tabla \\(\\ref{tbl-contrasts-compare}\\) se muestran las equivalencias de los coeficientes de cada modelo. Todas las filas de la misma columna corresponden a un determinado nivel para cada factor y la fórmula mostrada es el modelo resultante teniendo en cuenta que:\n\nEn el contraste treatment se utiliza como referencia el primer nivel de cada factor, que corresponderá con el intercepto; los coeficientes se denominan \\((Intercept)\\), \\(TreatB\\), \\(Period2\\) y \\(SeqBA\\) y son la diferencia del nivel que representa cada coeficiente con el intercepto; y los valores de cada nivel de factor son: \\(TreatA = 0\\), \\(TreatB = 1\\), \\(Period1 = 0\\), \\(Period2 = 1\\), \\(SeqAB = 0\\), \\(SeqBA = 1\\).\nEn el contraste sum, el intercepto es el valor medio y se excluye elcoeficiente del último nivel que se calcula como la suma del resto de niveles con signo opuesto 4; los coeficientes se denominan \\((Intercept)\\), \\(Treat1\\), \\(Period1\\) y \\(Seq1\\); y los valores de cada nivel de factor son:\\(TreatA = 1\\), \\(TreatB = -1\\), \\(Period1 = 1\\), \\(Period2 = -1\\), \\(SeqAB = 1\\), \\(SeqBA = -1\\)."
  },
  {
    "objectID": "77-Contrasts.html#footnotes",
    "href": "77-Contrasts.html#footnotes",
    "title": "Apéndice A — Efecto secuencia e interacción tratamiento vs. periodo",
    "section": "",
    "text": "Obsérvese que la variable Response en esta simulación es cuantitativa y no ordinal. Se ha realizado de esta forma para poder usar un ajuste de mínimos cuadrados en lugar de una regresión ordinal para facilitar el cálculo y su interpretación.↩︎\nR utiliza como valor de referencia el nivel más bajo de factor.↩︎\nEl nivel de referencia del factor tendrá valor 1 y el otro -1. Por ejemplo, en la variable Treat, \\(A\\) tendrá +1 y \\(B\\) tendrá valor -1.↩︎\nComo en este caso solo hay dos niveles en cada factor, el valor del segundo nivel será simplemente el opuesto del primer nivel.↩︎"
  }
]